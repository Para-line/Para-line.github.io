

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=dark>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/avatar.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Paraline">
  <meta name="keywords" content="">
  
    <meta name="description" content="cp_dataset.py 12345678910111213141516171819202122232425262728293031323334353637class CPDataset(data.Dataset):    &quot;&quot;&quot;        Dataset for CP-VTON.    &quot;&quot;&quot;    def __init__(se">
<meta property="og:type" content="article">
<meta property="og:title" content="HR-VITON代码笔记">
<meta property="og:url" content="https://blog.paraline.top/posts/hr-viton%E4%BB%A3%E7%A0%81%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="Paraline&#39;s Blog">
<meta property="og:description" content="cp_dataset.py 12345678910111213141516171819202122232425262728293031323334353637class CPDataset(data.Dataset):    &quot;&quot;&quot;        Dataset for CP-VTON.    &quot;&quot;&quot;    def __init__(se">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s2.loli.net/2024/05/04/9VWb7hZNxDGmeTj.png">
<meta property="og:image" content="https://s2.loli.net/2024/05/04/63AHx2J4MdfXzm7.jpg">
<meta property="og:image" content="https://s2.loli.net/2024/05/04/5IJfjAKRQEx8wU9.png">
<meta property="og:image" content="https://s2.loli.net/2024/05/04/1zBHFVmKOcAR4uN.png">
<meta property="og:image" content="https://s2.loli.net/2024/05/04/1zBHFVmKOcAR4uN.png">
<meta property="article:published_time" content="2024-05-06T14:17:00.000Z">
<meta property="article:modified_time" content="2024-05-27T12:22:55.068Z">
<meta property="article:author" content="Paraline">
<meta property="article:tag" content="VITON">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://s2.loli.net/2024/05/04/9VWb7hZNxDGmeTj.png">
  
  
  
  <title>HR-VITON代码笔记 - Paraline&#39;s Blog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  



  
<link rel="stylesheet" href="/css/paraline.css">
<link rel="stylesheet" href="/css/code.css">



  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"blog.paraline.top","root":"/","version":"1.9.5-a","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":"ynQw6Q7W2fOzEYRv4F6NsdZN-gzGzoHsz","app_key":"JWtWrXxjhx0fquDKEm4Zuz6H","server_url":"https://ynqw6q7w.lc-cn-n1-shared.com","path":"window.location.pathname","ignore_local":true}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  
    <!-- Google tag (gtag.js) -->
    <script async>
      if (!Fluid.ctx.dnt) {
        Fluid.utils.createScript("https://www.googletagmanager.com/gtag/js?id=", function() {
          window.dataLayer = window.dataLayer || [];
          function gtag() {
            dataLayer.push(arguments);
          }
          gtag('js', new Date());
          gtag('config', '');
        });
      }
    </script>
  

  

  

  

  
    
  



  
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
  <div id="web_bg"></div>

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Paraline&#39;s Blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('https://s2.loli.net/2023/08/03/KPgQDnv7y9rV2Ml.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="HR-VITON代码笔记"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-05-06 14:17" pubdate>
          2024/05/06 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          48k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          <!-- compatible with older versions-->
          预计阅读时长：400 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">HR-VITON代码笔记</h1>
            
              <p class="note note-info">
                
                  
                    本文最后更新于：2024年5月27日 中午
                  
                
              </p>
            
            
              <div class="markdown-body">
                
                <h1 id="cp_dataset.py">cp_dataset.py</h1>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">CPDataset</span>(data.Dataset):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        Dataset for CP-VTON.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, opt</span>):<br>        <span class="hljs-built_in">super</span>(CPDataset, self).__init__()<br>        <span class="hljs-comment"># base setting</span><br>        self.opt = opt<br>        self.root = opt.dataroot<br>        self.datamode = opt.datamode <span class="hljs-comment"># train or test or self-defined</span><br>        self.data_list = opt.data_list<br>        self.fine_height = opt.fine_height<br>        self.fine_width = opt.fine_width<br>        self.semantic_nc = opt.semantic_nc<br>        self.data_path = osp.join(opt.dataroot, opt.datamode)<br>        self.transform = transforms.Compose([  \<br>                transforms.ToTensor(),   \<br>                transforms.Normalize((<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>), (<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>))])<br><br>        <span class="hljs-comment"># load data list</span><br>        im_names = []<br>        c_names = []<br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(osp.join(opt.dataroot, opt.data_list), <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>            <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> f.readlines():<br>                im_name, c_name = line.strip().split()<br>                im_names.append(im_name)<br>                c_names.append(c_name)<br><br>        self.im_names = im_names<br>        self.c_names = <span class="hljs-built_in">dict</span>()<br>        self.c_names[<span class="hljs-string">&#x27;paired&#x27;</span>] = im_names<br>        self.c_names[<span class="hljs-string">&#x27;unpaired&#x27;</span>] = c_names<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">name</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;CPDataset&quot;</span><br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_agnostic</span>(<span class="hljs-params">self, im, im_parse, pose_data</span>)<br></code></pre></td></tr></table></figure>
<p>前面这些部分都和VITON-HD差不多。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, index</span>):<br>       im_name = self.im_names[index]<br>       im_name = <span class="hljs-string">&#x27;image/&#x27;</span> + im_name<br>       c_name = &#123;&#125;<br>       c = &#123;&#125;<br>       cm = &#123;&#125;<br>       <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> [<span class="hljs-string">&#x27;paired&#x27;</span>]:<br>           c_name[key] = self.c_names[key][index]<br>           c[key] = Image.<span class="hljs-built_in">open</span>(osp.join(self.data_path, <span class="hljs-string">&#x27;cloth&#x27;</span>, c_name[key])).convert(<span class="hljs-string">&#x27;RGB&#x27;</span>)<br>           c[key] = transforms.Resize(self.fine_width, interpolation=<span class="hljs-number">2</span>)(c[key])<br>           cm[key] = Image.<span class="hljs-built_in">open</span>(osp.join(self.data_path, <span class="hljs-string">&#x27;cloth-mask&#x27;</span>, c_name[key]))<br>           cm[key] = transforms.Resize(self.fine_width, interpolation=<span class="hljs-number">0</span>)(cm[key])<br><br>           c[key] = self.transform(c[key])  <span class="hljs-comment"># [-1,1]</span><br>           cm_array = np.array(cm[key])<br>           cm_array = (cm_array &gt;= <span class="hljs-number">128</span>).astype(np.float32)<br>           cm[key] = torch.from_numpy(cm_array)  <span class="hljs-comment"># [0,1]</span><br>           cm[key].unsqueeze_(<span class="hljs-number">0</span>)<br><br></code></pre></td></tr></table></figure>
<p>这里和VITON-HD一样，都是把衣服的图片和衣服掩码的图片加载出来，缩放至合适的大小。把衣服的图片进行标准化并且转化为tensor。并把衣服掩码转化为0，1的二值数组，也变成tensor。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># person image</span><br>im_pil_big = Image.<span class="hljs-built_in">open</span>(osp.join(self.data_path, im_name))<br>im_pil = transforms.Resize(self.fine_width, interpolation=<span class="hljs-number">2</span>)(im_pil_big)<br>im = self.transform(im_pil)<br><br><span class="hljs-comment"># load parsing image</span><br>parse_name = im_name.replace(<span class="hljs-string">&#x27;image&#x27;</span>, <span class="hljs-string">&#x27;image-parse-v3&#x27;</span>).replace(<span class="hljs-string">&#x27;.jpg&#x27;</span>, <span class="hljs-string">&#x27;.png&#x27;</span>)<br>im_parse_pil_big = Image.<span class="hljs-built_in">open</span>(osp.join(self.data_path, parse_name))<br>im_parse_pil = transforms.Resize(self.fine_width, interpolation=<span class="hljs-number">0</span>)(im_parse_pil_big)<br>parse = torch.from_numpy(np.array(im_parse_pil)[<span class="hljs-literal">None</span>]).long()<br>im_parse = self.transform(im_parse_pil.convert(<span class="hljs-string">&#x27;RGB&#x27;</span>))<br></code></pre></td></tr></table></figure>
<p>这里就是分别加载人物的图片和segmentation map。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># parse map</span><br>      labels = &#123;<br>          <span class="hljs-number">0</span>:  [<span class="hljs-string">&#x27;background&#x27;</span>,  [<span class="hljs-number">0</span>, <span class="hljs-number">10</span>]],<br>          <span class="hljs-number">1</span>:  [<span class="hljs-string">&#x27;hair&#x27;</span>,        [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>]],<br>          <span class="hljs-number">2</span>:  [<span class="hljs-string">&#x27;face&#x27;</span>,        [<span class="hljs-number">4</span>, <span class="hljs-number">13</span>]],<br>          <span class="hljs-number">3</span>:  [<span class="hljs-string">&#x27;upper&#x27;</span>,       [<span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>]],<br>          <span class="hljs-number">4</span>:  [<span class="hljs-string">&#x27;bottom&#x27;</span>,      [<span class="hljs-number">9</span>, <span class="hljs-number">12</span>]],<br>          <span class="hljs-number">5</span>:  [<span class="hljs-string">&#x27;left_arm&#x27;</span>,    [<span class="hljs-number">14</span>]],<br>          <span class="hljs-number">6</span>:  [<span class="hljs-string">&#x27;right_arm&#x27;</span>,   [<span class="hljs-number">15</span>]],<br>          <span class="hljs-number">7</span>:  [<span class="hljs-string">&#x27;left_leg&#x27;</span>,    [<span class="hljs-number">16</span>]],<br>          <span class="hljs-number">8</span>:  [<span class="hljs-string">&#x27;right_leg&#x27;</span>,   [<span class="hljs-number">17</span>]],<br>          <span class="hljs-number">9</span>:  [<span class="hljs-string">&#x27;left_shoe&#x27;</span>,   [<span class="hljs-number">18</span>]],<br>          <span class="hljs-number">10</span>: [<span class="hljs-string">&#x27;right_shoe&#x27;</span>,  [<span class="hljs-number">19</span>]],<br>          <span class="hljs-number">11</span>: [<span class="hljs-string">&#x27;socks&#x27;</span>,       [<span class="hljs-number">8</span>]],<br>          <span class="hljs-number">12</span>: [<span class="hljs-string">&#x27;noise&#x27;</span>,       [<span class="hljs-number">3</span>, <span class="hljs-number">11</span>]]<br>      &#125;<br>      <br>      parse_map = torch.FloatTensor(<span class="hljs-number">20</span>, self.fine_height, self.fine_width).zero_()<br>      parse_map = parse_map.scatter_(<span class="hljs-number">0</span>, parse, <span class="hljs-number">1.0</span>)<br>      new_parse_map = torch.FloatTensor(self.semantic_nc, self.fine_height, self.fine_width).zero_()<br><br>      <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(labels)):<br>          <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> labels[i][<span class="hljs-number">1</span>]:<br>              new_parse_map[i] += parse_map[label]<br>              <br>      parse_onehot = torch.FloatTensor(<span class="hljs-number">1</span>, self.fine_height, self.fine_width).zero_()<br>      <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(labels)):<br>          <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> labels[i][<span class="hljs-number">1</span>]:<br>              parse_onehot[<span class="hljs-number">0</span>] += parse_map[label] * i<br></code></pre></td></tr></table></figure>
<p>这里也是和VITON-HD做了相同的操作，先把segmentation map根据label分成20个channel，再把一些label合并起来，根据新的label又合并一些channel。并”更新“segmentation map。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># load image-parse-agnostic</span><br>image_parse_agnostic = Image.<span class="hljs-built_in">open</span>(osp.join(self.data_path, parse_name.replace(<span class="hljs-string">&#x27;image-parse-v3&#x27;</span>, <span class="hljs-string">&#x27;image-parse-agnostic-v3.2&#x27;</span>)))<br>image_parse_agnostic = transforms.Resize(self.fine_width, interpolation=<span class="hljs-number">0</span>)(image_parse_agnostic)<br>parse_agnostic = torch.from_numpy(np.array(image_parse_agnostic)[<span class="hljs-literal">None</span>]).long()<br>image_parse_agnostic = self.transform(image_parse_agnostic.convert(<span class="hljs-string">&#x27;RGB&#x27;</span>))<br><br>parse_agnostic_map = torch.FloatTensor(<span class="hljs-number">20</span>, self.fine_height, self.fine_width).zero_()<br>parse_agnostic_map = parse_agnostic_map.scatter_(<span class="hljs-number">0</span>, parse_agnostic, <span class="hljs-number">1.0</span>)<br>new_parse_agnostic_map = torch.FloatTensor(self.semantic_nc, self.fine_height, self.fine_width).zero_()<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(labels)):<br>    <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> labels[i][<span class="hljs-number">1</span>]:<br>        new_parse_agnostic_map[i] += parse_agnostic_map[label]        <br></code></pre></td></tr></table></figure>
<p>这里原文说：For the clothing-agnostic person representation, we employ a clothing-agnostic person image <span class="math inline">\(I_{a}\)</span> and a clothing-agnostic segmentation map <span class="math inline">\(S_{a}\)</span> as those of VITON-HD. 所以HR-VITON就直接调用VITON-HD处理好的图片。</p>
<p>这里的image_parse_agnostic就是原图的segmentation map，然后做一点点的变换。这里的parse_agnostic_map其实就是跟之前的parse_one_hot差不多，只是这里的parse_agnostic_map值只是0或1，并且已经是消除了衣服的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># parse cloth &amp; parse cloth mask</span><br>pcm = new_parse_map[<span class="hljs-number">3</span>:<span class="hljs-number">4</span>]<br>im_c = im * pcm + (<span class="hljs-number">1</span> - pcm)<br><br><span class="hljs-comment"># load pose points</span><br>pose_name = im_name.replace(<span class="hljs-string">&#x27;image&#x27;</span>, <span class="hljs-string">&#x27;openpose_img&#x27;</span>).replace(<span class="hljs-string">&#x27;.jpg&#x27;</span>, <span class="hljs-string">&#x27;_rendered.png&#x27;</span>)<br>pose_map = Image.<span class="hljs-built_in">open</span>(osp.join(self.data_path, pose_name))<br>pose_map = transforms.Resize(self.fine_width, interpolation=<span class="hljs-number">2</span>)(pose_map)<br>pose_map = self.transform(pose_map)  <span class="hljs-comment"># [-1,1]</span><br><br><span class="hljs-comment"># pose name</span><br>pose_name = im_name.replace(<span class="hljs-string">&#x27;image&#x27;</span>, <span class="hljs-string">&#x27;openpose_json&#x27;</span>).replace(<span class="hljs-string">&#x27;.jpg&#x27;</span>, <span class="hljs-string">&#x27;_keypoints.json&#x27;</span>)<br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(osp.join(self.data_path, pose_name), <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    pose_label = json.load(f)<br>    pose_data = pose_label[<span class="hljs-string">&#x27;people&#x27;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&#x27;pose_keypoints_2d&#x27;</span>]<br>    pose_data = np.array(pose_data)<br>    pose_data = pose_data.reshape((-<span class="hljs-number">1</span>, <span class="hljs-number">3</span>))[:, :<span class="hljs-number">2</span>]<br></code></pre></td></tr></table></figure>
<p>im_c是原图上的clothes mask。</p>
<p>pose这里也用的是和VITON-HD一样的。</p>
<p>pose_map是这样的图片</p>
<figure>
<img src="https://s2.loli.net/2024/05/04/9VWb7hZNxDGmeTj.png" srcset="/img/loading.gif" lazyload alt="" /><figcaption>00026_00_rendered.png</figcaption>
</figure>
<p>pose_data就是包含关键点坐标的json文件。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># load densepose</span><br>densepose_name = im_name.replace(<span class="hljs-string">&#x27;image&#x27;</span>, <span class="hljs-string">&#x27;image-densepose&#x27;</span>)<br>densepose_map = Image.<span class="hljs-built_in">open</span>(osp.join(self.data_path, densepose_name))<br>densepose_map = transforms.Resize(self.fine_width, interpolation=<span class="hljs-number">2</span>)(densepose_map)<br>densepose_map = self.transform(densepose_map)  <span class="hljs-comment"># [-1,1]</span><br><br><span class="hljs-comment"># agnostic</span><br>agnostic = self.get_agnostic(im_pil_big, im_parse_pil_big, pose_data)<br>agnostic = transforms.Resize(self.fine_width, interpolation=<span class="hljs-number">2</span>)(agnostic)<br>agnostic = self.transform(agnostic)<br></code></pre></td></tr></table></figure>
<p>densepose的图片是这样的</p>
<figure>
<img src="https://s2.loli.net/2024/05/04/63AHx2J4MdfXzm7.jpg" srcset="/img/loading.gif" lazyload alt="" /><figcaption>00026_00.jpg</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python">result = &#123;<br>    <span class="hljs-string">&#x27;c_name&#x27;</span>:   c_name,     <span class="hljs-comment"># for visualization</span><br>    <span class="hljs-string">&#x27;im_name&#x27;</span>:  im_name,    <span class="hljs-comment"># for visualization or ground truth</span><br>    <span class="hljs-comment"># intput 1 (clothfloww)</span><br>    <span class="hljs-string">&#x27;cloth&#x27;</span>:    c,          <span class="hljs-comment"># for input</span><br>    <span class="hljs-string">&#x27;cloth_mask&#x27;</span>:     cm,   <span class="hljs-comment"># for input</span><br>    <span class="hljs-comment"># intput 2 (segnet)</span><br>    <span class="hljs-string">&#x27;parse_agnostic&#x27;</span>: new_parse_agnostic_map,<br>    <span class="hljs-string">&#x27;densepose&#x27;</span>: densepose_map,<br>    <span class="hljs-string">&#x27;pose&#x27;</span>: pose_map,       <span class="hljs-comment"># for conditioning</span><br>    <span class="hljs-comment"># generator input</span><br>    <span class="hljs-string">&#x27;agnostic&#x27;</span> : agnostic,<br>    <span class="hljs-comment"># GT</span><br>    <span class="hljs-string">&#x27;parse_onehot&#x27;</span> : parse_onehot,  <span class="hljs-comment"># Cross Entropy</span><br>    <span class="hljs-string">&#x27;parse&#x27;</span>: new_parse_map, <span class="hljs-comment"># GAN Loss real</span><br>    <span class="hljs-string">&#x27;pcm&#x27;</span>: pcm,             <span class="hljs-comment"># L1 Loss &amp; vis</span><br>    <span class="hljs-string">&#x27;parse_cloth&#x27;</span>: im_c,    <span class="hljs-comment"># VGG Loss &amp; vis</span><br>    <span class="hljs-comment"># visualization &amp; GT</span><br>    <span class="hljs-string">&#x27;image&#x27;</span>:    im,         <span class="hljs-comment"># for visualization</span><br>    &#125;<br><br><span class="hljs-keyword">return</span> result<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">CPDataLoader</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, opt, dataset</span>):<br>        <span class="hljs-built_in">super</span>(CPDataLoader, self).__init__()<br><br>        <span class="hljs-keyword">if</span> opt.shuffle :<br>            train_sampler = torch.utils.data.sampler.RandomSampler(dataset)<br>        <span class="hljs-keyword">else</span>:<br>            train_sampler = <span class="hljs-literal">None</span><br><br>        self.data_loader = torch.utils.data.DataLoader(<br>                dataset, batch_size=opt.batch_size, shuffle=(train_sampler <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>),<br>                num_workers=opt.workers, pin_memory=<span class="hljs-literal">True</span>, drop_last=<span class="hljs-literal">True</span>, sampler=train_sampler)<br>        self.dataset = dataset<br>        self.data_iter = self.data_loader.__iter__()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">next_batch</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">try</span>:<br>            batch = self.data_iter.__next__()<br>        <span class="hljs-keyword">except</span> StopIteration:<br>            self.data_iter = self.data_loader.__iter__()<br>            batch = self.data_iter.__next__()<br><br>        <span class="hljs-keyword">return</span> batch<br></code></pre></td></tr></table></figure>
<p>然后这里也跟VITON-HD一样，这就是一个对batch进行抽样的类。</p>
<h1 id="get_parse_agnostic.py">get_parse_agnostic.py</h1>
<p>这里还专门定义了一个文件实现VITON-HD中的get_parse_agnostic函数。代码贴在这里，好像并没有什么特别的东西。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">from</span> os <span class="hljs-keyword">import</span> path <span class="hljs-keyword">as</span> osp<br><span class="hljs-keyword">import</span> os<br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image, ImageDraw<br><br><span class="hljs-keyword">import</span> argparse<br><br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_im_parse_agnostic</span>(<span class="hljs-params">im_parse, pose_data, w=<span class="hljs-number">768</span>, h=<span class="hljs-number">1024</span></span>):<br>    parse_array = np.array(im_parse)<br>    parse_upper = ((parse_array == <span class="hljs-number">5</span>).astype(np.float32) +<br>                    (parse_array == <span class="hljs-number">6</span>).astype(np.float32) +<br>                    (parse_array == <span class="hljs-number">7</span>).astype(np.float32))<br>    parse_neck = (parse_array == <span class="hljs-number">10</span>).astype(np.float32)<br><br>    r = <span class="hljs-number">10</span><br>    agnostic = im_parse.copy()<br><br>    <span class="hljs-comment"># mask arms</span><br>    <span class="hljs-keyword">for</span> parse_id, pose_ids <span class="hljs-keyword">in</span> [(<span class="hljs-number">14</span>, [<span class="hljs-number">2</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>]), (<span class="hljs-number">15</span>, [<span class="hljs-number">5</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>])]:<br>        mask_arm = Image.new(<span class="hljs-string">&#x27;L&#x27;</span>, (w, h), <span class="hljs-string">&#x27;black&#x27;</span>)<br>        mask_arm_draw = ImageDraw.Draw(mask_arm)<br>        i_prev = pose_ids[<span class="hljs-number">0</span>]<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> pose_ids[<span class="hljs-number">1</span>:]:<br>            <span class="hljs-keyword">if</span> (pose_data[i_prev, <span class="hljs-number">0</span>] == <span class="hljs-number">0.0</span> <span class="hljs-keyword">and</span> pose_data[i_prev, <span class="hljs-number">1</span>] == <span class="hljs-number">0.0</span>) <span class="hljs-keyword">or</span> (pose_data[i, <span class="hljs-number">0</span>] == <span class="hljs-number">0.0</span> <span class="hljs-keyword">and</span> pose_data[i, <span class="hljs-number">1</span>] == <span class="hljs-number">0.0</span>):<br>                <span class="hljs-keyword">continue</span><br>            mask_arm_draw.line([<span class="hljs-built_in">tuple</span>(pose_data[j]) <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> [i_prev, i]], <span class="hljs-string">&#x27;white&#x27;</span>, width=r*<span class="hljs-number">10</span>)<br>            pointx, pointy = pose_data[i]<br>            radius = r*<span class="hljs-number">4</span> <span class="hljs-keyword">if</span> i == pose_ids[-<span class="hljs-number">1</span>] <span class="hljs-keyword">else</span> r*<span class="hljs-number">15</span><br>            mask_arm_draw.ellipse((pointx-radius, pointy-radius, pointx+radius, pointy+radius), <span class="hljs-string">&#x27;white&#x27;</span>, <span class="hljs-string">&#x27;white&#x27;</span>)<br>            i_prev = i<br>        parse_arm = (np.array(mask_arm) / <span class="hljs-number">255</span>) * (parse_array == parse_id).astype(np.float32)<br>        agnostic.paste(<span class="hljs-number">0</span>, <span class="hljs-literal">None</span>, Image.fromarray(np.uint8(parse_arm * <span class="hljs-number">255</span>), <span class="hljs-string">&#x27;L&#x27;</span>))<br><br>    <span class="hljs-comment"># mask torso &amp; neck</span><br>    agnostic.paste(<span class="hljs-number">0</span>, <span class="hljs-literal">None</span>, Image.fromarray(np.uint8(parse_upper * <span class="hljs-number">255</span>), <span class="hljs-string">&#x27;L&#x27;</span>))<br>    agnostic.paste(<span class="hljs-number">0</span>, <span class="hljs-literal">None</span>, Image.fromarray(np.uint8(parse_neck * <span class="hljs-number">255</span>), <span class="hljs-string">&#x27;L&#x27;</span>))<br><br>    <span class="hljs-keyword">return</span> agnostic<br><br><br><span class="hljs-keyword">if</span> __name__==<span class="hljs-string">&quot;__main__&quot;</span>:<br>    parser = argparse.ArgumentParser()<br>    parser.add_argument(<span class="hljs-string">&#x27;--data_path&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;dataset dir&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;--output_path&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;output dir&quot;</span>)<br><br>    args = parser.parse_args()<br>    data_path = args.data_path<br>    output_path = args.output_path<br>    <br>    os.makedirs(output_path, exist_ok=<span class="hljs-literal">True</span>)<br>    <br>    <span class="hljs-keyword">for</span> im_name <span class="hljs-keyword">in</span> tqdm(os.listdir(osp.join(data_path, <span class="hljs-string">&#x27;image&#x27;</span>))):<br>        <br>        <span class="hljs-comment"># load pose image</span><br>        pose_name = im_name.replace(<span class="hljs-string">&#x27;.jpg&#x27;</span>, <span class="hljs-string">&#x27;_keypoints.json&#x27;</span>)<br>        <br>        <span class="hljs-keyword">try</span>:<br>            <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(osp.join(data_path, <span class="hljs-string">&#x27;openpose_json&#x27;</span>, pose_name), <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>                pose_label = json.load(f)<br>                pose_data = pose_label[<span class="hljs-string">&#x27;people&#x27;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&#x27;pose_keypoints_2d&#x27;</span>]<br>                pose_data = np.array(pose_data)<br>                pose_data = pose_data.reshape((-<span class="hljs-number">1</span>, <span class="hljs-number">3</span>))[:, :<span class="hljs-number">2</span>]<br>        <span class="hljs-keyword">except</span> IndexError:<br>            <span class="hljs-built_in">print</span>(pose_name)<br>            <span class="hljs-keyword">continue</span><br><br>        <span class="hljs-comment"># load parsing image</span><br>        parse_name = im_name.replace(<span class="hljs-string">&#x27;.jpg&#x27;</span>, <span class="hljs-string">&#x27;.png&#x27;</span>)<br>        im_parse = Image.<span class="hljs-built_in">open</span>(osp.join(data_path, <span class="hljs-string">&#x27;image-parse-v3&#x27;</span>, parse_name))<br><br>        agnostic = get_im_parse_agnostic(im_parse, pose_data)<br>        <br>        agnostic.save(osp.join(output_path, parse_name))<br></code></pre></td></tr></table></figure>
<h1 id="networks.py">networks.py</h1>
<p>这里就是定义网络结构的地方。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">ResBlock</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, in_nc, out_nc, scale=<span class="hljs-string">&#x27;down&#x27;</span>, norm_layer=nn.BatchNorm2d</span>):<br>        <span class="hljs-built_in">super</span>(ResBlock, self).__init__()<br>        use_bias = norm_layer == nn.InstanceNorm2d<br>        <span class="hljs-keyword">assert</span> scale <span class="hljs-keyword">in</span> [<span class="hljs-string">&#x27;up&#x27;</span>, <span class="hljs-string">&#x27;down&#x27;</span>, <span class="hljs-string">&#x27;same&#x27;</span>], <span class="hljs-string">&quot;ResBlock scale must be in &#x27;up&#x27; &#x27;down&#x27; &#x27;same&#x27;&quot;</span><br><br>        <span class="hljs-keyword">if</span> scale == <span class="hljs-string">&#x27;same&#x27;</span>:<br>            self.scale = nn.Conv2d(in_nc, out_nc, kernel_size=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>)<br>        <span class="hljs-keyword">if</span> scale == <span class="hljs-string">&#x27;up&#x27;</span>:<br>            self.scale = nn.Sequential(<br>                nn.Upsample(scale_factor=<span class="hljs-number">2</span>, mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>),<br>                nn.Conv2d(in_nc, out_nc, kernel_size=<span class="hljs-number">1</span>,bias=<span class="hljs-literal">True</span>)<br>            )<br>        <span class="hljs-keyword">if</span> scale == <span class="hljs-string">&#x27;down&#x27;</span>:<br>            self.scale = nn.Conv2d(in_nc, out_nc, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>, bias=use_bias)<br>            <br>        self.block = nn.Sequential(<br>            nn.Conv2d(out_nc, out_nc, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>, bias=use_bias),<br>            norm_layer(out_nc),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br>            nn.Conv2d(out_nc, out_nc, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>, bias=use_bias),<br>            norm_layer(out_nc)<br>        )<br>        self.relu = nn.ReLU(inplace=<span class="hljs-literal">True</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        residual = self.scale(x)<br>        <span class="hljs-keyword">return</span> self.relu(residual + self.block(residual))<br></code></pre></td></tr></table></figure>
<p>首先（不在代码最前面，但是是最底层的块）定义了一个ResBlock类。</p>
<p>然后通过<code>norm_layer == nn.InstanceNorm2d</code>判断是否要加入偏置项。</p>
<p>因为当使用规范化层时，卷积层中的偏置项（bias）通常是不必要的，因为规范化层会调整数据的均值和方差，这使得卷积层的偏置项变得多余。具体来说，对于批量归一化（BatchNorm）来讲，它会计算输入数据的均值和方差，并进行规范化，之后还会引入新的可学习参数（scale和shift），这些操作已经隐式地包含了偏置的功能。</p>
<p>然而，在实例归一化（InstanceNorm）的情况下，偏置的使用则取决于具体实现和应用的需求。实例归一化是针对每个样本单独进行的，它在某些应用中（如风格迁移）比批量归一化表现得更好。实例归一化后使用偏置有时可以帮助模型更好地学习和调整每个样本的特定特征。</p>
<p>这里使用了<code>self.relu = nn.ReLU(inplace=True)</code> 。 <code>inplace=True</code>的优缺点分别是：</p>
<ul>
<li><strong>优点</strong>：
<ul>
<li><strong>内存效率</strong>：使用 <code>inplace=True</code> 可以减少内存的使用，因为它避免了分配新的内存空间给操作的输出。这在处理大型网络或大规模数据时尤其有用，可以减少内存压力和潜在的内存不足错误。</li>
<li><strong>提速</strong>：少了内存分配的步骤，有时也可以稍微提高计算速度。</li>
</ul></li>
<li><strong>缺点</strong>：
<ul>
<li><strong>潜在的梯度计算问题</strong>：当 <code>inplace=True</code> 被用于那些需要在反向传播中使用原始输入数据的场景时，可能会造成问题。因为原始输入数据被修改了，所以无法再使用它来计算梯度。这可能会在某些情况下导致错误或者难以调试的问题。</li>
<li><strong>对模型调试的影响</strong>：由于输入数据被直接修改，调试时可能难以观察原始数据和操作后的数据的区别。</li>
</ul></li>
</ul>
<h2 id="conditiongenerator">ConditionGenerator</h2>
<h2 id="网络总体结构">网络总体结构</h2>
<p>总体的网络结构如图所示， <img src="https://s2.loli.net/2024/05/04/5IJfjAKRQEx8wU9.png" srcset="/img/loading.gif" lazyload /></p>
<p><img src="https://s2.loli.net/2024/05/04/1zBHFVmKOcAR4uN.png" srcset="/img/loading.gif" lazyload /></p>
<p>这里要引用一下原文才能够理解这个部分的代码： There are two pathways in the feature fusion block: the <em>flow</em> pathway and the <em>seg</em> pathway. The flow and seg pathway generate the appearance flow map <span class="math inline">\(F_{f_{i}}\)</span> and the segmentation feature <span class="math inline">\(F_{s_{i}}\)</span> , respectively.</p>
<p>For the green arrow, <span class="math inline">\(F_{f_{i} - 1}\)</span> is used to deform the feature extracted from c and cm, which is then concatenated with <span class="math inline">\(F_{f_{s_{i}} - 1}\)</span> and <span class="math inline">\(E_{s_{i}}\)</span> to generate <span class="math inline">\(F_{s_{i}}\)</span> . For the blue arrow, <span class="math inline">\(F_{f_{s_{i}} - 1}\)</span> is used to guide the flow estimation.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">ConditionGenerator</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, opt, input1_nc, input2_nc, output_nc, ngf=<span class="hljs-number">64</span>, norm_layer=nn.BatchNorm2d</span>):<br>        <span class="hljs-built_in">super</span>(ConditionGenerator, self).__init__()<br>        self.warp_feature = opt.warp_feature<br>        self.out_layer_opt = opt.out_layer<br>        <br>        self.ClothEncoder = nn.Sequential(<br>            ResBlock(input1_nc, ngf, norm_layer=norm_layer, scale=<span class="hljs-string">&#x27;down&#x27;</span>),  <span class="hljs-comment"># 128</span><br>            ResBlock(ngf, ngf * <span class="hljs-number">2</span>, norm_layer=norm_layer, scale=<span class="hljs-string">&#x27;down&#x27;</span>),  <span class="hljs-comment"># 64</span><br>            ResBlock(ngf * <span class="hljs-number">2</span>, ngf * <span class="hljs-number">4</span>, norm_layer=norm_layer, scale=<span class="hljs-string">&#x27;down&#x27;</span>),  <span class="hljs-comment"># 32</span><br>            ResBlock(ngf * <span class="hljs-number">4</span>, ngf * <span class="hljs-number">4</span>, norm_layer=norm_layer, scale=<span class="hljs-string">&#x27;down&#x27;</span>),  <span class="hljs-comment"># 16</span><br>            ResBlock(ngf * <span class="hljs-number">4</span>, ngf * <span class="hljs-number">4</span>, norm_layer=norm_layer, scale=<span class="hljs-string">&#x27;down&#x27;</span>)  <span class="hljs-comment"># 8</span><br>        )<br>        <br>        self.PoseEncoder = nn.Sequential(<br>            ResBlock(input2_nc, ngf, norm_layer=norm_layer, scale=<span class="hljs-string">&#x27;down&#x27;</span>),<br>            ResBlock(ngf, ngf * <span class="hljs-number">2</span>, norm_layer=norm_layer, scale=<span class="hljs-string">&#x27;down&#x27;</span>),<br>            ResBlock(ngf * <span class="hljs-number">2</span>, ngf * <span class="hljs-number">4</span>, norm_layer=norm_layer, scale=<span class="hljs-string">&#x27;down&#x27;</span>),<br>            ResBlock(ngf * <span class="hljs-number">4</span>, ngf * <span class="hljs-number">4</span>, norm_layer=norm_layer, scale=<span class="hljs-string">&#x27;down&#x27;</span>),<br>            ResBlock(ngf * <span class="hljs-number">4</span>, ngf * <span class="hljs-number">4</span>, norm_layer=norm_layer, scale=<span class="hljs-string">&#x27;down&#x27;</span>)<br>        )<br>        <br>        self.conv = ResBlock(ngf * <span class="hljs-number">4</span>, ngf * <span class="hljs-number">8</span>, norm_layer=norm_layer, scale=<span class="hljs-string">&#x27;same&#x27;</span>)<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> opt.warp_feature == <span class="hljs-string">&#x27;encoder&#x27;</span>:<br>            <span class="hljs-comment"># in_nc -&gt; [x, skip_connection, warped_cloth_encoder_feature(E1)]</span><br>            self.SegDecoder = nn.Sequential(<br>                ResBlock(ngf * <span class="hljs-number">8</span>, ngf * <span class="hljs-number">4</span>, norm_layer=norm_layer, scale=<span class="hljs-string">&#x27;up&#x27;</span>),  <span class="hljs-comment"># 16</span><br>                ResBlock(ngf * <span class="hljs-number">4</span> * <span class="hljs-number">3</span>, ngf * <span class="hljs-number">4</span>, norm_layer=norm_layer, scale=<span class="hljs-string">&#x27;up&#x27;</span>),  <span class="hljs-comment"># 32</span><br>                ResBlock(ngf * <span class="hljs-number">4</span> * <span class="hljs-number">3</span>, ngf * <span class="hljs-number">2</span>, norm_layer=norm_layer, scale=<span class="hljs-string">&#x27;up&#x27;</span>),  <span class="hljs-comment"># 64</span><br>                ResBlock(ngf * <span class="hljs-number">2</span> * <span class="hljs-number">3</span>, ngf, norm_layer=norm_layer, scale=<span class="hljs-string">&#x27;up&#x27;</span>),  <span class="hljs-comment"># 128</span><br>                ResBlock(ngf * <span class="hljs-number">1</span> * <span class="hljs-number">3</span>, ngf, norm_layer=norm_layer, scale=<span class="hljs-string">&#x27;up&#x27;</span>)  <span class="hljs-comment"># 256</span><br>            )<br><br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs python">    <span class="hljs-keyword">if</span> opt.out_layer == <span class="hljs-string">&#x27;relu&#x27;</span>:<br>        self.out_layer = ResBlock(ngf + input1_nc + input2_nc, output_nc, norm_layer=norm_layer, scale=<span class="hljs-string">&#x27;same&#x27;</span>)<br>    <span class="hljs-keyword">if</span> opt.out_layer == <span class="hljs-string">&#x27;conv&#x27;</span>:<br>        self.out_layer = nn.Sequential(<br>            ResBlock(ngf + input1_nc + input2_nc, ngf, norm_layer=norm_layer, scale=<span class="hljs-string">&#x27;same&#x27;</span>),<br>            nn.Conv2d(ngf, output_nc, kernel_size=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>)<br>        )<br>    <span class="hljs-comment"># Cloth Conv 1x1</span><br>    self.conv1 = nn.Sequential(<br>        nn.Conv2d(ngf, ngf * <span class="hljs-number">4</span>, kernel_size=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>),<br>        nn.Conv2d(ngf * <span class="hljs-number">2</span>, ngf * <span class="hljs-number">4</span>, kernel_size=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>),<br>        nn.Conv2d(ngf * <span class="hljs-number">4</span>, ngf * <span class="hljs-number">4</span>, kernel_size=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>),<br>        nn.Conv2d(ngf * <span class="hljs-number">4</span>, ngf * <span class="hljs-number">4</span>, kernel_size=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>),<br>    )<br><br>    <span class="hljs-comment"># Person Conv 1x1</span><br>    self.conv2 = nn.Sequential(<br>        nn.Conv2d(ngf, ngf * <span class="hljs-number">4</span>, kernel_size=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>),<br>        nn.Conv2d(ngf * <span class="hljs-number">2</span>, ngf * <span class="hljs-number">4</span>, kernel_size=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>),<br>        nn.Conv2d(ngf * <span class="hljs-number">4</span>, ngf * <span class="hljs-number">4</span>, kernel_size=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>),<br>        nn.Conv2d(ngf * <span class="hljs-number">4</span>, ngf * <span class="hljs-number">4</span>, kernel_size=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>),<br>    )<br>    <br>    self.flow_conv = nn.ModuleList([<br>        nn.Conv2d(ngf * <span class="hljs-number">8</span>, <span class="hljs-number">2</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>),<br>        nn.Conv2d(ngf * <span class="hljs-number">8</span>, <span class="hljs-number">2</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>),<br>        nn.Conv2d(ngf * <span class="hljs-number">8</span>, <span class="hljs-number">2</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>),<br>        nn.Conv2d(ngf * <span class="hljs-number">8</span>, <span class="hljs-number">2</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>),<br>        nn.Conv2d(ngf * <span class="hljs-number">8</span>, <span class="hljs-number">2</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>),<br>    ]<br>    )<br>    <br>    self.bottleneck = nn.Sequential(<br>        nn.Sequential(nn.Conv2d(ngf * <span class="hljs-number">4</span>, ngf * <span class="hljs-number">4</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>), nn.ReLU()),<br>        nn.Sequential(nn.Conv2d(ngf * <span class="hljs-number">4</span>, ngf * <span class="hljs-number">4</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>), nn.ReLU()),<br>        nn.Sequential(nn.Conv2d(ngf * <span class="hljs-number">2</span>, ngf * <span class="hljs-number">4</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>) , nn.ReLU()),<br>        nn.Sequential(nn.Conv2d(ngf, ngf * <span class="hljs-number">4</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>), nn.ReLU()),<br>    )<br>    <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">normalize</span>(<span class="hljs-params">self, x</span>):<br>    <span class="hljs-keyword">return</span> x<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,opt,input1, input2, upsample=<span class="hljs-string">&#x27;bilinear&#x27;</span></span>):<br>        E1_list = []<br>        E2_list = []<br>        flow_list = []<br>        <span class="hljs-comment"># warped_grid_list = []</span><br><br>        <span class="hljs-comment"># Feature Pyramid Network </span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>):<br>            <span class="hljs-keyword">if</span> i == <span class="hljs-number">0</span>:<br>                E1_list.append(self.ClothEncoder[i](input1))<br>                E2_list.append(self.PoseEncoder[i](input2))<br>            <span class="hljs-keyword">else</span>:<br>                E1_list.append(self.ClothEncoder[i](E1_list[i - <span class="hljs-number">1</span>]))<br>                E2_list.append(self.PoseEncoder[i](E2_list[i - <span class="hljs-number">1</span>]))      <br></code></pre></td></tr></table></figure>
<p>这里的input1这里的E1和E2应该就是指的论文里的 <span class="math inline">\(E_{c}\)</span> 和 <span class="math inline">\(E_{s}\)</span>。用原文的话说，这里做的是：</p>
<p>Our try-on condition generator consists of two encoders (i.e., a clothing encoder <span class="math inline">\(E_{c}\)</span> and a segmentation encoder <span class="math inline">\(E_{s}\)</span>) and a decoder. Given <span class="math inline">\((c, c_{m})\)</span> and <span class="math inline">\((S_{a}, P)\)</span>, we first extract the feature pyramid <span class="math inline">\(\{E_{c_{k}}\}_{k = 0}^{4}\)</span> and <span class="math inline">\(\{E_{s_{l}}\}_{l = 0}^{4}\)</span> from each encoder, respectively. The extracted features are fed into the feature fusion blocks of the decoder, where the feature maps obtained from the two different feature pyramids are fused to predict the segmentation map and the appearance flow for warping the clothing image.</p>
<h2 id="compute-clothflow">Compute Clothflow</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Compute Clothflow</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>):<br>    N, _, iH, iW = E1_list[<span class="hljs-number">4</span> - i].size()<br>    grid = make_grid(N, iH, iW,opt)<br><br><span class="hljs-comment"># Omitted, see detailed explanations below</span><br><br>N, _, iH, iW = input1.size()<br>grid = make_grid(N, iH, iW,opt)<br><br>flow = F.interpolate(flow_list[-<span class="hljs-number">1</span>].permute(<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>), scale_factor=<span class="hljs-number">2</span>, mode=upsample).permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)<br>flow_norm = torch.cat([flow[:, :, :, <span class="hljs-number">0</span>:<span class="hljs-number">1</span>] / ((iW/<span class="hljs-number">2</span> - <span class="hljs-number">1.0</span>) / <span class="hljs-number">2.0</span>), flow[:, :, :, <span class="hljs-number">1</span>:<span class="hljs-number">2</span>] / ((iH/<span class="hljs-number">2</span> - <span class="hljs-number">1.0</span>) / <span class="hljs-number">2.0</span>)], <span class="hljs-number">3</span>)<br>warped_input1 = F.grid_sample(input1, flow_norm + grid, padding_mode=<span class="hljs-string">&#x27;border&#x27;</span>)<br><br>x = self.out_layer(torch.cat([x, input2, warped_input1], <span class="hljs-number">1</span>))<br><br>warped_c = warped_input1[:, :-<span class="hljs-number">1</span>, :, :]<br>warped_cm = warped_input1[:, -<span class="hljs-number">1</span>:, :, :]<br><br><span class="hljs-keyword">return</span> flow_list, x, warped_c, warped_cm<br></code></pre></td></tr></table></figure>
<p>这里还要分成<code>i == 0</code>和<code>i != 0</code>来看： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> i == <span class="hljs-number">0</span>:<br>               T1 = E1_list[<span class="hljs-number">4</span> - i]  <span class="hljs-comment"># (ngf * 4) x 8 x 6</span><br>               T2 = E2_list[<span class="hljs-number">4</span> - i]<br>               E4 = torch.cat([T1, T2], <span class="hljs-number">1</span>)<br>               <br>               flow = self.flow_conv[i](self.normalize(E4)).permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)<br>               flow_list.append(flow)<br>               <br>               x = self.conv(T2)<br>               x = self.SegDecoder[i](x)<br></code></pre></td></tr></table></figure></p>
<p>第一层Feature Fusion Block的输入就是 <span class="math inline">\(F_{f_{0}}\)</span> 和 <span class="math inline">\(F_{s_{0}}\)</span> (也即 <span class="math inline">\(E_{c_{4}}\)</span> 和 <span class="math inline">\(E_{s_{4}}\)</span>). 然后把他们两个concatenate一下作为这里的E4，直接通过卷积网络得到。</p>
<p>然后将 E4 标准化之后通过<code>flow_conv[0]</code>（即一层卷积网络）得到flow_list里面的第一个元素。</p>
<p>然后再把T2在通过一次一次卷积得到x， 然后将 x 交给seg_decoder的第一层处理。</p>
<p><code>i != 0</code>时：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">else</span>:<br>    T1 = F.interpolate(T1, scale_factor=<span class="hljs-number">2</span>, mode=upsample) + \<br>        self.conv1[<span class="hljs-number">4</span> - i](E1_list[<span class="hljs-number">4</span> - i])<br>    T2 = F.interpolate(T2, scale_factor=<span class="hljs-number">2</span>, mode=upsample) + \<br>        self.conv2[<span class="hljs-number">4</span> - i](E2_list[<span class="hljs-number">4</span> - i])<br><br>    flow = F.interpolate(flow_list[i - <span class="hljs-number">1</span>].permute(<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>), scale_factor=<span class="hljs-number">2</span>,<br>                         <span class="hljs-comment"># upsample n-1 flow</span><br>                         mode=upsample).permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)<br>    flow_norm = torch.cat([flow[:, :, :, <span class="hljs-number">0</span>:<span class="hljs-number">1</span>] / ((iW/<span class="hljs-number">2</span> - <span class="hljs-number">1.0</span>) / <span class="hljs-number">2.0</span>),<br>                           flow[:, :, :, <span class="hljs-number">1</span>:<span class="hljs-number">2</span>] / ((iH/<span class="hljs-number">2</span> - <span class="hljs-number">1.0</span>) / <span class="hljs-number">2.0</span>)], <span class="hljs-number">3</span>)<br>    warped_T1 = F.grid_sample(T1, flow_norm + grid, padding_mode=<span class="hljs-string">&#x27;border&#x27;</span>)<br><br>    flow = flow + self.flow_conv[i](self.normalize(torch.cat(<br>          <span class="hljs-comment"># F(n)</span><br>          [warped_T1, self.bottleneck[i-<span class="hljs-number">1</span>](x)], <span class="hljs-number">1</span>))).permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)<br>    flow_list.append(flow)<br><br></code></pre></td></tr></table></figure>
<p>在python中对于<code>if</code>和<code>else</code>块中的变量，当在一个<code>if</code>块中初始化变量时，这些变量会在包含这个<code>if</code>块的更大代码块（如函数或循环）中存在，只要确保在使用这些变量之前已经对其进行了初始化。所以这里在else中能够直接调用<code>if i == 0</code>这个语句块中的 T1 和 T2。</p>
<p>这里T1是之前的T1和E1中相应元素进行相加而成的，T2同理。</p>
<p>这部分语句实际上是在处理 flow pathway。意思其实就是在说首先把T1和T2与前面连过来的feature相结合，以得到更好的效果。然后<span class="math inline">\(F_{f_{i-1}}\)</span>经过upsample之后，与<span class="math inline">\(E_{c_{i}}\)</span>一起预测变形后的衣服，也就是这里的warped_T1。然后warped_T1和 x 进行concatenation，然后再经过3x3卷积，并与flow求和，即得到了新的flow。下面再贴一下网络结构图以供参考。</p>
<p><img src="https://s2.loli.net/2024/05/04/1zBHFVmKOcAR4uN.png" srcset="/img/loading.gif" lazyload /></p>
<p><code>flow=F.interpolate(flow_list[i - 1].permute(0,3,1,2),scale_factor=2,mode=upsample).permute(0, 2, 3, 1)</code> 这行代码是用于处理图像中的光流场（flow field），其目的是将前一迭代（或层级）的光流场上采样（upsample）到当前处理层的分辨率。</p>
<p><code>flow_norm = torch.cat([flow[:, :, :, 0:1] / ((iW/2 - 1.0) / 2.0), flow[:, :, :, 1:2] / ((iH/2 - 1.0) / 2.0)], 3)</code></p>
<p>这行代码进行了光流的规范化操作。光流通常表示像素点在图像序列中从一个位置到另一个位置的位移。当进行空间变换，如 <code>grid_sample</code> 时，这些光流值需要与实际图像尺寸相匹配和规范化，以便正确地应用到图像上。这里的规范化是为了适配 <code>grid_sample</code> 函数使用的坐标系统，其中坐标值通常在<code>[-1,1]</code>的范围内。详细解释如下：</p>
<ul>
<li>光流的每个分量被除以 <code>(iW/2 - 1.0) / 2.0</code> 或 <code>(iH/2 - 1.0) / 2.0</code>。这里的计算基于图像的实际尺寸（<code>iW</code> 是图像宽度，<code>iH</code> 是图像高度），将光流值转换为 -1 到 1 的范围内。这种转换是基于以下逻辑：
<ul>
<li>图像的中心坐标（在像素索引中）大约是 <code>iW / 2</code> 和 <code>iH / 2</code>。</li>
<li>将宽度和高度除以 2 并减去 1 旨在获取到中心点左右各一半的距离。</li>
<li>进一步除以 2 是将坐标范围从 <code>[0, (iW/2 - 1)]</code> 调整到 <code>[0, 0.5]</code>，然后由于 grid_sample 中坐标要求为 <code>[-1, 1]</code>，因此不需要额外转换。</li>
</ul></li>
</ul>
<p><code>warped_T1 = F.grid_sample(T1, flow_norm + grid, padding_mode='border')</code> 这行代码使用了 PyTorch 的 <code>F.grid_sample</code> 函数，它是一个非常有用的函数，用于对给定的输入特征图 (<code>T1</code>) 进行空间变换。具体来说，它根据给定的流场 (<code>flow_norm</code>) 和网格 (<code>grid</code>) 来变形或重采样输入图像。</p>
<ul>
<li><strong>T1</strong>：这是被变换的特征图，可以视为一系列的高维数据（通常是图像或其特征表示）。</li>
<li><strong>flow_norm + grid</strong>：
<ul>
<li><strong>flow_norm</strong>：这是光流场，已经被规范化以适应图像的坐标系统（通常在[-1, 1]的范围）。它表示特定像素应该从原始位置移动到的新位置。</li>
<li><strong>grid</strong>：通常是一个规则的网格，表示图像中每个像素的原始坐标。</li>
<li>通过将 <code>flow_norm</code> 和 <code>grid</code> 相加，你创建了一个新的变形网格。这个网格不再是均匀的，而是根据光流字段调整，指示每个输出像素应该从输入图像的哪个位置采样。</li>
</ul></li>
<li><strong>padding_mode='border'</strong>：
<ul>
<li>这个参数定义了当采样位置超出输入图像边界时的行为。<code>'border'</code> 模式指定如果采样点超出边界，就使用边界上的像素值。这有助于防止引入任何不希望的伪影，特别是在边缘区域，因为其他模式如 <code>'zeros'</code> 可能会在图像边缘产生不自然的黑边。</li>
</ul></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> self.warp_feature == <span class="hljs-string">&#x27;T1&#x27;</span>:<br>     x = self.SegDecoder[i](torch.cat([x, E2_list[<span class="hljs-number">4</span>-i], warped_T1], <span class="hljs-number">1</span>))<br> <span class="hljs-keyword">if</span> self.warp_feature == <span class="hljs-string">&#x27;encoder&#x27;</span>:<br>     warped_E1 = F.grid_sample(<br>         E1_list[<span class="hljs-number">4</span>-i], flow_norm + grid, padding_mode=<span class="hljs-string">&#x27;border&#x27;</span>)<br>     x = self.SegDecoder[i](torch.cat([x, E2_list[<span class="hljs-number">4</span>-i], warped_E1], <span class="hljs-number">1</span>))<br></code></pre></td></tr></table></figure>
<p>然后这部分就是更新 x， 即<span class="math inline">\(F_{s_{i-1}}\)</span>。</p>
<p>然后这里分了两种情况（似乎是想比较直接用encoder的一层提取出来的特征，和把这些特征累加起来，产生效果的区别)。</p>
<p>如果<code>self.warp_feature == 'T1'</code>,那么就直接将<span class="math inline">\(F_{s_{i-1}}\)</span>（即 x）,<span class="math inline">\(E_{s_{i}}\)</span>, warped_T1 做concatenation，然后经过SegDecoder网络得到新的 x。</p>
<p>如果<code>self.warp_feature == 'encoder'</code>这种情况下就直接用encoder的一层提取出来的特征，然后产生新的 x。</p>
<h3 id="make_grid">make_grid</h3>
<p>然后对得到的结果进行进一步的处理： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">make_grid</span>(<span class="hljs-params">N, iH, iW,opt</span>):<br>    grid_x = torch.linspace(-<span class="hljs-number">1.0</span>, <span class="hljs-number">1.0</span>, iW).view(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, iW, <span class="hljs-number">1</span>).expand(N, iH, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>)<br>    grid_y = torch.linspace(-<span class="hljs-number">1.0</span>, <span class="hljs-number">1.0</span>, iH).view(<span class="hljs-number">1</span>, iH, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>).expand(N, -<span class="hljs-number">1</span>, iW, -<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">if</span> opt.cuda :<br>        grid = torch.cat([grid_x, grid_y], <span class="hljs-number">3</span>).cuda()<br>    <span class="hljs-keyword">else</span>:<br>        grid = torch.cat([grid_x, grid_y], <span class="hljs-number">3</span>)<br>    <span class="hljs-keyword">return</span> grid<br></code></pre></td></tr></table></figure></p>
<h4 id="view">view</h4>
<p><code>view</code> 方法用于改变张量的形状而不改变其数据。你可以将其视为重新排列或解释张量中数据的一种方式，但实际的数据内容和顺序不变。这通常用于调整数据的维度以匹配特定操作或模型的输入需求。</p>
<ul>
<li><strong>使用场景</strong>：例如，如果你有一个形状为 <code>[10, 256]</code> 的张量，你可以使用 <code>.view(10, 16, 16)</code> 将其重新形状为 <code>[10, 16, 16]</code>，这样做是为了将它用作图像批次，其中每张图像是 16x16 像素。</li>
<li><strong>限制</strong>：使用 <code>view</code> 需要张量在内存中是连续的（即无跨步问题）。如果不是，可能需要先调用 <code>.contiguous()</code>。</li>
</ul>
<h4 id="expand">expand</h4>
<p><code>expand</code> 方法用于“广播”一个张量，让它在某些维度上看起来更大，但实际上不复制数据。这是一种内存高效的方式来使用原始数据执行批量操作，因为它只是改变张量的视图而不实际创建新的数据副本。</p>
<p>在 PyTorch 中使用 <code>expand</code> 方法时，参数 <code>-1</code> 指示在该维度上保持当前的尺寸不变。它相当于说“在这个维度上，不需要扩展或重复数据”。</p>
<p>在 <code>torch.cat</code> 函数中，第三个参数指的是 <code>dim</code>，即维度参数，它告诉函数沿哪个维度进行张量的拼接。在您的示例 <code>torch.cat([grid_x, grid_y], 3)</code> 中，这个参数是 <code>3</code>，意味着张量将沿着第四个维度（维度索引从 0 开始）进行合并。</p>
<p>这个函数做了四件事：</p>
<ol type="1">
<li><strong>创建坐标网格</strong>:
<ul>
<li><code>torch.linspace(-1.0, 1.0, iW)</code> 和 <code>torch.linspace(-1.0, 1.0, iH)</code> 分别生成水平和垂直方向上从 -1 到 1 的均匀间隔的数值，这些数值代表了归一化坐标系统中的位置。<code>iW</code> 和 <code>iH</code> 是图像的宽度和高度，这确保了网格覆盖了整个图像的每个像素。</li>
</ul></li>
<li><strong>调整维度和复制</strong>:
<ul>
<li><code>view(1, 1, iW, 1)</code> 和 <code>view(1, iH, 1, 1)</code> 对生成的线性间隔进行维度调整，使其能够与图像的宽度和高度匹配。</li>
<li><code>expand(N, iH, -1, -1)</code> 和 <code>expand(N, -1, iW, -1)</code> 这两个函数调用将单个坐标行或列扩展成完整的 N×iH×iW 网格。<code>N</code> 是批处理大小，表示生成的网格需要复制 N 次以匹配批中的每个图像。</li>
</ul></li>
<li><strong>合并坐标网格</strong>:
<ul>
<li><code>torch.cat([grid_x, grid_y], 3)</code> 将水平和垂直坐标网格沿着最后一个维度（通道维）合并，形成一个完整的网格。这个网格中的每个元素都是一个二维坐标点，对应于输入图像中的一个像素位置。</li>
</ul></li>
<li><strong>处理 CUDA 支持</strong>:
<ul>
<li><code>if opt.cuda:</code> 检查一个选项（通常是一个配置对象）来确定是否使用 CUDA（即 GPU 加速）。如果是，将网格移动到 GPU 上以加速后续计算。否则，网格保留在 CPU 上。</li>
</ul></li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python">N, _, iH, iW = input1.size()<br>grid = make_grid(N, iH, iW, opt)<br><br>flow = F.interpolate(flow_list[-<span class="hljs-number">1</span>].permute(<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>),<br>                     scale_factor=<span class="hljs-number">2</span>, mode=upsample).permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)<br>flow_norm = torch.cat([flow[:, :, :, <span class="hljs-number">0</span>:<span class="hljs-number">1</span>] / ((iW/<span class="hljs-number">2</span> - <span class="hljs-number">1.0</span>) / <span class="hljs-number">2.0</span>),<br>                       flow[:, :, :, <span class="hljs-number">1</span>:<span class="hljs-number">2</span>] / ((iH/<span class="hljs-number">2</span> - <span class="hljs-number">1.0</span>) / <span class="hljs-number">2.0</span>)], <span class="hljs-number">3</span>)<br>warped_input1 = F.grid_sample(<br>    input1, flow_norm + grid, padding_mode=<span class="hljs-string">&#x27;border&#x27;</span>)<br><br>x = self.out_layer(torch.cat([x, input2, warped_input1], <span class="hljs-number">1</span>))<br><br>warped_c = warped_input1[:, :-<span class="hljs-number">1</span>, :, :]<br>warped_cm = warped_input1[:, -<span class="hljs-number">1</span>:, :, :]<br><br><span class="hljs-keyword">return</span> flow_list, x, warped_c, warped_cm<br><br></code></pre></td></tr></table></figure>
<p>这里的代码是循环执行完，即生成好了<span class="math inline">\(F_{f_{4}}\)</span>和<span class="math inline">\(\hat{S}_{raw}\)</span>后执行的，然后就是用flow来对input进行变形。然后将 x，输入的segmentation map和warped clothes结合起来，经过卷积网络，生成最后的Segmentation map。</p>
<ul>
<li><code>grid = make_grid(N, iH, iW, opt)</code> 生成一个规则网格，用于后续的图像空间变换。这个网格与图像的每个像素对齐，并为 <code>grid_sample</code> 函数提供了参考坐标。</li>
</ul>
<h4 id="光流的上采样和规范化">光流的上采样和规范化</h4>
<ol type="1">
<li><strong>光流上采样</strong>:
<ul>
<li><code>flow = F.interpolate(flow_list[-1].permute(0, 3, 1, 2), scale_factor=2, mode=upsample).permute(0, 2, 3, 1)</code> 从光流列表中取出最后一个光流字段。而<code>interpolate</code> 函数期望数据的格式通常是 <code>(N, C, H, W)</code>，所以首先调整其维度以适配 <code>interpolate</code> 函数的输入要求，进行上采样以匹配当前输入图像的分辨率，然后再次调整维度回到正常的布局。</li>
</ul></li>
<li><strong>光流规范化</strong>:
<ul>
<li><code>flow_norm = torch.cat([flow[:, :, :, 0:1] / ((iW/2 - 1.0) / 2.0), flow[:, :, :, 1:2] / ((iH/2 - 1.0) / 2.0)], 3)</code> 对上采样后的光流进行规范化，确保其值在<code>[-1, 1]</code>的范围内，适合用于 <code>grid_sample</code> 函数。</li>
</ul></li>
</ol>
<h4 id="图像的变形和特征处理">图像的变形和特征处理</h4>
<p>这里的input1是clothes image和clothes mask，而input2是parse_agnostic和densepose_map.</p>
<ol type="1">
<li><strong>应用光流和网格变形</strong>:
<ul>
<li><code>warped_input1 = F.grid_sample(input1, flow_norm + grid, padding_mode='border')</code> 使用规范化的光流和生成的网格对输入图像 <code>input1</code> 进行空间变换。这里使用的 <code>border</code> 填充模式，保证在图像边缘外的采样不会导致错误或异常值。</li>
</ul></li>
<li><strong>特征合并</strong>:
<ul>
<li><code>x = self.out_layer(torch.cat([x, input2, warped_input1], 1))</code> 将中间特征 <code>x</code>、第二输入 <code>input2</code> 和变形后的图像 <code>warped_input1</code> 合并，并通过模型的输出层处理。这一步整合了来自不同源的信息，以产生综合的输出特征。</li>
</ul></li>
</ol>
<h4 id="输出分割和返回">输出分割和返回</h4>
<ol type="1">
<li><strong>输出分割</strong>:
<ul>
<li><code>warped_c = warped_input1[:, :-1, :, :]</code>这行代码提取除了最后一个通道之外的所有通道。<code>warped_cm = warped_input1[:, -1:, :, :]</code> 这行代码专门提取 <code>warped_input1</code> 张量中的最后一个通道。这是为了从变形后的图像中分离出颜色部分和掩模部分。</li>
</ul></li>
<li><strong>函数返回</strong>:
<ul>
<li><code>return flow_list, x, warped_c, warped_cm</code> 返回光流列表、合成的输出特征 <code>x</code>、颜色信息 <code>warped_c</code> 和掩模信息 <code>warped_cm</code>。这些输出可以用于进一步的处理或作为模型训练的结果。</li>
</ul></li>
</ol>
<h2 id="loss-function">Loss Function</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Vgg19</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, requires_grad=<span class="hljs-literal">False</span></span>):<br>        <span class="hljs-built_in">super</span>(Vgg19, self).__init__()<br>        vgg_pretrained_features = models.vgg19(pretrained=<span class="hljs-literal">True</span>).features<br>        self.slice1 = torch.nn.Sequential()<br>        self.slice2 = torch.nn.Sequential()<br>        self.slice3 = torch.nn.Sequential()<br>        self.slice4 = torch.nn.Sequential()<br>        self.slice5 = torch.nn.Sequential()<br>        <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>):<br>            self.slice1.add_module(<span class="hljs-built_in">str</span>(x), vgg_pretrained_features[x])<br>        <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>, <span class="hljs-number">7</span>):<br>            self.slice2.add_module(<span class="hljs-built_in">str</span>(x), vgg_pretrained_features[x])<br>        <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">7</span>, <span class="hljs-number">12</span>):<br>            self.slice3.add_module(<span class="hljs-built_in">str</span>(x), vgg_pretrained_features[x])<br>        <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">12</span>, <span class="hljs-number">21</span>):<br>            self.slice4.add_module(<span class="hljs-built_in">str</span>(x), vgg_pretrained_features[x])<br>        <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">21</span>, <span class="hljs-number">30</span>):<br>            self.slice5.add_module(<span class="hljs-built_in">str</span>(x), vgg_pretrained_features[x])<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> requires_grad:<br>            <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.parameters():<br>                param.requires_grad = <span class="hljs-literal">False</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, X</span>):<br>        h_relu1 = self.slice1(X)<br>        h_relu2 = self.slice2(h_relu1)<br>        h_relu3 = self.slice3(h_relu2)<br>        h_relu4 = self.slice4(h_relu3)<br>        h_relu5 = self.slice5(h_relu4)<br>        out = [h_relu1, h_relu2, h_relu3, h_relu4, h_relu5]<br>        <span class="hljs-keyword">return</span> out<br></code></pre></td></tr></table></figure>
<p>首先定义了一个VGG19网络。</p>
<p><code>vgg_pretrained_features = models.vgg19(pretrained=True).features</code> 加载一个预训练的 VGG-19 模型，并且只获取其特征提取层（即卷积层和激活层，不包括分类用的全连接层）。</p>
<p><code>self.slice1</code> 到 <code>self.slice5</code> 是分层存储不同阶段的 VGG-19 特征图的模块。这些层按照在 VGG-19 中的顺序被组织，每个 <code>slice</code> 包含了一组特定的层，这样设计使得可以提取不同深度的特征。</p>
<p>循环通过预训练的 VGG-19 特征，将它们根据其在原始网络中的位置分配到五个 <code>slice</code> 中。每个 <code>slice</code> 包含了连续的几层，这是根据 VGG-19 网络的结构来划分的。</p>
<p>使用循环遍历 <code>vgg_pretrained_features</code>（这是一个从预训练 VGG-19 模型中提取出的模块序列，包含卷积层、ReLU 层等）。</p>
<p>如果 <code>requires_grad</code> 设置为 <code>False</code>（通常在特征提取任务中不需要计算梯度），则禁用所有参数的梯度计算，以提高效率和减少内存消耗。</p>
<p>在前向传播时，输入 <code>X</code> 依次通过每个 <code>slice</code>，每个 <code>slice</code> 输出的结果作为下一个 <code>slice</code> 的输入。这种方式允许模型在多个层次上提取特征。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">VGGLoss</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, opt,layids = <span class="hljs-literal">None</span></span>):<br>        <span class="hljs-built_in">super</span>(VGGLoss, self).__init__()<br>        self.vgg = Vgg19()<br>        <span class="hljs-keyword">if</span> opt.cuda:<br>            self.vgg.cuda()<br>        self.criterion = nn.L1Loss()<br>        self.weights = [<span class="hljs-number">1.0</span>/<span class="hljs-number">32</span>, <span class="hljs-number">1.0</span>/<span class="hljs-number">16</span>, <span class="hljs-number">1.0</span>/<span class="hljs-number">8</span>, <span class="hljs-number">1.0</span>/<span class="hljs-number">4</span>, <span class="hljs-number">1.0</span>]<br>        self.layids = layids<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x, y</span>):<br>        x_vgg, y_vgg = self.vgg(x), self.vgg(y)<br>        loss = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">if</span> self.layids <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            self.layids = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(x_vgg)))<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> self.layids:<br>            loss += self.weights[i] * self.criterion(x_vgg[i], y_vgg[i].detach())<br>        <span class="hljs-keyword">return</span> loss<br></code></pre></td></tr></table></figure>
<p><code>self.criterion = nn.L1Loss()</code> 初始化 L1 损失函数，用于计算预测和目标之间的绝对差异。</p>
<p><code>self.weights = [1.0/32, 1.0/16, 1.0/8, 1.0/4, 1.0]</code> 指定了不同层输出的权重，这些权重控制了每一层特征在总损失中的贡献。</p>
<p><code>self.layids = layids</code> 可选参数，允许用户指定使用 VGG-19 哪些层的输出来计算损失。如果未指定，默认使用所有层的输出。</p>
<p>在前向传播的时候，<code>x_vgg, y_vgg = self.vgg(x), self.vgg(y)</code> 分别计算两个输入 <code>x</code>（预测图像）和 <code>y</code>（目标图像）通过 VGG-19 网络的输出。结果是两个特征列表，每个列表包含由 <code>Vgg19</code> 类返回的五个层级的特征。</p>
<p><strong>损失计算</strong>: - 首先检查是否指定了 <code>layids</code>，若未指定，则使用所有层 (<code>list(range(len(x_vgg)))</code>)。 - 然后遍历每个指定的层索引，计算对应层的加权 L1 损失。<code>self.criterion(x_vgg[i], y_vgg[i].detach())</code> 计算两个特征图之间的差异，其中 <code>y_vgg[i].detach()</code> 确保目标图像特征不会参与梯度计算。 - 损失加权后累加，最终得到的 <code>loss</code> 表示两个图像在 VGG-19 不同层级特征上的整体差异。</p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
为什么只有y_vgg调用了detach</li>
</ul>
<h3 id="ganloss">GANLoss</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">GANLoss</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, use_lsgan=<span class="hljs-literal">True</span>, target_real_label=<span class="hljs-number">1.0</span>, target_fake_label=<span class="hljs-number">0.0</span>,</span><br><span class="hljs-params">                 tensor=torch.FloatTensor</span>):<br>        <span class="hljs-built_in">super</span>(GANLoss, self).__init__()<br>        self.real_label = target_real_label<br>        self.fake_label = target_fake_label<br>        self.real_label_var = <span class="hljs-literal">None</span><br>        self.fake_label_var = <span class="hljs-literal">None</span><br>        self.Tensor = tensor<br>        <span class="hljs-keyword">if</span> use_lsgan:<br>            self.loss = nn.MSELoss()<br>        <span class="hljs-keyword">else</span>:<br>            self.loss = nn.BCELoss()<br></code></pre></td></tr></table></figure>
<p><strong>初始化成员变量</strong>: - <code>self.real_label</code> 和 <code>self.fake_label</code> 设定了真实样本和假样本的标签默认值，通常在二分类问题中，真实样本标签为 1，假样本标签为 0。 - <code>self.real_label_var</code> 和 <code>self.fake_label_var</code> 初始化为 <code>None</code>，这些变量将用于存储基于当前批量大小的目标张量。</p>
<p><strong>选择损失函数</strong>: - <code>if use_lsgan:</code> 根据 <code>use_lsgan</code> 的值选择损失函数类型。如果为 <code>True</code>，使用均方误差损失（<code>nn.MSELoss()</code>），适用于LSGAN的设置。如果为 <code>False</code>，则使用二元交叉熵损失（<code>nn.BCELoss()</code>），适用于传统的GAN。</p>
<p><strong>设置张量类型</strong>: <code>self.Tensor</code> 用于指定在创建标签张量时使用的数据类型，通常是 <code>torch.FloatTensor</code> 或其他 PyTorch 支持的数据类型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_target_tensor</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span>, target_is_real</span>):<br>    <span class="hljs-keyword">if</span> target_is_real:<br>        create_label = ((self.real_label_var <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>) <span class="hljs-keyword">or</span><br>                        (self.real_label_var.numel() != <span class="hljs-built_in">input</span>.numel()))<br>        <span class="hljs-keyword">if</span> create_label:<br>            real_tensor = self.Tensor(<span class="hljs-built_in">input</span>.size()).fill_(self.real_label)<br>            self.real_label_var = Variable(real_tensor, requires_grad=<span class="hljs-literal">False</span>)<br>        target_tensor = self.real_label_var<br>    <span class="hljs-keyword">else</span>:<br>        create_label = ((self.fake_label_var <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>) <span class="hljs-keyword">or</span><br>                        (self.fake_label_var.numel() != <span class="hljs-built_in">input</span>.numel()))<br>        <span class="hljs-keyword">if</span> create_label:<br>            fake_tensor = self.Tensor(<span class="hljs-built_in">input</span>.size()).fill_(self.fake_label)<br>            self.fake_label_var = Variable(fake_tensor, requires_grad=<span class="hljs-literal">False</span>)<br>        target_tensor = self.fake_label_var<br>    <span class="hljs-keyword">return</span> target_tensor<br><br></code></pre></td></tr></table></figure>
<p>通过 <code>target_is_real</code> 参数判断需要创建的是真实标签还是假标签的张量。</p>
<p><code>if target_is_real</code>使用条件表达式检查 <code>self.real_label_var</code> 是否为 <code>None</code>（即之前没有创建过）或者其元素数量 (<code>numel()</code>) 是否与输入的元素数量不匹配。任一条件满足即重新创建标签张量。</p>
<p>如果需要，使用 <code>self.Tensor(input.size()).fill_(self.real_label)</code> 创建一个与输入相同大小的张量，并填充它为 <code>self.real_label</code>（通常为1.0）。</p>
<p><code>Variable</code>的用法： 1. <strong>封装<code>tensor</code></strong>: <code>Variable(real_tensor)</code>将<code>real_tensor</code>封装到一个<code>Variable</code>对象中。这样，原始的<code>tensor</code>现在有了自动梯度计算的功能。 2. <strong>梯度计算</strong>: 通过设置<code>requires_grad=False</code>，这个<code>Variable</code>被标记为不需要在反向传播过程中计算梯度。这通常用于目标标签或其他不需要学习的数据，因为标签的值是预设的，我们不需要对其进行优化。</p>
<p>从PyTorch 0.4.0版本开始，<code>Variable</code>和<code>tensor</code>被合并，现在直接使用<code>tensor</code>对象即可进行自动梯度计算，<code>Variable</code>类被废弃。现在可以直接对<code>tensor</code>设置<code>requires_grad</code>属性来控制梯度计算。如果您使用的是PyTorch的新版本，通常不需要显式使用<code>Variable</code>类。</p>
<p>假标签的处理步骤与真实标签处理类似，只是使用 <code>self.fake_label</code>（通常为0.0）来填充张量，创建假标签的目标张量。</p>
<p>最后，函数返回创建或更新后的目标张量 (<code>target_tensor</code>)，这将用于计算损失函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span>, target_is_real</span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(<span class="hljs-built_in">input</span>[<span class="hljs-number">0</span>], <span class="hljs-built_in">list</span>):<br>        loss = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> input_i <span class="hljs-keyword">in</span> <span class="hljs-built_in">input</span>:<br>            pred = input_i[-<span class="hljs-number">1</span>]<br>            target_tensor = self.get_target_tensor(pred, target_is_real)<br>            loss += self.loss(pred, target_tensor)<br>        <span class="hljs-keyword">return</span> loss<br>    <span class="hljs-keyword">else</span>:<br>        target_tensor = self.get_target_tensor(<span class="hljs-built_in">input</span>[-<span class="hljs-number">1</span>], target_is_real)<br>        <span class="hljs-keyword">return</span> self.loss(<span class="hljs-built_in">input</span>[-<span class="hljs-number">1</span>], target_tensor)<br></code></pre></td></tr></table></figure>
<p><code>__call__</code> 方法是 <code>GANLoss</code> 类的一个特殊方法，允许类的实例像函数一样被调用。这个方法处理输入数据，计算生成图像与目标图像（真实或假的）之间的损失。</p>
<p><code>if isinstance(input[0], list):</code> 检查输入 <code>input</code> 是否包含列表。这种情况通常发生在输入是一个批次数据，每个元素（或列表）包含一个或多个预测值。这种结构可能用于处理多输出的网络层。</p>
<p><strong>处理列表形式的输入</strong>: - 如果 <code>input</code> 包含列表，函数将初始化 <code>loss</code> 为 0，然后逐个处理列表中的每个元素（每个子列表代表一个单独的预测序列）。 - <strong>循环遍历每个输入元素</strong>： - 对于每个子列表 <code>input_i</code>，<code>pred = input_i[-1]</code> 提取该列表中的最后一个元素，假设它是最终的预测输出。 - 使用 <code>get_target_tensor(pred, target_is_real)</code> 生成与预测 <code>pred</code> 对应的目标张量。这里的 <code>target_is_real</code> 决定了目标张量表示真实图像还是假图像。 - 计算损失 <code>self.loss(pred, target_tensor)</code>，并将其累加到 <code>loss</code> 变量中。这里 <code>self.loss</code> 可以是 <code>MSELoss</code> 或 <code>BCELoss</code>，取决于类初始化时的设置。 - 返回计算得到的总损失。</p>
<p><strong>处理单一预测输出的输入</strong>: - <code>target_tensor = self.get_target_tensor(input[-1], target_is_real)</code> 获取对应的目标张量，同样基于 <code>target_is_real</code>。 - 计算并返回损失 <code>self.loss(input[-1], target_tensor)</code>。</p>
<h2 id="nlayerdiscriminator">NLayerDiscriminator</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">NLayerDiscriminator</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_nc, ndf=<span class="hljs-number">64</span>, n_layers=<span class="hljs-number">3</span>, norm_layer=nn.BatchNorm2d, use_sigmoid=<span class="hljs-literal">False</span>, getIntermFeat=<span class="hljs-literal">False</span>, Ddropout=<span class="hljs-literal">False</span>, spectral=<span class="hljs-literal">False</span></span>):<br>        <span class="hljs-built_in">super</span>(NLayerDiscriminator, self).__init__()<br>        self.getIntermFeat = getIntermFeat<br>        self.n_layers = n_layers<br>        self.spectral_norm = spectral_norm <span class="hljs-keyword">if</span> spectral <span class="hljs-keyword">else</span> <span class="hljs-keyword">lambda</span> x: x<br><br>        kw = <span class="hljs-number">4</span><br>        padw = <span class="hljs-built_in">int</span>(np.ceil((kw - <span class="hljs-number">1.0</span>) / <span class="hljs-number">2</span>))<br>        sequence = [[nn.Conv2d(input_nc, ndf, kernel_size=kw, stride=<span class="hljs-number">2</span>, padding=padw), nn.LeakyReLU(<span class="hljs-number">0.2</span>, <span class="hljs-literal">True</span>)]]<br><br>        nf = ndf<br>        <span class="hljs-keyword">for</span> n <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, n_layers):<br>            nf_prev = nf<br>            nf = <span class="hljs-built_in">min</span>(nf * <span class="hljs-number">2</span>, <span class="hljs-number">512</span>)<br>            <span class="hljs-keyword">if</span> Ddropout:<br>                sequence += [[<br>                self.spectral_norm(nn.Conv2d(nf_prev, nf, kernel_size=kw, stride=<span class="hljs-number">2</span>, padding=padw)),<br>                norm_layer(nf), nn.LeakyReLU(<span class="hljs-number">0.2</span>, <span class="hljs-literal">True</span>), nn.Dropout(<span class="hljs-number">0.5</span>)<br>            ]]<br>            <span class="hljs-keyword">else</span>:<br>                sequence += [[<br>                    self.spectral_norm(nn.Conv2d(nf_prev, nf, kernel_size=kw, stride=<span class="hljs-number">2</span>, padding=padw)),<br>                    norm_layer(nf), nn.LeakyReLU(<span class="hljs-number">0.2</span>, <span class="hljs-literal">True</span>)<br>                ]]<br></code></pre></td></tr></table></figure>
<p><code>sequence = [[nn.Conv2d(input_nc, ndf, kernel_size=kw, stride=2, padding=padw), nn.LeakyReLU(0.2, True)]]</code>这种写法可以方便之后使用列表乘法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python">nf_prev = nf<br>nf = <span class="hljs-built_in">min</span>(nf * <span class="hljs-number">2</span>, <span class="hljs-number">512</span>)<br>sequence += [[<br>    nn.Conv2d(nf_prev, nf, kernel_size=kw, stride=<span class="hljs-number">1</span>, padding=padw),<br>    norm_layer(nf),<br>    nn.LeakyReLU(<span class="hljs-number">0.2</span>, <span class="hljs-literal">True</span>)<br>]]<br><br>sequence += [[nn.Conv2d(nf, <span class="hljs-number">1</span>, kernel_size=kw, stride=<span class="hljs-number">1</span>, padding=padw)]]<br><br><span class="hljs-keyword">if</span> use_sigmoid:<br>    sequence += [[nn.Sigmoid()]]<br><br><span class="hljs-keyword">if</span> getIntermFeat:<br>    <span class="hljs-keyword">for</span> n <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(sequence)):<br>        <span class="hljs-built_in">setattr</span>(self, <span class="hljs-string">&#x27;model&#x27;</span> + <span class="hljs-built_in">str</span>(n), nn.Sequential(*sequence[n]))<br><span class="hljs-keyword">else</span>:<br>    sequence_stream = []<br>    <span class="hljs-keyword">for</span> n <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(sequence)):<br>        sequence_stream += sequence[n]<br>    self.model = nn.Sequential(*sequence_stream)<br></code></pre></td></tr></table></figure>
<p>这里就是定义了一些网络结构。</p>
<p>例如，如果<code>sequence[n]</code>是一个包含三个网络层（例如<code>[layer1, layer2, layer3]</code>）的列表，那么<code>nn.Sequential(*sequence[n])</code>等同于调用<code>nn.Sequential(layer1, layer2, layer3)</code>。这里的<code>nn.Sequential</code>是一个 PyTorch 中的模块，用于创建一个模块的容器，按顺序执行这些模块。</p>
<p>这里<code>getIntermFeat</code>表示是否需要从鉴别器中获取中间层的特征。如果是的话，就把中间层分别作为类的属性。反之就把整个网络作为类的属性。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span></span>):<br>    <span class="hljs-keyword">if</span> self.getIntermFeat:<br>        res = [<span class="hljs-built_in">input</span>]<br>        <span class="hljs-keyword">for</span> n <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.n_layers + <span class="hljs-number">2</span>):<br>            model = <span class="hljs-built_in">getattr</span>(self, <span class="hljs-string">&#x27;model&#x27;</span> + <span class="hljs-built_in">str</span>(n))<br>            res.append(model(res[-<span class="hljs-number">1</span>]))<br>        <span class="hljs-keyword">return</span> res[<span class="hljs-number">1</span>:]<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> self.model(<span class="hljs-built_in">input</span>)<br></code></pre></td></tr></table></figure>
<p>forward的时候，如果需要中间层的特征，就用res列表记录下每一个中间层的特征，否则就直接返回<code>self.model()</code>的结果。 ## MultiscaleDiscriminator</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MultiscaleDiscriminator</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_nc, ndf=<span class="hljs-number">64</span>, n_layers=<span class="hljs-number">3</span>, norm_layer=nn.BatchNorm2d,</span><br><span class="hljs-params">                 use_sigmoid=<span class="hljs-literal">False</span>, num_D=<span class="hljs-number">3</span>, getIntermFeat=<span class="hljs-literal">False</span>, Ddownx2=<span class="hljs-literal">False</span>, Ddropout=<span class="hljs-literal">False</span>, spectral=<span class="hljs-literal">False</span></span>):<br>        <span class="hljs-built_in">super</span>(MultiscaleDiscriminator, self).__init__()<br>        self.num_D = num_D<br>        self.n_layers = n_layers<br>        self.getIntermFeat = getIntermFeat<br>        self.Ddownx2 = Ddownx2<br></code></pre></td></tr></table></figure>
<ul>
<li><strong>参数解释</strong>:
<ul>
<li><code>input_nc</code>: 输入图像的通道数。</li>
<li><code>ndf</code>: 鉴别器的基本特征数。</li>
<li><code>n_layers</code>: 鉴别器中的层数。</li>
<li><code>norm_layer</code>: 使用的标准化层类型，这里默认是批标准化 <code>BatchNorm2d</code>。</li>
<li><code>use_sigmoid</code>: 在输出层是否使用 <code>Sigmoid</code> 激活函数。</li>
<li><code>num_D</code>: 多尺度鉴别器的数量。</li>
<li><code>getIntermFeat</code>: 是否获取并输出每个层的中间特征。</li>
<li><code>Ddownx2</code>: 是否在每个鉴别器之间对输入进行下采样。</li>
<li><code>Ddropout</code>: 是否在卷积层之后添加 Dropout。</li>
<li><code>spectral</code>: 是否应用 spectral normalization。</li>
</ul></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_D):<br>    netD = NLayerDiscriminator(input_nc, ndf, n_layers, norm_layer,<br>                        use_sigmoid,getIntermFeat,Ddropout,spectral=spectral)<br>    <span class="hljs-keyword">if</span> getIntermFeat:<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_layers + <span class="hljs-number">2</span>):<br>            <span class="hljs-built_in">setattr</span>(self, <span class="hljs-string">&#x27;scale&#x27;</span> + <span class="hljs-built_in">str</span>(i) + <span class="hljs-string">&#x27;_layer&#x27;</span> +<br>                    <span class="hljs-built_in">str</span>(j), <span class="hljs-built_in">getattr</span>(netD, <span class="hljs-string">&#x27;model&#x27;</span> + <span class="hljs-built_in">str</span>(j)))<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-built_in">setattr</span>(self, <span class="hljs-string">&#x27;layer&#x27;</span> + <span class="hljs-built_in">str</span>(i), netD.model)<br><br>self.downsample = nn.AvgPool2d(<br>    <span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>], count_include_pad=<span class="hljs-literal">False</span>)<br><br></code></pre></td></tr></table></figure>
<p>这里循环创建了 <code>num_D</code> 个鉴别器，每个鉴别器都是 <code>NLayerDiscriminator</code> 类的一个实例。如果<code>getIntermFeat == True</code>，那么这个类就会保存每一个<code>NLayerDiscriminator</code>的每一个中间层。否则就只保存每一个<code>NLayerDiscriminator</code>。</p>
<p>最后就是创建一个Average Pool层。参数 <code>count_include_pad</code> 在 <code>nn.AvgPool2d</code> 中用于控制在计算平均值时是否将填充（padding）像素包括在内。</p>
<p>剩下的就是一些helper function，这里就不再讲解。</p>
<h1 id="network_generator.py">network_generator.py</h1>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">BaseNetwork</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(BaseNetwork, self).__init__()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">print_network</span>(<span class="hljs-params">self</span>):<br>        num_params = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.parameters():<br>            num_params += param.numel()<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Network [&#123;&#125;] was created. Total number of parameters: &#123;:.1f&#125; million. &quot;</span><br>              <span class="hljs-string">&quot;To see the architecture, do print(network).&quot;</span>.<span class="hljs-built_in">format</span>(self.__class__.__name__, num_params / <span class="hljs-number">1000000</span>))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">init_weights</span>(<span class="hljs-params">self, init_type=<span class="hljs-string">&#x27;normal&#x27;</span>, gain=<span class="hljs-number">0.02</span></span>):<br>        <span class="hljs-keyword">def</span> <span class="hljs-title function_">init_func</span>(<span class="hljs-params">m</span>):<br>            classname = m.__class__.__name__<br>            <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;BatchNorm2d&#x27;</span> <span class="hljs-keyword">in</span> classname:<br>                <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(m, <span class="hljs-string">&#x27;weight&#x27;</span>) <span class="hljs-keyword">and</span> m.weight <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>                    init.normal_(m.weight.data, <span class="hljs-number">1.0</span>, gain)<br>                <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(m, <span class="hljs-string">&#x27;bias&#x27;</span>) <span class="hljs-keyword">and</span> m.bias <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>                    init.constant_(m.bias.data, <span class="hljs-number">0.0</span>)<br>            <span class="hljs-keyword">elif</span> (<span class="hljs-string">&#x27;Conv&#x27;</span> <span class="hljs-keyword">in</span> classname <span class="hljs-keyword">or</span> <span class="hljs-string">&#x27;Linear&#x27;</span> <span class="hljs-keyword">in</span> classname) <span class="hljs-keyword">and</span> <span class="hljs-built_in">hasattr</span>(m, <span class="hljs-string">&#x27;weight&#x27;</span>):<br>                <span class="hljs-keyword">if</span> init_type == <span class="hljs-string">&#x27;normal&#x27;</span>:<br>                    init.normal_(m.weight.data, <span class="hljs-number">0.0</span>, gain)<br>                <span class="hljs-keyword">elif</span> init_type == <span class="hljs-string">&#x27;xavier&#x27;</span>:<br>                    init.xavier_normal_(m.weight.data, gain=gain)<br>                <span class="hljs-keyword">elif</span> init_type == <span class="hljs-string">&#x27;xavier_uniform&#x27;</span>:<br>                    init.xavier_uniform_(m.weight.data, gain=<span class="hljs-number">1.0</span>)<br>                <span class="hljs-keyword">elif</span> init_type == <span class="hljs-string">&#x27;kaiming&#x27;</span>:<br>                    init.kaiming_normal_(m.weight.data, a=<span class="hljs-number">0</span>, mode=<span class="hljs-string">&#x27;fan_in&#x27;</span>)<br>                <span class="hljs-keyword">elif</span> init_type == <span class="hljs-string">&#x27;orthogonal&#x27;</span>:<br>                    init.orthogonal_(m.weight.data, gain=gain)<br>                <span class="hljs-keyword">elif</span> init_type == <span class="hljs-string">&#x27;none&#x27;</span>:  <span class="hljs-comment"># uses pytorch&#x27;s default init method</span><br>                    m.reset_parameters()<br>                <span class="hljs-keyword">else</span>:<br>                    <span class="hljs-keyword">raise</span> NotImplementedError(<span class="hljs-string">&quot;initialization method &#x27;&#123;&#125;&#x27; is not implemented&quot;</span>.<span class="hljs-built_in">format</span>(init_type))<br>                <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(m, <span class="hljs-string">&#x27;bias&#x27;</span>) <span class="hljs-keyword">and</span> m.bias <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>                    init.constant_(m.bias.data, <span class="hljs-number">0.0</span>)<br><br>        self.apply(init_func)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, *inputs</span>):<br>        <span class="hljs-keyword">pass</span><br></code></pre></td></tr></table></figure>
<p>这里定义了打印网络的函数，定义了初始化权重的方法。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MaskNorm</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, norm_nc</span>):<br>        <span class="hljs-built_in">super</span>(MaskNorm, self).__init__()<br><br>        self.norm_layer = nn.InstanceNorm2d(norm_nc, affine=<span class="hljs-literal">False</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">normalize_region</span>(<span class="hljs-params">self, region, mask</span>):<br>        b, c, h, w = region.size()<br><br>        num_pixels = mask.<span class="hljs-built_in">sum</span>((<span class="hljs-number">2</span>, <span class="hljs-number">3</span>), keepdim=<span class="hljs-literal">True</span>)  <span class="hljs-comment"># size: (b, 1, 1, 1)</span><br>        num_pixels[num_pixels == <span class="hljs-number">0</span>] = <span class="hljs-number">1</span><br>        mu = region.<span class="hljs-built_in">sum</span>((<span class="hljs-number">2</span>, <span class="hljs-number">3</span>), keepdim=<span class="hljs-literal">True</span>) / num_pixels  <span class="hljs-comment"># size: (b, c, 1, 1)</span><br><br>        normalized_region = self.norm_layer(region + (<span class="hljs-number">1</span> - mask) * mu)<br>        <span class="hljs-keyword">return</span> normalized_region * torch.sqrt(num_pixels / (h * w))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x, mask</span>):<br>        mask = mask.detach()<br>        normalized_foreground = self.normalize_region(x * mask, mask)<br>        normalized_background = self.normalize_region(x * (<span class="hljs-number">1</span> - mask), <span class="hljs-number">1</span> - mask)<br>        <span class="hljs-keyword">return</span> normalized_foreground + normalized_background<br></code></pre></td></tr></table></figure>
<p>这里定义了MaskNorm，沿用了VITON-HD的代码，实际效果就是VITON-HD中所说的ALIASNorm.</p>
<h2 id="spadenorm">SPADENorm</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">SPADENorm</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,opt, norm_type, norm_nc, label_nc</span>):<br>        <span class="hljs-built_in">super</span>(SPADENorm, self).__init__()<br>        self.param_opt=opt<br>        self.noise_scale = nn.Parameter(torch.zeros(norm_nc))<br><br>        <span class="hljs-keyword">assert</span> norm_type.startswith(<span class="hljs-string">&#x27;alias&#x27;</span>)<br>        param_free_norm_type = norm_type[<span class="hljs-built_in">len</span>(<span class="hljs-string">&#x27;alias&#x27;</span>):]<br>        <span class="hljs-keyword">if</span> param_free_norm_type == <span class="hljs-string">&#x27;batch&#x27;</span>:<br>            self.param_free_norm = nn.BatchNorm2d(norm_nc, affine=<span class="hljs-literal">False</span>)<br>        <span class="hljs-keyword">elif</span> param_free_norm_type == <span class="hljs-string">&#x27;instance&#x27;</span>:<br>            self.param_free_norm = nn.InstanceNorm2d(norm_nc, affine=<span class="hljs-literal">False</span>)<br>        <span class="hljs-keyword">elif</span> param_free_norm_type == <span class="hljs-string">&#x27;mask&#x27;</span>:<br>            self.param_free_norm = MaskNorm(norm_nc)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">raise</span> ValueError(<br>                <span class="hljs-string">&quot;&#x27;&#123;&#125;&#x27; is not a recognized parameter-free normalization type in SPADENorm&quot;</span>.<span class="hljs-built_in">format</span>(param_free_norm_type)<br>            )<br><br>        nhidden = <span class="hljs-number">128</span><br>        ks = <span class="hljs-number">3</span><br>        pw = ks // <span class="hljs-number">2</span><br>        self.conv_shared = nn.Sequential(nn.Conv2d(label_nc, nhidden, kernel_size=ks, padding=pw), nn.ReLU())<br>        self.conv_gamma = nn.Conv2d(nhidden, norm_nc, kernel_size=ks, padding=pw)<br>        self.conv_beta = nn.Conv2d(nhidden, norm_nc, kernel_size=ks, padding=pw)<br></code></pre></td></tr></table></figure>
<p>SPADE（Spatially-Adaptive (De)normalization）是一种先进的归一化技术，特别用于生成模型中，如生成对抗网络（GANs）。这种技术首次在论文《Semantic Image Synthesis with Spatially-Adaptive Normalization》中被详细介绍，该论文主要针对语义图像合成任务。 ### SPADENorm 的工作原理： - <strong>目的</strong>：传统的归一化技术（如Batch Normalization）会移除特征图中的语义信息，这对于分类任务可能是有利的，但在图像生成任务中可能会导致生成质量下降。SPADE 的目的是在进行归一化的同时保留足够的语义信息，以提高生成图像的质量和相关性。 - <strong>操作</strong>：SPADENorm 替代了标准的归一化方法中的scale和bias参数，使用从输入语义布局（例如，语义标签图）学习到的参数来调制归一化后的特征图。具体来说，它首先对特征图进行标准的归一化处理（均值为 0，方差为 1），然后通过一个从语义图学习的网络（通常是卷积网络）来预测调制（modulate）每个像素的scale和bias参数。 - <strong>结构</strong>：这个调制网络接受语义布局图作为输入，输出与归一化特征图尺寸相同的scale和bias图，这些图随后用于调整归一化特征图的每个像素。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x, seg, misalign_mask=<span class="hljs-literal">None</span></span>):<br>    <span class="hljs-comment"># Part 1. Generate parameter-free normalized activations.</span><br>    b, c, h, w = x.size()<br>    <span class="hljs-keyword">if</span> self.param_opt.cuda :<br>        noise = (torch.randn(b, w, h, <span class="hljs-number">1</span>).cuda() * self.noise_scale).transpose(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>)<br>    <span class="hljs-keyword">else</span>:<br>        noise = (torch.randn(b, w, h, <span class="hljs-number">1</span>)* self.noise_scale).transpose(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>)<br><br>    <span class="hljs-keyword">if</span> misalign_mask <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>        normalized = self.param_free_norm(x + noise)<br>    <span class="hljs-keyword">else</span>:<br>        normalized = self.param_free_norm(x + noise, misalign_mask)<br><br>    <span class="hljs-comment"># Part 2. Produce affine parameters conditioned on the segmentation map.</span><br>    actv = self.conv_shared(seg)<br>    gamma = self.conv_gamma(actv)<br>    beta = self.conv_beta(actv)<br><br>    <span class="hljs-comment"># Apply the affine parameters.</span><br>    output = normalized * (<span class="hljs-number">1</span> + gamma) + beta<br>    <span class="hljs-keyword">return</span> output<br></code></pre></td></tr></table></figure>
<p>这后面的处理也是和VITON-HD一样的，只是这里明确指出了这个是使用了SPADENorm。即通过一个从segmentation map学习的网络（通常是卷积网络）来预测调制（modulate）每个像素的scale和bias参数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">SPADEResBlock</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, opt, input_nc, output_nc, use_mask_norm=<span class="hljs-literal">True</span></span>):<br>        <span class="hljs-built_in">super</span>(SPADEResBlock, self).__init__()<br>        self.param_opt=opt<br>        self.learned_shortcut = (input_nc != output_nc)<br>        middle_nc = <span class="hljs-built_in">min</span>(input_nc, output_nc)<br><br>        self.conv_0 = nn.Conv2d(input_nc, middle_nc, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>)<br>        self.conv_1 = nn.Conv2d(middle_nc, output_nc, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">if</span> self.learned_shortcut:<br>            self.conv_s = nn.Conv2d(input_nc, output_nc, kernel_size=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">False</span>)<br><br>        subnorm_type = opt.norm_G<br>        <span class="hljs-keyword">if</span> subnorm_type.startswith(<span class="hljs-string">&#x27;spectral&#x27;</span>):<br>            subnorm_type = subnorm_type[<span class="hljs-built_in">len</span>(<span class="hljs-string">&#x27;spectral&#x27;</span>):]<br>            self.conv_0 = spectral_norm(self.conv_0)<br>            self.conv_1 = spectral_norm(self.conv_1)<br>            <span class="hljs-keyword">if</span> self.learned_shortcut:<br>                self.conv_s = spectral_norm(self.conv_s)<br><br>        gen_semantic_nc = opt.gen_semantic_nc<br>        <span class="hljs-keyword">if</span> use_mask_norm:<br>            subnorm_type = <span class="hljs-string">&#x27;aliasmask&#x27;</span><br>            gen_semantic_nc = gen_semantic_nc + <span class="hljs-number">1</span><br><br>        self.norm_0 = SPADENorm(opt,subnorm_type, input_nc, gen_semantic_nc)<br>        self.norm_1 = SPADENorm(opt,subnorm_type, middle_nc, gen_semantic_nc)<br>        <span class="hljs-keyword">if</span> self.learned_shortcut:<br>            self.norm_s = SPADENorm(opt,subnorm_type, input_nc, gen_semantic_nc)<br><br>        self.relu = nn.LeakyReLU(<span class="hljs-number">0.2</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">shortcut</span>(<span class="hljs-params">self, x, seg, misalign_mask</span>):<br>        <span class="hljs-keyword">if</span> self.learned_shortcut:<br>            <span class="hljs-keyword">return</span> self.conv_s(self.norm_s(x, seg, misalign_mask))<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">return</span> x<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x, seg, misalign_mask=<span class="hljs-literal">None</span></span>):<br>        seg = F.interpolate(seg, size=x.size()[<span class="hljs-number">2</span>:], mode=<span class="hljs-string">&#x27;nearest&#x27;</span>)<br>        <span class="hljs-keyword">if</span> misalign_mask <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            misalign_mask = F.interpolate(misalign_mask, size=x.size()[<span class="hljs-number">2</span>:], mode=<span class="hljs-string">&#x27;nearest&#x27;</span>)<br><br>        x_s = self.shortcut(x, seg, misalign_mask)<br><br>        dx = self.conv_0(self.relu(self.norm_0(x, seg, misalign_mask)))<br>        dx = self.conv_1(self.relu(self.norm_1(dx, seg, misalign_mask)))<br>        output = x_s + dx<br>        <span class="hljs-keyword">return</span> output<br></code></pre></td></tr></table></figure>
<p>这里也同样沿用了VITON-HD的代码，内容基本和VITON-HD中的ALIASResBlock基本一致。</p>
<p>下面的SPADEGenerator也和VITON-HD的ALIASGenerator几乎一模一样，不过为了完整性我还是把代码贴在下面。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">SPADEGenerator</span>(<span class="hljs-title class_ inherited__">BaseNetwork</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, opt, input_nc</span>):<br>        <span class="hljs-built_in">super</span>(SPADEGenerator, self).__init__()<br>        self.num_upsampling_layers = opt.num_upsampling_layers<br>        self.param_opt=opt<br>        self.sh, self.sw = self.compute_latent_vector_size(opt)<br><br>        nf = opt.ngf<br>        self.conv_0 = nn.Conv2d(input_nc, nf * <span class="hljs-number">16</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">8</span>):<br>            self.add_module(<span class="hljs-string">&#x27;conv_&#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(i), nn.Conv2d(input_nc, <span class="hljs-number">16</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>))<br><br>        self.head_0 = SPADEResBlock(opt, nf * <span class="hljs-number">16</span>, nf * <span class="hljs-number">16</span>, use_mask_norm=<span class="hljs-literal">False</span>)<br><br>        self.G_middle_0 = SPADEResBlock(opt, nf * <span class="hljs-number">16</span> + <span class="hljs-number">16</span>, nf * <span class="hljs-number">16</span>, use_mask_norm=<span class="hljs-literal">False</span>)<br>        self.G_middle_1 = SPADEResBlock(opt, nf * <span class="hljs-number">16</span> + <span class="hljs-number">16</span>, nf * <span class="hljs-number">16</span>, use_mask_norm=<span class="hljs-literal">False</span>)<br><br>        self.up_0 = SPADEResBlock(opt, nf * <span class="hljs-number">16</span> + <span class="hljs-number">16</span>, nf * <span class="hljs-number">8</span>, use_mask_norm=<span class="hljs-literal">False</span>)<br>        self.up_1 = SPADEResBlock(opt, nf * <span class="hljs-number">8</span> + <span class="hljs-number">16</span>, nf * <span class="hljs-number">4</span>, use_mask_norm=<span class="hljs-literal">False</span>)<br>        self.up_2 = SPADEResBlock(opt, nf * <span class="hljs-number">4</span> + <span class="hljs-number">16</span>, nf * <span class="hljs-number">2</span>, use_mask_norm=<span class="hljs-literal">False</span>)<br>        self.up_3 = SPADEResBlock(opt, nf * <span class="hljs-number">2</span> + <span class="hljs-number">16</span>, nf * <span class="hljs-number">1</span>, use_mask_norm=<span class="hljs-literal">False</span>)<br>        <span class="hljs-keyword">if</span> self.num_upsampling_layers == <span class="hljs-string">&#x27;most&#x27;</span>:<br>            self.up_4 = SPADEResBlock(opt, nf * <span class="hljs-number">1</span> + <span class="hljs-number">16</span>, nf // <span class="hljs-number">2</span>, use_mask_norm=<span class="hljs-literal">False</span>)<br>            nf = nf // <span class="hljs-number">2</span><br><br>        self.conv_img = nn.Conv2d(nf, <span class="hljs-number">3</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>)<br><br>        self.up = nn.Upsample(scale_factor=<span class="hljs-number">2</span>, mode=<span class="hljs-string">&#x27;nearest&#x27;</span>)<br>        self.relu = nn.LeakyReLU(<span class="hljs-number">0.2</span>)<br>        self.tanh = nn.Tanh()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_latent_vector_size</span>(<span class="hljs-params">self, opt</span>):<br>        <span class="hljs-keyword">if</span> self.num_upsampling_layers == <span class="hljs-string">&#x27;normal&#x27;</span>:<br>            num_up_layers = <span class="hljs-number">5</span><br>        <span class="hljs-keyword">elif</span> self.num_upsampling_layers == <span class="hljs-string">&#x27;more&#x27;</span>:<br>            num_up_layers = <span class="hljs-number">6</span><br>        <span class="hljs-keyword">elif</span> self.num_upsampling_layers == <span class="hljs-string">&#x27;most&#x27;</span>:<br>            num_up_layers = <span class="hljs-number">7</span><br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&quot;opt.num_upsampling_layers &#x27;&#123;&#125;&#x27; is not recognized&quot;</span>.<span class="hljs-built_in">format</span>(self.num_upsampling_layers))<br><br>        sh = opt.fine_height // <span class="hljs-number">2</span>**num_up_layers<br>        sw = opt.fine_width // <span class="hljs-number">2</span>**num_up_layers<br>        <span class="hljs-keyword">return</span> sh, sw<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x, seg</span>):<br>        samples = [F.interpolate(x, size=(self.sh * <span class="hljs-number">2</span>**i, self.sw * <span class="hljs-number">2</span>**i), mode=<span class="hljs-string">&#x27;nearest&#x27;</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">8</span>)]<br>        features = [self._modules[<span class="hljs-string">&#x27;conv_&#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(i)](samples[i]) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">8</span>)]<br><br>        x = self.head_0(features[<span class="hljs-number">0</span>], seg)<br>        x = self.up(x)<br>        x = self.G_middle_0(torch.cat((x, features[<span class="hljs-number">1</span>]), <span class="hljs-number">1</span>), seg)<br>        <span class="hljs-keyword">if</span> self.num_upsampling_layers <span class="hljs-keyword">in</span> [<span class="hljs-string">&#x27;more&#x27;</span>, <span class="hljs-string">&#x27;most&#x27;</span>]:<br>            x = self.up(x)<br>        x = self.G_middle_1(torch.cat((x, features[<span class="hljs-number">2</span>]), <span class="hljs-number">1</span>), seg)<br><br>        x = self.up(x)<br>        x = self.up_0(torch.cat((x, features[<span class="hljs-number">3</span>]), <span class="hljs-number">1</span>), seg)<br>        x = self.up(x)<br>        x = self.up_1(torch.cat((x, features[<span class="hljs-number">4</span>]), <span class="hljs-number">1</span>), seg)<br>        x = self.up(x)<br>        x = self.up_2(torch.cat((x, features[<span class="hljs-number">5</span>]), <span class="hljs-number">1</span>), seg)<br>        x = self.up(x)<br>        x = self.up_3(torch.cat((x, features[<span class="hljs-number">6</span>]), <span class="hljs-number">1</span>), seg)<br>        <span class="hljs-keyword">if</span> self.num_upsampling_layers == <span class="hljs-string">&#x27;most&#x27;</span>:<br>            x = self.up(x)<br>            x = self.up_4(torch.cat((x, features[<span class="hljs-number">7</span>]), <span class="hljs-number">1</span>), seg)<br><br>        x = self.conv_img(self.relu(x))<br>        <span class="hljs-keyword">return</span> self.tanh(x)<br></code></pre></td></tr></table></figure>
<h2 id="another-nlayerdiscriminator">Another NLayerDiscriminator</h2>
<p>这里又定义了一个NLayerDiscriminator <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">NLayerDiscriminator</span>(<span class="hljs-title class_ inherited__">BaseNetwork</span>):<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, opt</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.no_ganFeat_loss = opt.no_ganFeat_loss<br>        nf = opt.ndf<br><br>        kw = <span class="hljs-number">4</span><br>        pw = <span class="hljs-built_in">int</span>(np.ceil((kw - <span class="hljs-number">1.0</span>) / <span class="hljs-number">2</span>))<br>        norm_layer = get_nonspade_norm_layer(opt.norm_D)<br><br>        input_nc = opt.gen_semantic_nc + <span class="hljs-number">3</span><br>        <span class="hljs-comment"># input_nc = opt.gen_semantic_nc + 13</span><br>        sequence = [[nn.Conv2d(input_nc, nf, kernel_size=kw, stride=<span class="hljs-number">2</span>, padding=pw),<br>                     nn.LeakyReLU(<span class="hljs-number">0.2</span>, <span class="hljs-literal">False</span>)]]<br><br>        <span class="hljs-keyword">for</span> n <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, opt.n_layers_D):<br>            nf_prev = nf<br>            nf = <span class="hljs-built_in">min</span>(nf * <span class="hljs-number">2</span>, <span class="hljs-number">512</span>)<br>            sequence += [[norm_layer(nn.Conv2d(nf_prev, nf, kernel_size=kw, stride=<span class="hljs-number">2</span>, padding=pw)),<br>                          nn.LeakyReLU(<span class="hljs-number">0.2</span>, <span class="hljs-literal">False</span>)]]<br><br>        sequence += [[nn.Conv2d(nf, <span class="hljs-number">1</span>, kernel_size=kw, stride=<span class="hljs-number">1</span>, padding=pw)]]<br><br>        <span class="hljs-comment"># We divide the layers into groups to extract intermediate layer outputs</span><br>        <span class="hljs-keyword">for</span> n <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(sequence)):<br>            self.add_module(<span class="hljs-string">&#x27;model&#x27;</span> + <span class="hljs-built_in">str</span>(n), nn.Sequential(*sequence[n]))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span></span>):<br>        results = [<span class="hljs-built_in">input</span>]<br>        <span class="hljs-keyword">for</span> submodel <span class="hljs-keyword">in</span> self.children():<br>            intermediate_output = submodel(results[-<span class="hljs-number">1</span>])<br>            results.append(intermediate_output)<br><br>        get_intermediate_features = <span class="hljs-keyword">not</span> self.no_ganFeat_loss<br>        <span class="hljs-keyword">if</span> get_intermediate_features:<br>            <span class="hljs-keyword">return</span> results[<span class="hljs-number">1</span>:]<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">return</span> results[-<span class="hljs-number">1</span>]<br></code></pre></td></tr></table></figure></p>
<p>不同点在于，这次初始化网络的时候默认把中间层分开，然后在最后forward也算出所有中间特征，然后再视情况决定要不要返回中间的特征。</p>
<h2 id="another-multiscalediscriminator">Another MultiscaleDiscriminator</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MultiscaleDiscriminator</span>(<span class="hljs-title class_ inherited__">BaseNetwork</span>):<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, opt</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.no_ganFeat_loss = opt.no_ganFeat_loss<br><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(opt.num_D):<br>            subnetD = NLayerDiscriminator(opt)<br>            self.add_module(<span class="hljs-string">&#x27;discriminator_%d&#x27;</span> % i, subnetD)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">downsample</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span></span>):<br>        <span class="hljs-keyword">return</span> F.avg_pool2d(<span class="hljs-built_in">input</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>], count_include_pad=<span class="hljs-literal">False</span>)<br><br>    <span class="hljs-comment"># Returns list of lists of discriminator outputs.</span><br>    <span class="hljs-comment"># The final result is of size opt.num_D x opt.n_layers_D</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span></span>):<br>        result = []<br>        get_intermediate_features = <span class="hljs-keyword">not</span> self.no_ganFeat_loss<br>        <span class="hljs-keyword">for</span> name, D <span class="hljs-keyword">in</span> self.named_children():<br>            out = D(<span class="hljs-built_in">input</span>)<br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> get_intermediate_features:<br>                out = [out]<br>            result.append(out)<br>            <span class="hljs-built_in">input</span> = self.downsample(<span class="hljs-built_in">input</span>)<br><br>        <span class="hljs-keyword">return</span> result<br></code></pre></td></tr></table></figure>
<p><code>for name, D in self.named_children():</code> - <code>named_children()</code> 是 <code>nn.Module</code> 的一个方法，它返回一个迭代器，包含模块的所有子模块（children），每个子模块以 (name, module) 的形式呈现。这行代码的意思是对每个子模块进行遍历。</p>
<h2 id="ganloss-for-image-generator">GANLoss for Image Generator</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">GANLoss</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, gan_mode, target_real_label=<span class="hljs-number">1.0</span>, target_fake_label=<span class="hljs-number">0.0</span>, tensor=torch.FloatTensor</span>):<br>        <span class="hljs-built_in">super</span>(GANLoss, self).__init__()<br>        self.real_label = target_real_label<br>        self.fake_label = target_fake_label<br>        self.real_label_tensor = <span class="hljs-literal">None</span><br>        self.fake_label_tensor = <span class="hljs-literal">None</span><br>        self.zero_tensor = <span class="hljs-literal">None</span><br>        self.Tensor = tensor<br>        self.gan_mode = gan_mode<br>        <span class="hljs-keyword">if</span> gan_mode == <span class="hljs-string">&#x27;ls&#x27;</span>:<br>            <span class="hljs-keyword">pass</span><br>        <span class="hljs-keyword">elif</span> gan_mode == <span class="hljs-string">&#x27;original&#x27;</span>:<br>            <span class="hljs-keyword">pass</span><br>        <span class="hljs-keyword">elif</span> gan_mode == <span class="hljs-string">&#x27;w&#x27;</span>:<br>            <span class="hljs-keyword">pass</span><br>        <span class="hljs-keyword">elif</span> gan_mode == <span class="hljs-string">&#x27;hinge&#x27;</span>:<br>            <span class="hljs-keyword">pass</span><br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&#x27;Unexpected gan_mode &#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(gan_mode))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_target_tensor</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span>, target_is_real</span>):<br>        <span class="hljs-keyword">if</span> target_is_real:<br>            <span class="hljs-keyword">if</span> self.real_label_tensor <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>                self.real_label_tensor = self.Tensor(<span class="hljs-number">1</span>).fill_(self.real_label)<br>                self.real_label_tensor.requires_grad_(<span class="hljs-literal">False</span>)<br>            <span class="hljs-keyword">return</span> self.real_label_tensor.expand_as(<span class="hljs-built_in">input</span>)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">if</span> self.fake_label_tensor <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>                self.fake_label_tensor = self.Tensor(<span class="hljs-number">1</span>).fill_(self.fake_label)<br>                self.fake_label_tensor.requires_grad_(<span class="hljs-literal">False</span>)<br>            <span class="hljs-keyword">return</span> self.fake_label_tensor.expand_as(<span class="hljs-built_in">input</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_zero_tensor</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span></span>):<br>        <span class="hljs-keyword">if</span> self.zero_tensor <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            self.zero_tensor = self.Tensor(<span class="hljs-number">1</span>).fill_(<span class="hljs-number">0</span>)<br>            self.zero_tensor.requires_grad_(<span class="hljs-literal">False</span>)<br>        <span class="hljs-keyword">return</span> self.zero_tensor.expand_as(<span class="hljs-built_in">input</span>)<br></code></pre></td></tr></table></figure>
<p><code>gan_mode</code>: 一个字符串参数，指定使用的GAN模式，比如 <code>'ls'</code>（最小二乘GAN），<code>'original'</code>（原始GAN），<code>'w'</code>（Wasserstein GAN），或者 <code>'hinge'</code>。</p>
<p>然后代码根据不同的 <code>gan_mode</code> 设置损失函数的具体行为。当前代码示例中，对每种模式都只是简单通过 <code>pass</code> 语句占位，没有具体的实现。如果传入的 <code>gan_mode</code> 不是预期值之一，会抛出一个 <code>ValueError</code>。</p>
<p><code>get_target_tensor</code>方法用于生成目标张量，这个张量将用于计算损失函数。根据 <code>target_is_real</code> 的真假决定返回针对真实数据的标签张量还是假数据的标签张量。如果相应的张量尚未初始化，则创建一个新的填充了相应标签值的张量，并设置其不需要梯度。</p>
<p><code>get_zero_tensor</code>方法用于生成一个值为0的张量，主要用于计算某些类型的GAN损失函数时，需要用到0值的场景。同样地，如果零值张量尚未初始化，则创建它。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">loss</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span>, target_is_real, for_discriminator=<span class="hljs-literal">True</span></span>):<br>    <span class="hljs-keyword">if</span> self.gan_mode == <span class="hljs-string">&#x27;original&#x27;</span>:  <span class="hljs-comment"># cross entropy loss</span><br>        target_tensor = self.get_target_tensor(<span class="hljs-built_in">input</span>, target_is_real)<br>        loss = F.binary_cross_entropy_with_logits(<span class="hljs-built_in">input</span>, target_tensor)<br>        <span class="hljs-keyword">return</span> loss<br>    <span class="hljs-keyword">elif</span> self.gan_mode == <span class="hljs-string">&#x27;ls&#x27;</span>:<br>        target_tensor = self.get_target_tensor(<span class="hljs-built_in">input</span>, target_is_real)<br>        <span class="hljs-keyword">return</span> F.mse_loss(<span class="hljs-built_in">input</span>, target_tensor)<br>    <span class="hljs-keyword">elif</span> self.gan_mode == <span class="hljs-string">&#x27;hinge&#x27;</span>:<br>        <span class="hljs-keyword">if</span> for_discriminator:<br>            <span class="hljs-keyword">if</span> target_is_real:<br>                minval = torch.<span class="hljs-built_in">min</span>(<span class="hljs-built_in">input</span> - <span class="hljs-number">1</span>, self.get_zero_tensor(<span class="hljs-built_in">input</span>))<br>                loss = -torch.mean(minval)<br>            <span class="hljs-keyword">else</span>:<br>                minval = torch.<span class="hljs-built_in">min</span>(-<span class="hljs-built_in">input</span> - <span class="hljs-number">1</span>, self.get_zero_tensor(<span class="hljs-built_in">input</span>))<br>                loss = -torch.mean(minval)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">assert</span> target_is_real, <span class="hljs-string">&quot;The generator&#x27;s hinge loss must be aiming for real&quot;</span><br>            loss = -torch.mean(<span class="hljs-built_in">input</span>)<br>        <span class="hljs-keyword">return</span> loss<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-comment"># wgan</span><br>        <span class="hljs-keyword">if</span> target_is_real:<br>            <span class="hljs-keyword">return</span> -<span class="hljs-built_in">input</span>.mean()<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">return</span> <span class="hljs-built_in">input</span>.mean()<br></code></pre></td></tr></table></figure>
<p>这里是根据不同的gan_mode选用了不同的loss function。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span>, target_is_real, for_discriminator=<span class="hljs-literal">True</span></span>):<br>    <span class="hljs-comment"># computing loss is a bit complicated because |input| may not be</span><br>    <span class="hljs-comment"># a tensor, but list of tensors in case of multiscale discriminator</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(<span class="hljs-built_in">input</span>, <span class="hljs-built_in">list</span>):<br>        loss = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> pred_i <span class="hljs-keyword">in</span> <span class="hljs-built_in">input</span>:<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(pred_i, <span class="hljs-built_in">list</span>):<br>                pred_i = pred_i[-<span class="hljs-number">1</span>]<br>            loss_tensor = self.loss(pred_i, target_is_real, for_discriminator)<br>            bs = <span class="hljs-number">1</span> <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(loss_tensor.size()) == <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> loss_tensor.size(<span class="hljs-number">0</span>)<br>            new_loss = torch.mean(loss_tensor.view(bs, -<span class="hljs-number">1</span>), dim=<span class="hljs-number">1</span>)<br>            loss += new_loss<br>        <span class="hljs-keyword">return</span> loss / <span class="hljs-built_in">len</span>(<span class="hljs-built_in">input</span>)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> self.loss(<span class="hljs-built_in">input</span>, target_is_real, for_discriminator)<br></code></pre></td></tr></table></figure>
<p>然后call的时候，这里的注释能帮助我们理解为什么要看input是不是一个list（ |input| may not be a tensor, but list of tensors in case of multiscale discriminator）</p>
<p>多尺度判别器是一种特殊类型的判别器，它在多个不同的尺度（即不同的分辨率或细节层次）上分析输入数据，以提高模型的性能和鉴别能力。</p>
<p>这里的<code>for_discriminator</code>我暂时还不知道是什么意思，之后再看看各种关于GAN的论文吧。</p>
<h2 id="get_nonspade_norm_layer">get_nonspade_norm_layer</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_nonspade_norm_layer</span>(<span class="hljs-params">norm_type=<span class="hljs-string">&#x27;instance&#x27;</span></span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_out_channel</span>(<span class="hljs-params">layer</span>):<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(layer, <span class="hljs-string">&#x27;out_channels&#x27;</span>):<br>            <span class="hljs-keyword">return</span> <span class="hljs-built_in">getattr</span>(layer, <span class="hljs-string">&#x27;out_channels&#x27;</span>)<br>        <span class="hljs-keyword">return</span> layer.weight.size(<span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure>
<p>首先这个函数里面定义了另外一个函数，以获得当前layer的output_channels，以方便使用norm_layer。</p>
<p>在深度学习框架如PyTorch中，<code>layer.weight</code>通常是一个张量（Tensor），它的维度或形状依赖于层的类型和配置。 - <strong>全连接层（Dense或Linear）</strong>：权重是一个二维张量，形状通常是[输出特征数量, 输入特征数量]。 - <strong>卷积层（Convolutional）</strong>：权重是一个四维张量，形状通常是[输出通道数, 输入通道数, 卷积核高度, 卷积核宽度]。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">add_norm_layer</span>(<span class="hljs-params">layer</span>):<br>    <span class="hljs-keyword">nonlocal</span> norm_type<br>    <span class="hljs-keyword">if</span> norm_type.startswith(<span class="hljs-string">&#x27;spectral&#x27;</span>):<br>        layer = spectral_norm(layer)<br>        subnorm_type = norm_type[<span class="hljs-built_in">len</span>(<span class="hljs-string">&#x27;spectral&#x27;</span>):]<br><br>    <span class="hljs-keyword">if</span> subnorm_type == <span class="hljs-string">&#x27;none&#x27;</span> <span class="hljs-keyword">or</span> <span class="hljs-built_in">len</span>(subnorm_type) == <span class="hljs-number">0</span>:<br>        <span class="hljs-keyword">return</span> layer<br><br>    <span class="hljs-comment"># remove bias in the previous layer, which is meaningless</span><br>    <span class="hljs-comment"># since it has no effect after normalization</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">getattr</span>(layer, <span class="hljs-string">&#x27;bias&#x27;</span>, <span class="hljs-literal">None</span>) <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>        <span class="hljs-built_in">delattr</span>(layer, <span class="hljs-string">&#x27;bias&#x27;</span>)<br>        layer.register_parameter(<span class="hljs-string">&#x27;bias&#x27;</span>, <span class="hljs-literal">None</span>)<br><br>    <span class="hljs-keyword">if</span> subnorm_type == <span class="hljs-string">&#x27;batch&#x27;</span>:<br>        norm_layer = nn.BatchNorm2d(get_out_channel(layer), affine=<span class="hljs-literal">True</span>)<br>    <span class="hljs-comment"># elif subnorm_type == &#x27;sync_batch&#x27;:</span><br>    <span class="hljs-comment">#     norm_layer = SynchronizedBatchNorm2d(get_out_channel(layer), affine=True)</span><br>    <span class="hljs-keyword">elif</span> subnorm_type == <span class="hljs-string">&#x27;instance&#x27;</span>:<br>        norm_layer = nn.InstanceNorm2d(get_out_channel(layer), affine=<span class="hljs-literal">False</span>)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&#x27;normalization layer %s is not recognized&#x27;</span> % subnorm_type)<br><br>    <span class="hljs-keyword">return</span> nn.Sequential(layer, norm_layer)<br><br><span class="hljs-keyword">return</span> add_norm_layer<br></code></pre></td></tr></table></figure>
<p>然后函数里面又定义了一个add_norm_layer这个函数，它根据不同的subnorm_type来创建不用的norm_layer。</p>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
看看讲这几种normalization方式的原始论文。</li>
</ul>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/CV/" class="category-chain-item">CV</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/VITON/" class="print-no-link">#VITON</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>HR-VITON代码笔记</div>
      <div>https://blog.paraline.top/posts/hr-viton代码笔记/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Paraline</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2024年5月6日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/posts/hr-viton%E4%BB%A3%E7%A0%81%E7%AC%94%E8%AE%B0%E4%BA%8C/" title="HR-VITON代码笔记二">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">HR-VITON代码笔记二</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/posts/viton-hd%E4%BB%A3%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" title="VITON-HD代码阅读笔记">
                        <span class="hidden-mobile">VITON-HD代码阅读笔记</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  
  
    <article id="comments" lazyload>
      
  <script type="text/javascript">
    Fluid.utils.loadComments('#comments', function() {
      var light = 'github-light';
      var dark = 'github-dark';
      var schema = document.documentElement.getAttribute('data-user-color-scheme');
      if (schema === 'dark') {
        schema = dark;
      } else {
        schema = light;
      }
      window.UtterancesThemeLight = light;
      window.UtterancesThemeDark = dark;
      var s = document.createElement('script');
      s.setAttribute('src', 'https://utteranc.es/client.js');
      s.setAttribute('repo', 'Para-line/BlogComment');
      s.setAttribute('issue-term', 'pathname');
      
      s.setAttribute('label', 'utterances');
      
      s.setAttribute('theme', schema);
      s.setAttribute('crossorigin', 'anonymous');
      document.getElementById('comments').appendChild(s);
    })
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


    </article>
  


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="leancloud-site-pv-container" style="display: none">
        Visits 
        <span id="leancloud-site-pv"></span>
         
      </span>
    
    
      <span id="leancloud-site-uv-container" style="display: none">
        Visitors 
        <span id="leancloud-site-uv"></span>
         
      </span>
    
    

  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script defer src="/js/leancloud.js" ></script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  <script src="/js/background.js"></script>

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
