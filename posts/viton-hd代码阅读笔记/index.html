

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=dark>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/avatar.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Paraline">
  <meta name="keywords" content="">
  
    <meta name="description" content="datasets.py VITONDataset 1class VITONDataset(data.Dataset): 1234self.transform &#x3D; transforms.Compose([            transforms.ToTensor(),            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)">
<meta property="og:type" content="article">
<meta property="og:title" content="VITON-HD代码阅读笔记">
<meta property="og:url" content="https://blog.paraline.top/posts/viton-hd%E4%BB%A3%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="Paraline&#39;s Blog">
<meta property="og:description" content="datasets.py VITONDataset 1class VITONDataset(data.Dataset): 1234self.transform &#x3D; transforms.Compose([            transforms.ToTensor(),            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s2.loli.net/2024/04/25/hfJByAauVMXis2m.png">
<meta property="og:image" content="https://s2.loli.net/2024/04/25/97SCKBGxqjYvEbh.png">
<meta property="og:image" content="https://s2.loli.net/2024/04/25/wFP6m9AOZRg3bkG.png">
<meta property="og:image" content="https://s2.loli.net/2024/04/25/khQVsaCcjtm4u7b.png">
<meta property="og:image" content="https://s2.loli.net/2024/04/25/UdrE4RCvhxeK7Zb.jpg">
<meta property="og:image" content="https://s2.loli.net/2024/04/25/Hprkd7su1gyJXPD.jpg">
<meta property="og:image" content="https://s2.loli.net/2024/04/25/5j34UgQvF1REbsh.jpg">
<meta property="og:image" content="https://s2.loli.net/2024/04/27/VRkCs2NeiMJ6hE9.png">
<meta property="article:published_time" content="2024-04-28T18:00:00.000Z">
<meta property="article:modified_time" content="2024-05-27T12:22:55.072Z">
<meta property="article:author" content="Paraline">
<meta property="article:tag" content="VITON">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://s2.loli.net/2024/04/25/hfJByAauVMXis2m.png">
  
  
  
  <title>VITON-HD代码阅读笔记 - Paraline&#39;s Blog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  



  
<link rel="stylesheet" href="/css/paraline.css">
<link rel="stylesheet" href="/css/code.css">



  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"blog.paraline.top","root":"/","version":"1.9.5-a","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":"ynQw6Q7W2fOzEYRv4F6NsdZN-gzGzoHsz","app_key":"JWtWrXxjhx0fquDKEm4Zuz6H","server_url":"https://ynqw6q7w.lc-cn-n1-shared.com","path":"window.location.pathname","ignore_local":true}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  
    <!-- Google tag (gtag.js) -->
    <script async>
      if (!Fluid.ctx.dnt) {
        Fluid.utils.createScript("https://www.googletagmanager.com/gtag/js?id=", function() {
          window.dataLayer = window.dataLayer || [];
          function gtag() {
            dataLayer.push(arguments);
          }
          gtag('js', new Date());
          gtag('config', '');
        });
      }
    </script>
  

  

  

  

  
    
  



  
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
  <div id="web_bg"></div>

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Paraline&#39;s Blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('https://s2.loli.net/2023/08/03/KPgQDnv7y9rV2Ml.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="VITON-HD代码阅读笔记"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-04-28 18:00" pubdate>
          2024/04/28 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          45k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          <!-- compatible with older versions-->
          预计阅读时长：377 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">VITON-HD代码阅读笔记</h1>
            
              <p class="note note-info">
                
                  
                    本文最后更新于：2024年5月27日 中午
                  
                
              </p>
            
            
              <div class="markdown-body">
                
                <h1 id="datasets.py">datasets.py</h1>
<h2 id="vitondataset">VITONDataset</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">VITONDataset</span>(data.Dataset):<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">self.transform = transforms.Compose([<br>            transforms.ToTensor(),<br>            transforms.Normalize((<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>), (<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>))<br>        ])<br></code></pre></td></tr></table></figure>
<p><code>ToTensor()</code> 函数将读入的图片转化为tensor，它会自动将图像的数据从0到255的整数转换成0到1的浮点数。</p>
<p><code>transforms.Normalize(mean, std)</code> 对图像的每一个通道进行标准化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">img_names = []<br>      c_names = []<br>      <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(osp.join(opt.dataset_dir, opt.dataset_list), <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>          <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> f.readlines():<br>              img_name, c_name = line.strip().split()<br>              img_names.append(img_name)<br>              c_names.append(c_name)<br><br>      self.img_names = img_names<br>      self.c_names = <span class="hljs-built_in">dict</span>()<br>      self.c_names[<span class="hljs-string">&#x27;unpaired&#x27;</span>] = c_names<br></code></pre></td></tr></table></figure>
<p><code>line.strip()</code> 去除行首行尾的空白字符（如空格、换行符等）。</p>
<p><code>line.strip().split()</code> 默认以空格为分隔符将处理过的字符串分割成多个部分。在这个例子中，它预期每行有两部分：一个是 <code>img_name</code>（图像的文件名），另一个是 <code>c_name</code>（图像对应的类别名或标签）。</p>
<p><code>c_names</code> 是一个列表，用于存储每一行数据中通过分割操作获得的第二个元素，这通常表示类别名或衣物名称等。</p>
<h3 id="图像加载__getitem__函数">图像加载（__getitem__函数）</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, index</span>):<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">c[key] = Image.<span class="hljs-built_in">open</span>(osp.join(self.data_path, <span class="hljs-string">&#x27;cloth&#x27;</span>, c_name[key])).convert(<span class="hljs-string">&#x27;RGB&#x27;</span>)<br></code></pre></td></tr></table></figure>
<p><code>Image.open()</code> 是来自 PIL（Python Imaging Library，也称为 Pillow）库的一个函数，用于打开并加载图像文件。上述 <code>osp.join(...)</code> 的结果是一个完整的文件路径，指向特定的衣物图像文件。<code>Image.open()</code> 使用这个路径打开相应的图像文件。</p>
<p><code>.convert('RGB')</code> 是 PIL 库中的一个方法，用于将图像转换为指定的颜色模式。在这里，使用 <code>'RGB'</code> 参数，意味着无论原始图像是什么颜色模式（如灰度、CMYK等），都会被转换成 RGB 模式。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">cm[key] = transforms.Resize(self.load_width, interpolation=<span class="hljs-number">0</span>)(cm[key])<br></code></pre></td></tr></table></figure>
<p>解释 <code>interpolation</code> 参数：</p>
<ul>
<li><strong><code>interpolation=2</code></strong>: 这通常代表 <code>BILINEAR</code> 插值。双线性插值是一种相对简单的技术，它通过对四个最接近的像素点进行加权平均来计算新像素的值。这种方法适用于放大和缩小图像，能够保持较好的图像质量，但可能在某些情况下造成图像轻微模糊。</li>
<li><strong><code>interpolation=0</code></strong>: 这通常代表 <code>NEAREST</code> 插值，也就是最邻近插值算法。最邻近插值是最简单的插值方法，它将输出像素的值设置为输入图像中最近像素的值。这种方法的计算速度非常快，但可能会在图像中产生锯齿边缘，特别是在显著放大时。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">c[key] = self.transform(c[key])  <span class="hljs-comment"># [-1,1]</span><br></code></pre></td></tr></table></figure>
<p>这里调用了之前的self.transform： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">self.transform = transforms.Compose([<br>            transforms.ToTensor(),<br>            transforms.Normalize((<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>), (<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>))<br>        ])<br></code></pre></td></tr></table></figure></p>
<p>即同时将图片转化为tensor，并将每个通道的数据标准化，转化为<code>[-1,1]</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">cm_array = np.array(cm[key])<br>cm_array = (cm_array &gt;= <span class="hljs-number">128</span>).astype(np.float32)<br>cm[key] = torch.from_numpy(cm_array)  <span class="hljs-comment"># [0,1]</span><br>cm[key].unsqueeze_(<span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure>
<p>使用 <code>np.array()</code> 将这个 PIL 图像转换为一个 NumPy 数组。结果数组 <code>cm_array</code> 的形状将是 <code>(height, width)</code> 对于灰度图像，或 <code>(height, width, channels)</code> 对于彩色图像。数据类型通常是 <code>uint8</code>，表示像素值范围在 0 到 255。</p>
<p><strong><code>torch.from_numpy()</code></strong>：这是 PyTorch 的函数，用于将 NumPy 数组转换为 PyTorch 张量。这一步是必要的，因为 PyTorch 模型不能直接使用 NumPy 数组，它们需要 PyTorch 张量格式。</p>
<p>为什么不直接把<code>cm[key]</code>转化为 tensor？ 因为要先进行二值化操作，在numpy中实现更高效。</p>
<p><code>unsqueeze_(0)</code>：这是 PyTorch 张量的一个方法，用于在指定位置添加一个额外的维度，这里的 <code>0</code> 表示在最前面添加。<code>unsqueeze_</code> 的就地（in-place）版本意味着修改将直接作用于原张量，而不创建新的张量。这通常用于为单个图像添加批处理维度，以符合深度学习模型通常期望的输入形状 <code>[batch_size, channels, height, width]</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(osp.join(self.data_path, <span class="hljs-string">&#x27;openpose-json&#x27;</span>, pose_name), <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>            pose_label = json.load(f)<br>            pose_data = pose_label[<span class="hljs-string">&#x27;people&#x27;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&#x27;pose_keypoints_2d&#x27;</span>]<br>            pose_data = np.array(pose_data)<br>            pose_data = pose_data.reshape((-<span class="hljs-number">1</span>, <span class="hljs-number">3</span>))[:, :<span class="hljs-number">2</span>]<br></code></pre></td></tr></table></figure>
<p>json 文件加载后是一个字典的形式，字典里面的每个value都是一个列表</p>
<p>这个dataset的json文件大概是如下结构，这里<code>"people"</code>是字典的一个key，然后value是一个列表，列表的第一个元素是一个字典（也只有一个元素） <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br><span class="hljs-attr">&quot;version&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-number">1.3</span><span class="hljs-punctuation">,</span><br><span class="hljs-attr">&quot;people&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-punctuation">[</span><span class="hljs-punctuation">&#123;</span><span class="hljs-attr">&quot;person_id&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-punctuation">[</span><span class="hljs-number">-1</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><span class="hljs-attr">&quot;pose_keypoints_2d&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-punctuation">[</span><span class="hljs-number">374.438</span><span class="hljs-punctuation">,</span><span class="hljs-number">128.121</span><span class="hljs-punctuation">,</span>...<span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><span class="hljs-attr">&quot;face_keypoints_2d&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-punctuation">[</span><span class="hljs-number">318.361</span><span class="hljs-punctuation">,</span><span class="hljs-number">106.306</span><span class="hljs-punctuation">,</span><span class="hljs-number">0.771347</span>...<span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><span class="hljs-attr">&quot;hand_left_keypoints_2d&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-punctuation">[</span><span class="hljs-number">499.4</span><span class="hljs-punctuation">,</span><span class="hljs-number">487.407</span><span class="hljs-punctuation">,</span><span class="hljs-number">0.307236</span>...<span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><span class="hljs-attr">&quot;hand_right_keypoints_2d&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-punctuation">[</span><span class="hljs-number">218.23</span><span class="hljs-punctuation">,</span><span class="hljs-number">729.128</span><span class="hljs-punctuation">,</span><span class="hljs-number">0.672563</span><span class="hljs-punctuation">,</span>...<span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><span class="hljs-attr">&quot;pose_keypoints_3d&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-punctuation">[</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><span class="hljs-attr">&quot;face_keypoints_3d&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-punctuation">[</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><span class="hljs-attr">&quot;hand_left_keypoints_3d&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-punctuation">[</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><span class="hljs-attr">&quot;hand_right_keypoints_3d&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-punctuation">[</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">]</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure></p>
<p><code>pose_data.reshape((-1, 3))</code>：使用 <code>reshape</code> 方法重新排列数组的形状。<code>(-1, 3)</code> 表示将数组转换为三列，行数自动计算。每行三个元素对应一个关键点的 x 坐标、y 坐标和置信度。</p>
<p><code>[:, :2]</code>：这个索引操作切片数组的前两列，即丢弃置信度，只保留 x 和 y 坐标。这里的列数表示方法的意思就是：0到2，左闭右开。也即<span class="math inline">\([0,2)\)</span>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">parse_name = img_name.replace(<span class="hljs-string">&#x27;.jpg&#x27;</span>, <span class="hljs-string">&#x27;.png&#x27;</span>)<br>parse = Image.<span class="hljs-built_in">open</span>(osp.join(self.data_path, <span class="hljs-string">&#x27;image-parse&#x27;</span>, parse_name))<br>parse = transforms.Resize(self.load_width, interpolation=<span class="hljs-number">0</span>)(parse)<br>parse_agnostic = self.get_parse_agnostic(parse, pose_data)<br>parse_agnostic = torch.from_numpy(np.array(parse_agnostic)[<span class="hljs-literal">None</span>]).long()<br></code></pre></td></tr></table></figure>
<p>这段读取的代码就很trivial了，但是要看到数据集才知道他的parse到底指的是什么（虽然可以猜到是segmentation map）。</p>
<p>这里的 <code>get_parse_agnostic</code> 在下面马上会讲到，就是把segmentation map中和衣服与手臂有关的部分删掉。（刚开始看<code>get_parse_agnostic</code>这个函数硬是看不懂，现在知道parse, pose_data这些的含义了就好理解多了。)</p>
<p>同样的，<code>get_img_agnostic</code>同理。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python">labels = &#123;<br>    <span class="hljs-number">0</span>: [<span class="hljs-string">&#x27;background&#x27;</span>, [<span class="hljs-number">0</span>, <span class="hljs-number">10</span>]],<br>    <span class="hljs-number">1</span>: [<span class="hljs-string">&#x27;hair&#x27;</span>, [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>]],<br>    <span class="hljs-number">2</span>: [<span class="hljs-string">&#x27;face&#x27;</span>, [<span class="hljs-number">4</span>, <span class="hljs-number">13</span>]],<br>    <span class="hljs-number">3</span>: [<span class="hljs-string">&#x27;upper&#x27;</span>, [<span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>]],<br>    <span class="hljs-number">4</span>: [<span class="hljs-string">&#x27;bottom&#x27;</span>, [<span class="hljs-number">9</span>, <span class="hljs-number">12</span>]],<br>    <span class="hljs-number">5</span>: [<span class="hljs-string">&#x27;left_arm&#x27;</span>, [<span class="hljs-number">14</span>]],<br>    <span class="hljs-number">6</span>: [<span class="hljs-string">&#x27;right_arm&#x27;</span>, [<span class="hljs-number">15</span>]],<br>    <span class="hljs-number">7</span>: [<span class="hljs-string">&#x27;left_leg&#x27;</span>, [<span class="hljs-number">16</span>]],<br>    <span class="hljs-number">8</span>: [<span class="hljs-string">&#x27;right_leg&#x27;</span>, [<span class="hljs-number">17</span>]],<br>    <span class="hljs-number">9</span>: [<span class="hljs-string">&#x27;left_shoe&#x27;</span>, [<span class="hljs-number">18</span>]],<br>    <span class="hljs-number">10</span>: [<span class="hljs-string">&#x27;right_shoe&#x27;</span>, [<span class="hljs-number">19</span>]],<br>    <span class="hljs-number">11</span>: [<span class="hljs-string">&#x27;socks&#x27;</span>, [<span class="hljs-number">8</span>]],<br>    <span class="hljs-number">12</span>: [<span class="hljs-string">&#x27;noise&#x27;</span>, [<span class="hljs-number">3</span>, <span class="hljs-number">11</span>]]<br>&#125;<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">parse_agnostic_map = torch.zeros(<br>    <span class="hljs-number">20</span>, self.load_height, self.load_width, dtype=torch.<span class="hljs-built_in">float</span>)<br>parse_agnostic_map.scatter_(<span class="hljs-number">0</span>, parse_agnostic, <span class="hljs-number">1.0</span>)<br>new_parse_agnostic_map = torch.zeros(self.semantic_nc, self.load_height, self.load_width, dtype=torch.<span class="hljs-built_in">float</span>)<br></code></pre></td></tr></table></figure>
<p><code>scatter_</code> 的基本调用形式如下：</p>
<p><code>tensor.scatter_(dim, index, src)</code></p>
<ul>
<li><code>dim</code>：是你想要操作的维度。</li>
<li><code>index</code>：是一个与原始张量同形的张量，包含在指定维度上填充数据的位置。</li>
<li><code>src</code>：是要填充的值，可以是一个与原始张量同形的张量或单个值。</li>
</ul>
<p>对于这里的图像，</p>
<ul>
<li><strong>维度 0</strong> - 深度：图像堆叠的深度，例如一系列医学扫描图像的序列。</li>
<li><strong>维度 1</strong> - 高度：每个图像的高度。</li>
<li><strong>维度 2</strong> - 宽度：每个图像的宽度。</li>
</ul>
<p>这里即把一张segmentation map分成20个通道，每个通道对应一个人体部位。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(labels)):<br>            <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> labels[i][<span class="hljs-number">1</span>]:<br>                new_parse_agnostic_map[i] += parse_agnostic_map[label]<br></code></pre></td></tr></table></figure>
<p>这里是把20个通道又压缩到labels中的12个通道。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># load person image</span><br>img = Image.<span class="hljs-built_in">open</span>(osp.join(self.data_path, <span class="hljs-string">&#x27;image&#x27;</span>, img_name))<br>img = transforms.Resize(self.load_width, interpolation=<span class="hljs-number">2</span>)(img)<br>img_agnostic = self.get_img_agnostic(img, parse, pose_data)<br>img = self.transform(img)<br>img_agnostic = self.transform(img_agnostic)  <span class="hljs-comment"># [-1,1]</span><br></code></pre></td></tr></table></figure>
<p>对person image也做同样的处理</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">result = &#123;<br>            <span class="hljs-string">&#x27;img_name&#x27;</span>: img_name,<br>            <span class="hljs-string">&#x27;c_name&#x27;</span>: c_name,<br>            <span class="hljs-string">&#x27;img&#x27;</span>: img,<br>            <span class="hljs-string">&#x27;img_agnostic&#x27;</span>: img_agnostic,<br>            <span class="hljs-string">&#x27;parse_agnostic&#x27;</span>: new_parse_agnostic_map,<br>            <span class="hljs-string">&#x27;pose&#x27;</span>: pose_rgb,<br>            <span class="hljs-string">&#x27;cloth&#x27;</span>: c,<br>            <span class="hljs-string">&#x27;cloth_mask&#x27;</span>: cm,<br>        &#125;<br>        <span class="hljs-keyword">return</span> result<br></code></pre></td></tr></table></figure>
<p>最后返回关于这个index所有需要的信息。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.img_names)<br></code></pre></td></tr></table></figure>
<h3 id="图像的格式">图像的格式</h3>
<p>在打开parse image的时候，图像是以“调色板”模式存储的。这种模式通常用于表示具有有限颜色的图像。</p>
<p>当你将一个以 <code>'P'</code> 模式（调色板模式）打开的 PIL 图像转换为 NumPy 数组时，得到的数组将反映图像中的像素值，这些像素值代表调色板中的索引，而不是直接的颜色值。这意味着每个像素的值将是一个整数，这个整数指向调色板中相应的颜色。</p>
<ol type="1">
<li><strong>数组形状</strong>： 转换为 NumPy 数组后，你将得到一个二维数组，其形状为 <code>(height, width)</code>。每个元素的值是一个介于 0 到 255 之间的整数（假设使用的是标准的256色调色板），这个值是调色板中颜色的索引。</li>
<li><strong>查看索引</strong>： 数组中的每个索引值对应于调色板中的一个颜色。颜色本身是以 RGB 形式定义的，但在数组中，这些颜色仅通过索引来引用。 ### parse label的对照表</li>
</ol>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs markdown"><span class="hljs-bullet">0.</span> Background<br><span class="hljs-bullet">1.</span> Hat<br><span class="hljs-bullet">2.</span> Hair<br><span class="hljs-bullet">3.</span> Glove<br><span class="hljs-bullet">4.</span> Sunglasses<br><span class="hljs-bullet">5.</span> Upper-clothes<br><span class="hljs-bullet">6.</span> Dress<br><span class="hljs-bullet">7.</span> Coat<br><span class="hljs-bullet">8.</span> Socks<br><span class="hljs-bullet">9.</span> Pants<br><span class="hljs-bullet">10.</span> Jumpsuits<br><span class="hljs-bullet">11.</span> Scarf<br><span class="hljs-bullet">12.</span> Skirt<br><span class="hljs-bullet">13.</span> Face<br><span class="hljs-bullet">14.</span> Left-arm<br><span class="hljs-bullet">15.</span> Right-arm<br><span class="hljs-bullet">16.</span> Left-leg<br><span class="hljs-bullet">17.</span> Right-leg<br><span class="hljs-bullet">18.</span> Left-shoe<br><span class="hljs-bullet">19.</span> Right-shoe<br></code></pre></td></tr></table></figure>
<h3 id="get_parse_agnostic">get_parse_agnostic</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_parse_agnostic</span>(<span class="hljs-params">self, parse, pose_data</span>):<br></code></pre></td></tr></table></figure>
<p>这里的parse就是segmentation map, pose_data是之前的那个关键点。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">parse_array = np.array(parse)<br><br>parse_upper = ((parse_array == <span class="hljs-number">5</span>).astype(np.float32) +<br>	            (parse_array == <span class="hljs-number">6</span>).astype(np.float32) +<br>                (parse_array == <span class="hljs-number">7</span>).astype(np.float32))<br>parse_neck = (parse_array == <span class="hljs-number">10</span>).astype(np.float32) <br></code></pre></td></tr></table></figure>
<p>标签10是jumpsuit, 好像和脖子没什么关系？脖子在这个model里面本身就是不标记的。</p>
<p><img src="https://s2.loli.net/2024/04/25/hfJByAauVMXis2m.png" srcset="/img/loading.gif" lazyload /></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> parse_id, pose_ids <span class="hljs-keyword">in</span> [(<span class="hljs-number">14</span>, [<span class="hljs-number">2</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>]), (<span class="hljs-number">15</span>, [<span class="hljs-number">5</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>])]<br></code></pre></td></tr></table></figure>
<p><strong>第一次迭代</strong></p>
<ul>
<li><strong>元组</strong>: <code>(14, [2, 5, 6, 7])</code>
<ul>
<li><code>parse_id</code> 被赋值为 14。</li>
<li><code>pose_ids</code> 被赋值为列表 <code>[2, 5, 6, 7]</code>。</li>
<li>循环体中的代码现在可以使用这两个值来执行特定的操作，比如处理与 <code>parse_id</code> 14 相关的数据，使用索引 2, 5, 6, 7 来访问或操作数据结构中的元素。</li>
</ul></li>
</ul>
<p><strong>第二次迭代</strong></p>
<ul>
<li><strong>元组</strong>: <code>(15, [5, 2, 3, 4])</code>
<ul>
<li><code>parse_id</code> 被赋值为 15。</li>
<li><code>pose_ids</code> 被赋值为列表 <code>[5, 2, 3, 4]</code>。</li>
<li>这一次，循环体中的代码将根据 <code>parse_id</code> 15 来处理数据，使用列表中的索引 5, 2, 3, 4 来执行相关操作。</li>
</ul></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">mask_arm = Image.new(<span class="hljs-string">&#x27;L&#x27;</span>, (self.load_width, self.load_height), <span class="hljs-string">&#x27;black&#x27;</span>)`<br></code></pre></td></tr></table></figure>
<h3 id="一些尺寸的问题">一些尺寸的问题</h3>
<p><strong>注意:</strong> 特别注意，在<code>torchvision.transforms.Resize</code>中，给的<code>size</code>参数是<code>(height,width)</code>，而在<code>Image.new</code>中，给的参数是<code>(width, height)</code>。</p>
<p>并且在<code>torchvision.transforms</code>中，if size is an int, smaller edge of the image will be matched to this number.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">mask_arm_draw = ImageDraw.Draw(mask_arm)<br></code></pre></td></tr></table></figure>
<p>创建一个新的灰度图像（'L' 模式），初始填充为黑色，大小由对象的 <code>load_width</code> 和 <code>load_height</code> 属性决定</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">i_prev = pose_ids[<span class="hljs-number">0</span>]<br><br><span class="hljs-comment"># mask arms</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> pose_ids[<span class="hljs-number">1</span>:]:<br>    <span class="hljs-keyword">if</span> (pose_data[i_prev, <span class="hljs-number">0</span>] == <span class="hljs-number">0.0</span> <span class="hljs-keyword">and</span> pose_data[i_prev, <span class="hljs-number">1</span>] == <span class="hljs-number">0.0</span>) <span class="hljs-keyword">or</span> (pose_data[i, <span class="hljs-number">0</span>] == <span class="hljs-number">0.0</span> <span class="hljs-keyword">and</span> pose_data[i, <span class="hljs-number">1</span>] == <span class="hljs-number">0.0</span>):<br>        <span class="hljs-keyword">continue</span><br>    mask_arm_draw.line([<span class="hljs-built_in">tuple</span>(pose_data[j]) <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> [i_prev, i]], <span class="hljs-string">&#x27;white&#x27;</span>, width=r*<span class="hljs-number">10</span>)<br>    pointx, pointy = pose_data[i]<br>    radius = r*<span class="hljs-number">4</span> <span class="hljs-keyword">if</span> i == pose_ids[-<span class="hljs-number">1</span>] <span class="hljs-keyword">else</span> r*<span class="hljs-number">15</span><br>    mask_arm_draw.ellipse((pointx-radius, pointy-radius, pointx+radius, pointy+radius), <span class="hljs-string">&#x27;white&#x27;</span>, <span class="hljs-string">&#x27;white&#x27;</span>)<br>    i_prev = i<br></code></pre></td></tr></table></figure>
<p><code>mask_arm_draw</code>是用于在<code>mask_arm</code>图像上进行绘图的对象，通过这个对象执行的任何绘图操作（如绘制线条、椭圆等）都会修改<code>mask_arm</code>图像的内容。</p>
<p>这段代码产生的大致图像如下，即根据keypoints生成一个很粗略的pose，然后和segmentation map结合</p>
<p>这里引用论文原文：The pose map P is utilized to remove the arms, but not the hands, as they are difficult to reproduce. (其实更直接说是The pose map P is utilized to preserve the hands.) 所以说代码在手那里的圆圈画的很小</p>
<figure>
<img src="https://s2.loli.net/2024/04/25/97SCKBGxqjYvEbh.png" srcset="/img/loading.gif" lazyload alt="" /><figcaption>{70D0DED9-C3D4-4fbd-9E93-A5DD1EB45345}.png</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">parse_arm = (np.array(mask_arm) / <span class="hljs-number">255</span>) * (parse_array == parse_id).astype(np.float32)<br>agnostic.paste(<span class="hljs-number">0</span>, <span class="hljs-literal">None</span>, Image.fromarray(np.uint8(parse_arm * <span class="hljs-number">255</span>), <span class="hljs-string">&#x27;L&#x27;</span>))<br></code></pre></td></tr></table></figure>
<p><code>np.array(mask_arm) / 255</code> 这部分是将 <code>mask_arm</code> 图像（一个PIL图像对象）转换成NumPy数组，并且将每个像素值从0-255的整数范围标准化到0-1的浮点数范围。这是图像处理中常见的归一化步骤，有助于后续的数学运算。</p>
<p><code>(parse_array == parse_id).astype(np.float32)</code> 这部分是在创建一个条件掩码，其中 <code>parse_array</code> 是一个数组，可能代表某种图像分割的结果（例如，每个像素属于某个部分的标识符），<code>parse_id</code> 是指定的部位标识符。这里将左右手的区域标记出来。</p>
<p>最后，两个数组相乘。这个操作将 <code>mask_arm</code> 的归一化像素值与条件掩码相乘。结果是一个新的数组 <code>parse_arm</code>，其中只有当 <code>parse_array</code> 的值等于 <code>parse_id</code> 时，原 <code>mask_arm</code> 中对应位置的像素值才被保留，其他位置的值将被置为0。这里是把 <code>pose_data</code> 的信息和 <code>segmentation</code>的信息结合起来，构成论文中说的 <em>Clothing-Agnostic Person Representation</em>。</p>
<p>将keypoints信息与parse信息match之后的结果如下：</p>
<p><img src="https://s2.loli.net/2024/04/25/wFP6m9AOZRg3bkG.png" srcset="/img/loading.gif" lazyload /></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># mask torso &amp; neck</span><br>agnostic.paste(<span class="hljs-number">0</span>, <span class="hljs-literal">None</span>, Image.fromarray(np.uint8(parse_upper * <span class="hljs-number">255</span>), <span class="hljs-string">&#x27;L&#x27;</span>))<br>agnostic.paste(<span class="hljs-number">0</span>, <span class="hljs-literal">None</span>, Image.fromarray(np.uint8(parse_neck * <span class="hljs-number">255</span>), <span class="hljs-string">&#x27;L&#x27;</span>))<br><br><span class="hljs-keyword">return</span> agnostic<br></code></pre></td></tr></table></figure>
<p>至此就得到了一张parse_agnostic image</p>
<figure>
<img src="https://s2.loli.net/2024/04/25/khQVsaCcjtm4u7b.png" srcset="/img/loading.gif" lazyload alt="" /><figcaption>00000_00.png</figcaption>
</figure>
<h3 id="get_image_agnostic">get_image_agnostic</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_img_agnostic</span>(<span class="hljs-params">self, img, parse, pose_data</span>):<br></code></pre></td></tr></table></figure>
<p>这个函数做的就也是很类似的事情了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">length_a = np.linalg.norm(pose_data[<span class="hljs-number">5</span>] - pose_data[<span class="hljs-number">2</span>])<br>length_b = np.linalg.norm(pose_data[<span class="hljs-number">12</span>] - pose_data[<span class="hljs-number">9</span>])<br>point = (pose_data[<span class="hljs-number">9</span>] + pose_data[<span class="hljs-number">12</span>]) / <span class="hljs-number">2</span><br>pose_data[<span class="hljs-number">9</span>] = point + (pose_data[<span class="hljs-number">9</span>] - point) / length_b * length_a<br>pose_data[<span class="hljs-number">12</span>] = point + (pose_data[<span class="hljs-number">12</span>] - point) / length_b * length_a<br></code></pre></td></tr></table></figure>
<p>这里是对pose_data的数据做了一些处理，其中<code>linalg</code>默认是求所给向量（矩阵）的 <span class="math inline">\(l_{2}\)</span> 范数。这里也就是欧几里得距离。</p>
<p>根据对照表，length_a是两肩的距离，length_b是左右髋关节的距离。</p>
<p>关于openpose的pose data数据的label，这里也写一个对照表： <figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs txt">// const std::map&lt;unsigned int, std::string&gt; POSE_BODY_25_BODY_PARTS &#123;<br>//     &#123;0,  &quot;Nose&quot;&#125;,<br>//     &#123;1,  &quot;Neck&quot;&#125;,<br>//     &#123;2,  &quot;RShoulder&quot;&#125;,<br>//     &#123;3,  &quot;RElbow&quot;&#125;,<br>//     &#123;4,  &quot;RWrist&quot;&#125;,<br>//     &#123;5,  &quot;LShoulder&quot;&#125;,<br>//     &#123;6,  &quot;LElbow&quot;&#125;,<br>//     &#123;7,  &quot;LWrist&quot;&#125;,<br>//     &#123;8,  &quot;MidHip&quot;&#125;,<br>//     &#123;9,  &quot;RHip&quot;&#125;,<br>//     &#123;10, &quot;RKnee&quot;&#125;,<br>//     &#123;11, &quot;RAnkle&quot;&#125;,<br>//     &#123;12, &quot;LHip&quot;&#125;,<br>//     &#123;13, &quot;LKnee&quot;&#125;,<br>//     &#123;14, &quot;LAnkle&quot;&#125;,<br>//     &#123;15, &quot;REye&quot;&#125;,<br>//     &#123;16, &quot;LEye&quot;&#125;,<br>//     &#123;17, &quot;REar&quot;&#125;,<br>//     &#123;18, &quot;LEar&quot;&#125;,<br>//     &#123;19, &quot;LBigToe&quot;&#125;,<br>//     &#123;20, &quot;LSmallToe&quot;&#125;,<br>//     &#123;21, &quot;LHeel&quot;&#125;,<br>//     &#123;22, &quot;RBigToe&quot;&#125;,<br>//     &#123;23, &quot;RSmallToe&quot;&#125;,<br>//     &#123;24, &quot;RHeel&quot;&#125;,<br>//     &#123;25, &quot;Background&quot;&#125;<br>// &#125;;<br></code></pre></td></tr></table></figure></p>
<p>这个函数之后就也是一些作图的逻辑了，只不过是在原图上直接画。</p>
<p>在这里生成的结果其实就已经参差不齐了，因为他在通过pose_map生成mask的时候用了人类的知识，但这种知识不能覆盖所有情况。</p>
<figure>
<img src="https://s2.loli.net/2024/04/25/UdrE4RCvhxeK7Zb.jpg" srcset="/img/loading.gif" lazyload alt="" /><figcaption>00283_00.jpg</figcaption>
</figure>
<figure>
<img src="https://s2.loli.net/2024/04/25/Hprkd7su1gyJXPD.jpg" srcset="/img/loading.gif" lazyload alt="" /><figcaption>00107_00.jpg</figcaption>
</figure>
<figure>
<img src="https://s2.loli.net/2024/04/25/5j34UgQvF1REbsh.jpg" srcset="/img/loading.gif" lazyload alt="" /><figcaption>00228_00.jpg</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> (pose_data[i - <span class="hljs-number">1</span>, <span class="hljs-number">0</span>] == <span class="hljs-number">0.0</span> <span class="hljs-keyword">and</span> pose_data[i - <span class="hljs-number">1</span>, <span class="hljs-number">1</span>] == <span class="hljs-number">0.0</span>) <span class="hljs-keyword">or</span> (pose_data[i, <span class="hljs-number">0</span>] == <span class="hljs-number">0.0</span> <span class="hljs-keyword">and</span> pose_data[i, <span class="hljs-number">1</span>] == <span class="hljs-number">0.0</span>):<br>    <span class="hljs-keyword">continue</span><br></code></pre></td></tr></table></figure>
<p>最后这张图好像是因为有些代码没有像处理pose_data不存在的情况，并且如果<code>pose_data[9]</code>和<code>pose_data[12]</code>没检测到，前面还会出现除以零的错误。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, index</span>):<br>img_name = self.img_names[index]<br>c_name = &#123;&#125;<br>c = &#123;&#125;<br>cm = &#123;&#125;<br><span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> self.c_names:<br>    c_name[key] = self.c_names[key][index]<br>    c[key] = Image.<span class="hljs-built_in">open</span>(<br>        osp.join(self.data_path, <span class="hljs-string">&#x27;cloth&#x27;</span>, c_name[key])).convert(<span class="hljs-string">&#x27;RGB&#x27;</span>)<br>    c[key] = transforms.Resize(self.load_width, interpolation=<span class="hljs-number">2</span>)(c[key])<br>    cm[key] = Image.<span class="hljs-built_in">open</span>(<br>        osp.join(self.data_path, <span class="hljs-string">&#x27;cloth-mask&#x27;</span>, c_name[key]))<br>    cm[key] = transforms.Resize(self.load_width, interpolation=<span class="hljs-number">0</span>)(cm[key])<br><br>    c[key] = self.transform(c[key])  <span class="hljs-comment"># [-1,1]</span><br>    cm_array = np.array(cm[key])<br>    cm_array = (cm_array &gt;= <span class="hljs-number">128</span>).astype(np.float32)<br>    cm[key] = torch.from_numpy(cm_array)  <span class="hljs-comment"># [0,1]</span><br>    cm[key].unsqueeze_(<span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure>
<h2 id="vitondataloader">VITONDataLoader</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">VITONDataLoader</span><br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">VITONDataLoader</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, opt, dataset</span>):<br>        <span class="hljs-built_in">super</span>(VITONDataLoader, self).__init__()<br><br>        <span class="hljs-keyword">if</span> opt.shuffle:<br>            train_sampler = data.sampler.RandomSampler(dataset)<br>        <span class="hljs-keyword">else</span>:<br>            train_sampler = <span class="hljs-literal">None</span><br></code></pre></td></tr></table></figure>
<p>根据<code>opt.shuffle</code>选择是否对<code>dataset</code>进行随机采样。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">self.data_loader = data.DataLoader(<br>        dataset, batch_size=opt.batch_size, shuffle=(train_sampler <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>),<br>        num_workers=opt.workers, pin_memory=<span class="hljs-literal">True</span>, drop_last=<span class="hljs-literal">True</span>, sampler=train_sampler<br>)<br></code></pre></td></tr></table></figure>
<p><strong>data.sampler.RandomSampler</strong></p>
<ul>
<li><strong>定义</strong>：<code>RandomSampler</code> 是 PyTorch 中一个具体的迭代器，它每次迭代时都随机地从数据集中抽取元素，而不是按顺序选取。</li>
<li><strong>用途</strong>：当你需要更多控制或者需要在自定义采样器中嵌入额外的逻辑时使用。例如，你可以在不改变原始数据集结构的情况下实现复杂的抽样策略。</li>
<li><strong>实现</strong>：当你指定 <code>RandomSampler</code> 作为 <code>DataLoader</code> 的 <code>sampler</code> 参数时，应该将 <code>shuffle</code> 设置为 <code>False</code>，因为 <code>shuffle</code> 和 <code>sampler</code> 参数不能同时使用。如果同时使用，<code>DataLoader</code> 会抛出错误。</li>
</ul>
<p><strong><code>shuffle=True</code> 在 <code>DataLoader</code> 中</strong></p>
<ul>
<li><strong>定义</strong>：这是一个简便的参数，可以直接在 <code>DataLoader</code> 初始化时设置。如果设置为 <code>True</code>，<code>DataLoader</code> 将在每个epoch开始时对数据进行随机打乱。</li>
<li><strong>用途</strong>：当你不需要复杂的抽样逻辑，仅仅想在每个epoch训练前打乱数据时使用。</li>
<li><strong>实现</strong>：当 <code>shuffle=True</code> 时，<code>DataLoader</code> 内部实际上使用了一个随机抽样器，但你不需要显式地定义它。这种方式比较简洁，适合大多数标准的训练场景。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">self.dataset = dataset<br>   self.data_iter = self.data_loader.__iter__()<br>   <br>   <span class="hljs-keyword">def</span> <span class="hljs-title function_">next_batch</span>(<span class="hljs-params">self</span>):<br>       <span class="hljs-keyword">try</span>:<br>           batch = self.data_iter.__next__()<br>       <span class="hljs-keyword">except</span> StopIteration:<br>           self.data_iter = self.data_loader.__iter__()<br>           batch = self.data_iter.__next__()<br><br>       <span class="hljs-keyword">return</span> batch<br></code></pre></td></tr></table></figure>
<h3 id="iter__-方法"><code>__iter__()</code> 方法：</h3>
<ul>
<li><strong>定义</strong>：<code>__iter__()</code> 是Python中的一个特殊方法，用于获取一个对象的迭代器。当对象支持迭代时，<code>__iter__()</code> 方法会返回迭代器对象本身，这个迭代器包含了一个 <code>__next__()</code> 方法，用于获取迭代器的下一个元素。</li>
<li><strong>用途</strong>：在 <code>DataLoader</code> 的上下文中，<code>__iter__()</code> 被用来创建一个可以遍历数据集所有批次的迭代器。每次调用这个迭代器的 <code>__next__()</code> 方法时，它会返回数据集的下一个批次。</li>
</ul>
<h3 id="在-dataloader-中的应用">在 <code>DataLoader</code> 中的应用：</h3>
<ul>
<li><strong>初始化迭代器</strong>：<code>self.data_iter = self.data_loader.__iter__()</code> 这行代码初始化了一个迭代器，该迭代器负责从 <code>DataLoader</code> 中逐批次提取数据。通过这种方式，你可以在训练循环中连续调用 <code>__next__()</code> 来获取新的数据批次，直到数据集的所有数据都被处理完毕。</li>
<li><strong>数据批次的提取</strong>：每次调用迭代器的 <code>__next__()</code> 方法（如在你的 <code>next_batch</code> 方法中所做的），都会加载下一批数据。如果数据已经迭代完毕，迭代器会抛出 <code>StopIteration</code> 异常，此时通常会重新初始化迭代器，从而开始新一轮的数据遍历。</li>
</ul>
<h1 id="utils.py">utils.py</h1>
<h2 id="gen_noise">gen_noise</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">gen_noise</span>(<span class="hljs-params">shape</span>):<br>    noise = np.zeros(shape, dtype=np.uint8)<br>    <span class="hljs-comment">### noise</span><br>    noise = cv2.randn(noise, <span class="hljs-number">0</span>, <span class="hljs-number">255</span>)<br>    noise = np.asarray(noise / <span class="hljs-number">255</span>, dtype=np.uint8)<br>    noise = torch.tensor(noise, dtype=torch.float32)<br>    <span class="hljs-keyword">return</span> noise<br></code></pre></td></tr></table></figure>
<p>使用 <code>cv2.randn()</code> 函数填充数组，生成平均值为 0，标准差为 255 的正态分布噪声。 将噪声值缩放到 <code>[0, 1]</code> 范围内，并转换为 <code>uint8</code> 类型。</p>
<h3 id="np.asarray-与-np.array-的不同">np.asarray 与 np.array 的不同</h3>
<p><code>np.asarray</code>的定义： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">asarray</span>(<span class="hljs-params">a, dtype=<span class="hljs-literal">None</span>, order=<span class="hljs-literal">None</span></span>):<br>    <span class="hljs-keyword">return</span> array(a, dtype, copy=<span class="hljs-literal">False</span>, order=order)<br></code></pre></td></tr></table></figure></p>
<p>而 <code>np.array</code>的定义： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">array</span>(<span class="hljs-params">a, dtype=<span class="hljs-literal">None</span>, order=<span class="hljs-literal">None</span></span>):<br>    <span class="hljs-keyword">return</span> array(a, dtype, copy=<span class="hljs-literal">True</span>, order=order)<br></code></pre></td></tr></table></figure></p>
<p><strong><code>np.array</code></strong>：此函数默认情况下会创建输入数据的一个新副本，即使输入数据已经是一个 NumPy 数组。这意味着即使原始数据没有必要被复制，<code>np.array</code> 也会进行复制，除非显式设置 <code>copy=False</code>。</p>
<p><strong><code>np.asarray</code></strong>：这个函数会尽可能避免复制原始数据。如果输入数据已经是一个 NumPy 数组，<code>np.asarray</code> 将不会创建数据的副本，而是直接返回原始数组。</p>
<p>用来做data augmentation</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">save_images</span>(<span class="hljs-params">img_tensors, img_names, save_dir</span>):<br>    <span class="hljs-keyword">for</span> img_tensor, img_name <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(img_tensors, img_names):<br>        tensor = (img_tensor.clone()+<span class="hljs-number">1</span>) * <span class="hljs-number">0.5</span> * <span class="hljs-number">255</span><br>        tensor = tensor.cpu().clamp(<span class="hljs-number">0</span>,<span class="hljs-number">255</span>)<br><br>        <span class="hljs-keyword">try</span>:<br>            array = tensor.numpy().astype(<span class="hljs-string">&#x27;uint8&#x27;</span>)<br>        <span class="hljs-keyword">except</span>:<br>            array = tensor.detach().numpy().astype(<span class="hljs-string">&#x27;uint8&#x27;</span>)<br><br>        <span class="hljs-keyword">if</span> array.shape[<span class="hljs-number">0</span>] == <span class="hljs-number">1</span>:<br>            array = array.squeeze(<span class="hljs-number">0</span>)<br>        <span class="hljs-keyword">elif</span> array.shape[<span class="hljs-number">0</span>] == <span class="hljs-number">3</span>:<br>            array = array.swapaxes(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>).swapaxes(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br><br>        im = Image.fromarray(array)<br>        im.save(os.path.join(save_dir, img_name), <span class="hljs-built_in">format</span>=<span class="hljs-string">&#x27;JPEG&#x27;</span>)<br></code></pre></td></tr></table></figure>
<p>这是保存图像的函数，首先将 tensor 去标准化。 <code>.cpu()</code> 确保张量被移动到CPU。如果张量原先在GPU上，这一步是必要的，因为接下来的保存或进一步处理通常在CPU上进行。</p>
<p><code>.clamp(0, 255)</code>: <code>clamp()</code> 方法用于将张量中的所有元素限制在指定的范围内，本例中是0到255。这是一个安全措施，用来确保即使在之前的操作中有任何计算误差或异常值，最终的像素值也会被限制在有效的RGB范围内。</p>
<p><strong><code>tensor.numpy()</code></strong>：这个方法尝试将 PyTorch 张量直接转换为一个 NumPy 数组。这一转换要求张量 <code>tensor</code> 必须在 CPU 上，并且没有计算图依赖（即它必须是一个叶子张量）。在 PyTorch 中，只有当张量是叶子节点并且不要求梯度时，才能直接通过 <code>.numpy()</code> 方法转换为 NumPy 数组。如果张量是计算图的一部分，直接调用 <code>.numpy()</code> 会抛出错误，因为这会尝试绕过 PyTorch 的自动微分系统。使用 <code>.detach()</code> 是确保张量从任何梯度计算中分离出来，从而安全地进行转换。</p>
<p><strong><code>tensor.detach()</code></strong>：这个方法创建了张量的一个副本，但副本与原始数据共享内存，并且从当前计算图中分离出来。这意味着这个新张量不会有梯度信息，可以安全地转换为 NumPy 数组，而不会影响反向传播或梯度计算。</p>
<p><strong>叶子张量</strong></p>
<p><strong>定义</strong>：在PyTorch的计算图中，叶子张量（Leaf Tensor）是直接由用户创建的张量，而不是通过任何前向操作（如加法或乘法）生成的。简而言之，叶子张量是计算图中的输入节点。</p>
<h3 id="对灰度图和rgb图的不同处理">对灰度图和RGB图的不同处理</h3>
<p>处理单通道图像 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> array.shape[<span class="hljs-number">0</span>] == <span class="hljs-number">1</span>:     <br>	array = array.squeeze(<span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure></p>
<ul>
<li><strong>条件</strong>：检查数组的第一个维度（通道数）是否为1，即判断这是否是一个单通道（如灰度）图像。</li>
<li><strong>操作</strong>：使用 <code>.squeeze(0)</code> 方法从数组中移除第一个维度。这是因为单通道图像在某些图像处理库中不需要显式的单一通道维度，<code>squeeze(0)</code> 将形状从 <code>(1, height, width)</code> 改变为 <code>(height, width)</code>，使其适合作为灰度图像处理或显示。</li>
</ul>
<p>处理三通道图像</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">elif</span> array.shape[<span class="hljs-number">0</span>] == <span class="hljs-number">3</span>:     <br>	array = array.swapaxes(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>).swapaxes(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br></code></pre></td></tr></table></figure>
<ul>
<li><strong>条件</strong>：检查数组的第一个维度是否为3，这通常意味着它是一个具有三个颜色通道（通常是RGB）的图像。</li>
<li><strong>操作</strong>：
<ul>
<li><strong><code>array.swapaxes(0, 1)</code></strong>：这一步将第一个维度（通常是通道）与第二个维度（高度）交换。此操作后，数组形状从 <code>(3, height, width)</code> 变为 <code>(height, 3, width)</code>。</li>
<li><strong><code>.swapaxes(1, 2)</code></strong>：接着将现在的第二个维度（原先的通道现在的位置）与第三个维度（宽度）交换。这将形状最终从 <code>(height, 3, width)</code> 调整为 <code>(height, width, 3)</code>。</li>
</ul></li>
</ul>
<p>这种调整是必要的因为在PyTorch（和很多其他深度学习框架中）中，图像数据通常按照 <code>(channels, height, width)</code>（CHW）的顺序存储，而在常规图像处理库（如PIL）和图像格式中，数据通常需要以 <code>(height, width, channels)</code>（HWC）的格式存在。这种转换确保图像数据在可视化或保存时具有正确的格式。</p>
<h3 id="pil和numpy互换">PIL和numpy互换</h3>
<h4 id="从-pil-image-到-numpy-数组">从 PIL Image 到 NumPy 数组</h4>
<ul>
<li><strong>PIL Image</strong>：在PIL中，图像被视为 <code>(width, height)</code> 格式，其中 <code>width</code> 是图像的宽度（列数），<code>height</code> 是图像的高度（行数）。</li>
<li><strong>转换为 NumPy</strong>：当你使用例如 <code>numpy.array()</code> 函数将PIL图像转换为NumPy数组时，得到的数组将按 <code>(height, width)</code> 的顺序排列。如果是彩色图像，它会有三个维度 <code>(height, width, channels)</code>，其中 <code>channels</code> 表示颜色通道（通常为RGB三个通道）。</li>
</ul>
<h3 id="从-numpy-数组到-pil-image">从 NumPy 数组到 PIL Image</h3>
<ul>
<li><strong>NumPy 数组</strong>：通常，NumPy数组存储图像数据时使用 <code>(height, width, channels)</code> 的格式，对于灰度图像则是 <code>(height, width)</code>。</li>
<li><strong>转换为 PIL Image</strong>：当你想把一个NumPy数组转换回PIL图像时，你需要确保数组是 <code>(height, width)</code> 或 <code>(height, width, channels)</code> 格式。PIL的<code>Image.fromarray()</code>方法接受这种格式，直接将它转换为PIL Image对象。 ### 总结 在转换过程中，你通常不需要手动交换宽度和高度的维度，因为这些库的函数已经处理好了这些细节。当从PIL Image转到NumPy数组时，维度自动从 <code>(width, height)</code> 转换为 <code>(height, width)</code>，反之亦然。这个细节尤其重要，当你在使用这两个库进行图像处理和分析时，需要清楚它们数据表示的不同。</li>
</ul>
<h2 id="load_checkpoint">load_checkpoint</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_checkpoint</span>(<span class="hljs-params">model, checkpoint_path</span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(checkpoint_path):<br>        <span class="hljs-keyword">raise</span> ValueError(<br>            <span class="hljs-string">&quot;&#x27;&#123;&#125;&#x27; is not a valid checkpointpath&quot;</span>.<span class="hljs-built_in">format</span>(checkpoint_path))<br>    model.load_state_dict(torch.load(checkpoint_path))<br></code></pre></td></tr></table></figure>
<p><code>model.load_state_dict(torch.load(checkpoint_path))</code>: 这行代码是加载和应用检查点的核心。</p>
<p><code>torch.load(checkpoint_path)</code>: 使用PyTorch的<code>torch.load</code>函数从指定的文件路径加载检查点。这个函数默认情况下会读取文件内容，并反序列化为Python对象，这里是模型的状态字典。</p>
<p><code>model.load_state_dict(...)</code>: 这个方法将加载的状态字典应用到提供的模型上。状态字典通常包括模型参数（权重和偏差）等。这一步是将保存的模型状态恢复到指定的模型实例中。</p>
<h3 id="重要性">重要性</h3>
<p>加载检查点对于深度学习模型的训练非常重要，尤其是在训练过程需要中断后继续训练的场景。此外，这也是将训练好的模型部署到生产环境中的常见步骤，因为你通常会保存训练好的模型并在需要时加载它们进行预测。</p>
<h3 id="总结">总结</h3>
<p>这个<code>load_checkpoint</code>函数提供了一种简洁的方法来确保模型状态可以从磁盘恢复。通过检查文件存在性并使用PyTorch的API加载和应用状态字典，这段代码有效地支持了模型的持久化和再利用，是深度学习工作流中的一个基本组件。</p>
<h1 id="nn.module">nn.Module</h1>
<p><code>nn.Module</code> 是 PyTorch 中所有神经网络模块的基类，几乎所有使用 PyTorch 构建的神经网络组件都应该继承自这个类。这个类封装了神经网络需要的多种功能，使得网络构建、训练、保存和加载都变得方便和直观。下面是 <code>nn.Module</code> 中的一些重要特性和组成部分： ## 主要属性和方法</p>
<ol type="1">
<li><strong>构造函数 <code>__init__()</code></strong>:
<ul>
<li>这是初始化模块时调用的方法，通常用于定义模型的层和其他需要的组件。在这里，通常会调用父类的构造函数来保证 <code>Module</code> 的正确初始化。</li>
</ul></li>
<li><strong><code>forward()</code> 方法</strong>:
<ul>
<li>必须由所有继承自 <code>nn.Module</code> 的类实现的方法。这是定义模块如何执行前向传递的地方。在 PyTorch 中，你不直接调用这个方法，而是通过调用模块实例来间接调用它。</li>
</ul></li>
<li><strong><code>parameters()</code> 和 <code>named_parameters()</code></strong>:
<ul>
<li><code>parameters()</code> 返回模块的参数迭代器，通常用于优化器配置。这些参数是需要通过训练学习的权重和偏置。</li>
<li><code>named_parameters()</code> 同样返回参数迭代器，但它会返回一个元组，其中包含参数的名称和参数本身，非常有用于调试和特定参数的操作。</li>
</ul></li>
<li><strong><code>children()</code> 和 <code>modules()</code></strong>:
<ul>
<li><code>children()</code> 方法返回模块的直接子模块迭代器，而 <code>modules()</code> 返回当前模块的所有子模块（递归地），包括模块本身。</li>
</ul></li>
<li><strong><code>to(device)</code></strong>:
<ul>
<li>将模块的所有参数和缓冲区移动到给定的设备（CPU或GPU）上。这是多设备支持的关键方法，非常重要以确保计算的一致性。</li>
</ul></li>
<li><strong><code>train()</code> 和 <code>eval()</code></strong>:
<ul>
<li><code>train()</code> 将模块设置为训练模式，这对于某些层（如Dropout和BatchNorm）是必要的，因为它们在训练和评估阶段的行为是不同的。</li>
<li><code>eval()</code> 将模块设置为评估模式。</li>
</ul></li>
<li><strong><code>state_dict()</code></strong>:
<ul>
<li>返回包含模块所有状态信息（参数和持久缓冲区）的字典。这在保存和加载模型时非常有用。</li>
</ul></li>
<li><strong><code>load_state_dict(state_dict)</code></strong>:
<ul>
<li>加载一个状态字典。这通常用于模型的反序列化，是在训练后恢复模型状态的标准方法。</li>
</ul></li>
</ol>
<h2 id="parameters">parameters()</h2>
<p>在 PyTorch 中，<code>self.parameters()</code> 和 <code>param.numel()</code> 是与模型参数操作相关的重要方法和函数。它们通常用于管理和统计模型中的参数。下面详细解释这两者的作用和使用方法：</p>
<h4 id="定义和用途">定义和用途</h4>
<ul>
<li><p><code>self.parameters()</code> 是 <code>nn.Module</code> 类的一个方法，它返回一个生成器，遍历模型中所有的参数（通常是权重和偏差），这些参数是需要通过训练学习的。此方法是许多 PyTorch 操作的基础，特别是在配置优化器和计算模型的总参数数量时。 #### 返回值</p></li>
<li><p>返回的生成器包含模型中定义为 <code>nn.Parameter</code> 的所有参数。<code>nn.Parameter</code> 是对张量的一个封装，标记这些张量是模型的一部分，需要进行梯度计算。</p></li>
</ul>
<h3 id="param.numel"><code>param.numel()</code></h3>
<h4 id="定义和用途-1">定义和用途</h4>
<ul>
<li><code>numel()</code> 是一个 PyTorch 张量（Tensor）的方法，它返回张量中元素的总数。这对于确定模型大小或进行性能分析是非常有用的。</li>
</ul>
<h4 id="返回值">返回值</h4>
<ul>
<li>返回一个整数，表示张量中的元素总数。</li>
</ul>
<h3 id="生成器">生成器</h3>
<p>生成器是使用简单的函数来创建的，函数中包含 <code>yield</code> 表达式。当函数执行到 <code>yield</code> 时，函数会暂停并返回一个值，下次迭代时，函数从停止的位置继续执行。</p>
<p>生成器自动实现了迭代器协议，所以不需要显式定义 <code>__iter__()</code> 和 <code>__next__()</code>。</p>
<p>使用生成器通常比手动实现迭代器更简洁、更易于编写和理解。</p>
<h4 id="生成器示例"><strong>生成器示例</strong>：</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">simple_generator</span>():     <br>	<span class="hljs-keyword">yield</span> <span class="hljs-number">1</span>     <br>	<span class="hljs-keyword">yield</span> <span class="hljs-number">2</span>     <br>	<span class="hljs-keyword">yield</span> <span class="hljs-number">3</span>  <br>	<br><span class="hljs-comment"># 使用生成器 </span><br>gen = simple_generator() <br><span class="hljs-keyword">for</span> value <span class="hljs-keyword">in</span> gen:     <br>	<span class="hljs-built_in">print</span>(value)  <span class="hljs-comment"># 输出 1, 2, 3</span><br></code></pre></td></tr></table></figure>
<h1 id="networks.py">networks.py</h1>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> init<br><span class="hljs-keyword">from</span> torch.nn.utils.spectral_norm <span class="hljs-keyword">import</span> spectral_norm<br></code></pre></td></tr></table></figure>
<h2 id="common-classes">common classes</h2>
<h3 id="basenetwork">BaseNetwork</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">BaseNetwork</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(BaseNetwork, self).__init__()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">print_network</span>(<span class="hljs-params">self</span>):<br>        num_params = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.parameters():<br>            num_params += param.numel()<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Network [&#123;&#125;] was created. Total number of parameters: &#123;:.1f&#125; million. &quot;</span><br>              <span class="hljs-string">&quot;To see the architecture, do print(network).&quot;</span>.<span class="hljs-built_in">format</span>(self.__class__.__name__, num_params / <span class="hljs-number">1000000</span>))<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_weights</span>(<span class="hljs-params">self, init_type=<span class="hljs-string">&#x27;normal&#x27;</span>, gain=<span class="hljs-number">0.02</span></span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">init_func</span>(<span class="hljs-params">m</span>):<br>        classname = m.__class__.__name__<br>        <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;BatchNorm2d&#x27;</span> <span class="hljs-keyword">in</span> classname:<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(m, <span class="hljs-string">&#x27;weight&#x27;</span>) <span class="hljs-keyword">and</span> m.weight <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>                init.normal_(m.weight.data, <span class="hljs-number">1.0</span>, gain)<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(m, <span class="hljs-string">&#x27;bias&#x27;</span>) <span class="hljs-keyword">and</span> m.bias <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>                init.constant_(m.bias.data, <span class="hljs-number">0.0</span>)<br>        <span class="hljs-keyword">elif</span> (<span class="hljs-string">&#x27;Conv&#x27;</span> <span class="hljs-keyword">in</span> classname <span class="hljs-keyword">or</span> <span class="hljs-string">&#x27;Linear&#x27;</span> <span class="hljs-keyword">in</span> classname) <span class="hljs-keyword">and</span> <span class="hljs-built_in">hasattr</span>(m, <span class="hljs-string">&#x27;weight&#x27;</span>):<br>            <span class="hljs-keyword">if</span> init_type == <span class="hljs-string">&#x27;normal&#x27;</span>:<br>                init.normal_(m.weight.data, <span class="hljs-number">0.0</span>, gain)<br>            <span class="hljs-keyword">elif</span> init_type == <span class="hljs-string">&#x27;xavier&#x27;</span>:<br>                init.xavier_normal_(m.weight.data, gain=gain)<br>            <span class="hljs-keyword">elif</span> init_type == <span class="hljs-string">&#x27;xavier_uniform&#x27;</span>:<br>                init.xavier_uniform_(m.weight.data, gain=<span class="hljs-number">1.0</span>)<br>            <span class="hljs-keyword">elif</span> init_type == <span class="hljs-string">&#x27;kaiming&#x27;</span>:<br>                init.kaiming_normal_(m.weight.data, a=<span class="hljs-number">0</span>, mode=<span class="hljs-string">&#x27;fan_in&#x27;</span>)<br>            <span class="hljs-keyword">elif</span> init_type == <span class="hljs-string">&#x27;orthogonal&#x27;</span>:<br>                init.orthogonal_(m.weight.data, gain=gain)<br>            <span class="hljs-keyword">elif</span> init_type == <span class="hljs-string">&#x27;none&#x27;</span>:  <span class="hljs-comment"># uses pytorch&#x27;s default init method</span><br>                m.reset_parameters()<br>            <span class="hljs-keyword">else</span>:<br>                <span class="hljs-keyword">raise</span> NotImplementedError(<br>                    <span class="hljs-string">&quot;initialization method &#x27;&#123;&#125;&#x27; is not implemented&quot;</span>.<span class="hljs-built_in">format</span>(init_type))<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(m, <span class="hljs-string">&#x27;bias&#x27;</span>) <span class="hljs-keyword">and</span> m.bias <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>                init.constant_(m.bias.data, <span class="hljs-number">0.0</span>)<br><br>    self.apply(init_func)<br></code></pre></td></tr></table></figure>
<p>这里定义了几种初始化weight的方式，根据不同的layer选择。</p>
<p>这里的<code>init_weights</code>是一个高阶函数，会根据你需要的类型选择一个具体的初始化函数。</p>
<p>这里的apply表示将这个初始化函数应用于self的所有子模块，也就是构成模型的各个组件（可以是单独的卷积层、池化层、全连接层（线性层）、激活层，或者是更高级的组合，如块（block）或序列（sequence）等）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, *inputs</span>):<br>    <span class="hljs-keyword">pass</span> <br></code></pre></td></tr></table></figure>
<p>这里的forward需要根据具体的网络来实现，所以在BaseNetwork中先不写。</p>
<h2 id="seggenerator-related-classes">SegGenerator-related classes</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">SegGenerator</span>(<span class="hljs-title class_ inherited__">BaseNetwork</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, opt, input_nc, output_nc=<span class="hljs-number">13</span>, norm_layer=nn.InstanceNorm2d</span>):<br>        <span class="hljs-built_in">super</span>(SegGenerator, self).__init__()<br><br>	    self.conv1 = nn.Sequential(nn.Conv2d(input_nc, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>), norm_layer(<span class="hljs-number">64</span>), nn.ReLU(),<br>		                           nn.Conv2d(<span class="hljs-number">64</span>, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>), norm_layer(<span class="hljs-number">64</span>), nn.ReLU())<br>		<br>		<span class="hljs-comment"># ...</span><br><br>		 self.up6 = nn.Sequential(nn.Upsample(scale_factor=<span class="hljs-number">2</span>, mode=<span class="hljs-string">&#x27;nearest&#x27;</span>),<br>                                 nn.Conv2d(<span class="hljs-number">1024</span>, <span class="hljs-number">512</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>), norm_layer(<span class="hljs-number">512</span>), nn.ReLU())<br>		<br>        self.pool = nn.MaxPool2d(<span class="hljs-number">2</span>)<br>        self.drop = nn.Dropout(<span class="hljs-number">0.5</span>)<br>        self.sigmoid = nn.Sigmoid()<br><br>        self.print_network()<br>        self.init_weights(opt.init_type, opt.init_variance)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        conv1 = self.conv1(x)<br>        conv2 = self.conv2(self.pool(conv1))<br>        conv3 = self.conv3(self.pool(conv2))<br>        conv4 = self.drop(self.conv4(self.pool(conv3)))<br>        conv5 = self.drop(self.conv5(self.pool(conv4)))<br><br>        conv6 = self.conv6(torch.cat((conv4, self.up6(conv5)), <span class="hljs-number">1</span>))<br>        conv7 = self.conv7(torch.cat((conv3, self.up7(conv6)), <span class="hljs-number">1</span>))<br>        conv8 = self.conv8(torch.cat((conv2, self.up8(conv7)), <span class="hljs-number">1</span>))<br>        conv9 = self.conv9(torch.cat((conv1, self.up9(conv8)), <span class="hljs-number">1</span>))<br>        <span class="hljs-keyword">return</span> self.sigmoid(conv9)<br></code></pre></td></tr></table></figure>
<p><code>nn.Conv2d</code>函数原型: <code>torch.nn.Conv2d(_in_channels_, _out_channels_, _kernel_size_, _stride=1_, _padding=0_, _dilation=1_, _groups=1_, _bias=True_, _padding_mode='zeros'_, _device=None_, _dtype=None_)</code></p>
<ol type="1">
<li><strong>in_channels</strong> (<code>input_nc</code>): 输入通道数。这指定了输入数据的深度（例如，对于RGB图像，深度为3）。</li>
<li><strong>out_channels</strong> (<code>64</code>): 输出通道数。这是卷积操作后生成的特征图（或称为过滤器或卷积核）的数量。</li>
<li></li>
<li><strong>kernel_size</strong> (<code>3</code>): 卷积核的大小。这里是<code>3</code>，表示使用3x3的卷积核。这个参数可以是一个单一的整数或一个元组，指定卷积核在每个空间维度的长度。</li>
<li><strong>stride</strong> (默认为<code>1</code>): 卷积步长。这决定了卷积核在输入数据上滑动时每次移动的像素数。步长为1意味着卷积核每次移动一个像素。</li>
<li><strong>padding</strong> (<code>1</code>): 边缘填充。这是在输入数据的边缘添加的零填充的层数，用于控制输出的空间维度。填充为1意味着在输入的每一边均添加一层零。</li>
<li><strong>dilation</strong> (默认为<code>1</code>): 卷积核元素之间的间隔。这个参数允许你使用间隔更大的卷积核来提取更广范围的特征。</li>
<li><strong>groups</strong> (默认为<code>1</code>): 分组卷积的组数。这是一个高级功能，允许网络设计者将输入通道和输出通道分组，独立进行卷积操作。</li>
<li><strong>bias</strong> (默认为<code>True</code>): 是否添加偏置项。大多数卷积层会有一个可学习的偏置参数，每个输出通道一个。</li>
</ol>
<p>使用两个<code>nn.Conv2d</code>是为了<strong>深度特征提取</strong>：通过在一个卷积层中使用两个连续的卷积操作（<code>nn.Conv2d</code>），网络能够在不改变特征图空间尺寸的情况下学习更深层次的特征。这是因为第一个卷积层提取基本特征后，第二个卷积层可以在这些特征的基础上进一步构建更复杂的特征表示。</p>
<p><code>norm_layer(64)</code>中的数字64表示规范化层应该处理的通道数。这个数字必须与它前面的卷积层输出的通道数相匹配。</p>
<p><code>mode='nearest'</code>：这个参数定义了上采样时使用的插值方法。<code>'nearest'</code>意味着使用最近邻插值，这是一种简单的插值方法，直接将源像素的值赋给最近的目标像素，不涉及任何计算。相比其他插值方法如双线性（bilinear）或双三次（bicubic）插值，最近邻插值计算速度更快，但可能在视觉质量上不如其他方法平滑。</p>
<p><code>self.pool = nn.MaxPool2d(2)</code>：这表示池化窗口的大小是2x2。</p>
<p><code>self.drop = nn.Dropout(0.5)</code> 这表示在训练过程中，每个神经元有50%的概率被丢弃（其输出被设置为0）。这种随机性使得网络的不同部分能够独立学习特征，从而提高了模型的泛化能力</p>
<h2 id="gmm-related-geometric-matching-module-classes">GMM-related (Geometric Matching Module) classes</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">FeatureExtraction</span>(<span class="hljs-title class_ inherited__">BaseNetwork</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_nc, ngf=<span class="hljs-number">64</span>, num_layers=<span class="hljs-number">4</span>, norm_layer=nn.BatchNorm2d</span>):<br>        <span class="hljs-built_in">super</span>(FeatureExtraction, self).__init__()<br><br>        nf = ngf <span class="hljs-comment"># number of generator features</span><br>        layers = [nn.Conv2d(input_nc, nf, kernel_size=<span class="hljs-number">4</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>), nn.ReLU(), norm_layer(nf)]<br><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, num_layers):<br>            nf_prev = nf<br>            nf = <span class="hljs-built_in">min</span>(nf * <span class="hljs-number">2</span>, <span class="hljs-number">512</span>)<br>            layers += [nn.Conv2d(nf_prev, nf, kernel_size=<span class="hljs-number">4</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>), nn.ReLU(), norm_layer(nf)]<br><br>        layers += [nn.Conv2d(nf, <span class="hljs-number">512</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>), nn.ReLU(), norm_layer(<span class="hljs-number">512</span>)]<br>        layers += [nn.Conv2d(<span class="hljs-number">512</span>, <span class="hljs-number">512</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>), nn.ReLU()]<br><br>        self.model = nn.Sequential(*layers)<br>        self.init_weights()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">return</span> self.model(x)<br><br></code></pre></td></tr></table></figure>
<p>这个类的目的是实现一个特征提取网络，通常用于深度学习和计算机视觉任务中从输入图像中自动学习有效特征。</p>
<p>在<code>nn.Sequential(*layers)</code>这段代码中，<code>*layers</code>的作用就是将<code>layers</code>列表中的每个元素作为单独的参数传递给<code>nn.Sequential</code>构造器。</p>
<h3 id="featurecorrelation-and-featureregression-class">FeatureCorrelation and FeatureRegression Class</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">FeatureCorrelation</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(FeatureCorrelation, self).__init__()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, featureA, featureB</span>):<br>        <span class="hljs-comment"># Reshape features for matrix multiplication.</span><br>        b, c, h, w = featureA.size()<br>        featureA = featureA.permute(<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>).reshape(b, w * h, c)<br>        featureB = featureB.reshape(b, c, h * w)<br><br>        <span class="hljs-comment"># Perform matrix multiplication.</span><br>        corr = torch.bmm(featureA, featureB).reshape(b, w * h, h, w)<br>        <span class="hljs-keyword">return</span> corr<br></code></pre></td></tr></table></figure>
<p><code>FeatureCorrelation</code>类用于计算两组特征映射（featureA和featureB）之间的相关性。这通常用于确定两个不同图像区域的相似度或特征对齐程度。</p>
<h5 id="permute函数">permute函数：</h5>
<p>在PyTorch中，<code>permute</code>函数用于重新排列多维数组（张量）的维度。</p>
<p><strong>示例：</strong></p>
<p>假设有一个四维张量<code>A</code>，其形状为<code>(b, c, h, w)</code>，其中<code>b</code>是批大小，<code>c</code>是通道数，<code>h</code>是高度，<code>w</code>是宽度。 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">A_permuted = A.permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure></p>
<p>这会改变<code>A</code>的形状为<code>(b, h, w, c)</code>。</p>
<h4 id="三维矩阵乘法batch-matrix-multiplication">三维矩阵乘法（batch matrix multiplication）</h4>
<p><code>torch.bmm</code>用于批次矩阵乘法。这个函数接受两个三维张量，通常形状为<code>(b, n, m)</code>和<code>(b, m, p)</code>，并对这两个张量的每一个相应的二维矩阵执行矩阵乘法，结果是一个形状为<code>(b, n, p)</code>的三维张量。</p>
<h5 id="为什么用三维矩阵乘法">为什么用三维矩阵乘法：</h5>
<p>在处理批次数据时，常常需要独立地对每个样本执行操作。使用<code>torch.bmm</code>允许在一个操作中同时处理整个批次，这比循环每个样本进行矩阵乘法要高效得多。</p>
<p>这里的乘法其实就是对 H x W 图像的每一个像素点上的feature vector与另一个图像上的每一个feature vector做dot product得到的矩阵.</p>
<p>reshape之后，图像的大小还是 <span class="math inline">\(H \times W\)</span>， 然后每个channel表示图像A在这个位置的feature vector, 与图像B每个位置feature vector的点积构成的 <span class="math inline">\(H \times W\)</span> 的map</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">FeatureRegression</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_nc=<span class="hljs-number">512</span>, output_size=<span class="hljs-number">6</span>, norm_layer=nn.BatchNorm2d</span>):<br>        <span class="hljs-built_in">super</span>(FeatureRegression, self).__init__()<br><br>        self.conv = nn.Sequential(<br>            nn.Conv2d(input_nc, <span class="hljs-number">512</span>, kernel_size=<span class="hljs-number">4</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>), norm_layer(<span class="hljs-number">512</span>), nn.ReLU(),<br>            nn.Conv2d(<span class="hljs-number">512</span>, <span class="hljs-number">256</span>, kernel_size=<span class="hljs-number">4</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>), norm_layer(<span class="hljs-number">256</span>), nn.ReLU(),<br>            nn.Conv2d(<span class="hljs-number">256</span>, <span class="hljs-number">128</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>), norm_layer(<span class="hljs-number">128</span>), nn.ReLU(),<br>            nn.Conv2d(<span class="hljs-number">128</span>, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>), norm_layer(<span class="hljs-number">64</span>), nn.ReLU()<br>        )<br>        self.linear = nn.Linear(<span class="hljs-number">64</span> * (input_nc // <span class="hljs-number">16</span>), output_size)<br>        self.tanh = nn.Tanh()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.conv(x)<br>        x = self.linear(x.reshape(x.size(<span class="hljs-number">0</span>), -<span class="hljs-number">1</span>))<br>        <span class="hljs-keyword">return</span> self.tanh(x)<br></code></pre></td></tr></table></figure>
<p><code>FeatureRegression</code>类通过多层卷积网络进一步处理特征（或已经某种方式提取的特征），然后使用一个线性层将结果映射到一个较小的输出空间（通常用于决策或预测）。例如，在视觉姿态估计中，可以用于从特征映射中预测对象的旋转和平移。</p>
<ol type="1">
<li>第一层卷积层<code>nn.Conv2d(input_nc, 512, kernel_size=4, stride=2, padding=1)</code>: 这一层会将特征图的高度和宽度都减半（假设h和w足够大，可以被2整除）。新的尺寸大约是 <code>h/2</code> 和 <code>w/2</code>。</li>
<li>第二层卷积层<code>nn.Conv2d(512, 256, kernel_size=4, stride=2, padding=1)</code>: 再次将特征图尺寸减半，变为 <code>h/4</code> 和 <code>w/4</code>。</li>
<li>第三层卷积层<code>nn.Conv2d(256, 128, kernel_size=3, padding=1)</code>: 这一层因为步长默认为1，所以尺寸几乎保持不变，仍然是 <code>h/4</code> 和 <code>w/4</code>。</li>
<li>第四层卷积层<code>nn.Conv2d(128, 64, kernel_size=3, padding=1)</code>: 同样，尺寸几乎保持不变，为 <code>h/4</code> 和 <code>w/4</code>。</li>
</ol>
<p>所以最后一个卷积层输出的特征图的尺寸是 <code>(b, 64, h/4, w/4)</code>，所以线性层的大小应该为<code>64 * (h/4) * (w/4)</code>， 而这里是令<code>input_nc = h * w</code>，所以就有了他最后的表达式<code>self.linear = nn.Linear(64 * (input_nc // 16), output_size)</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">TpsGridGen</span>(nn.Module)<br></code></pre></td></tr></table></figure>
<p>然后是一个TPS变换的实现，这里我不太懂原理，就先不写了。</p>
<h3 id="gmm-class">GMM Class</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">GMM</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, opt, inputA_nc, inputB_nc</span>):<br>        <span class="hljs-built_in">super</span>(GMM, self).__init__()<br><br>        self.extractionA = FeatureExtraction(inputA_nc, ngf=<span class="hljs-number">64</span>, num_layers=<span class="hljs-number">4</span>)<br>        self.extractionB = FeatureExtraction(inputB_nc, ngf=<span class="hljs-number">64</span>, num_layers=<span class="hljs-number">4</span>)<br>        self.correlation = FeatureCorrelation()<br>        self.regression = FeatureRegression(input_nc=(opt.load_width // <span class="hljs-number">64</span>) * (opt.load_height // <span class="hljs-number">64</span>),<br>                                            output_size=<span class="hljs-number">2</span> * opt.grid_size**<span class="hljs-number">2</span>)<br>        self.gridGen = TpsGridGen(opt)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, inputA, inputB</span>):<br>        featureA = F.normalize(self.extractionA(inputA), dim=<span class="hljs-number">1</span>)<br>        featureB = F.normalize(self.extractionB(inputB), dim=<span class="hljs-number">1</span>)<br>        corr = self.correlation(featureA, featureB)<br>        theta = self.regression(corr)<br><br>        warped_grid = self.gridGen(theta)<br>        <span class="hljs-keyword">return</span> theta, warped_grid<br></code></pre></td></tr></table></figure>
<p><code>self.regression = FeatureRegression(input_nc=(opt.load_width // 64) * (opt.load_height // 64), output_size=2 * opt.grid_size**2)</code>实例化一个特征回归模块，用于从特征相关性数据中回归出变换参数。输入特征数量是图像维度减小64倍后的乘积，输出大小是控制点数量的两倍（通常用于薄板样条变换）。</p>
<p><code>self.gridGen = TpsGridGen(opt)</code> 初始化一个TPS网格生成模块，用于根据回归出的变换参数生成变形后的网格。</p>
<p><code>return theta, warped_grid</code>返回变换参数theta和变换后的网格。这使得可以进一步用于图像变形或分析变换效果。 ## ALIASGenerator-related classes</p>
<h3 id="masknorm">MaskNorm</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MaskNorm</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, norm_nc</span>):<br>        <span class="hljs-built_in">super</span>(MaskNorm, self).__init__()<br><br>        self.norm_layer = nn.InstanceNorm2d(norm_nc, affine=<span class="hljs-literal">False</span>)<br></code></pre></td></tr></table></figure>
<p>在深度学习中，特别是在使用归一化层（如批量归一化、实例归一化等）时，"affine" 参数指的是是否要在归一化之后应用可学习的缩放（scale）和平移（shift）参数。这两个参数允许模型在归一化过程中进一步调整数据，以适应特定的数据分布。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">normalize_region</span>(<span class="hljs-params">self, region, mask</span>):<br>    b, c, h, w = region.size()<br><br>    num_pixels = mask.<span class="hljs-built_in">sum</span>((<span class="hljs-number">2</span>, <span class="hljs-number">3</span>), keepdim=<span class="hljs-literal">True</span>)  <span class="hljs-comment"># size: (b, 1, 1, 1)</span><br>    num_pixels[num_pixels == <span class="hljs-number">0</span>] = <span class="hljs-number">1</span><br>    mu = region.<span class="hljs-built_in">sum</span>((<span class="hljs-number">2</span>, <span class="hljs-number">3</span>), keepdim=<span class="hljs-literal">True</span>) / num_pixels  <span class="hljs-comment"># size: (b, c, 1, 1)</span><br><br>    normalized_region = self.norm_layer(region + (<span class="hljs-number">1</span> - mask) * mu)<br>    <span class="hljs-keyword">return</span> normalized_region * torch.sqrt(num_pixels / (h * w))<br></code></pre></td></tr></table></figure>
<p>根据论文，这里的region是 <span class="math inline">\(\hat{S}_{c}\)</span> , 即segmentation map中的衣服部分, 然后mask即为<span class="math inline">\(W(M_{c}, \theta)\)</span>.</p>
<p><code>num_pixels = mask.sum((2, 3), keepdim=True)  # size: (b, 1, 1, 1)</code></p>
<ul>
<li><code>mask.sum((2, 3), keepdim=True)</code>：这里的<code>mask</code>是一个形状为<code>(b, c, h, w)</code>的张量，其中<code>b</code>是批次大小，<code>c</code>是通道数，<code>h</code>和<code>w</code>分别是高度和宽度。<code>mask.sum((2, 3), keepdim=True)</code>对每个通道的所有像素进行求和，这意味着对每个样本（batch）和每个通道，在高度<code>h</code>和宽度<code>w</code>的维度上进行求和。</li>
<li><code>keepdim=True</code>保持原有的四维张量形状，使输出的维度仍然是<code>(b, c, 1, 1)</code>而不是折叠成<code>(b, c)</code>。这对于后续的广播操作非常重要。</li>
</ul>
<p><code>num_pixels[num_pixels == 0] = 1</code></p>
<ul>
<li>这行代码处理了一个特殊情况：如果某个通道中没有任何被掩码覆盖的像素（即该通道的像素总和为0），则将这些通道的像素数设置为1。这样做的目的是避免后续计算中出现除以零的错误。</li>
<li>将像素数设为1是一个常用的技巧，以保证数值稳定性。这在统计和计算中很常见，例如，在计算平均值或归一化时，需要通过总数除以某个数，如果这个数为零则会导致计算错误或结果为无穷大。</li>
</ul>
<p><code>mu = region.sum((2, 3), keepdim=True) / num_pixels  # size: (b, c, 1, 1)</code>计算被掩码覆盖的区域的均值<code>mu</code>。</p>
<p><code>normalized_region = self.norm_layer(region + (1 - mask) * mu)</code></p>
<p>这一句使整张图像素的均值变成<span class="math inline">\(\mu\)</span> , 从而对整张图进行normalization相当于只在mask的区域上进行normalization。</p>
<p><code>return normalized_region * torch.sqrt(num_pixels / (h * w))</code></p>
<p>原文: ALIAS normalization standardizes the regions of <span class="math inline">\(M_{misalign}\)</span> and the other regions in <span class="math inline">\(h_{i}\)</span> separately, and then modulates the standardized activation using affine (仿射的）transformation parameters inferred from <span class="math inline">\(\hat{S}_{div}\)</span> .</p>
<p>返回归一化后的区域，乘以一个校正因子，这个因子基于掩码覆盖的像素数与总像素数的比例的平方根，以调整归一化的尺度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x, mask</span>):<br>    mask = mask.detach()<br>    normalized_foreground = self.normalize_region(x * mask, mask)<br>    normalized_background = self.normalize_region(x * (<span class="hljs-number">1</span> - mask), <span class="hljs-number">1</span> - mask)<br>    <span class="hljs-keyword">return</span> normalized_foreground + normalized_background<br></code></pre></td></tr></table></figure>
<p>在 PyTorch 中，当你使用 <code>.detach()</code> 方法时，你实际上是在创建一个新的张量，该张量与原始张量共享数据，但不会在其上进行梯度计算。</p>
<h3 id="aliasnorm">ALIASNorm</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">ALIASNorm</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, norm_type, norm_nc, label_nc</span>):<br>        <span class="hljs-built_in">super</span>(ALIASNorm, self).__init__()<br><br>        self.noise_scale = nn.Parameter(torch.zeros(norm_nc))<br><br>        <span class="hljs-keyword">assert</span> norm_type.startswith(<span class="hljs-string">&#x27;alias&#x27;</span>)<br>        param_free_norm_type = norm_type[<span class="hljs-built_in">len</span>(<span class="hljs-string">&#x27;alias&#x27;</span>):]<br>        <span class="hljs-keyword">if</span> param_free_norm_type == <span class="hljs-string">&#x27;batch&#x27;</span>:<br>            self.param_free_norm = nn.BatchNorm2d(norm_nc, affine=<span class="hljs-literal">False</span>)<br>        <span class="hljs-keyword">elif</span> param_free_norm_type == <span class="hljs-string">&#x27;instance&#x27;</span>:<br>            self.param_free_norm = nn.InstanceNorm2d(norm_nc, affine=<span class="hljs-literal">False</span>)<br>        <span class="hljs-keyword">elif</span> param_free_norm_type == <span class="hljs-string">&#x27;mask&#x27;</span>:<br>            self.param_free_norm = MaskNorm(norm_nc)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">raise</span> ValueError(<br>                <span class="hljs-string">&quot;&#x27;&#123;&#125;&#x27; is not a recognized parameter-free normalization type in ALIASNorm&quot;</span>.<span class="hljs-built_in">format</span>(param_free_norm_type)<br>            )<br><br>        nhidden = <span class="hljs-number">128</span> <br>        ks = <span class="hljs-number">3</span> <span class="hljs-comment"># kernel size</span><br>        pw = ks // <span class="hljs-number">2</span> <span class="hljs-comment"># Padding Width</span><br>        self.conv_shared = nn.Sequential(nn.Conv2d(label_nc, nhidden, kernel_size=ks, padding=pw), nn.ReLU())<br>        self.conv_gamma = nn.Conv2d(nhidden, norm_nc, kernel_size=ks, padding=pw)<br>        self.conv_beta = nn.Conv2d(nhidden, norm_nc, kernel_size=ks, padding=pw)<br></code></pre></td></tr></table></figure>
<p><code>self.noise_scale = nn.Parameter(torch.zeros(norm_nc))</code>定义一个可学习的参数 <code>noise_scale</code>，其形状为 <code>(norm_nc,)</code>，用于调整噪声的强度。</p>
<p>这里传入的归一化类型以 "alias" 开始，并从 <code>norm_type</code> 字符串中提取真实的归一化类型。</p>
<p>定义三个卷积层：<code>conv_shared</code> 用于从输入的分割图中提取特征；<code>conv_gamma</code> 和 <code>conv_beta</code> 用这些特征生成 <code>gamma</code>（缩放）和 <code>beta</code>（偏移）参数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x, seg, misalign_mask=<span class="hljs-literal">None</span></span>):<br>    <span class="hljs-comment"># Part 1. Generate parameter-free normalized activations.</span><br>    b, c, h, w = x.size()<br>    noise = (torch.randn(b, w, h, <span class="hljs-number">1</span>).cuda() * self.noise_scale).transpose(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>)<br><br>    <span class="hljs-keyword">if</span> misalign_mask <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>        normalized = self.param_free_norm(x + noise)<br>    <span class="hljs-keyword">else</span>:<br>        normalized = self.param_free_norm(x + noise, misalign_mask)<br><br>    <span class="hljs-comment"># Part 2. Produce affine parameters conditioned on the segmentation map.</span><br>    actv = self.conv_shared(seg)<br>    gamma = self.conv_gamma(actv)<br>    beta = self.conv_beta(actv)<br><br>    <span class="hljs-comment"># Apply the affine parameters.</span><br>    output = normalized * (<span class="hljs-number">1</span> + gamma) + beta<br>    <span class="hljs-keyword">return</span> output<br></code></pre></td></tr></table></figure>
<p><code>torch.randn(b, w, h, 1)</code> 生成一个形状为 <code>(b, w, h, 1)</code> 的张量, 这个形状的选择初始是不匹配输入 <code>x</code> 的形状 <code>(b, c, h, w)</code>，特别是在通道维度上。</p>
<p><code>.transpose(1, 3)</code> 交换噪声张量的第二和第四维，从 <code>(b, w, h, 1)</code> 转换为 <code>(b, 1, h, w)</code>。这个转置操作是为了使噪声张量的形状与输入 <code>x</code> 的形状对齐，特别是匹配通道维度 <code>c</code>，使得噪声可以被正确地加到输入 <code>x</code> 上。</p>
<p><code>.cuda()</code> 确保生成的噪声张量在 GPU 上进行计算（假设使用 CUDA），以加速后续操作。 <code>* self.noise_scale</code> 将噪声张量的每个元素乘以一个可学习的参数</p>
<p>这种方式生成并处理噪声的目的是为了引入一种随机性，可能用于增强模型的泛化能力，防止过拟合，或在特定应用中模拟一些实际的变化情况（如在图像数据中模拟感应器噪声等）。通过可学习的噪声强度，模型可以自适应地调整噪声对学习过程的影响程度。</p>
<h3 id="aliasresblock">ALIASResBlock</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">ALIASResBlock</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, opt, input_nc, output_nc, use_mask_norm=<span class="hljs-literal">True</span></span>):<br>        <span class="hljs-built_in">super</span>(ALIASResBlock, self).__init__()<br><br>        self.learned_shortcut = (input_nc != output_nc)<br>        middle_nc = <span class="hljs-built_in">min</span>(input_nc, output_nc)<br><br>        self.conv_0 = nn.Conv2d(input_nc, middle_nc, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>)<br>        self.conv_1 = nn.Conv2d(middle_nc, output_nc, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">if</span> self.learned_shortcut:<br>            self.conv_s = nn.Conv2d(input_nc, output_nc, kernel_size=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">False</span>)<br><br>        subnorm_type = opt.norm_G<br>        <span class="hljs-keyword">if</span> subnorm_type.startswith(<span class="hljs-string">&#x27;spectral&#x27;</span>):<br>            subnorm_type = subnorm_type[<span class="hljs-built_in">len</span>(<span class="hljs-string">&#x27;spectral&#x27;</span>):]<br>            self.conv_0 = spectral_norm(self.conv_0)<br>            self.conv_1 = spectral_norm(self.conv_1)<br>            <span class="hljs-keyword">if</span> self.learned_shortcut:<br>                self.conv_s = spectral_norm(self.conv_s)<br><br>        semantic_nc = opt.semantic_nc<br>        <span class="hljs-keyword">if</span> use_mask_norm:<br>            subnorm_type = <span class="hljs-string">&#x27;aliasmask&#x27;</span><br>            semantic_nc = semantic_nc + <span class="hljs-number">1</span><br><br>        self.norm_0 = ALIASNorm(subnorm_type, input_nc, semantic_nc)<br>        self.norm_1 = ALIASNorm(subnorm_type, middle_nc, semantic_nc)<br>        <span class="hljs-keyword">if</span> self.learned_shortcut:<br>            self.norm_s = ALIASNorm(subnorm_type, input_nc, semantic_nc)<br><br>        self.relu = nn.LeakyReLU(<span class="hljs-number">0.2</span>)<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> use_mask_norm:<br>    subnorm_type = <span class="hljs-string">&#x27;aliasmask&#x27;</span><br>    semantic_nc = semantic_nc + <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure>
<p>这段代码是因为之后的Generator中，如果用mask_norm，那么传给ALIASResBlock的channel就会多一个。</p>
<p>通过<code>self.learned_shortcut = (input_nc != output_nc)</code>判断输入和输出通道数是否相同，以决定是否需要学习一个额外的快捷路径（shortcut 或 skip connection）。如果通道数不同，通过一个卷积层调整维度使之匹配。因为这里的相加并不是concatenate，就是直接把数值相加。</p>
<p><code>middle_nc = min(input_nc, output_nc)</code>选择输入和输出通道数中较小的一个作为中间层的通道数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> self.learned_shortcut:         <br>	self.conv_s = nn.Conv2d(input_nc, output_nc, kernel_size=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">False</span>)`<br></code></pre></td></tr></table></figure>
<p>如果需要一个学习的快捷路径（当输入和输出通道数不同时），则定义一个额外的 <code>conv_s</code> 卷积层，使用 1x1 的卷积核调整通道数，没有偏置项（<code>bias=False</code>），以减少参数数量。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> subnorm_type.startswith(<span class="hljs-string">&#x27;spectral&#x27;</span>):<br></code></pre></td></tr></table></figure>
<p>这句话检验是否指定了频谱归一化（<code>spectral</code>）。如果是，将频谱归一化应用于相关的卷积层，以稳定训练过程并限制特定层的权重范围。</p>
<p><code>semantic_nc = opt.semantic_nc</code>获取语义通道数，用于后续的归一化层配置。</p>
<p>如果启用了掩码归一化，则设置归一化类型为 <code>aliasmask</code> 并调整语义通道数。</p>
<p>定义两个归一化层 <code>norm_0</code> 和 <code>norm_1</code>，分别应用于 <code>conv_0</code> 和 <code>conv_1</code> 的输出。</p>
<p>如果有学习的快捷路径，则为该路径也定义一个归一化层。</p>
<ul>
<li>定义激活函数为泄漏的ReLU，斜率为0.2，这有助于保持梯度流通，特别是在GAN中常见。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x, seg, misalign_mask=<span class="hljs-literal">None</span></span>):<br>    seg = F.interpolate(seg, size=x.size()[<span class="hljs-number">2</span>:], mode=<span class="hljs-string">&#x27;nearest&#x27;</span>)<br>    <span class="hljs-keyword">if</span> misalign_mask <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>        misalign_mask = F.interpolate(misalign_mask, size=x.size()[<span class="hljs-number">2</span>:], mode=<span class="hljs-string">&#x27;nearest&#x27;</span>)<br><br>    x_s = self.shortcut(x, seg, misalign_mask)<br><br>    dx = self.conv_0(self.relu(self.norm_0(x, seg, misalign_mask)))<br>    dx = self.conv_1(self.relu(self.norm_1(dx, seg, misalign_mask)))<br>    output = x_s + dx<br>    <span class="hljs-keyword">return</span> output<br></code></pre></td></tr></table></figure>
<p>先看forward，这里的逻辑与图片相匹配，一条线是 x 经过两次conv， 一条线是 x 经过一次conv，然后加在一起。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">ALIASNorm</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, norm_type, norm_nc, label_nc</span>)<br>		<span class="hljs-keyword">elif</span> param_free_norm_type == <span class="hljs-string">&#x27;mask&#x27;</span>:<br>            self.param_free_norm = MaskNorm(norm_nc)<br>            <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x, seg, misalign_mask=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-comment"># Part 1. Generate parameter-free normalized activations.</span><br>        b, c, h, w = x.size()<br>        noise = (torch.randn(b, w, h, <span class="hljs-number">1</span>).cuda() * self.noise_scale).transpose(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>)<br><br>        <span class="hljs-keyword">if</span> misalign_mask <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            normalized = self.param_free_norm(x + noise)<br>        <span class="hljs-keyword">else</span>:<br>            normalized = self.param_free_norm(x + noise, misalign_mask)<br><br>        <span class="hljs-comment"># Part 2. Produce affine parameters conditioned on the segmentation map.</span><br>        actv = self.conv_shared(seg)<br>        gamma = self.conv_gamma(actv)<br>        beta = self.conv_beta(actv)<br><br>        <span class="hljs-comment"># Apply the affine parameters.</span><br>        output = normalized * (<span class="hljs-number">1</span> + gamma) + beta<br>        <span class="hljs-keyword">return</span> output<br><br>self.norm_0 = ALIASNorm(subnorm_type, input_nc, semantic_nc)<br><br>dx = self.conv_0(self.relu(self.norm_0(x, seg, misalign_mask)))<br></code></pre></td></tr></table></figure>
<p>这里嵌套有点多了，所以解释一下: 这里 ALIASResBlock 的每一个 norm 层都是一个 ALIAS norm实例，然后这里的<code>norm_nc</code>是归一化层的通道数，即 <span class="math inline">\(C\)</span>. <code>label_nc</code>表示segmentation map的通道数，因为 shift parameters 还要通过 segmentation map 经过卷积产生。</p>
<p>这里返回的是一个ALIASNorm对象，为什么可以直接再当做函数，对<code>(x, seg, misalignment_mask)</code>调用呢: 在 PyTorch 中，实例化后的对象（如 <code>ALIASNorm</code>）可以直接调用，这通常是因为该类实现了一个 <code>__call__</code> 方法。在大多数 PyTorch 模块中，这是通过继承自 <code>nn.Module</code> 并实现 <code>forward</code> 方法实现的。当你像调用函数那样调用一个模块实例时，Python 实际上会执行该对象的 <code>__call__</code> 方法，而 <code>__call__</code> 方法会进一步调用 <code>forward</code> 方法。</p>
<p>所以这里<code>self.norm_0(x, seg, misalign_mask)</code>其实是<code>ALIASNorm.forward(x, seg, misalign_mask)</code>，然后在forward的过程中，seg被用来产生<span class="math inline">\(\gamma\)</span> 和 <span class="math inline">\(\beta\)</span>。<code>(x, seg)</code>又被<code>MaskNorm.forward(x, seg)</code>来进行ALIAS Normalization.（如果使用论文中所说的方法的话）</p>
<p><img src="https://s2.loli.net/2024/04/27/VRkCs2NeiMJ6hE9.png" srcset="/img/loading.gif" lazyload /> ### ALIASGenerator 先看看这个类的compute_latent_vector_size函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">ALIASGenerator</span>(<span class="hljs-title class_ inherited__">BaseNetwork</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_latent_vector_size</span>(<span class="hljs-params">self, opt</span>):<br>        <span class="hljs-keyword">if</span> self.num_upsampling_layers == <span class="hljs-string">&#x27;normal&#x27;</span>:<br>            num_up_layers = <span class="hljs-number">5</span><br>        <span class="hljs-keyword">elif</span> self.num_upsampling_layers == <span class="hljs-string">&#x27;more&#x27;</span>:<br>            num_up_layers = <span class="hljs-number">6</span><br>        <span class="hljs-keyword">elif</span> self.num_upsampling_layers == <span class="hljs-string">&#x27;most&#x27;</span>:<br>            num_up_layers = <span class="hljs-number">7</span><br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&quot;opt.num_upsampling_layers &#x27;&#123;&#125;&#x27; is not recognized&quot;</span>.<span class="hljs-built_in">format</span>(self.num_upsampling_layers))<br><br>        sh = opt.load_height // <span class="hljs-number">2</span>**num_up_layers<br>        sw = opt.load_width // <span class="hljs-number">2</span>**num_up_layers<br>        <span class="hljs-keyword">return</span> sh, sw    <br></code></pre></td></tr></table></figure>
<p><code>compute_latent_vector_size</code> 方法的目的是为了确定生成模型在生成过程开始时应该使用的潜在向量的初始尺寸，从而确保整个上采样过程能够顺利进行，最终生成期望尺寸的图像。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, opt, input_nc</span>):<br>    <span class="hljs-built_in">super</span>(ALIASGenerator, self).__init__()<br>    self.num_upsampling_layers = opt.num_upsampling_layers<br><br>    self.sh, self.sw = self.compute_latent_vector_size(opt)<br><br>    nf = opt.ngf<br>    self.conv_0 = nn.Conv2d(input_nc, nf * <span class="hljs-number">16</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">8</span>):<br>        self.add_module(<span class="hljs-string">&#x27;conv_&#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(i), nn.Conv2d(input_nc, <span class="hljs-number">16</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>))<br><br>    self.head_0 = ALIASResBlock(opt, nf * <span class="hljs-number">16</span>, nf * <span class="hljs-number">16</span>)<br><br>    self.G_middle_0 = ALIASResBlock(opt, nf * <span class="hljs-number">16</span> + <span class="hljs-number">16</span>, nf * <span class="hljs-number">16</span>)<br>    self.G_middle_1 = ALIASResBlock(opt, nf * <span class="hljs-number">16</span> + <span class="hljs-number">16</span>, nf * <span class="hljs-number">16</span>)<br><br>    self.up_0 = ALIASResBlock(opt, nf * <span class="hljs-number">16</span> + <span class="hljs-number">16</span>, nf * <span class="hljs-number">8</span>)<br>    self.up_1 = ALIASResBlock(opt, nf * <span class="hljs-number">8</span> + <span class="hljs-number">16</span>, nf * <span class="hljs-number">4</span>)<br>    self.up_2 = ALIASResBlock(opt, nf * <span class="hljs-number">4</span> + <span class="hljs-number">16</span>, nf * <span class="hljs-number">2</span>, use_mask_norm=<span class="hljs-literal">False</span>)<br>    self.up_3 = ALIASResBlock(opt, nf * <span class="hljs-number">2</span> + <span class="hljs-number">16</span>, nf * <span class="hljs-number">1</span>, use_mask_norm=<span class="hljs-literal">False</span>)<br>    <span class="hljs-keyword">if</span> self.num_upsampling_layers == <span class="hljs-string">&#x27;most&#x27;</span>:<br>        self.up_4 = ALIASResBlock(opt, nf * <span class="hljs-number">1</span> + <span class="hljs-number">16</span>, nf // <span class="hljs-number">2</span>, use_mask_norm=<span class="hljs-literal">False</span>)<br>        nf = nf // <span class="hljs-number">2</span><br><br>    self.conv_img = nn.Conv2d(nf, <span class="hljs-number">3</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>)<br><br>    self.up = nn.Upsample(scale_factor=<span class="hljs-number">2</span>, mode=<span class="hljs-string">&#x27;nearest&#x27;</span>)<br>    self.relu = nn.LeakyReLU(<span class="hljs-number">0.2</span>)<br>    self.tanh = nn.Tanh()<br><br>    self.print_network()<br>    self.init_weights(opt.init_type, opt.init_variance)<br></code></pre></td></tr></table></figure>
<p>这里就是定义了一些基本模块，要结合下面的<code>forward</code>函数来看。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x, seg, seg_div, misalign_mask</span>):<br>    samples = [F.interpolate(x, size=(self.sh * <span class="hljs-number">2</span>**i, self.sw * <span class="hljs-number">2</span>**i), mode=<span class="hljs-string">&#x27;nearest&#x27;</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">8</span>)]<br>    features = [self._modules[<span class="hljs-string">&#x27;conv_&#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(i)](samples[i]) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">8</span>)]<br><br>    x = self.head_0(features[<span class="hljs-number">0</span>], seg_div, misalign_mask)<br><br>    x = self.up(x)<br>    x = self.G_middle_0(torch.cat((x, features[<span class="hljs-number">1</span>]), <span class="hljs-number">1</span>), seg_div, misalign_mask)<br>    <span class="hljs-keyword">if</span> self.num_upsampling_layers <span class="hljs-keyword">in</span> [<span class="hljs-string">&#x27;more&#x27;</span>, <span class="hljs-string">&#x27;most&#x27;</span>]:<br>        x = self.up(x)<br>    x = self.G_middle_1(torch.cat((x, features[<span class="hljs-number">2</span>]), <span class="hljs-number">1</span>), seg_div, misalign_mask)<br><br>    x = self.up(x)<br>    x = self.up_0(torch.cat((x, features[<span class="hljs-number">3</span>]), <span class="hljs-number">1</span>), seg_div, misalign_mask)<br>    x = self.up(x)<br>    x = self.up_1(torch.cat((x, features[<span class="hljs-number">4</span>]), <span class="hljs-number">1</span>), seg_div, misalign_mask)<br>    x = self.up(x)<br>    x = self.up_2(torch.cat((x, features[<span class="hljs-number">5</span>]), <span class="hljs-number">1</span>), seg)<br>    x = self.up(x)<br>    x = self.up_3(torch.cat((x, features[<span class="hljs-number">6</span>]), <span class="hljs-number">1</span>), seg)<br>    <span class="hljs-keyword">if</span> self.num_upsampling_layers == <span class="hljs-string">&#x27;most&#x27;</span>:<br>        x = self.up(x)<br>        x = self.up_4(torch.cat((x, features[<span class="hljs-number">7</span>]), <span class="hljs-number">1</span>), seg)<br><br>    x = self.conv_img(self.relu(x))<br>    <span class="hljs-keyword">return</span> self.tanh(x)<br></code></pre></td></tr></table></figure>
<p>这里第一步缩放 x，用原文的话说就是</p>
<blockquote>
<p>The input <span class="math inline">\((I_{a}, P, \mathcal{W}(c, \theta)\)</span> is resized and injected into each layer of the generator. In this manner, the network performs the multi-scale refinement at a feature level that preserves the clothing details than a single refinement at the pixel level.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">features = [self._modules[<span class="hljs-string">&#x27;conv_&#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(i)](samples[i]) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">8</span>)]<br></code></pre></td></tr></table></figure>
<p>然后进一步是从图片中提取feature</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">x = self.up_0(torch.cat((x, features[<span class="hljs-number">3</span>]), <span class="hljs-number">1</span>), seg_div, misalign_mask)<br></code></pre></td></tr></table></figure>
<p>这里引用原文就是</p>
<blockquote>
<p>Before each ResBlk, the resized inputs <span class="math inline">\((I_{a}, P, \mathcal{W}(c, \theta)\)</span> are concatenated to the activation of the previous layer after passing through a convolutional layer, and each ResBlk utilizes the concatenated inputs to refine the activations. # test.py</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> argparse<br><span class="hljs-keyword">import</span> os<br><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">import</span> torchgeometry <span class="hljs-keyword">as</span> tgm<br><br><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> VITONDataset, VITONDataLoader<br><span class="hljs-keyword">from</span> networks <span class="hljs-keyword">import</span> SegGenerator, GMM, ALIASGenerator<br><span class="hljs-keyword">from</span> utils <span class="hljs-keyword">import</span> gen_noise, load_checkpoint, save_images<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_opt</span>():<br>    parser = argparse.ArgumentParser()<br>    parser.add_argument(<span class="hljs-string">&#x27;--name&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, required=<span class="hljs-literal">True</span>)<br><br>    parser.add_argument(<span class="hljs-string">&#x27;-b&#x27;</span>, <span class="hljs-string">&#x27;--batch_size&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">1</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;-j&#x27;</span>, <span class="hljs-string">&#x27;--workers&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">1</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;--load_height&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">1024</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;--load_width&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">768</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;--shuffle&#x27;</span>, action=<span class="hljs-string">&#x27;store_true&#x27;</span>)<br><br>	<span class="hljs-comment"># 中间省略了很多的add_argument</span><br>	<br>    opt = parser.parse_args()<br>    <span class="hljs-keyword">return</span> opt<br></code></pre></td></tr></table></figure>
<p>这个函数使用 Python 的 <code>argparse</code> 库来解析命令行参数。<code>argparse</code> 是一个非常有用的库，用于编写用户友好的命令行接口，它能够处理用户输入的参数，并自动生成帮助和使用信息。</p>
<p><code>parser = argparse.ArgumentParser()</code>: 创建一个新的 <code>ArgumentParser</code> 对象，这个对象会存储所有需要从命令行解析的信息。</p>
<p><code>parser.add_argument('--name', type=str, required=True)</code>: 这行代码添加了一个必需的参数 <code>--name</code>。用户在命令行中必须提供这个参数，否则程序会报错。参数类型被设定为字符串 (<code>str</code>)。</p>
<p><code>parser.add_argument('-b', '--batch_size', type=int, default=1)</code>: 添加一个可选参数 <code>--batch_size</code>，它有一个短选项 <code>-b</code>。这个参数的类型是整数 (<code>int</code>)，如果用户没有在命令行中指定这个参数，它的默认值将为 <code>1</code>。</p>
<p>在 Python 的 <code>argparse</code> 模块中，<code>action</code> 选项是 <code>add_argument()</code> 函数的一个参数，用来定义当参数在命令行中出现时应该执行什么操作。<code>action</code> 选项决定了如何处理命令行参数的值。下面是一些常用的 <code>action</code> 选项：</p>
<p><code>store</code> 这是默认的动作。当使用此动作时，会存储命令行中参数的值。如果没有指定动作，那么使用 <code>store</code> 是默认行为。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">parser.add_argument(<span class="hljs-string">&#x27;--name&#x27;</span>, action=<span class="hljs-string">&#x27;store&#x27;</span>)<br></code></pre></td></tr></table></figure>
<p>这将把 <code>--name</code> 后面指定的值存储在 <code>name</code> 属性中。</p>
<h3 id="store_true-和-store_false"><code>store_true</code> 和 <code>store_false</code></h3>
<p>这两种动作用于创建布尔开关。<code>store_true</code> 会在指定了参数的情况下设置属性为 <code>True</code>，未指定时为 <code>False</code>；<code>store_false</code> 则相反，当参数被指定时设置属性为 <code>False</code>，未指定时为 <code>True</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">parser.add_argument(<span class="hljs-string">&#x27;--shuffle&#x27;</span>, action=<span class="hljs-string">&#x27;store_true&#x27;</span>) <br>parser.add_argument(<span class="hljs-string">&#x27;--no-shuffle&#x27;</span>, action=<span class="hljs-string">&#x27;store_false&#x27;</span>)<br></code></pre></td></tr></table></figure>
<p>这样，如果命令行中包含了 <code>--shuffle</code>，则 <code>args.shuffle</code> 会被设置为 <code>True</code>。如果包含了 <code>--no-shuffle</code>，则相应的属性会被设置为 <code>False</code>。</p>
<p>默认情况下，参数的属性名（即在 <code>args</code> 对象中访问此参数的名称）将基于长选项名称。长选项名称通常是在双破折号 <code>--</code> 之后的字符串。对于 <code>--no-shuffle</code> 这个选项，属性名会是 <code>no_shuffle</code>。</p>
<h2 id="test">test</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">test</span>(<span class="hljs-params">opt, seg, gmm, alias</span>):<br>    up = nn.Upsample(size=(opt.load_height, opt.load_width), mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>)<br>    gauss = tgm.image.GaussianBlur((<span class="hljs-number">15</span>, <span class="hljs-number">15</span>), (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>))<br>    gauss.cuda()<br><br>    test_dataset = VITONDataset(opt)<br>    test_loader = VITONDataLoader(opt, test_dataset)<br></code></pre></td></tr></table></figure>
<p>如果给定的<code>size</code>小于图像本身的尺寸，通常<code>Upsample</code>仍会执行，但实际操作将是下采样（减小图像尺寸），这依赖于<code>mode</code>参数。</p>
<p><strong>Gaussian Blur（高斯模糊）</strong>:</p>
<ul>
<li><code>tgm.image.GaussianBlur</code>是应用高斯模糊的操作。高斯模糊是一种图像滤波技术，用于减少图像噪声和细节，通常用于图像预处理以改善后续处理步骤的性能或质量。</li>
<li>这里使用了一个15x15的核和标准差为3的高斯函数。这种较大的核会使图像变得更加模糊。</li>
<li>将高斯模糊应用于图像可以帮助平滑过渡区域，减少模型训练或推断中可能遇到的边缘效应，或是用来预处理以降低过拟合的风险。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> i, inputs <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(test_loader.data_loader):<br>            img_names = inputs[<span class="hljs-string">&#x27;img_name&#x27;</span>]<br>            c_names = inputs[<span class="hljs-string">&#x27;c_name&#x27;</span>][<span class="hljs-string">&#x27;unpaired&#x27;</span>]<br><br>            img_agnostic = inputs[<span class="hljs-string">&#x27;img_agnostic&#x27;</span>].cuda()<br>            parse_agnostic = inputs[<span class="hljs-string">&#x27;parse_agnostic&#x27;</span>].cuda()<br>            pose = inputs[<span class="hljs-string">&#x27;pose&#x27;</span>].cuda()<br>            c = inputs[<span class="hljs-string">&#x27;cloth&#x27;</span>][<span class="hljs-string">&#x27;unpaired&#x27;</span>].cuda()<br>            cm = inputs[<span class="hljs-string">&#x27;cloth_mask&#x27;</span>][<span class="hljs-string">&#x27;unpaired&#x27;</span>].cuda()<br><br>            <span class="hljs-comment"># Part 1. Segmentation generation</span><br>            parse_agnostic_down = F.interpolate(parse_agnostic, size=(<span class="hljs-number">256</span>, <span class="hljs-number">192</span>), mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>)<br>            pose_down = F.interpolate(pose, size=(<span class="hljs-number">256</span>, <span class="hljs-number">192</span>), mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>)<br>            c_masked_down = F.interpolate(c * cm, size=(<span class="hljs-number">256</span>, <span class="hljs-number">192</span>), mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>)<br>            cm_down = F.interpolate(cm, size=(<span class="hljs-number">256</span>, <span class="hljs-number">192</span>), mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>)<br>            seg_input = torch.cat((cm_down, c_masked_down, parse_agnostic_down, pose_down, gen_noise(cm_down.size()).cuda()), dim=<span class="hljs-number">1</span>)<br><br>            parse_pred_down = seg(seg_input)<br>            parse_pred = gauss(up(parse_pred_down))<br>            parse_pred = parse_pred.argmax(dim=<span class="hljs-number">1</span>)[:, <span class="hljs-literal">None</span>]<br><br>            parse_old = torch.zeros(parse_pred.size(<span class="hljs-number">0</span>), <span class="hljs-number">13</span>, opt.load_height, opt.load_width, dtype=torch.<span class="hljs-built_in">float</span>).cuda()<br>            parse_old.scatter_(<span class="hljs-number">1</span>, parse_pred, <span class="hljs-number">1.0</span>)<br></code></pre></td></tr></table></figure>
<p><code>parse_pred_down</code>表示生成出来的穿上相应衣服 <span class="math inline">\(c\)</span> 后的segmentation map。然后再对其进行上采样和高斯模糊处理。</p>
<p><code>parse_pred = parse_pred.argmax(dim=1)[:, None]</code></p>
<p><code>parse_pred.argmax(dim=1)</code>在每个像素位置找出具有最高预测概率的类别索引。这里<code>dim=1</code>表示沿着类别的维度进行操作，因为模型输出的每个像素位置都有一个概率分布来表示属于各个类别的概率。 <code>[:, None]</code>：这个操作会在结果张量中增加一个新的维度。这是在原有的二维结果（形状为 <code>[batch_size, height, width]</code>）上，沿着第二维（索引为 1 的维度）添加一个新的维度，从而将其变为 <code>[batch_size, 1, height, width]</code>。</p>
<p><code>None</code> is an alias for NP.newaxis. It creates an axis with length 1.</p>
<p><code>A = A[:, :, None, None]</code></p>
<p>这里的每个组件的作用是：</p>
<ul>
<li>第一个 <code>:</code> 表示选择 <code>batch_size</code> 维度上的所有数据。</li>
<li>第二个 <code>:</code> 表示选择 <code>height</code> 维度上的所有数据，并在其后使用 <code>None</code> 来插入一个新的维度。</li>
<li>最后一个 <code>None</code> 是在 <code>width</code> 维度之后插入另一个新的维度。</li>
</ul>
<p>执行上述操作后，原始张量 <code>A</code> 的形状 <code>[batch_size, height, width]</code> 将变为 <code>[batch_size, height, 1, width, 1]</code>。这样，每个原先的 <code>height</code> 和 <code>width</code> 维度后面都会跟随一个大小为 1 的新维度。</p>
<p><code>parse_old.scatter_(1, parse_pred, 1.0)</code>是一个就地操作（由下划线<code>_</code>表示）。这个操作将<code>parse_pred</code>中的类别索引用于填充<code>parse_old</code>。具体来说，它将<code>parse_old</code>中对应于<code>parse_pred</code>中每个位置的类别索引的位置设为1.0。这样，<code>parse_old</code>的每个通道就成为了一个二进制掩码，表示预测的类别。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">labels = &#123;<br>    <span class="hljs-number">0</span>:  [<span class="hljs-string">&#x27;background&#x27;</span>,  [<span class="hljs-number">0</span>]],<br>    <span class="hljs-number">1</span>:  [<span class="hljs-string">&#x27;paste&#x27;</span>,       [<span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">9</span>, <span class="hljs-number">10</span>, <span class="hljs-number">11</span>]],<br>    <span class="hljs-number">2</span>:  [<span class="hljs-string">&#x27;upper&#x27;</span>,       [<span class="hljs-number">3</span>]],<br>    <span class="hljs-number">3</span>:  [<span class="hljs-string">&#x27;hair&#x27;</span>,        [<span class="hljs-number">1</span>]],<br>    <span class="hljs-number">4</span>:  [<span class="hljs-string">&#x27;left_arm&#x27;</span>,    [<span class="hljs-number">5</span>]],<br>    <span class="hljs-number">5</span>:  [<span class="hljs-string">&#x27;right_arm&#x27;</span>,   [<span class="hljs-number">6</span>]],<br>    <span class="hljs-number">6</span>:  [<span class="hljs-string">&#x27;noise&#x27;</span>,       [<span class="hljs-number">12</span>]]<br>&#125;<br>parse = torch.zeros(parse_pred.size(<span class="hljs-number">0</span>), <span class="hljs-number">7</span>, opt.load_height, opt.load_width, dtype=torch.<span class="hljs-built_in">float</span>).cuda()<br><span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(labels)):<br>    <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> labels[j][<span class="hljs-number">1</span>]:<br>        parse[:, j] += parse_old[:, label]<br></code></pre></td></tr></table></figure>
<p>这段代码又把其中一些标签和为一类。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Part 2. Clothes Deformation</span><br>agnostic_gmm = F.interpolate(img_agnostic, size=(<span class="hljs-number">256</span>, <span class="hljs-number">192</span>), mode=<span class="hljs-string">&#x27;nearest&#x27;</span>)<br>parse_cloth_gmm = F.interpolate(parse[:, <span class="hljs-number">2</span>:<span class="hljs-number">3</span>], size=(<span class="hljs-number">256</span>, <span class="hljs-number">192</span>), mode=<span class="hljs-string">&#x27;nearest&#x27;</span>)<br>pose_gmm = F.interpolate(pose, size=(<span class="hljs-number">256</span>, <span class="hljs-number">192</span>), mode=<span class="hljs-string">&#x27;nearest&#x27;</span>)<br>c_gmm = F.interpolate(c, size=(<span class="hljs-number">256</span>, <span class="hljs-number">192</span>), mode=<span class="hljs-string">&#x27;nearest&#x27;</span>)<br>gmm_input = torch.cat((parse_cloth_gmm, pose_gmm, agnostic_gmm), dim=<span class="hljs-number">1</span>)<br><br>_, warped_grid = gmm(gmm_input, c_gmm)<br>warped_c = F.grid_sample(c, warped_grid, padding_mode=<span class="hljs-string">&#x27;border&#x27;</span>)<br>warped_cm = F.grid_sample(cm, warped_grid, padding_mode=<span class="hljs-string">&#x27;border&#x27;</span>)<br><br></code></pre></td></tr></table></figure>
<p>With the correlation matrix as an input, the regression network predicts the TPS transformation parameters <span class="math inline">\(\theta \in R^{2 \times 5 \times 5}\)</span>, and then c is warped by θ.</p>
<p>在 PyTorch 中，<code>F.grid_sample</code> 函数是用于进行高级图像采样操作的一个功能强大的工具。这个函数允许你根据指定的变换网格（通常是一个流场或变形场）来对输入图像进行重新采样。这在许多计算机视觉任务中非常有用，特别是在涉及到图像对齐、形变或任意几何变换的情况下。</p>
<p><code>F.grid_sample</code> 接受一个输入图像和一个变换网格。它使用变换网格中的坐标来从输入图像中抓取像素值，并生成输出图像。如果网格指定的位置在原始输入图像的边界之外，它将根据<code>padding_mode</code>来处理。</p>
<p><code>padding_mode='border'</code> 表示如果网格引导采样点超出原始图像的边界，那么采样操作将使用边界上的像素值。这有助于防止在图像边缘产生伪影。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Part 3. Try-on synthesis</span><br>misalign_mask = parse[:, <span class="hljs-number">2</span>:<span class="hljs-number">3</span>] - warped_cm<br>misalign_mask[misalign_mask &lt; <span class="hljs-number">0.0</span>] = <span class="hljs-number">0.0</span><br>parse_div = torch.cat((parse, misalign_mask), dim=<span class="hljs-number">1</span>)<br>parse_div[:, <span class="hljs-number">2</span>:<span class="hljs-number">3</span>] -= misalign_mask<br><br>output = alias(torch.cat((img_agnostic, pose, warped_c), dim=<span class="hljs-number">1</span>), parse, parse_div, misalign_mask)<br><br></code></pre></td></tr></table></figure>
<p><code>misalign_mask = parse[:, 2:3] - warped_cm</code></p>
<p><code>parse[:, 2:3]</code> 提取了解析图中代表上衣的部分（假设索引 2 对应于上衣）。这是一个包含衣物应在模型上出现位置的掩模。</p>
<p>然后就是进行最后的生成： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">unpaired_names = []<br>         <span class="hljs-keyword">for</span> img_name, c_name <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(img_names, c_names):<br>             unpaired_names.append(<span class="hljs-string">&#x27;&#123;&#125;_&#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(img_name.split(<span class="hljs-string">&#x27;_&#x27;</span>)[<span class="hljs-number">0</span>], c_name))<br><br>         save_images(output, unpaired_names, os.path.join(opt.save_dir, opt.name))<br><br>         <span class="hljs-keyword">if</span> (i + <span class="hljs-number">1</span>) % opt.display_freq == <span class="hljs-number">0</span>:<br>             <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;step: &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(i + <span class="hljs-number">1</span>))<br><br></code></pre></td></tr></table></figure></p>
<p>这里第一个循环通过结合 <code>img_names</code> 和 <code>c_names</code> 中的元素来构建输出图片的新文件名。具体来说，它取每个 <code>img_name</code> 的第一部分（用下划线分割）并附加相应的 <code>c_name</code>。这种命名方案有助于组织和识别基于输入和使用的特定服装项生成的图片。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> (i + <span class="hljs-number">1</span>) % opt.display_freq == <span class="hljs-number">0</span>:     <br>	<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;step: &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(i + <span class="hljs-number">1</span>))<br></code></pre></td></tr></table></figure>
<p>这行代码在每处理 <code>opt.display_freq</code> 设定次数的图片后记录当前步骤。通过打印当前的步骤编号，可以跟踪处理进度，这在处理大量数据时尤其有用，以监控程序运行状态。</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/CV/" class="category-chain-item">CV</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/VITON/" class="print-no-link">#VITON</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>VITON-HD代码阅读笔记</div>
      <div>https://blog.paraline.top/posts/viton-hd代码阅读笔记/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Paraline</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2024年4月28日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/posts/hr-viton%E4%BB%A3%E7%A0%81%E7%AC%94%E8%AE%B0/" title="HR-VITON代码笔记">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">HR-VITON代码笔记</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                  </article>
                </div>
              
            </div>

            
  
  
    <article id="comments" lazyload>
      
  <script type="text/javascript">
    Fluid.utils.loadComments('#comments', function() {
      var light = 'github-light';
      var dark = 'github-dark';
      var schema = document.documentElement.getAttribute('data-user-color-scheme');
      if (schema === 'dark') {
        schema = dark;
      } else {
        schema = light;
      }
      window.UtterancesThemeLight = light;
      window.UtterancesThemeDark = dark;
      var s = document.createElement('script');
      s.setAttribute('src', 'https://utteranc.es/client.js');
      s.setAttribute('repo', 'Para-line/BlogComment');
      s.setAttribute('issue-term', 'pathname');
      
      s.setAttribute('label', 'utterances');
      
      s.setAttribute('theme', schema);
      s.setAttribute('crossorigin', 'anonymous');
      document.getElementById('comments').appendChild(s);
    })
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


    </article>
  


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="leancloud-site-pv-container" style="display: none">
        Visits 
        <span id="leancloud-site-pv"></span>
         
      </span>
    
    
      <span id="leancloud-site-uv-container" style="display: none">
        Visitors 
        <span id="leancloud-site-uv"></span>
         
      </span>
    
    

  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script defer src="/js/leancloud.js" ></script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  <script src="/js/background.js"></script>

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
