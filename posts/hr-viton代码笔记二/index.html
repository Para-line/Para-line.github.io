

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=dark>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/avatar.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Paraline">
  <meta name="keywords" content="">
  
    <meta name="description" content="train_condition.py 123456789101112131415import torchimport torch.nn as nnfrom torchvision.utils import make_gridfrom networks import make_grid as mkgridimport argparseimport osimport timefrom cp_datas">
<meta property="og:type" content="article">
<meta property="og:title" content="HR-VITON代码笔记二">
<meta property="og:url" content="https://blog.paraline.top/posts/hr-viton%E4%BB%A3%E7%A0%81%E7%AC%94%E8%AE%B0%E4%BA%8C/index.html">
<meta property="og:site_name" content="Paraline&#39;s Blog">
<meta property="og:description" content="train_condition.py 123456789101112131415import torchimport torch.nn as nnfrom torchvision.utils import make_gridfrom networks import make_grid as mkgridimport argparseimport osimport timefrom cp_datas">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s2.loli.net/2024/05/05/9uDBxajop3U5F4O.png">
<meta property="og:image" content="https://s2.loli.net/2024/05/04/1zBHFVmKOcAR4uN.png">
<meta property="og:image" content="https://s2.loli.net/2024/05/12/csQ6BhPAKMWbCyf.png">
<meta property="article:published_time" content="2024-05-13T21:47:00.000Z">
<meta property="article:modified_time" content="2024-05-27T12:22:55.072Z">
<meta property="article:author" content="Paraline">
<meta property="article:tag" content="VITON">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://s2.loli.net/2024/05/05/9uDBxajop3U5F4O.png">
  
  
  
  <title>HR-VITON代码笔记二 - Paraline&#39;s Blog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  



  
<link rel="stylesheet" href="/css/paraline.css">
<link rel="stylesheet" href="/css/code.css">



  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"blog.paraline.top","root":"/","version":"1.9.5-a","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":"ynQw6Q7W2fOzEYRv4F6NsdZN-gzGzoHsz","app_key":"JWtWrXxjhx0fquDKEm4Zuz6H","server_url":"https://ynqw6q7w.lc-cn-n1-shared.com","path":"window.location.pathname","ignore_local":true}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  
    <!-- Google tag (gtag.js) -->
    <script async>
      if (!Fluid.ctx.dnt) {
        Fluid.utils.createScript("https://www.googletagmanager.com/gtag/js?id=", function() {
          window.dataLayer = window.dataLayer || [];
          function gtag() {
            dataLayer.push(arguments);
          }
          gtag('js', new Date());
          gtag('config', '');
        });
      }
    </script>
  

  

  

  

  
    
  



  
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
  <div id="web_bg"></div>

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Paraline&#39;s Blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('https://s2.loli.net/2023/08/03/KPgQDnv7y9rV2Ml.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="HR-VITON代码笔记二"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-05-13 21:47" pubdate>
          2024/05/13 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          61k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          <!-- compatible with older versions-->
          预计阅读时长：510 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">HR-VITON代码笔记二</h1>
            
              <p class="note note-info">
                
                  
                    本文最后更新于：2024年5月27日 中午
                  
                
              </p>
            
            
              <div class="markdown-body">
                
                <h1 id="train_condition.py">train_condition.py</h1>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br><span class="hljs-keyword">from</span> torchvision.utils <span class="hljs-keyword">import</span> make_grid<br><span class="hljs-keyword">from</span> networks <span class="hljs-keyword">import</span> make_grid <span class="hljs-keyword">as</span> mkgrid<br><br><span class="hljs-keyword">import</span> argparse<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">from</span> cp_dataset <span class="hljs-keyword">import</span> CPDataset, CPDatasetTest, CPDataLoader<br><span class="hljs-keyword">from</span> networks <span class="hljs-keyword">import</span> ConditionGenerator, VGGLoss, GANLoss, load_checkpoint, save_checkpoint, define_D<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><span class="hljs-keyword">from</span> tensorboardX <span class="hljs-keyword">import</span> SummaryWriter<br><span class="hljs-keyword">from</span> utils <span class="hljs-keyword">import</span> *<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Subset<br></code></pre></td></tr></table></figure>
<p>引入了很多库。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">iou_metric</span>(<span class="hljs-params">y_pred_batch, y_true_batch</span>):<br>    B = y_pred_batch.shape[<span class="hljs-number">0</span>]<br>    iou = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(B):<br>        y_pred = y_pred_batch[i]<br>        y_true = y_true_batch[i]<br>        <span class="hljs-comment"># y_pred is not one-hot, so need to threshold it</span><br>        y_pred = y_pred &gt; <span class="hljs-number">0.5</span><br>        <br>        y_pred = y_pred.flatten()<br>        y_true = y_true.flatten()<br><br>    <br>        intersection = torch.<span class="hljs-built_in">sum</span>(y_pred[y_true == <span class="hljs-number">1</span>])<br>        union = torch.<span class="hljs-built_in">sum</span>(y_pred) + torch.<span class="hljs-built_in">sum</span>(y_true)<br><br>    <br>        iou += (intersection + <span class="hljs-number">1e-7</span>) / (union - intersection + <span class="hljs-number">1e-7</span>) / B<br>    <span class="hljs-keyword">return</span> iou<br></code></pre></td></tr></table></figure>
<p>这个函数是用来计算IoU的，即Intersection Over Union，计算公式为 <span class="math display">\[IoU = \frac{\text{Area of Intersection}}{\text{Area of Union}}\]</span></p>
<p><img src="https://s2.loli.net/2024/05/05/9uDBxajop3U5F4O.png" srcset="/img/loading.gif" lazyload /></p>
<p>这里代码中分母用的是<code>union - intersection</code>的原因是，代码中的"union"不是真正的并集，而是把他们两个的区域面积直接加起来，多算了一次交集的面积，所以要减掉。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">remove_overlap</span>(<span class="hljs-params">seg_out, warped_cm</span>):<br>    <br>    <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(warped_cm.shape) == <span class="hljs-number">4</span><br>    <br>    warped_cm = warped_cm - (torch.cat([seg_out[:, <span class="hljs-number">1</span>:<span class="hljs-number">3</span>, :, :], seg_out[:, <span class="hljs-number">5</span>:, :, :]], dim=<span class="hljs-number">1</span>)).<span class="hljs-built_in">sum</span>(dim=<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">True</span>) * warped_cm<br>    <span class="hljs-keyword">return</span> warped_cm<br></code></pre></td></tr></table></figure>
<p>其中<code>torch.cat([seg_out[:, 1:3, :, :], seg_out[:, 5:, :, :]], dim=1)</code>表示segmentation中可能和clothes mask重叠的人体部位。</p>
<p>这里就是把warped clothes mask中和segmentation map中没对齐的部分消掉。看下面这张图就很清晰了。</p>
<p><img src="https://s2.loli.net/2024/05/04/1zBHFVmKOcAR4uN.png" srcset="/img/loading.gif" lazyload /></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_opt</span>():<br>    parser = argparse.ArgumentParser()<br><br>    parser.add_argument(<span class="hljs-string">&quot;--name&quot;</span>, default=<span class="hljs-string">&quot;test&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--gpu_ids&quot;</span>, default=<span class="hljs-string">&quot;&quot;</span>)<br><br>	<span class="hljs-comment"># omitted</span><br>	<br>    opt = parser.parse_args()<br>    <span class="hljs-keyword">return</span> opt<br></code></pre></td></tr></table></figure>
<p>然后是<code>get_opt</code>函数，从命令行中获取参数。</p>
<h2 id="train">train</h2>
<p>然后是训练的主体函数。HR-VITON在开源代码里提供了训练的细节，而VITON-HD根本没有关于训练的部分，可以作为一个很好的补充。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">opt, train_loader, test_loader, val_loader, board, tocg, D</span>):<br>    <span class="hljs-comment"># Model</span><br>    tocg.cuda() <br>    tocg.train()<br>    D.cuda()<br>    D.train()<br></code></pre></td></tr></table></figure>
<p>这里tocg指的是Try-On Condition Generator, D是Try-On Image Generator.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># criterion</span><br>criterionL1 = nn.L1Loss()<br>criterionVGG = VGGLoss(opt)<br><span class="hljs-keyword">if</span> opt.fp16:<br>    criterionGAN = GANLoss(use_lsgan=<span class="hljs-literal">True</span>, tensor=torch.cuda.HalfTensor)<br><span class="hljs-keyword">else</span> :<br>    criterionGAN = GANLoss(use_lsgan=<span class="hljs-literal">True</span>, tensor=torch.cuda.FloatTensor <span class="hljs-keyword">if</span> opt.gpu_ids <span class="hljs-keyword">else</span> torch.Tensor)<br><br><span class="hljs-comment"># optimizer</span><br>optimizer_G = torch.optim.Adam(tocg.parameters(), lr=opt.G_lr, betas=(<span class="hljs-number">0.5</span>, <span class="hljs-number">0.999</span>))<br>optimizer_D = torch.optim.Adam(D.parameters(), lr=opt.D_lr, betas=(<span class="hljs-number">0.5</span>, <span class="hljs-number">0.999</span>))<br></code></pre></td></tr></table></figure>
<p><strong>VGG Loss</strong>: - <code>criterionVGG = VGGLoss(opt)</code>：VGG损失是一种基于预训练的VGG网络的特征表示来计算的感知损失。它不仅比较像素值的差异，而且比较高级特征的差异，有助于生成视觉上更令人满意的结果。<code>opt</code>可能包含了配置VGG损失所需的特定选项或参数。</p>
<p>根据<code>opt.fp16</code>的设置，GAN损失可能使用半精度浮点数（<code>torch.cuda.HalfTensor</code>）以提高计算效率和降低内存使用，或者使用全精度浮点数（<code>torch.cuda.FloatTensor</code>）。<code>opt.gpu_ids</code>可能用来检查是否有GPU可用，如果没有，则使用默认的CPU tensor（<code>torch.Tensor</code>）。</p>
<p><code>optimizer_G = torch.optim.Adam(tocg.parameters(), lr=opt.G_lr, betas=(0.5, 0.999))</code>：为生成器<code>tocg</code>设置Adam优化器。这里，<code>lr=opt.G_lr</code>是学习率，<code>betas</code>是Adam优化器的动量项，用于调节梯度下降过程中的移动平均。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> step <span class="hljs-keyword">in</span> tqdm(<span class="hljs-built_in">range</span>(opt.load_step, opt.keep_step)):<br>        iter_start_time = time.time()<br>        inputs = train_loader.next_batch()<br></code></pre></td></tr></table></figure>
<p>这里tqdm是一个可以在控制台显示进度条的库。效果如下：</p>
<p><img src="https://s2.loli.net/2024/05/12/csQ6BhPAKMWbCyf.png" srcset="/img/loading.gif" lazyload /></p>
<ul>
<li><code>opt.load_step</code>：可能表示模型加载时的起始步骤或迭代次数。在某些情况下，模型可能需要从先前训练的检查点继续训练，而 <code>opt.load_step</code> 就是指定了从哪一步开始加载模型的参数。</li>
<li><code>opt.keep_step</code>：可能表示模型训练的结束步骤或迭代次数。当模型训练达到这个步骤时，循环就会结束。</li>
</ul>
<p>然后就是用DataLoader加载数据集：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># input1</span><br>c_paired = inputs[<span class="hljs-string">&#x27;cloth&#x27;</span>][<span class="hljs-string">&#x27;paired&#x27;</span>].cuda()<br>cm_paired = inputs[<span class="hljs-string">&#x27;cloth_mask&#x27;</span>][<span class="hljs-string">&#x27;paired&#x27;</span>].cuda()<br>cm_paired = torch.FloatTensor((cm_paired.detach().cpu().numpy() &gt; <span class="hljs-number">0.5</span>).astype(np.<span class="hljs-built_in">float</span>)).cuda()<br><span class="hljs-comment"># input2</span><br>parse_agnostic = inputs[<span class="hljs-string">&#x27;parse_agnostic&#x27;</span>].cuda()<br>densepose = inputs[<span class="hljs-string">&#x27;densepose&#x27;</span>].cuda()<br>openpose = inputs[<span class="hljs-string">&#x27;pose&#x27;</span>].cuda()<br><span class="hljs-comment"># GT</span><br>label_onehot = inputs[<span class="hljs-string">&#x27;parse_onehot&#x27;</span>].cuda()  <span class="hljs-comment"># CE</span><br>label = inputs[<span class="hljs-string">&#x27;parse&#x27;</span>].cuda()  <span class="hljs-comment"># GAN loss</span><br>parse_cloth_mask = inputs[<span class="hljs-string">&#x27;pcm&#x27;</span>].cuda()  <span class="hljs-comment"># L1</span><br>im_c = inputs[<span class="hljs-string">&#x27;parse_cloth&#x27;</span>].cuda()  <span class="hljs-comment"># VGG</span><br><span class="hljs-comment"># visualization</span><br>im = inputs[<span class="hljs-string">&#x27;image&#x27;</span>]<br><br><span class="hljs-comment"># inputs</span><br>input1 = torch.cat([c_paired, cm_paired], <span class="hljs-number">1</span>)<br>input2 = torch.cat([parse_agnostic, densepose], <span class="hljs-number">1</span>)<br><br><span class="hljs-comment"># forward</span><br>flow_list, fake_segmap, warped_cloth_paired, warped_clothmask_paired = tocg(input1, input2)<br><br><span class="hljs-comment"># warped cloth mask one hot </span><br><br>warped_cm_onehot = torch.FloatTensor((warped_clothmask_paired.detach().cpu().numpy() &gt; <span class="hljs-number">0.5</span>).astype(np.<span class="hljs-built_in">float</span>)).cuda()<br></code></pre></td></tr></table></figure>
<p>加载之后经过Try-On Condition Generator产生相应的结果。并把产生的warped_cm进行二值化处理。</p>
<p>这里的fake_segmap应该并不是说产生的segmentation map是有问题的，而是说这个segmentation map并不是来自于真实的图像，而是计算机合成的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># fake segmap cloth channel * warped clothmask</span><br>   <span class="hljs-keyword">if</span> opt.clothmask_composition != <span class="hljs-string">&#x27;no_composition&#x27;</span>:<br>        <span class="hljs-keyword">if</span> opt.clothmask_composition == <span class="hljs-string">&#x27;detach&#x27;</span>:<br>            cloth_mask = torch.ones_like(fake_segmap.detach())<br>            cloth_mask[:, <span class="hljs-number">3</span>:<span class="hljs-number">4</span>, :, :] = warped_cm_onehot<br>            fake_segmap = fake_segmap * cloth_mask<br></code></pre></td></tr></table></figure>
<p>检查是否需要合成衣物掩码。如果 <code>opt.clothmask_composition</code> 不等于 <code>'no_composition'</code>，则表示需要进行衣物掩码的合成 - <code>opt.clothmask_composition == 'detach'</code>：如果选择了使用 <code>detach</code> 方式合成衣物掩码，则将生成的虚假分割图 <code>fake_segmap</code> 与变形后的衣物掩码 <code>warped_cm_onehot</code> 相乘。这里使用 <code>detach</code> 可能是为了避免反向传播对 <code>warped_cm_onehot</code> 的影响。 - <code>opt.clothmask_composition == 'warp_grad'</code>：如果选择了使用 <code>warp_grad</code> 方式合成衣物掩码，则将生成的虚假分割图 <code>fake_segmap</code> 与变形后的衣物掩码 <code>warped_clothmask_paired</code> 相乘。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> opt.occlusion:<br>    warped_clothmask_paired = remove_overlap(<br>        F.softmax(fake_segmap, dim=<span class="hljs-number">1</span>), warped_clothmask_paired)<br>    warped_cloth_paired = warped_cloth_paired * warped_clothmask_paired + \<br>        torch.ones_like(warped_cloth_paired) * (<span class="hljs-number">1</span>-warped_clothmask_paired)<br></code></pre></td></tr></table></figure>
<p>这里是做occlusion handling。</p>
<p>调用<code>remove_overlap</code>把warped clothes mask与segmentation map中不重叠的部分消除掉，然后对warped_cloth也根据warped clothes mask把不重叠的地方消除掉。</p>
<p><code>warped_cloth_paired * warped_clothmask_paired</code>让<code>warped_clothmask_paired</code>让未被遮挡的衣服保留下来，<code>torch.ones_like(warped_cloth_paired) * (1-warped_clothmask_paired)</code>为被遮挡的地方填充一个默认值（白色）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">fake_clothmask = (torch.argmax(fake_segmap.detach(), dim=<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">True</span>) == <span class="hljs-number">3</span>).long()<br>misalign = fake_clothmask - warped_cm_onehot<br>misalign[misalign &lt; <span class="hljs-number">0.0</span>] = <span class="hljs-number">0.0</span><br></code></pre></td></tr></table></figure>
<p><code>fake_clothmask = (torch.argmax(fake_segmap.detach(), dim=1, keepdim=True) == 3).long()</code>这句话找出了在fake_segmap上最有可能是衣服的像素点，当做<code>fake_clothmask</code>。然后与ground truth相比，计算损失。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">loss_l1_cloth = criterionL1(warped_clothmask_paired, parse_cloth_mask) <br>loss_vgg = criterionVGG(warped_cloth_paired, im_c) <br>loss_tv = <span class="hljs-number">0</span><br></code></pre></td></tr></table></figure>
<p>这里计算相应的损失。</p>
<p>首先计算了生成的clothmask和ground truth之间的 L1 Loss。</p>
<p>然后再计算了变形后的衣服与ground truth衣服之间的VGG Loss。</p>
<p>loss_tv先设置为0，下面再进行实际的运算。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> opt.edgeawaretv == <span class="hljs-string">&#x27;no_edge&#x27;</span>:<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.lasttvonly:<br>        <span class="hljs-keyword">for</span> flow <span class="hljs-keyword">in</span> flow_list:<br>            y_tv = torch.<span class="hljs-built_in">abs</span>(flow[:, <span class="hljs-number">1</span>:, :, :] - flow[:, :-<span class="hljs-number">1</span>, :, :]).mean()<br>            x_tv = torch.<span class="hljs-built_in">abs</span>(flow[:, :, <span class="hljs-number">1</span>:, :] - flow[:, :, :-<span class="hljs-number">1</span>, :]).mean()<br>            loss_tv = loss_tv + y_tv + x_tv<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">for</span> flow <span class="hljs-keyword">in</span> flow_list[-<span class="hljs-number">1</span>:]:<br>            y_tv = torch.<span class="hljs-built_in">abs</span>(flow[:, <span class="hljs-number">1</span>:, :, :] - flow[:, :-<span class="hljs-number">1</span>, :, :]).mean()<br>            x_tv = torch.<span class="hljs-built_in">abs</span>(flow[:, :, <span class="hljs-number">1</span>:, :] - flow[:, :, :-<span class="hljs-number">1</span>, :]).mean()<br>            loss_tv = loss_tv + y_tv + x_tv<br><br></code></pre></td></tr></table></figure>
<p>这里是Total Variation Loss的计算。</p>
<p>这里flow的四个维度分别为<span class="math inline">\((N, H, W, C)\)</span>。</p>
<p>我们这里回忆一下图像梯度的计算公式： <span class="math display">\[\frac{ \partial I(x,y) }{ \partial x } =  \frac{I(x + 1, y) - I(x - 1,y)}{2}\]</span> <span class="math display">\[\frac{ \partial I(x,y) }{ \partial y } = \frac{I(x, y + 1) - I(x,y-1)}{2}\]</span> 也可以写成： <span class="math display">\[\frac{ \partial I(x,y) }{ \partial x } =  \frac{I(x + 1, y) - I(x,y)}{1}\]</span> <span class="math display">\[\frac{ \partial I(x,y) }{ \partial y } = \frac{I(x, y + 1) - I(x,y)}{1}\]</span></p>
<p>如果 <code>opt.edgeawaretv</code> 为 <code>'no_edge'</code> 且未指定 <code>'lasttvonly'</code>: - 对于每个流（<code>flow</code>）： - 分别计算垂直方向（<code>y_tv</code>）和水平方向（<code>x_tv</code>）的像素变化的绝对值的平均值。 - 将这两个方向的总变差加到总的变差损失中。</p>
<p><code>flow[:, 1:, :, :]</code>意思是取出2到n行，<code>flow[:, :-1, :, :]</code>意思是取出1到n-1行，两者作差即得到我们需要的n-1个对应上下两行的差，即第二行减第一行，第三行减第二行，……，第n行减第n-1行。</p>
<p>如果指定了<code>'lasttvonly'</code>: - 仅对最后一个流进行处理。 - 与上述类似，计算垂直和水平方向的像素变化绝对值的平均值。</p>
<p>这里的<code>opt.edgeawaretv</code>表示在计算total variation的时候是否考虑边缘的信息。如果只有最后一个光流考虑边缘的信息。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">else</span>:<br>			    <span class="hljs-keyword">if</span> opt.edgeawaretv == <span class="hljs-string">&#x27;last_only&#x27;</span>:<br>                flow = flow_list[-<span class="hljs-number">1</span>]<br>                warped_clothmask_paired_down = F.interpolate(warped_clothmask_paired, flow.shape[<span class="hljs-number">1</span>:<span class="hljs-number">3</span>], mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>)<br>                y_tv = torch.<span class="hljs-built_in">abs</span>(flow[:, <span class="hljs-number">1</span>:, :, :] - flow[:, :-<span class="hljs-number">1</span>, :, :])<br>                x_tv = torch.<span class="hljs-built_in">abs</span>(flow[:, :, <span class="hljs-number">1</span>:, :] - flow[:, :, :-<span class="hljs-number">1</span>, :])<br>                mask_y = torch.exp(-<span class="hljs-number">15</span>*torch.<span class="hljs-built_in">abs</span>(0warped_clothmask_paired_down.permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)[:, <span class="hljs-number">1</span>:, :, :] - warped_clothmask_paired_down.permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)[:, :-<span class="hljs-number">1</span>, :, :]))<br>                mask_x = torch.exp(-<span class="hljs-number">150</span>*torch.<span class="hljs-built_in">abs</span>(warped_clothmask_paired_down.permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)[:, :, <span class="hljs-number">1</span>:, :] - warped_clothmask_paired_down.permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)[:, :, :-<span class="hljs-number">1</span>, :]))<br>                y_tv = y_tv * mask_y<br>                x_tv = x_tv * mask_x<br>                y_tv = y_tv.mean()<br>                x_tv = x_tv.mean()<br>                loss_tv = loss_tv + y_tv + x_tv           <br></code></pre></td></tr></table></figure>
<p>这里首先是跟上一步一样，计算了垂直方向（<code>y_tv</code>）和水平方向（<code>x_tv</code>）的像素变化的绝对值的平均值。</p>
<p><code>mask_y = torch.exp(-150*torch.abs(warped_clothmask_paired_down.permute(0, 2, 3, 1)[:, 1:, :, :] - warped_clothmask_paired_down.permute(0, 2, 3, 1)[:, :-1, :, :]))</code>这个表达式，根据<code>warped_clothmask_paired_down</code>计算在垂直和水平方向上的像素变化幅度来计算<code>mask_y</code>。在变化幅度越大的地方权值越小。</p>
<p>因为在边缘区域，我们期望有更大的像素变化以保留边缘信息。通过这样的处理，梯度损失能更好地适应图像内容的具体情况，减少对边缘细节的平滑，这对于维持图像质量和视觉效果是非常重要的。</p>
<p>我们之后将这些计算出的边缘权重与原始的梯度值（<code>y_tv</code> 和 <code>x_tv</code>）相乘，并取平均值，得到最终的tv值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">elif</span> opt.edgeawaretv == <span class="hljs-string">&#x27;weighted&#x27;</span>:<br>                <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>):<br>                    flow = flow_list[i]<br>                    warped_clothmask_paired_down = F.interpolate(warped_clothmask_paired, flow.shape[<span class="hljs-number">1</span>:<span class="hljs-number">3</span>], mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>)<br>                    y_tv = torch.<span class="hljs-built_in">abs</span>(flow[:, <span class="hljs-number">1</span>:, :, :] - flow[:, :-<span class="hljs-number">1</span>, :, :])<br>                    x_tv = torch.<span class="hljs-built_in">abs</span>(flow[:, :, <span class="hljs-number">1</span>:, :] - flow[:, :, :-<span class="hljs-number">1</span>, :])<br>                    mask_y = torch.exp(-<span class="hljs-number">150</span>*torch.<span class="hljs-built_in">abs</span>(warped_clothmask_paired_down.permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)[:, <span class="hljs-number">1</span>:, :, :] - warped_clothmask_paired_down.permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)[:, :-<span class="hljs-number">1</span>, :, :]))<br>                    mask_x = torch.exp(-<span class="hljs-number">150</span>*torch.<span class="hljs-built_in">abs</span>(warped_clothmask_paired_down.permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)[:, :, <span class="hljs-number">1</span>:, :] - warped_clothmask_paired_down.permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)[:, :, :-<span class="hljs-number">1</span>, :]))<br>                    y_tv = y_tv * mask_y<br>                    x_tv = x_tv * mask_x<br>                    y_tv = y_tv.mean() / (<span class="hljs-number">2</span> ** (<span class="hljs-number">4</span>-i))<br>                    x_tv = x_tv.mean() / (<span class="hljs-number">2</span> ** (<span class="hljs-number">4</span>-i))<br>                    loss_tv = loss_tv + y_tv + x_tv  <br></code></pre></td></tr></table></figure>
<p>如果<code>opt.edgeawaretv == 'weighted'</code>，这里的处理大体上和上面相似，只是上面只计算最后一个flow的TV值，而这里计算所有flow的TV值，并对他们进行加权。</p>
<p>使用 2 ** (4-i) 对不同阶段的损失进行动态加权，越晚的光流被赋予更大的权重，可能因为后期的图像变换更能代表整个图像序列的重要特征。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> opt.add_lasttv:<br>    <span class="hljs-keyword">for</span> flow <span class="hljs-keyword">in</span> flow_list[-<span class="hljs-number">1</span>:]:<br>        y_tv = torch.<span class="hljs-built_in">abs</span>(flow[:, <span class="hljs-number">1</span>:, :, :] - flow[:, :-<span class="hljs-number">1</span>, :, :]).mean()<br>        x_tv = torch.<span class="hljs-built_in">abs</span>(flow[:, :, <span class="hljs-number">1</span>:, :] - flow[:, :, :-<span class="hljs-number">1</span>, :]).mean()<br>        loss_tv = loss_tv + y_tv + x_tv<br></code></pre></td></tr></table></figure>
<p>最后如果add_lasttv为true，那么就加上最后一个flow的TV值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> opt.interflowloss:<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(flow_list)-<span class="hljs-number">1</span>):<br>        flow = flow_list[i]<br>        N, fH, fW, _ = flow.size()<br>        grid = mkgrid(N, iH, iW)<br>        flow = F.interpolate(flow.permute(<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>), size=c_paired.shape[<span class="hljs-number">2</span>:], mode=opt.upsample).permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)<br>        flow_norm = torch.cat([flow[:, :, :, <span class="hljs-number">0</span>:<span class="hljs-number">1</span>] / ((fW - <span class="hljs-number">1.0</span>) / <span class="hljs-number">2.0</span>), flow[:, :, :, <span class="hljs-number">1</span>:<span class="hljs-number">2</span>] / ((fH - <span class="hljs-number">1.0</span>) / <span class="hljs-number">2.0</span>)], <span class="hljs-number">3</span>)<br>        warped_c = F.grid_sample(c_paired, flow_norm + grid, padding_mode=<span class="hljs-string">&#x27;border&#x27;</span>)<br>        warped_cm = F.grid_sample(cm_paired, flow_norm + grid, padding_mode=<span class="hljs-string">&#x27;border&#x27;</span>)<br>        warped_cm = remove_overlap(F.softmax(fake_segmap, dim=<span class="hljs-number">1</span>), warped_cm)<br>        loss_l1_cloth += criterionL1(warped_cm, parse_cloth_mask) / (<span class="hljs-number">2</span> ** (<span class="hljs-number">4</span>-i))<br>        loss_vgg += criterionVGG(warped_c, im_c) / (<span class="hljs-number">2</span> ** (<span class="hljs-number">4</span>-i))<br></code></pre></td></tr></table></figure>
<p>这里计算中间过程中的损失。同样是越后面的权重越大。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># loss segmentation</span><br><span class="hljs-comment"># generator</span><br>CE_loss = cross_entropy2d(fake_segmap, label_onehot.transpose(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>)[<span class="hljs-number">0</span>].long())<br></code></pre></td></tr></table></figure>
<p>这里首先计算生成的segmentation map和实际的segmentation map之间的cross entropy loss。</p>
<p>在深度学习中，交叉熵损失函数常用于分类任务中。而在像素级的分类任务，比如图像语义分割，每个像素都需要分到一个类别中。使用独热编码的标签形式有几个好处：</p>
<ol type="1">
<li><strong>方便计算：</strong> 独热编码的标签形式将标签表示为一个向量，其中只有一个元素是1，其余元素都是0。这样在计算损失时，只需要比较模型的输出与独热编码的标签，计算对应位置的交叉熵损失即可，计算起来相对简单高效。</li>
<li><strong>适用性广泛：</strong> 独热编码的标签形式适用于多类别分类问题，可以处理类别不平衡的情况，每个类别的权重都可以独立地被考虑。</li>
<li><strong>数学上的连续性：</strong> 交叉熵损失函数可以直接衡量两个概率分布之间的差异，而独热编码的标签形式与概率分布形式相对应，这使得交叉熵损失函数的数学解释更加直观。</li>
</ol>
<p>这里的<code>cross_entropy2d</code>是在utils.py中定义的，并不是一个内置的函数。 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">cross_entropy2d</span>(<span class="hljs-params"><span class="hljs-built_in">input</span>, target, weight=<span class="hljs-literal">None</span>, size_average=<span class="hljs-literal">True</span></span>):<br>    n, c, h, w = <span class="hljs-built_in">input</span>.size()<br>    nt, ht, wt = target.size()<br><br>    <span class="hljs-comment"># Handle inconsistent size between input and target</span><br>    <span class="hljs-keyword">if</span> h != ht <span class="hljs-keyword">or</span> w != wt:<br>        <span class="hljs-built_in">input</span> = F.interpolate(<span class="hljs-built_in">input</span>, size=(ht, wt), mode=<span class="hljs-string">&quot;bilinear&quot;</span>, align_corners=<span class="hljs-literal">True</span>)<br><br>    <span class="hljs-built_in">input</span> = <span class="hljs-built_in">input</span>.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>).transpose(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>).contiguous().view(-<span class="hljs-number">1</span>, c)<br>    target = target.view(-<span class="hljs-number">1</span>)<br>    loss = F.cross_entropy(<br>        <span class="hljs-built_in">input</span>, target, weight=weight, size_average=size_average, ignore_index=<span class="hljs-number">250</span><br>    )<br>    <span class="hljs-keyword">return</span> loss<br></code></pre></td></tr></table></figure></p>
<p>首先取出了input和target的形状。如果input和target的形状不同，就进行缩放处理。</p>
<p><code>input.transpose(1, 2).transpose(2, 3).contiguous()</code> 将输入张量从 <code>(N, C, H, W)</code> 转换为 <code>(N, H, W, C)</code>。便于之后的展平。</p>
<p>这里我们回忆一下view的用法： <code>view</code> 方法用于改变张量的形状而不改变其数据。你可以将其视为重新排列或解释张量中数据的一种方式，但实际的数据内容和顺序不变。这通常用于调整数据的维度以匹配特定操作或模型的输入需求。 - <strong>使用场景</strong>：例如，如果你有一个形状为 <code>[10, 256]</code> 的张量，你可以使用 <code>.view(10, 16, 16)</code> 将其重新形状为 <code>[10, 16, 16]</code>，这样做是为了将它用作图像批次，其中每张图像是 16x16 像素。 - <strong>限制</strong>：使用 <code>view</code> 需要张量在内存中是连续的（即无跨步问题）。如果不是，可能需要先调用 <code>.contiguous()</code>。 - <strong>自动推断维度</strong>：用 <code>-1</code> 作为 <code>view</code> 方法中的一个参数，PyTorch 将自动计算这一维的大小，以使得总元素数量保持不变。</p>
<p><code>F.cross_entropy(input, target, weight=weight, size_average=size_average, ignore_index=250)</code>使用 PyTorch 提供的交叉熵函数计算损失。ignore_index=250 参数指示函数忽略值为 250 的目标标签，这通常用于表示某些像素不应该被计算损失（例如，标注不清的区域）。</p>
<p>现在我们再回过头来看刚才的CE Loss计算。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">CE_loss = cross_entropy2d(fake_segmap, label_onehot.transpose(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>)[<span class="hljs-number">0</span>].long())<br></code></pre></td></tr></table></figure>
<p>label_onehot的维度为(N, 1, H, W)，这样然后调用transpose转化为(1, N, H, W)，最后把第一维去掉，得到(N, H, W)，符合cross_entropy2d函数的要求。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> opt.no_GAN_loss:<br>    loss_G = (<span class="hljs-number">10</span> * loss_l1_cloth + loss_vgg + opt.tvlambda * loss_tv) + (CE_loss * opt.CElamda)<br>    <span class="hljs-comment"># step</span><br>    optimizer_G.zero_grad()<br>    loss_G.backward()<br>    optimizer_G.step()<br></code></pre></td></tr></table></figure>
<ol type="1">
<li><code>optimizer_G.zero_grad()</code>: 这一步是将生成器的梯度缓存清零。在PyTorch中，梯度是累积的，因此在每次反向传播之前需要将梯度清零，以避免梯度的累积影响下一次的计算。</li>
<li><code>loss_G.backward()</code>: 这一步是执行反向传播，计算生成器损失 <code>loss_G</code> 对生成器参数的梯度。反向传播会沿着计算图反向传播误差，并计算每个参数对总体损失的贡献度。</li>
<li><code>optimizer_G.step()</code>: 这一步是利用优化器 <code>optimizer_G</code> 根据生成器参数的梯度更新参数值。优化器根据梯度和设定的优化算法（如随机梯度下降）更新参数，以减小损失函数的值，从而使生成器更好地生成符合期望的输出。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">else</span>:<br>            fake_segmap_softmax = torch.softmax(fake_segmap, <span class="hljs-number">1</span>)<br><br>            pred_segmap = D(torch.cat((input1.detach(), input2.detach(), fake_segmap_softmax), dim=<span class="hljs-number">1</span>))<br>            <br>            loss_G_GAN = criterionGAN(pred_segmap, <span class="hljs-literal">True</span>)<br>            <br></code></pre></td></tr></table></figure>
<p>这里是如果要加入GANLoss的操作。</p>
<p><code>pred_segmap = D(torch.cat((input1.detach(), input2.detach(), fake_segmap_softmax), dim=1))</code>：这一步将经过softmax处理后的生成器输出与输入图像以及其他信息（如输入的衣服图像）进行拼接，然后输入到鉴别器 <code>D</code> 中进行预测。预测得到的 <code>pred_segmap</code> 是鉴别器对合成图像的预测结果。</p>
<p><code>loss_G_GAN = criterionGAN(pred_segmap, True)</code>表示Generator希望它被判定为真实的。并计算相应的loss。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.G_D_seperate:<br>    <span class="hljs-comment"># discriminator</span><br>    fake_segmap_pred = D(torch.cat((input1.detach(), input2.detach(), fake_segmap_softmax.detach()), dim=<span class="hljs-number">1</span>))<br>    real_segmap_pred = D(torch.cat((input1.detach(), input2.detach(), label), dim=<span class="hljs-number">1</span>))<br>    loss_D_fake = criterionGAN(fake_segmap_pred, <span class="hljs-literal">False</span>)<br>    loss_D_real = criterionGAN(real_segmap_pred, <span class="hljs-literal">True</span>)<br><br>    <span class="hljs-comment"># loss sum</span><br>    loss_G = (<span class="hljs-number">10</span> * loss_l1_cloth + loss_vgg + opt.tvlambda * loss_tv) + (<br>                CE_loss * opt.CElamda + loss_G_GAN * opt.GANlambda)  <span class="hljs-comment"># warping + seg_generation</span><br>    loss_D = loss_D_fake + loss_D_real<br><br>    <span class="hljs-comment"># step</span><br>    optimizer_G.zero_grad()<br>    loss_G.backward()<br>    optimizer_G.step()<br><br>    optimizer_D.zero_grad()<br>    loss_D.backward()<br>    optimizer_D.step()<br></code></pre></td></tr></table></figure>
<p>如果Generator和Discriminator不分开训练，那么就再计算Discriminator的Loss，然后计算Generator的总Loss。然后调用optimizer进行优化。</p>
<p>这里将真实的input和fake_segmap一起作为<code>fake_segmap_pred</code>可能是因为将真实数据与生成数据一起输入判别器可以帮助判别器更好地学习如何区分真实数据和生成数据。</p>
<p><code>fake_segmap_pred = D(torch.cat((input1.detach(), input2.detach(), fake_segmap_softmax.detach()), dim=1))</code>这句使用 <code>detach</code> 函数将生成器输出的梯度信息从计算图中分离出来，以防止梯度更新传播到生成器，从而保持生成器参数不变。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">else</span>: <span class="hljs-comment"># train G first after that train D</span><br>                <span class="hljs-comment"># loss G sum</span><br>                loss_G = (<span class="hljs-number">10</span> * loss_l1_cloth + loss_vgg + opt.tvlambda * loss_tv) + (CE_loss * opt.CElamda + loss_G_GAN * opt.GANlambda)  <span class="hljs-comment"># warping + seg_generation</span><br>                <br>                <span class="hljs-comment"># step G</span><br>                optimizer_G.zero_grad()<br>                loss_G.backward()<br>                optimizer_G.step()<br>                <br>                <span class="hljs-comment"># discriminator</span><br>                <span class="hljs-keyword">with</span> torch.no_grad():<br>                    _, fake_segmap, _, _ = tocg(input1, input2)<br>                fake_segmap_softmax = torch.softmax(fake_segmap, <span class="hljs-number">1</span>)<br>                <br>                <span class="hljs-comment"># loss discriminator</span><br>                fake_segmap_pred = D(torch.cat((input1.detach(), input2.detach(), fake_segmap_softmax.detach()),dim=<span class="hljs-number">1</span>))<br>                real_segmap_pred = D(torch.cat((input1.detach(), input2.detach(), label),dim=<span class="hljs-number">1</span>))<br>                loss_D_fake = criterionGAN(fake_segmap_pred, <span class="hljs-literal">False</span>)<br>                loss_D_real = criterionGAN(real_segmap_pred, <span class="hljs-literal">True</span>)<br>                <br>                loss_D = loss_D_fake + loss_D_real<br>                <br>                optimizer_D.zero_grad()<br>                loss_D.backward()<br>                optimizer_D.step()<br></code></pre></td></tr></table></figure>
<p>如果<code>opt.G_D_seperate == True</code>，就先训练Generator，再训练Discriminator。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> (step + <span class="hljs-number">1</span>) % opt.val_count == <span class="hljs-number">0</span>:  <br>    tocg.<span class="hljs-built_in">eval</span>()  <br>    iou_list = []  <br>    <span class="hljs-keyword">with</span> torch.no_grad():  <br>        <span class="hljs-keyword">for</span> cnt <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2000</span> // opt.batch_size):  <br>  <br>            inputs = val_loader.next_batch()  <br>            <span class="hljs-comment"># input1  </span><br>            c_paired = inputs[<span class="hljs-string">&#x27;cloth&#x27;</span>][<span class="hljs-string">&#x27;paired&#x27;</span>].cuda()  <br>            cm_paired = inputs[<span class="hljs-string">&#x27;cloth_mask&#x27;</span>][<span class="hljs-string">&#x27;paired&#x27;</span>].cuda()  <br>            cm_paired = torch.FloatTensor((cm_paired.detach().cpu().numpy() &gt; <span class="hljs-number">0.5</span>).astype(np.<span class="hljs-built_in">float</span>)).cuda()  <br>            <span class="hljs-comment"># input2  </span><br>            parse_agnostic = inputs[<span class="hljs-string">&#x27;parse_agnostic&#x27;</span>].cuda()  <br>            densepose = inputs[<span class="hljs-string">&#x27;densepose&#x27;</span>].cuda()  <br>            openpose = inputs[<span class="hljs-string">&#x27;pose&#x27;</span>].cuda()  <br>            <span class="hljs-comment"># GT  </span><br>            label_onehot = inputs[<span class="hljs-string">&#x27;parse_onehot&#x27;</span>].cuda()  <span class="hljs-comment"># CE  </span><br>            label = inputs[<span class="hljs-string">&#x27;parse&#x27;</span>].cuda()  <span class="hljs-comment"># GAN loss  </span><br>            parse_cloth_mask = inputs[<span class="hljs-string">&#x27;pcm&#x27;</span>].cuda()  <span class="hljs-comment"># L1  </span><br>            im_c = inputs[<span class="hljs-string">&#x27;parse_cloth&#x27;</span>].cuda()  <span class="hljs-comment"># VGG  </span><br>            <span class="hljs-comment"># visualization            im = inputs[&#x27;image&#x27;]  </span><br>  <br>            input1 = torch.cat([c_paired, cm_paired], <span class="hljs-number">1</span>)  <br>            input2 = torch.cat([parse_agnostic, densepose], <span class="hljs-number">1</span>)  <br></code></pre></td></tr></table></figure>
<p><code>if (step + 1) % opt.val_count == 0:</code>每隔一段时间对模型进行一次评估。</p>
<p><code>tocg.eval()</code>将模型设置为评估模式，这会影响到某些层的行为，例如Dropout和Batch Normalization层，在评估模式下会采用不同的统计信息，以便更好地进行评估。</p>
<p>通过<code>torch.no_grad()</code>上下文管理器，禁用梯度计算，因为在验证过程中不需要计算梯度，这样可以减少内存的使用并提高计算速度。</p>
<p>接着循环遍历验证集，每次加载一个批次的数据，然后将数据传输到GPU上（如果可用）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># forward</span><br>flow_list, fake_segmap, warped_cloth_paired, warped_clothmask_paired = tocg(input1, input2)  <br>  <br><span class="hljs-comment"># fake segmap cloth channel * warped clothmask  </span><br><span class="hljs-keyword">if</span> opt.clothmask_composition != <span class="hljs-string">&#x27;no_composition&#x27;</span>:  <br>    <span class="hljs-keyword">if</span> opt.clothmask_composition == <span class="hljs-string">&#x27;detach&#x27;</span>:  <br>        cloth_mask = torch.ones_like(fake_segmap.detach())  <br>        cloth_mask[:, <span class="hljs-number">3</span>:<span class="hljs-number">4</span>, :, :] = warped_cm_onehot  <br>        fake_segmap = fake_segmap * cloth_mask  <br>  <br>    <span class="hljs-keyword">if</span> opt.clothmask_composition == <span class="hljs-string">&#x27;warp_grad&#x27;</span>:  <br>        cloth_mask = torch.ones_like(fake_segmap.detach())  <br>        cloth_mask[:, <span class="hljs-number">3</span>:<span class="hljs-number">4</span>, :, :] = warped_clothmask_paired  <br>        fake_segmap = fake_segmap * cloth_mask  <br>  <br><span class="hljs-comment"># calculate iou  </span><br>iou = iou_metric(F.softmax(fake_segmap, dim=<span class="hljs-number">1</span>).detach(), label)  <br>iou_list.append(iou.item())  <br>  <br>tocg.train()  <br>board.add_scalar(<span class="hljs-string">&#x27;val/iou&#x27;</span>, np.mean(iou_list), step + <span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>
<p>下面是<code>board.add_scalar</code>函数的各个参数的解释： <code>'val/iou'</code>：标签，用于标识被记录的数据类型，以便在tensorboard中显示。 <code>np.mean(iou_list)</code>：要记录的数值，这里是平均的IoU值。 <code>step + 1</code>：当前的步数，用于在tensorboard中横轴显示，以便对应模型训练的进度。</p>
<p>这里+1是因为循环的step从0开始，但是对于我们人类来说step从1开始更直观，所以我们+1。</p>
<p>Tensorboard是一个由Google开发的用于可视化神经网络训练过程中的各种指标和结果的工具。它可以帮助用户更直观地理解模型的训练过程和性能表现。在Tensorboard中，用户可以查看训练过程中的损失函数曲线、准确率曲线、模型参数分布、模型结构等信息，以及进行多组数据的对比分析。通过可视化，用户可以更好地监控模型的训练过程，发现潜在问题，并优化模型的训练策略。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># tensorboard  </span><br><span class="hljs-keyword">if</span> (step + <span class="hljs-number">1</span>) % opt.tensorboard_count == <span class="hljs-number">0</span>:  <br>    <span class="hljs-comment"># loss G  </span><br>    board.add_scalar(<span class="hljs-string">&#x27;Loss/G&#x27;</span>, loss_G.item(), step + <span class="hljs-number">1</span>)  <br>    board.add_scalar(<span class="hljs-string">&#x27;Loss/G/l1_cloth&#x27;</span>, loss_l1_cloth.item(), step + <span class="hljs-number">1</span>)  <br>    board.add_scalar(<span class="hljs-string">&#x27;Loss/G/vgg&#x27;</span>, loss_vgg.item(), step + <span class="hljs-number">1</span>)  <br>    board.add_scalar(<span class="hljs-string">&#x27;Loss/G/tv&#x27;</span>, loss_tv.item(), step + <span class="hljs-number">1</span>)  <br>    board.add_scalar(<span class="hljs-string">&#x27;Loss/G/CE&#x27;</span>, CE_loss.item(), step + <span class="hljs-number">1</span>)  <br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.no_GAN_loss:  <br>        board.add_scalar(<span class="hljs-string">&#x27;Loss/G/GAN&#x27;</span>, loss_G_GAN.item(), step + <span class="hljs-number">1</span>)  <br>        <span class="hljs-comment"># loss D  </span><br>        board.add_scalar(<span class="hljs-string">&#x27;Loss/D&#x27;</span>, loss_D.item(), step + <span class="hljs-number">1</span>)  <br>        board.add_scalar(<span class="hljs-string">&#x27;Loss/D/pred_real&#x27;</span>, loss_D_real.item(), step + <span class="hljs-number">1</span>)  <br>        board.add_scalar(<span class="hljs-string">&#x27;Loss/D/pred_fake&#x27;</span>, loss_D_fake.item(), step + <span class="hljs-number">1</span>)  <br>  <br>    grid = make_grid(  <br>        [(c_paired[<span class="hljs-number">0</span>].cpu() / <span class="hljs-number">2</span> + <span class="hljs-number">0.5</span>), (cm_paired[<span class="hljs-number">0</span>].cpu()).expand(<span class="hljs-number">3</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>), visualize_segmap(parse_agnostic.cpu()),  <br>         ((densepose.cpu()[<span class="hljs-number">0</span>] + <span class="hljs-number">1</span>) / <span class="hljs-number">2</span>),  <br>         (im_c[<span class="hljs-number">0</span>].cpu() / <span class="hljs-number">2</span> + <span class="hljs-number">0.5</span>), parse_cloth_mask[<span class="hljs-number">0</span>].cpu().expand(<span class="hljs-number">3</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>),  <br>         (warped_cloth_paired[<span class="hljs-number">0</span>].cpu().detach() / <span class="hljs-number">2</span> + <span class="hljs-number">0.5</span>), (warped_cm_onehot[<span class="hljs-number">0</span>].cpu().detach()).expand(<span class="hljs-number">3</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>),  <br>         visualize_segmap(label.cpu()), visualize_segmap(fake_segmap.cpu()), (im[<span class="hljs-number">0</span>] / <span class="hljs-number">2</span> + <span class="hljs-number">0.5</span>),  <br>         (misalign[<span class="hljs-number">0</span>].cpu().detach()).expand(<span class="hljs-number">3</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>)],  <br>        nrow=<span class="hljs-number">4</span>)  <br>    board.add_images(<span class="hljs-string">&#x27;train_images&#x27;</span>, grid.unsqueeze(<span class="hljs-number">0</span>), step + <span class="hljs-number">1</span>)  <br></code></pre></td></tr></table></figure>
<p>然后这段代码是在tensorboard里面记录一些其他的数据。</p>
<p>这里用的是torchvision库中的make_grid函数，而不是用的先前自己定义的。</p>
<p><code>make_grid</code> 函数是 PyTorch 中用于将一组图像排列成一个网格的工具函数。它接受一个张量列表作为输入，这些张量通常代表一组图像。下面是它的部分参数：</p>
<ol type="1">
<li><strong>tensor (list of tensors)</strong>: 这是包含图像的张量列表。每个张量都代表一张图像，通常是 <code>(C, H, W)</code> 形状的张量，其中 <code>C</code> 是通道数，<code>H</code> 是高度，<code>W</code> 是宽度。这些张量可以具有不同的形状，但是它们的通道数必须相同。如果输入的张量是 <code>[N, C, H, W]</code> 形状的，<code>make_grid</code> 函数会将它们合并成一个 <code>(C, H, W * N)</code> 的张量，其中 <code>N</code> 是输入张量的数量。</li>
<li><strong>nrow (int, optional)</strong>: 这是一个可选参数，用于指定生成的网格中每行包含的图像数量。默认值为 8。</li>
<li><strong>padding (int, optional)</strong>: 这也是一个可选参数，用于指定每个图像之间的填充像素数。默认值为 2。</li>
<li><strong>normalize (bool, optional)</strong>: 这是一个可选参数，用于指定是否对输入张量进行归一化。如果设置为 <code>True</code>，则会对输入张量进行归一化，使其像素值范围在 <code>[0, 1]</code> 内。默认值为 <code>False</code>。</li>
<li><strong>value (float, optional)</strong>: 这是一个可选参数，用于指定填充像素的值。默认值为 0。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.no_test_visualize:  <br>    inputs = test_loader.next_batch()  <br>    <span class="hljs-comment"># input1  </span><br>    c_paired = inputs[<span class="hljs-string">&#x27;cloth&#x27;</span>][opt.test_datasetting].cuda()  <br>    cm_paired = inputs[<span class="hljs-string">&#x27;cloth_mask&#x27;</span>][opt.test_datasetting].cuda()  <br>    cm_paired = torch.FloatTensor((cm_paired.detach().cpu().numpy() &gt; <span class="hljs-number">0.5</span>).astype(np.<span class="hljs-built_in">float</span>)).cuda()  <br>    <span class="hljs-comment"># input2  </span><br>    parse_agnostic = inputs[<span class="hljs-string">&#x27;parse_agnostic&#x27;</span>].cuda()  <br>    densepose = inputs[<span class="hljs-string">&#x27;densepose&#x27;</span>].cuda()  <br>    openpose = inputs[<span class="hljs-string">&#x27;pose&#x27;</span>].cuda()  <br>    <span class="hljs-comment"># GT  </span><br>    label_onehot = inputs[<span class="hljs-string">&#x27;parse_onehot&#x27;</span>].cuda()  <span class="hljs-comment"># CE  </span><br>    label = inputs[<span class="hljs-string">&#x27;parse&#x27;</span>].cuda()  <span class="hljs-comment"># GAN loss  </span><br>    parse_cloth_mask = inputs[<span class="hljs-string">&#x27;pcm&#x27;</span>].cuda()  <span class="hljs-comment"># L1  </span><br>    im_c = inputs[<span class="hljs-string">&#x27;parse_cloth&#x27;</span>].cuda()  <span class="hljs-comment"># VGG  </span><br>    <span class="hljs-comment"># visualization        im = inputs[&#x27;image&#x27;]  </span><br>  <br>    tocg.<span class="hljs-built_in">eval</span>()<br></code></pre></td></tr></table></figure>
<p>如果不是no_test_visualize的话，</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.no_test_visualize:  <br>    inputs = test_loader.next_batch()  <br>    <span class="hljs-comment"># input1  </span><br>    c_paired = inputs[<span class="hljs-string">&#x27;cloth&#x27;</span>][opt.test_datasetting].cuda()  <br>    cm_paired = inputs[<span class="hljs-string">&#x27;cloth_mask&#x27;</span>][opt.test_datasetting].cuda()  <br>    cm_paired = torch.FloatTensor((cm_paired.detach().cpu().numpy() &gt; <span class="hljs-number">0.5</span>).astype(np.<span class="hljs-built_in">float</span>)).cuda()  <br>    <span class="hljs-comment"># input2  </span><br>    parse_agnostic = inputs[<span class="hljs-string">&#x27;parse_agnostic&#x27;</span>].cuda()  <br>    densepose = inputs[<span class="hljs-string">&#x27;densepose&#x27;</span>].cuda()  <br>    openpose = inputs[<span class="hljs-string">&#x27;pose&#x27;</span>].cuda()  <br>    <span class="hljs-comment"># GT  </span><br>    label_onehot = inputs[<span class="hljs-string">&#x27;parse_onehot&#x27;</span>].cuda()  <span class="hljs-comment"># CE  </span><br>    label = inputs[<span class="hljs-string">&#x27;parse&#x27;</span>].cuda()  <span class="hljs-comment"># GAN loss  </span><br>    parse_cloth_mask = inputs[<span class="hljs-string">&#x27;pcm&#x27;</span>].cuda()  <span class="hljs-comment"># L1  </span><br>    im_c = inputs[<span class="hljs-string">&#x27;parse_cloth&#x27;</span>].cuda()  <span class="hljs-comment"># VGG  </span><br>    <span class="hljs-comment"># visualization    im = inputs[&#x27;image&#x27;]  </span><br>  <br>    tocg.<span class="hljs-built_in">eval</span>()  <br>    <span class="hljs-keyword">with</span> torch.no_grad():  <br>        <span class="hljs-comment"># inputs  </span><br>        input1 = torch.cat([c_paired, cm_paired], <span class="hljs-number">1</span>)  <br>        input2 = torch.cat([parse_agnostic, densepose], <span class="hljs-number">1</span>)  <br>  <br>        <span class="hljs-comment"># forward  </span><br>        flow_list, fake_segmap, warped_cloth_paired, warped_clothmask_paired = tocg(input1, input2)  <br>  <br>        warped_cm_onehot = torch.FloatTensor(  <br>            (warped_clothmask_paired.detach().cpu().numpy() &gt; <span class="hljs-number">0.5</span>).astype(np.<span class="hljs-built_in">float</span>)).cuda()  <br>        <span class="hljs-keyword">if</span> opt.clothmask_composition != <span class="hljs-string">&#x27;no_composition&#x27;</span>:  <br>            <span class="hljs-keyword">if</span> opt.clothmask_composition == <span class="hljs-string">&#x27;detach&#x27;</span>:  <br>                cloth_mask = torch.ones_like(fake_segmap)  <br>                cloth_mask[:, <span class="hljs-number">3</span>:<span class="hljs-number">4</span>, :, :] = warped_cm_onehot  <br>                fake_segmap = fake_segmap * cloth_mask  <br>  <br>            <span class="hljs-keyword">if</span> opt.clothmask_composition == <span class="hljs-string">&#x27;warp_grad&#x27;</span>:  <br>                cloth_mask = torch.ones_like(fake_segmap)  <br>                cloth_mask[:, <span class="hljs-number">3</span>:<span class="hljs-number">4</span>, :, :] = warped_clothmask_paired  <br>                fake_segmap = fake_segmap * cloth_mask  <br>        <span class="hljs-keyword">if</span> opt.occlusion:  <br>            warped_clothmask_paired = remove_overlap(F.softmax(fake_segmap, dim=<span class="hljs-number">1</span>), warped_clothmask_paired)  <br>            warped_cloth_paired = warped_cloth_paired * warped_clothmask_paired + torch.ones_like(  <br>                warped_cloth_paired) * (<span class="hljs-number">1</span> - warped_clothmask_paired)  <br>  <br>        <span class="hljs-comment"># generated fake cloth mask &amp; misalign mask  </span><br>        fake_clothmask = (torch.argmax(fake_segmap.detach(), dim=<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">True</span>) == <span class="hljs-number">3</span>).long()  <br>        misalign = fake_clothmask - warped_cm_onehot  <br>        misalign[misalign &lt; <span class="hljs-number">0.0</span>] = <span class="hljs-number">0.0</span>  <br>  <br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(opt.num_test_visualize):  <br>        grid = make_grid([(c_paired[i].cpu() / <span class="hljs-number">2</span> + <span class="hljs-number">0.5</span>), (cm_paired[i].cpu()).expand(<span class="hljs-number">3</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>),  <br>                          visualize_segmap(parse_agnostic.cpu(), batch=i), ((densepose.cpu()[i] + <span class="hljs-number">1</span>) / <span class="hljs-number">2</span>),  <br>                          (im_c[i].cpu() / <span class="hljs-number">2</span> + <span class="hljs-number">0.5</span>), parse_cloth_mask[i].cpu().expand(<span class="hljs-number">3</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>),  <br>                          (warped_cloth_paired[i].cpu().detach() / <span class="hljs-number">2</span> + <span class="hljs-number">0.5</span>),  <br>                          (warped_cm_onehot[i].cpu().detach()).expand(<span class="hljs-number">3</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>),  <br>                          visualize_segmap(label.cpu(), batch=i), visualize_segmap(fake_segmap.cpu(), batch=i),  <br>                          (im[i] / <span class="hljs-number">2</span> + <span class="hljs-number">0.5</span>), (misalign[i].cpu().detach()).expand(<span class="hljs-number">3</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>)],  <br>                         nrow=<span class="hljs-number">4</span>)  <br>        board.add_images(<span class="hljs-string">f&#x27;test_images/<span class="hljs-subst">&#123;i&#125;</span>&#x27;</span>, grid.unsqueeze(<span class="hljs-number">0</span>), step + <span class="hljs-number">1</span>)  <br>    tocg.train()<br></code></pre></td></tr></table></figure>
<p>这段代码和上面的差不多，只是做的是test时候的visualization。这个train函数训练到一定的时候，不仅会看看在训练集上的效果，还会加载一些测试集的数据来评估一下。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># display  </span><br><span class="hljs-keyword">if</span> (step + <span class="hljs-number">1</span>) % opt.display_count == <span class="hljs-number">0</span>:  <br>    t = time.time() - iter_start_time  <br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.no_GAN_loss:  <br>        <span class="hljs-built_in">print</span>(  <br>            <span class="hljs-string">&quot;step: %8d, time: %.3f\nloss G: %.4f, L1_cloth loss: %.4f, VGG loss: %.4f, TV loss: %.4f CE: %.4f, G GAN: %.4f\nloss D: %.4f, D real: %.4f, D fake: %.4f&quot;</span>  <br>            % (step + <span class="hljs-number">1</span>, t, loss_G.item(), loss_l1_cloth.item(), loss_vgg.item(), loss_tv.item(), CE_loss.item(),  <br>               loss_G_GAN.item(), loss_D.item(), loss_D_real.item(), loss_D_fake.item()), flush=<span class="hljs-literal">True</span>)  <br>  <br><span class="hljs-comment"># save  </span><br><span class="hljs-keyword">if</span> (step + <span class="hljs-number">1</span>) % opt.save_count == <span class="hljs-number">0</span>:  <br>    save_checkpoint(tocg, os.path.join(opt.checkpoint_dir, opt.name, <span class="hljs-string">&#x27;tocg_step_%06d.pth&#x27;</span> % (step + <span class="hljs-number">1</span>)), opt)  <br>    save_checkpoint(D, os.path.join(opt.checkpoint_dir, opt.name, <span class="hljs-string">&#x27;D_step_%06d.pth&#x27;</span> % (step + <span class="hljs-number">1</span>)), opt)<br></code></pre></td></tr></table></figure>
<p>这部分代码是用于在训练过程中进行显示和保存操作。</p>
<ol type="1">
<li><strong>显示（Display）</strong>：当达到一定的步数间隔时，通过 <code>opt.display_count</code> 控制，会打印当前训练的一些信息，例如损失值、当前步数、训练时间等，以便实时监控训练过程中的情况。这可以帮助调试和监控模型的训练过程。</li>
<li><strong>保存（Save）</strong>：当达到一定的步数间隔时，通过 <code>opt.save_count</code> 控制，会保存当前的模型参数到文件中。这样可以定期保存模型的状态，以便在需要时进行恢复或者继续训练。</li>
</ol>
<p>然后就是调用train的main函数，就没什么特别的了：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():<br>    opt = get_opt()<br>    <span class="hljs-built_in">print</span>(opt)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Start to train %s!&quot;</span> % opt.name)<br>    os.environ[<span class="hljs-string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>] = opt.gpu_ids<br>    <br>    <span class="hljs-comment"># create train dataset &amp; loader</span><br>    train_dataset = CPDataset(opt)<br>    train_loader = CPDataLoader(opt, train_dataset)<br>    <br>    <span class="hljs-comment"># create test dataset &amp; loader</span><br>    test_loader = <span class="hljs-literal">None</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.no_test_visualize:<br>        train_bsize = opt.batch_size<br>        opt.batch_size = opt.num_test_visualize<br>        opt.dataroot = opt.test_dataroot<br>        opt.datamode = <span class="hljs-string">&#x27;test&#x27;</span><br>        opt.data_list = opt.test_data_list<br>        test_dataset = CPDatasetTest(opt)<br>        opt.batch_size = train_bsize<br>        val_dataset = Subset(test_dataset, np.arange(<span class="hljs-number">2000</span>))<br>        test_loader = CPDataLoader(opt, test_dataset)<br>        val_loader = CPDataLoader(opt, val_dataset)<br>    <span class="hljs-comment"># visualization</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(opt.tensorboard_dir):<br>        os.makedirs(opt.tensorboard_dir)<br>    board = SummaryWriter(log_dir=os.path.join(opt.tensorboard_dir, opt.name))<br><br>    <span class="hljs-comment"># Model</span><br>    input1_nc = <span class="hljs-number">4</span>  <span class="hljs-comment"># cloth + cloth-mask</span><br>    input2_nc = opt.semantic_nc + <span class="hljs-number">3</span>  <span class="hljs-comment"># parse_agnostic + densepose</span><br>    tocg = ConditionGenerator(opt, input1_nc=<span class="hljs-number">4</span>, input2_nc=input2_nc, output_nc=opt.output_nc, ngf=<span class="hljs-number">96</span>, norm_layer=nn.BatchNorm2d)<br>    D = define_D(input_nc=input1_nc + input2_nc + opt.output_nc, Ddownx2 = opt.Ddownx2, Ddropout = opt.Ddropout, n_layers_D=<span class="hljs-number">3</span>, spectral = opt.spectral, num_D = opt.num_D)<br>    <br>    <span class="hljs-comment"># Load Checkpoint</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.tocg_checkpoint == <span class="hljs-string">&#x27;&#x27;</span> <span class="hljs-keyword">and</span> os.path.exists(opt.tocg_checkpoint):<br>        load_checkpoint(tocg, opt.tocg_checkpoint)<br><br>    <span class="hljs-comment"># Train</span><br>    train(opt, train_loader, val_loader, test_loader, board, tocg, D)<br><br>    <span class="hljs-comment"># Save Checkpoint</span><br>    save_checkpoint(tocg, os.path.join(opt.checkpoint_dir, opt.name, <span class="hljs-string">&#x27;tocg_final.pth&#x27;</span>),opt)<br>    save_checkpoint(D, os.path.join(opt.checkpoint_dir, opt.name, <span class="hljs-string">&#x27;D_final.pth&#x27;</span>),opt)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Finished training %s!&quot;</span> % opt.name)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    main()<br></code></pre></td></tr></table></figure>
<h1 id="train_generator.py">train_generator.py</h1>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_opt</span>():<br>    parser = argparse.ArgumentParser()<br><br>    parser.add_argument(<span class="hljs-string">&#x27;--name&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, required=<span class="hljs-literal">True</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;--gpu_ids&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=<span class="hljs-string">&#x27;0&#x27;</span>)<br><br>	<span class="hljs-comment"># detailes omitted</span><br><br>    opt = parser.parse_args()<br><br>    <span class="hljs-comment"># set gpu ids</span><br>    str_ids = opt.gpu_ids.split(<span class="hljs-string">&#x27;,&#x27;</span>)<br>    opt.gpu_ids = []<br>    <span class="hljs-keyword">for</span> str_id <span class="hljs-keyword">in</span> str_ids:<br>        <span class="hljs-built_in">id</span> = <span class="hljs-built_in">int</span>(str_id)<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">id</span> &gt;= <span class="hljs-number">0</span>:<br>            opt.gpu_ids.append(<span class="hljs-built_in">id</span>)<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(opt.gpu_ids) &gt; <span class="hljs-number">0</span>:<br>        torch.cuda.set_device(opt.gpu_ids[<span class="hljs-number">0</span>])<br><br>    <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(opt.gpu_ids) == <span class="hljs-number">0</span> <span class="hljs-keyword">or</span> opt.batch_size % <span class="hljs-built_in">len</span>(opt.gpu_ids) == <span class="hljs-number">0</span>, \<br>        <span class="hljs-string">&quot;Batch size %d is wrong. It must be a multiple of # GPUs %d.&quot;</span> \<br>        % (opt.batch_size, <span class="hljs-built_in">len</span>(opt.gpu_ids))<br><br>    <span class="hljs-keyword">return</span> opt<br></code></pre></td></tr></table></figure>
<p>这里还是调用parser来获取用户的参数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">opt, train_loader, test_loader, test_vis_loader, board, tocg, generator, discriminator, model</span>):  <br>    <span class="hljs-comment"># Model  </span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.GT:  <br>        tocg.cuda()  <br>        tocg.<span class="hljs-built_in">eval</span>()  <br>    generator.train()  <br>    discriminator.train()  <br>    model.<span class="hljs-built_in">eval</span>()<br></code></pre></td></tr></table></figure>
<p>这里opt.GT控制是使用真实的数据（segmentation map）训练还是使用tocg生成的segmentation map进行训练。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># criterion  </span><br><span class="hljs-keyword">if</span> opt.fp16:  <br>    criterionGAN = GANLoss(<span class="hljs-string">&#x27;hinge&#x27;</span>, tensor=torch.cuda.HalfTensor)  <br><span class="hljs-keyword">else</span>:  <br>    criterionGAN = GANLoss(<span class="hljs-string">&#x27;hinge&#x27;</span>, tensor=torch.cuda.FloatTensor)  <br><span class="hljs-comment"># criterionL1 = nn.L1Loss()  </span><br>criterionFeat = nn.L1Loss()  <br>criterionVGG = VGGLoss(opt)  <br>  <br><span class="hljs-comment"># optimizer  </span><br>optimizer_gen = torch.optim.Adam(generator.parameters(), lr=opt.G_lr, betas=(<span class="hljs-number">0</span>, <span class="hljs-number">0.9</span>))  <br>scheduler_gen = torch.optim.lr_scheduler.LambdaLR(optimizer_gen, lr_lambda=<span class="hljs-keyword">lambda</span> step: <span class="hljs-number">1.0</span> -  <span class="hljs-built_in">max</span>(<span class="hljs-number">0</span>,step * <span class="hljs-number">1000</span> + opt.load_step - opt.keep_step) / <span class="hljs-built_in">float</span>(opt.decay_step + <span class="hljs-number">1</span>))  <br><br>optimizer_dis = torch.optim.Adam(discriminator.parameters(), lr=opt.D_lr, betas=(<span class="hljs-number">0</span>, <span class="hljs-number">0.9</span>))  <br>scheduler_dis = torch.optim.lr_scheduler.LambdaLR(optimizer_dis, lr_lambda=<span class="hljs-keyword">lambda</span> step: <span class="hljs-number">1.0</span> -  <span class="hljs-built_in">max</span>(<span class="hljs-number">0</span>, step * <span class="hljs-number">1000</span> + opt.load_step - opt.keep_step) / <span class="hljs-built_in">float</span>(opt.decay_step + <span class="hljs-number">1</span>))<br></code></pre></td></tr></table></figure>
<p>这里使用hinge loss。</p>
<p>这里还使用了学习率调度器（scheduler）。在深度学习训练过程中，学习率调度器（scheduler）是用来调整优化器的学习率的工具，以便控制训练过程中的学习速度。在这段代码中，使用的是 <code>torch.optim.lr_scheduler.LambdaLR</code> 调度器。这个调度器通过一个 lambda 函数来自定义学习率的调整策略，这提供了很大的灵活性。</p>
<p>这里的学习率调整策略为 <span class="math display">\[\lambda(\text{step}) = 1.0 - \frac{\max(0, \text{step} \times 1000 + \text{opt.load\_step} - \text{opt.keep\_step})}{\text{opt.decay\_step} + 1}\]</span> <strong>公式分析：</strong> 参数的含义：</p>
<p><strong>opt.load_step</strong></p>
<ul>
<li><strong>含义</strong>：<code>opt.load_step</code> 通常指的是从哪一个训练步骤开始加载模型继续训练。这个参数在恢复中断的训练或从预训练模型开始训练时特别有用。它表示已经执行的训练步骤数，用于确保学习率调度和其他训练逻辑可以从正确的时间点开始。</li>
</ul>
<p><strong>opt.keep_step</strong></p>
<ul>
<li><strong>含义</strong>：<code>opt.keep_step</code> 是指在训练过程中保持初始学习率不变的步数。换句话说，这是一个阈值，直到该步数之前，学习率将保持为开始时设置的初始值。</li>
<li><strong>作用</strong>：通过设定一个初始阶段在该步数内不改变学习率，可以让模型在训练初期快速下降到一个合理的损失水平。在很多优化任务中，初期使用较高的固定学习率可以帮助模型跳出不良的局部最小值，或更快地接近全局最小值。</li>
</ul>
<p><strong>opt.decay_step</strong></p>
<ul>
<li><strong>含义</strong>：<code>opt.decay_step</code> 定义了从 <code>opt.keep_step</code> 计算起，学习率需要经过多少步骤减少到0或接近0的一个阈值。它是学习率开始衰减后，直到衰减结束的步数总和。</li>
<li><strong>作用</strong>：这个参数控制了学习率衰减的速度和持续时间。较大的 <code>decay_step</code> 值意味着学习率将以较慢的速度减少，这可能有助于模型在接近优化问题的解时进行更细致的调整。相反，较小的 <code>decay_step</code> 值会使学习率较快减小，这可能在某些需要快速收敛的场景中更为适合。</li>
</ul>
<p><strong>step * 1000</strong></p>
<ul>
<li><strong>含义</strong>：在这个表达式中，<code>step * 1000</code> 很可能是用来加速学习率衰减过程的一个因子。这里的 <code>1000</code> 是一个放大系数，用于增加每一步对学习率调整影响的幅度。</li>
<li><strong>作用</strong>：这个乘法因子可以看作是加速衰减的一种方式。在许多训练场景中，可能希望在训练初期保持较高的学习率，而在经过较少的训练迭代后迅速减小学习率。<code>step * 1000</code> 通过增加步骤的权重，使得学习率在经过较少的迭代后迅速接近衰减的阶段，这样可以在训练早期快速探索，之后快速细化。</li>
</ul>
<p>我们其实可以先把这个公式看成 <span class="math display">\[\lambda(\text{step}) = 1.0 - \frac{\max(0, \text{step} + \text{opt.load\_step} - \text{opt.keep\_step})}{\text{opt.decay\_step} + 1}\]</span></p>
<p>这里step+load_step就表示真正的训练步数，然后在达到keep_step之前，分子一直是为0的，所以学习率一直保持不变，然后到了keep_step之后，经过decay_step步后衰减为0。这里分母decay_step加了1使代码更robust，防止除以0的错误。然后原始的公式step乘以了1000，也就是说分子近似于变为之前的1000倍，让 <span class="math inline">\(\lambda\)</span> 的衰减更快。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> opt.fp16:  <br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.GT:  <br>        <span class="hljs-keyword">from</span> apex <span class="hljs-keyword">import</span> amp  <br>        [tocg, generator, discriminator], [optimizer_gen, optimizer_dis] = amp.initialize(  <br>            [tocg, generator, discriminator], [optimizer_gen, optimizer_dis], opt_level=<span class="hljs-string">&#x27;O1&#x27;</span>, num_losses=<span class="hljs-number">2</span>)  <br>    <br>    <span class="hljs-keyword">else</span>:  <br>        <span class="hljs-keyword">from</span> apex <span class="hljs-keyword">import</span> amp  <br>        [generator, discriminator], [optimizer_gen, optimizer_dis] = amp.initialize(  <br>            [generator, discriminator], [optimizer_gen, optimizer_dis], opt_level=<span class="hljs-string">&#x27;O1&#x27;</span>, num_losses=<span class="hljs-number">2</span>)<br></code></pre></td></tr></table></figure>
<p>这部分代码涉及到混合精度训练（Mixed Precision Training），这是一种可以加快深度学习模型训练速度并减少模型训练或推断时所需内存的技术。在这个代码段中，使用了NVIDIA的 <code>apex</code> 库中的 <code>amp</code> (Automatic Mixed Precision) 模块来实现混合精度训练。</p>
<ol type="1">
<li><strong>检查是否使用半精度（FP16）</strong>:
<ul>
<li><code>if opt.fp16</code>: 这一行检查是否配置了使用FP16精度。FP16精度使用16位浮点数存储和计算，与传统的32位（FP32）相比，可以减少内存占用并提高计算速度。</li>
</ul></li>
<li><strong>混合精度初始化</strong>:
<ul>
<li><code>from apex import amp</code>: 导入 <code>amp</code> 模块，它是专为PyTorch设计的，用于实现自动混合精度功能。</li>
<li><code>amp.initialize(...)</code>: 这个函数用于初始化模型和优化器以使用混合精度。它接收模型和优化器作为输入，并返回经过修改的模型和优化器，这些都是为混合精度训练准备的。</li>
</ul></li>
<li><strong>优化级别和损失数量</strong>:
<ul>
<li><code>opt_level='O1'</code>: 这个参数指定了混合精度的优化级别。<code>O1</code> 是常用的优化级别之一，它执行动态张量类型转换。这意味着AMP会自动决定何时使用FP16何时使用FP32，以平衡计算速度和数值稳定性。</li>
<li><code>num_losses=2</code>: 这个参数指示有多少个损失函数会在训练过程中被计算。这对于正确地进行梯度缩放和更新非常关键。</li>
</ul></li>
<li><strong>对模型的处理</strong>:
<ul>
<li><code>if not opt.GT</code>: <code>tocg</code>, <code>generator</code>, <code>discriminator</code> 三个模型同时进行混合精度配置。</li>
<li><code>else</code>: 如果使用GT进行训练，只对 <code>generator</code> 和 <code>discriminator</code> 进行混合精度配置。</li>
</ul></li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(opt.gpu_ids) &gt; <span class="hljs-number">0</span>:<br>       <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.GT:<br>           tocg = DataParallelWithCallback(tocg, device_ids=opt.gpu_ids)<br>       generator = DataParallelWithCallback(generator, device_ids=opt.gpu_ids)<br>       discriminator = DataParallelWithCallback(discriminator, device_ids=opt.gpu_ids)<br>       criterionGAN = DataParallelWithCallback(criterionGAN, device_ids=opt.gpu_ids)<br>       criterionFeat = DataParallelWithCallback(criterionFeat, device_ids=opt.gpu_ids)<br>       criterionVGG = DataParallelWithCallback(criterionVGG, device_ids=opt.gpu_ids)<br>       <br>   upsample = torch.nn.Upsample(scale_factor=<span class="hljs-number">4</span>, mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>)<br>   gauss = tgm.image.GaussianBlur((<span class="hljs-number">15</span>, <span class="hljs-number">15</span>), (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>))<br>   gauss = gauss.cuda()<br></code></pre></td></tr></table></figure>
<p>这里的<code>DataParallelWithCallback</code>与<code>torch.nn.DataParallel</code>类似。</p>
<h3 id="dataparallel-工作原理">DataParallel 工作原理</h3>
<ol type="1">
<li><strong>复制模型</strong>：在使用 <code>DataParallel</code> 时，首先在每个 GPU 上复制一份完整的模型。</li>
<li><strong>分割数据</strong>：将输入数据分割成多个小批次，每个批次由一个 GPU 处理。</li>
<li><strong>并行计算</strong>：每个 GPU 接收到分配给它的数据后，独立地进行前向和反向计算。</li>
<li><strong>梯度聚合</strong>：所有 GPU 上的梯度会被聚合到主 GPU 上，然后更新模型参数。</li>
<li><strong>同步参数</strong>：更新后的模型参数会从主 GPU 同步到其他所有 GPU，确保所有 GPU 上的模型保持一致。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> step <span class="hljs-keyword">in</span> tqdm(<span class="hljs-built_in">range</span>(opt.load_step, opt.keep_step + opt.decay_step)):  <br>    iter_start_time = time.time()  <br>    inputs = train_loader.next_batch()  <br>  <br>    <span class="hljs-comment"># input  </span><br>    agnostic = inputs[<span class="hljs-string">&#x27;agnostic&#x27;</span>].cuda()  <br>    parse_GT = inputs[<span class="hljs-string">&#x27;parse&#x27;</span>].cuda()  <br>    pose = inputs[<span class="hljs-string">&#x27;densepose&#x27;</span>].cuda()  <br>    parse_cloth = inputs[<span class="hljs-string">&#x27;parse_cloth&#x27;</span>].cuda()  <br>    parse_agnostic = inputs[<span class="hljs-string">&#x27;parse_agnostic&#x27;</span>].cuda()  <br>    pcm = inputs[<span class="hljs-string">&#x27;pcm&#x27;</span>].cuda()  <br>    cm = inputs[<span class="hljs-string">&#x27;cloth_mask&#x27;</span>][<span class="hljs-string">&#x27;paired&#x27;</span>].cuda()  <br>    c_paired = inputs[<span class="hljs-string">&#x27;cloth&#x27;</span>][<span class="hljs-string">&#x27;paired&#x27;</span>].cuda()  <br>  <br>    <span class="hljs-comment"># target  </span><br>    im = inputs[<span class="hljs-string">&#x27;image&#x27;</span>].cuda()<br></code></pre></td></tr></table></figure>
<p>然后这里就是开始正式训练。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">with</span> torch.no_grad():  <br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.GT:  <br>        <span class="hljs-comment"># Warping Cloth  </span><br>        <span class="hljs-comment"># down        pre_clothes_mask_down = F.interpolate(cm, size=(256, 192), mode=&#x27;nearest&#x27;)  </span><br>        input_parse_agnostic_down = F.interpolate(parse_agnostic, size=(<span class="hljs-number">256</span>, <span class="hljs-number">192</span>), mode=<span class="hljs-string">&#x27;nearest&#x27;</span>)  <br>        clothes_down = F.interpolate(c_paired, size=(<span class="hljs-number">256</span>, <span class="hljs-number">192</span>), mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>)  <br>        densepose_down = F.interpolate(pose, size=(<span class="hljs-number">256</span>, <span class="hljs-number">192</span>), mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>)  <br>  <br>        <span class="hljs-comment"># multi-task inputs  </span><br>        input1 = torch.cat([clothes_down, pre_clothes_mask_down], <span class="hljs-number">1</span>)  <br>        input2 = torch.cat([input_parse_agnostic_down, densepose_down], <span class="hljs-number">1</span>)  <br>  <br>        <span class="hljs-comment"># forward  </span><br>        flow_list, fake_segmap, _, warped_clothmask_paired = tocg(input1, input2)  <br>  <br>        <span class="hljs-comment"># warped cloth mask one hot   </span><br>warped_cm_onehot = torch.FloatTensor(  <br>            (warped_clothmask_paired.detach().cpu().numpy() &gt; <span class="hljs-number">0.5</span>).astype(np.<span class="hljs-built_in">float</span>)).cuda()  <br>  <br>        <span class="hljs-keyword">if</span> opt.clothmask_composition != <span class="hljs-string">&#x27;no_composition&#x27;</span>:  <br>            <span class="hljs-keyword">if</span> opt.clothmask_composition == <span class="hljs-string">&#x27;detach&#x27;</span>:  <br>                cloth_mask = torch.ones_like(fake_segmap)  <br>                cloth_mask[:, <span class="hljs-number">3</span>:<span class="hljs-number">4</span>, :, :] = warped_cm_onehot  <br>                fake_segmap = fake_segmap * cloth_mask  <br>  <br>            <span class="hljs-keyword">if</span> opt.clothmask_composition == <span class="hljs-string">&#x27;warp_grad&#x27;</span>:  <br>                cloth_mask = torch.ones_like(fake_segmap)  <br>                cloth_mask[:, <span class="hljs-number">3</span>:<span class="hljs-number">4</span>, :, :] = warped_clothmask_paired  <br>                fake_segmap = fake_segmap * cloth_mask<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">N, _, iH, iW = c_paired.shape  <br>grid = make_grid(N, iH, iW, opt)  <br>flow = F.interpolate(flow_list[-<span class="hljs-number">1</span>].permute(<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>), size=(iH, iW), mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>).permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)  <br>flow_norm = torch.cat([flow[:, :, :, <span class="hljs-number">0</span>:<span class="hljs-number">1</span>] / ((<span class="hljs-number">96</span> - <span class="hljs-number">1.0</span>) / <span class="hljs-number">2.0</span>), flow[:, :, :, <span class="hljs-number">1</span>:<span class="hljs-number">2</span>] / ((<span class="hljs-number">128</span> - <span class="hljs-number">1.0</span>) / <span class="hljs-number">2.0</span>)], <span class="hljs-number">3</span>)  <br>warped_grid = grid + flow_norm  <br>warped_cloth_paired = F.grid_sample(c_paired, warped_grid, padding_mode=<span class="hljs-string">&#x27;border&#x27;</span>).detach()  <br>warped_clothmask = F.grid_sample(cm, warped_grid, padding_mode=<span class="hljs-string">&#x27;border&#x27;</span>)<br></code></pre></td></tr></table></figure>
<p>这里是对光流场进行归一化。</p>
<p>在图像处理中，尤其是在使用网格采样 (<code>grid_sample</code>) 进行图像变形时，光流场必须归一化到 <code>[-1, 1]</code> 的范围内。这是因为 <code>grid_sample</code> 函数期望网格坐标在这个范围内，其中 <code>-1</code> 和 <code>1</code> 分别表示图像的边缘。如果光流数据没有正确归一化，变形效果可能会超出图像边界或无法正确对齐，从而导致图像质量下降或者边缘出现不期望的效果。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># make generator input parse map  </span><br>fake_parse_gauss = gauss(F.interpolate(fake_segmap, size=(iH, iW), mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>))  <br>fake_parse = fake_parse_gauss.argmax(dim=<span class="hljs-number">1</span>)[:, <span class="hljs-literal">None</span>]<br></code></pre></td></tr></table></figure>
<p><strong>高斯模糊</strong>： <code>gauss(...)</code>：应用高斯模糊函数到缩放后的 <code>fake_segmap</code> 上。高斯模糊是一种常用的图像平滑技术，用于去除图像噪声或细节，可以使图像的类别边界更加柔和。这在处理分割图时特别有用，因为它有助于减少类别边界处的锯齿效应或像素级的分类错误。</p>
<p><strong>求最大值索引</strong>： <code>fake_parse_gauss.argmax(dim=1)[:, None]</code>：这一步是从经过高斯模糊处理的分割图 <code>fake_parse_gauss</code> 中，沿特定维度（这里是维度 1，通常对应于通道维，假设每个通道代表一个特定的类别）求取最大值的索引。这意味着每个像素位置都会被赋予其最可能的类别标签。</p>
<p><code>[:, None]</code> 这部分是为了在结果中添加一个新的单通道维度，从而将这个二维数据转换为三维数据结构。保持一个统一的数据维度格式有助于减少数据处理中的错误，使得模型的设计和实现更加清晰和一致。</p>
<p>如果不用ground_truth进行训练，就先调用tocg产生相应的fake_segmap。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">else</span>:  <br><span class="hljs-comment"># parse pre-process  </span><br>    fake_parse = parse_GT.argmax(dim=<span class="hljs-number">1</span>)[:, <span class="hljs-literal">None</span>]  <br>    warped_cloth_paired = parse_cloth<br></code></pre></td></tr></table></figure>
<p>否则就用真实图像的segmentation map。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python">old_parse = torch.FloatTensor(fake_parse.size(<span class="hljs-number">0</span>), <span class="hljs-number">13</span>, opt.fine_height, opt.fine_width).zero_().cuda()  <br>old_parse.scatter_(<span class="hljs-number">1</span>, fake_parse, <span class="hljs-number">1.0</span>)  <br>  <br>labels = &#123;  <br>    <span class="hljs-number">0</span>: [<span class="hljs-string">&#x27;background&#x27;</span>, [<span class="hljs-number">0</span>]],  <br>    <span class="hljs-number">1</span>: [<span class="hljs-string">&#x27;paste&#x27;</span>, [<span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">9</span>, <span class="hljs-number">10</span>, <span class="hljs-number">11</span>]],  <br>    <span class="hljs-number">2</span>: [<span class="hljs-string">&#x27;upper&#x27;</span>, [<span class="hljs-number">3</span>]],  <br>    <span class="hljs-number">3</span>: [<span class="hljs-string">&#x27;hair&#x27;</span>, [<span class="hljs-number">1</span>]],  <br>    <span class="hljs-number">4</span>: [<span class="hljs-string">&#x27;left_arm&#x27;</span>, [<span class="hljs-number">5</span>]],  <br>    <span class="hljs-number">5</span>: [<span class="hljs-string">&#x27;right_arm&#x27;</span>, [<span class="hljs-number">6</span>]],  <br>    <span class="hljs-number">6</span>: [<span class="hljs-string">&#x27;noise&#x27;</span>, [<span class="hljs-number">12</span>]]  <br>&#125;  <br>parse = torch.FloatTensor(fake_parse.size(<span class="hljs-number">0</span>), <span class="hljs-number">7</span>, opt.fine_height, opt.fine_width).zero_().cuda()  <br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(labels)):  <br>    <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> labels[i][<span class="hljs-number">1</span>]:  <br>        parse[:, i] += old_parse[:, label]  <br>  <br>parse = parse.detach()<br></code></pre></td></tr></table></figure>
<p>这里又调整了原始的segmentation map。</p>
<p><code>"paste"</code> 类别的意义：</p>
<ul>
<li><code>"paste"</code> 在这里作为一个类别名称，很可能是为了简化模型处理的复杂性而创造的一个集合类别，它合并了多种不同的衣物和配件。这种合并可能是因为这些元素在特定任务（如风格迁移、虚拟试衣等）中具有相似的处理方式或者对结果的影响类似。</li>
<li>将多个类别合并为一个 <code>"paste"</code> 类别可以减少模型需要直接处理的类别总数，简化学习任务，尤其是在类别间差异不大或者对最终任务影响不大的情况下。</li>
</ul>
<p>这里再贴一个parse label的参考表来作为对照。 <figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs markdown"><span class="hljs-bullet">0.</span> Background<br><span class="hljs-bullet">1.</span> Hat<br><span class="hljs-bullet">2.</span> Hair<br><span class="hljs-bullet">3.</span> Glove<br><span class="hljs-bullet">4.</span> Sunglasses<br><span class="hljs-bullet">5.</span> Upper-clothes<br><span class="hljs-bullet">6.</span> Dress<br><span class="hljs-bullet">7.</span> Coat<br><span class="hljs-bullet">8.</span> Socks<br><span class="hljs-bullet">9.</span> Pants<br><span class="hljs-bullet">10.</span> Jumpsuits<br><span class="hljs-bullet">11.</span> Scarf<br><span class="hljs-bullet">12.</span> Skirt<br><span class="hljs-bullet">13.</span> Face<br><span class="hljs-bullet">14.</span> Left-arm<br><span class="hljs-bullet">15.</span> Right-arm<br><span class="hljs-bullet">16.</span> Left-leg<br><span class="hljs-bullet">17.</span> Right-leg<br><span class="hljs-bullet">18.</span> Left-shoe<br><span class="hljs-bullet">19.</span> Right-shoe<br></code></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Train the generator  </span><br>output_paired = generator(torch.cat((agnostic, pose, warped_cloth_paired), dim=<span class="hljs-number">1</span>), parse)  <br>  <br>fake_concat = torch.cat((parse, output_paired), dim=<span class="hljs-number">1</span>)  <br>real_concat = torch.cat((parse, im), dim=<span class="hljs-number">1</span>)  <br>pred = discriminator(torch.cat((fake_concat, real_concat), dim=<span class="hljs-number">0</span>))  <br>  <br><span class="hljs-comment"># the prediction contains the intermediate outputs of multiscale GAN,  </span><br><span class="hljs-comment"># so it&#x27;s usually a list  </span><br><span class="hljs-keyword">if</span> <span class="hljs-built_in">type</span>(pred) == <span class="hljs-built_in">list</span>:  <br>    pred_fake = []  <br>    pred_real = []  <br>    <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> pred:  <br>        pred_fake.append([tensor[:tensor.size(<span class="hljs-number">0</span>) // <span class="hljs-number">2</span>] <span class="hljs-keyword">for</span> tensor <span class="hljs-keyword">in</span> p])  <br>        pred_real.append([tensor[tensor.size(<span class="hljs-number">0</span>) // <span class="hljs-number">2</span>:] <span class="hljs-keyword">for</span> tensor <span class="hljs-keyword">in</span> p])  <br><span class="hljs-keyword">else</span>:  <br>    pred_fake = pred[:pred.size(<span class="hljs-number">0</span>) // <span class="hljs-number">2</span>]  <br>    pred_real = pred[pred.size(<span class="hljs-number">0</span>) // <span class="hljs-number">2</span>:]  <br>  <br>G_losses = &#123;&#125;  <br>G_losses[<span class="hljs-string">&#x27;GAN&#x27;</span>] = criterionGAN(pred_fake, <span class="hljs-literal">True</span>, for_discriminator=<span class="hljs-literal">False</span>)  <br>  <br><span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.no_ganFeat_loss:  <br>    num_D = <span class="hljs-built_in">len</span>(pred_fake)  <br>    GAN_Feat_loss = torch.cuda.FloatTensor(<span class="hljs-built_in">len</span>(opt.gpu_ids)).zero_()  <br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_D):  <span class="hljs-comment"># for each discriminator  </span><br>        <span class="hljs-comment"># last output is the final prediction, so we exclude it        num_intermediate_outputs = len(pred_fake[i]) - 1  </span><br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_intermediate_outputs):  <span class="hljs-comment"># for each layer output  </span><br>            unweighted_loss = criterionFeat(pred_fake[i][j], pred_real[i][j].detach())  <br>            GAN_Feat_loss += unweighted_loss * opt.lambda_feat / num_D  <br>    G_losses[<span class="hljs-string">&#x27;GAN_Feat&#x27;</span>] = GAN_Feat_loss  <br>  <br><span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.no_vgg_loss:  <br>    G_losses[<span class="hljs-string">&#x27;VGG&#x27;</span>] = criterionVGG(output_paired, im) * opt.lambda_vgg  <br>  <br>loss_gen = <span class="hljs-built_in">sum</span>(G_losses.values()).mean()  <br>  <br>optimizer_gen.zero_grad()  <br><span class="hljs-keyword">if</span> opt.fp16:  <br>    <span class="hljs-keyword">with</span> amp.scale_loss(loss_gen, optimizer_gen, loss_id=<span class="hljs-number">0</span>) <span class="hljs-keyword">as</span> loss_gen_scaled:  <br>        loss_gen_scaled.backward()  <br><span class="hljs-keyword">else</span>:  <br>    loss_gen.backward()  <br>optimizer_gen.step()<br></code></pre></td></tr></table></figure>
<p>首先把<code>torch.cat((agnostic, pose, warped_cloth_paired)</code>输入进去产生假的图像。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">fake_concat = torch.cat((parse, output_paired), dim=<span class="hljs-number">1</span>)  <br>real_concat = torch.cat((parse, im), dim=<span class="hljs-number">1</span>)<br>pred = discriminator(torch.cat((fake_concat, real_concat), dim=<span class="hljs-number">0</span>))  <br></code></pre></td></tr></table></figure>
<p>然后把生成的和parse拼接在一起作为fake_concat，把GT和parse拼接在一起作为real_concat。然后传给discriminator让它来分辨。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> <span class="hljs-built_in">type</span>(pred) == <span class="hljs-built_in">list</span>:  <br>    pred_fake = []  <br>    pred_real = []  <br>    <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> pred:  <br>        pred_fake.append([tensor[:tensor.size(<span class="hljs-number">0</span>) // <span class="hljs-number">2</span>] <span class="hljs-keyword">for</span> tensor <span class="hljs-keyword">in</span> p])  <br>        pred_real.append([tensor[tensor.size(<span class="hljs-number">0</span>) // <span class="hljs-number">2</span>:] <span class="hljs-keyword">for</span> tensor <span class="hljs-keyword">in</span> p])  <br><span class="hljs-keyword">else</span>:  <br>    pred_fake = pred[:pred.size(<span class="hljs-number">0</span>) // <span class="hljs-number">2</span>]  <br>    pred_real = pred[pred.size(<span class="hljs-number">0</span>) // <span class="hljs-number">2</span>:]<br></code></pre></td></tr></table></figure>
<p>然后由于discriminator在不同分辨率下都产生了一个prediction，所以<code>pred</code>大概率是一个列表。然后把第一个维度（batch维度）的前一半加入到pred_fake中（对fake_concat的prediction），把第一个维度的后一半加入到pred_real中（对real_concat的prediction）。（因为discriminator的输入是fake_concat 和 real_concat 的 concatenation。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python">G_losses = &#123;&#125;  <br>G_losses[<span class="hljs-string">&#x27;GAN&#x27;</span>] = criterionGAN(pred_fake, <span class="hljs-literal">True</span>, for_discriminator=<span class="hljs-literal">False</span>)  <br>  <br><span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.no_ganFeat_loss:  <br>    num_D = <span class="hljs-built_in">len</span>(pred_fake)  <br>    GAN_Feat_loss = torch.cuda.FloatTensor(<span class="hljs-built_in">len</span>(opt.gpu_ids)).zero_()  <br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_D):  <span class="hljs-comment"># for each discriminator  </span><br>        <span class="hljs-comment"># last output is the final prediction, so we exclude it        num_intermediate_outputs = len(pred_fake[i]) - 1  </span><br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_intermediate_outputs):  <span class="hljs-comment"># for each layer output  </span><br>            unweighted_loss = criterionFeat(pred_fake[i][j], pred_real[i][j].detach())  <br>            GAN_Feat_loss += unweighted_loss * opt.lambda_feat / num_D  <br>    G_losses[<span class="hljs-string">&#x27;GAN_Feat&#x27;</span>] = GAN_Feat_loss<br></code></pre></td></tr></table></figure>
<p>然后先在Generator的Loss里面加入一个hinge Loss。</p>
<p>然后如果要ganFeat_loss的话，就相应的计算Generator生成的图片经过Discriminator分辨的结果与真实图片之间的差距，这个差距越小越好。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.no_vgg_loss:  <br>    G_losses[<span class="hljs-string">&#x27;VGG&#x27;</span>] = criterionVGG(output_paired, im) * opt.lambda_vgg<br></code></pre></td></tr></table></figure>
<p>然后加入VGG Loss。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">loss_gen = <span class="hljs-built_in">sum</span>(G_losses.values()).mean()  <br>  <br>optimizer_gen.zero_grad()  <br><span class="hljs-keyword">if</span> opt.fp16:  <br>    <span class="hljs-keyword">with</span> amp.scale_loss(loss_gen, optimizer_gen, loss_id=<span class="hljs-number">0</span>) <span class="hljs-keyword">as</span> loss_gen_scaled:  <br>        loss_gen_scaled.backward()  <br><span class="hljs-keyword">else</span>:  <br>    loss_gen.backward()  <br>optimizer_gen.step()<br></code></pre></td></tr></table></figure>
<p>然后就是对loss取平均，然后进行训练。</p>
<p><code>loss_gen.backward()</code> 或 <code>loss_gen_scaled.backward()</code>：根据是否开启了混合精度训练，使用 PyTorch 的自动求导功能计算生成器模型损失函数关于参数的梯度。</p>
<p><code>optimizer_gen.step()</code>：根据计算得到的梯度更新生成器模型的参数，这是优化器的一次迭代步骤。</p>
<p>接下来用类似的方法训练Discriminator。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">with</span> torch.no_grad():  <br>    output = generator(torch.cat((agnostic, pose, warped_cloth_paired), dim=<span class="hljs-number">1</span>), parse)  <br>    output = output.detach()  <br>    output.requires_grad_()  <br>  <br>fake_concat = torch.cat((parse, output), dim=<span class="hljs-number">1</span>)  <br>real_concat = torch.cat((parse, im), dim=<span class="hljs-number">1</span>)  <br>pred = discriminator(torch.cat((fake_concat, real_concat), dim=<span class="hljs-number">0</span>))<br></code></pre></td></tr></table></figure>
<p>这里不是很懂为什么在detach之后马上又调用<code>requires_grad_()</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">D_losses = &#123;&#125;  <br>D_losses[<span class="hljs-string">&#x27;D_Fake&#x27;</span>] = criterionGAN(pred_fake, <span class="hljs-literal">False</span>, for_discriminator=<span class="hljs-literal">True</span>)  <br>D_losses[<span class="hljs-string">&#x27;D_Real&#x27;</span>] = criterionGAN(pred_real, <span class="hljs-literal">True</span>, for_discriminator=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>
<p>对于Discriminator，它的loss就是对于假的图片，产生的prediction与全为假的tensor有多少差距，对于真的图片，产生的prediction与全为真的tensor有多少差距。</p>
<p>然后下面又是一段到一定时间把数据记录到TensorBoard，然后可视化当前产生的图片的代码，这里就不再赘述。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> (step + <span class="hljs-number">1</span>) % opt.tensorboard_count == <span class="hljs-number">0</span>:<br>	<span class="hljs-comment"># omitted</span><br></code></pre></td></tr></table></figure>
<p>然后到达一定时间之后也计算 lpips 指标。 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> (step + <span class="hljs-number">1</span>) % opt.lpips_count == <span class="hljs-number">0</span>:  <br>    generator.<span class="hljs-built_in">eval</span>()<br>    <span class="hljs-comment"># omitted</span><br><br>	output_paired = generator(torch.cat((agnostic, pose, warped_cloth_paired), dim=<span class="hljs-number">1</span>), parse)  <br>	avg_distance += model.forward(T2(im), T2(output_paired))<br><br>avg_distance = avg_distance / <span class="hljs-number">500</span>  <br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;LPIPS<span class="hljs-subst">&#123;avg_distance&#125;</span>&quot;</span>)  <br>board.add_scalar(<span class="hljs-string">&#x27;test/LPIPS&#x27;</span>, avg_distance, step + <span class="hljs-number">1</span>)  <br>  <br>generator.train()<br></code></pre></td></tr></table></figure></p>
<p>LPIPS（Learned Perceptual Image Patch Similarity）是一种衡量图像之间感知相似度的指标，它使用了深度学习模型来学习图像的感知特征，并根据这些特征来度量图像之间的相似度。这里的model是一个VGG，用来计算perceputal loss。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> (step + <span class="hljs-number">1</span>) % opt.display_count == <span class="hljs-number">0</span>:<br>    t = time.time() - iter_start_time<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;step: %8d, time: %.3f, G_loss: %.4f, G_adv_loss: %.4f, D_loss: %.4f, D_fake_loss: %.4f, D_real_loss: %.4f&quot;</span><br>          % (step + <span class="hljs-number">1</span>, t, loss_gen.item(), G_losses[<span class="hljs-string">&#x27;GAN&#x27;</span>].mean().item(), loss_dis.item(),<br>             D_losses[<span class="hljs-string">&#x27;D_Fake&#x27;</span>].mean().item(), D_losses[<span class="hljs-string">&#x27;D_Real&#x27;</span>].mean().item()), flush=<span class="hljs-literal">True</span>)<br><br><span class="hljs-keyword">if</span> (step + <span class="hljs-number">1</span>) % opt.save_count == <span class="hljs-number">0</span>:<br>    save_checkpoint(generator.module, os.path.join(opt.checkpoint_dir, opt.name, <span class="hljs-string">&#x27;gen_step_%06d.pth&#x27;</span> % (step + <span class="hljs-number">1</span>)), opt)<br>    save_checkpoint(discriminator.module, os.path.join(opt.checkpoint_dir, opt.name, <span class="hljs-string">&#x27;dis_step_%06d.pth&#x27;</span> % (step + <span class="hljs-number">1</span>)),<br>                    opt)<br><br><span class="hljs-keyword">if</span> (step + <span class="hljs-number">1</span>) % <span class="hljs-number">1000</span> == <span class="hljs-number">0</span>:<br>    scheduler_gen.step()<br>    scheduler_dis.step()<br></code></pre></td></tr></table></figure>
<p>然后<code>if (step + 1) % opt.display_count == 0</code>，就在控制台打印出相应的数据。然后到一定的时候也保存一下检查点。</p>
<p>在 PyTorch 中，学习率调度器（<code>lr_scheduler</code>）并不会自动在每个训练步骤中更新学习率。它必须通过调用 <code>scheduler.step()</code> 手动进行更新。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():<br>    opt = get_opt()<br>    <span class="hljs-built_in">print</span>(opt)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Start to train %s!&quot;</span> % opt.name)<br><br>    <span class="hljs-comment"># create dataset</span><br>    train_dataset = CPDataset(opt)<br><br>    <span class="hljs-comment"># create dataloader</span><br>    train_loader = CPDataLoader(opt, train_dataset)<br>    <br>    <span class="hljs-comment"># test dataloader</span><br>    opt.batch_size = <span class="hljs-number">1</span><br>    opt.dataroot = opt.test_dataroot<br>    opt.datamode = <span class="hljs-string">&#x27;test&#x27;</span><br>    opt.data_list = opt.test_data_list<br>    test_dataset = CPDatasetTest(opt)<br>    test_dataset = Subset(test_dataset, np.arange(<span class="hljs-number">500</span>))<br>    test_loader = CPDataLoader(opt, test_dataset)<br>    <br>    <span class="hljs-comment"># test vis loader</span><br>    opt.batch_size = opt.num_test_visualize<br>    test_vis_dataset = CPDatasetTest(opt)<br>    test_vis_loader = CPDataLoader(opt, test_vis_dataset)<br>    <br>    <span class="hljs-comment"># visualization</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(opt.tensorboard_dir):<br>        os.makedirs(opt.tensorboard_dir)<br>    board = SummaryWriter(log_dir=os.path.join(opt.tensorboard_dir, opt.name))<br>    <br>    <span class="hljs-comment"># warping-seg Model</span><br>    tocg = <span class="hljs-literal">None</span><br>    <br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.GT:<br>        input1_nc = <span class="hljs-number">4</span>  <span class="hljs-comment"># cloth + cloth-mask</span><br>        input2_nc = opt.semantic_nc + <span class="hljs-number">3</span>  <span class="hljs-comment"># parse_agnostic + densepose</span><br>        tocg = ConditionGenerator(opt, input1_nc=input1_nc, input2_nc=input2_nc, output_nc=<span class="hljs-number">13</span>, ngf=<span class="hljs-number">96</span>, norm_layer=nn.BatchNorm2d)<br>        <span class="hljs-comment"># Load Checkpoint</span><br>        load_checkpoint(tocg, opt.tocg_checkpoint)<br><br>    <span class="hljs-comment"># Generator model</span><br>    generator = SPADEGenerator(opt, <span class="hljs-number">3</span>+<span class="hljs-number">3</span>+<span class="hljs-number">3</span>)<br>    generator.print_network()<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(opt.gpu_ids) &gt; <span class="hljs-number">0</span>:<br>        <span class="hljs-keyword">assert</span>(torch.cuda.is_available())<br>        generator.cuda()<br>    generator.init_weights(opt.init_type, opt.init_variance)<br>    discriminator = create_network(MultiscaleDiscriminator, opt)<br><br>    <span class="hljs-comment"># lpips</span><br>    model = models.PerceptualLoss(model=<span class="hljs-string">&#x27;net-lin&#x27;</span>,net=<span class="hljs-string">&#x27;alex&#x27;</span>,use_gpu=<span class="hljs-literal">True</span>)<br><br>    <span class="hljs-comment"># Load Checkpoint</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.gen_checkpoint == <span class="hljs-string">&#x27;&#x27;</span> <span class="hljs-keyword">and</span> os.path.exists(opt.gen_checkpoint):<br>        load_checkpoint(generator, opt.gen_checkpoint)<br>        load_checkpoint(discriminator, opt.dis_checkpoint)<br><br>    <span class="hljs-comment"># Train</span><br>    train(opt, train_loader, test_loader, test_vis_loader, board, tocg, generator, discriminator, model)<br><br>    <span class="hljs-comment"># Save Checkpoint</span><br>    save_checkpoint(generator, os.path.join(opt.checkpoint_dir, opt.name, <span class="hljs-string">&#x27;gen_model_final.pth&#x27;</span>),opt)<br>    save_checkpoint(discriminator, os.path.join(opt.checkpoint_dir, opt.name, <span class="hljs-string">&#x27;dis_model_final.pth&#x27;</span>),opt)<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Finished training %s!&quot;</span> % opt.name)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    main()<br></code></pre></td></tr></table></figure>
<p>然后主函数就和训练generator的差不多了。</p>
<h1 id="evaluate.py">evaluate.py</h1>
<p>这个文件主要用于评估图像生成模型的性能。它计算了几个关键的图像质量评估指标，包括结构相似性指数（SSIM）、均方误差（MSE）、感知相似性指标（LPIPS），以及 Inception 分数（IS）。</p>
<h2 id="结构相似性指数-ssim">结构相似性指数 (SSIM)</h2>
<p>SSIM 用于衡量两幅图像的视觉相似度。它考虑了图像的亮度、对比度和结构三个方面的相似性。SSIM 的值范围在 -1 到 1 之间，1 表示两幅图像完全相同。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> i, img_pred <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(pred_list):<br>    img = img_pred.split(<span class="hljs-string">&#x27;_&#x27;</span>)[<span class="hljs-number">0</span>] + <span class="hljs-string">&#x27;_00.jpg&#x27;</span><br>    <span class="hljs-comment"># Calculate SSIM</span><br>    gt_img = Image.<span class="hljs-built_in">open</span>(os.path.join(opt.ground_truth_dir, img))<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.resolution == <span class="hljs-number">1024</span>:<br>        <span class="hljs-keyword">if</span> opt.resolution == <span class="hljs-number">512</span>:<br>            gt_img = gt_img.resize((<span class="hljs-number">384</span>, <span class="hljs-number">512</span>), Image.BILINEAR)<br>        <span class="hljs-keyword">elif</span> opt.resolution == <span class="hljs-number">256</span>:<br>            gt_img = gt_img.resize((<span class="hljs-number">192</span>, <span class="hljs-number">256</span>), Image.BILINEAR)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">raise</span> NotImplementedError<br><br>    gt_np = np.asarray(gt_img.convert(<span class="hljs-string">&#x27;L&#x27;</span>))<br>    pred_img = Image.<span class="hljs-built_in">open</span>(os.path.join(opt.predict_dir, img_pred))<br>    <span class="hljs-keyword">assert</span> gt_img.size == pred_img.size, <span class="hljs-string">f&quot;<span class="hljs-subst">&#123;gt_img.size&#125;</span> vs <span class="hljs-subst">&#123;pred_img.size&#125;</span>&quot;</span><br>    pred_np = np.asarray(pred_img.convert(<span class="hljs-string">&#x27;L&#x27;</span>))<br>    avg_ssim += ssim(gt_np, pred_np, data_range=<span class="hljs-number">255</span>, gaussian_weights=<span class="hljs-literal">True</span>, use_sample_covariance=<span class="hljs-literal">False</span>)<br></code></pre></td></tr></table></figure>
<p>这里简单来说就就是加载了ground truth和生成的图片，然后计算两幅图之间的SSIM。</p>
<p>SSIM的计算方法：</p>
<p><strong>亮度比较（Luminance Comparison）</strong>： <span class="math display">\[
L(x, y) = \frac{2 \mu_x \mu_y + C_1}{\mu_x^2 + \mu_y^2 + C_1}
\]</span> <strong>对比度比较（Contrast Comparison）</strong>： <span class="math display">\[
C(x, y) = \frac{2 \sigma_x \sigma_y + C_2}{\sigma_x^2 + \sigma_y^2 + C_2}
\]</span> <strong>结构比较（Structure Comparison）</strong> <span class="math display">\[
S(x, y) = \frac{\sigma_{xy} + C_3}{\sigma_x \sigma_y + C_3}
\]</span> <strong>综合计算 SSIM</strong> <span class="math display">\[
SSIM(x, y) = [L(x, y)]^\alpha \cdot [C(x, y)]^\beta \cdot [S(x, y)]^\gamma
\]</span> 通常取<span class="math inline">\(\alpha = \beta = \gamma = 1\)</span></p>
<p>公式变为： <span class="math display">\[
SSIM(x, y) = \frac{(2 \mu_x \mu_y + C_1)(2 \sigma_{xy} + C_2)}{(\mu_x^2 + \mu_y^2 + C_1)(\sigma_x^2 + \sigma_y^2 + C_2)}
\]</span></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Calculate LPIPS  </span><br>gt_img_LPIPS = T2(gt_img).unsqueeze(<span class="hljs-number">0</span>).cuda()  <br>pred_img_LPIPS = T2(pred_img).unsqueeze(<span class="hljs-number">0</span>).cuda()  <br>lpips_list.append((img_pred, model.forward(gt_img_LPIPS, pred_img_LPIPS).item()))  <br>avg_distance += lpips_list[-<span class="hljs-number">1</span>][<span class="hljs-number">1</span>]  <br></code></pre></td></tr></table></figure>
<p><code>.item()</code>：将计算得到的距离从张量（Tensor）转换为 Python 标量（scalar）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Calculate Inception model prediction  </span><br>pred_img_IS = T3(pred_img).unsqueeze(<span class="hljs-number">0</span>).cuda()  <br>preds[i] = F.softmax(inception_model(pred_img_IS)).data.cpu().numpy()  <br>  <br>gt_img_MSE = T1(gt_img).unsqueeze(<span class="hljs-number">0</span>).cuda()  <br>pred_img_MSE = T1(pred_img).unsqueeze(<span class="hljs-number">0</span>).cuda()  <br>avg_mse += F.mse_loss(gt_img_MSE, pred_img_MSE)  <br>  <br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;step: <span class="hljs-subst">&#123;i + <span class="hljs-number">1</span>&#125;</span> evaluation... lpips:<span class="hljs-subst">&#123;lpips_list[-<span class="hljs-number">1</span>][<span class="hljs-number">1</span>]&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure>
<p>这段代码计算perceptual loss。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">avg_ssim /= <span class="hljs-built_in">len</span>(gt_list)<br>avg_mse = avg_mse / <span class="hljs-built_in">len</span>(gt_list)<br>avg_distance = avg_distance / <span class="hljs-built_in">len</span>(gt_list)<br><br>lpips_list.sort(key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>], reverse=<span class="hljs-literal">True</span>)  <br><span class="hljs-keyword">for</span> name, score <span class="hljs-keyword">in</span> lpips_list:  <br>    f = <span class="hljs-built_in">open</span>(os.path.join(opt.predict_dir, <span class="hljs-string">&#x27;lpips.txt&#x27;</span>), <span class="hljs-string">&#x27;a&#x27;</span>)  <br>    f.write(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;name&#125;</span> <span class="hljs-subst">&#123;score&#125;</span>\n&quot;</span>)  <br>    f.close()<br></code></pre></td></tr></table></figure>
<p>这里对之前算的结果取一个平均值。然后是排序并记录inception score。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">split_scores = [] <span class="hljs-comment"># Now compute the mean kl-divergence</span><br><br><span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(splits):  <br>    part = preds[k * (<span class="hljs-built_in">len</span>(gt_list) // splits): (k + <span class="hljs-number">1</span>) * (<span class="hljs-built_in">len</span>(gt_list) // splits), :]  <br>    py = np.mean(part, axis=<span class="hljs-number">0</span>)  <br>    scores = []  <br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(part.shape[<span class="hljs-number">0</span>]):  <br>        pyx = part[i, :]  <br>        scores.append(entropy(pyx, py))  <br>    split_scores.append(np.exp(np.mean(scores)))<br></code></pre></td></tr></table></figure>
<p>这里将 <code>preds</code> 划分为 <code>splits</code> 个部分。<code>py = np.mean(part, axis=0)</code>计算每个部分的边缘概率分布 <code>py</code>（即p(y))。</p>
<p>假设有 <span class="math inline">\(N\)</span> 张生成图像，每张图像通过 Inception 模型得到一个概率分布<span class="math inline">\(p(y|x_i)\)</span>，其中<span class="math inline">\(x_{i}\)</span>表示第 <span class="math inline">\(i\)</span> 张生成图像。那么<span class="math inline">\(p(y) = \frac{1}{N} \sum_{i=1}^{N} p(y|x_i)\)</span>。</p>
<p>然后进行以下步骤：</p>
<ol type="1">
<li><strong>计算每个图像的 KL 散度</strong>： 对每个图像，计算其预测概率 <span class="math inline">\(p(y|x)\)</span> 与边缘概率 <span class="math inline">\(p(y)\)</span>之间的 KL 散度。</li>
<li><strong>计算子集得分</strong>： 对每个子集的所有 KL 散度取平均，并取指数，得到该子集的 Inception Score。</li>
<li><strong>计算最终得分</strong>： 最后对所有子集的 Inception Score 取均值和标准差，作为最终的 Inception Score。</li>
</ol>
<p>这个函数的最后就是把评估结果写到文件中：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">f = <span class="hljs-built_in">open</span>(os.path.join(opt.predict_dir, <span class="hljs-string">&#x27;eval.txt&#x27;</span>), <span class="hljs-string">&#x27;a&#x27;</span>)  <br>f.write(<span class="hljs-string">f&quot;SSIM : <span class="hljs-subst">&#123;avg_ssim&#125;</span> / MSE : <span class="hljs-subst">&#123;avg_mse&#125;</span> / LPIPS : <span class="hljs-subst">&#123;avg_distance&#125;</span>\n&quot;</span>)  <br>f.write(<span class="hljs-string">f&quot;IS_mean : <span class="hljs-subst">&#123;IS_mean&#125;</span> / IS_std : <span class="hljs-subst">&#123;IS_std&#125;</span>\n&quot;</span>)  <br>  <br>f.close()  <br><span class="hljs-keyword">return</span> avg_ssim, avg_mse, avg_distance, IS_mean, IS_std<br></code></pre></td></tr></table></figure>
<p>下面主函数直接调用就好了：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():<br>    opt = get_opt()<br><br>    <span class="hljs-comment"># Output과 Ground Truth Data</span><br>    pred_list = os.listdir(opt.predict_dir)<br>    gt_list = os.listdir(opt.ground_truth_dir)<br>    pred_list.sort()<br>    gt_list.sort()<br><br>    avg_ssim, avg_mse, avg_distance, IS_mean, IS_std = Evaluation(opt, pred_list, gt_list)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;SSIM : %f / MSE : %f / LPIPS : %f&quot;</span> % (avg_ssim, avg_mse, avg_distance))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;IS_mean : %f / IS_std : %f&quot;</span> % (IS_mean, IS_std))<br><br></code></pre></td></tr></table></figure>
<h1 id="get_norm_const.py">get_norm_const.py</h1>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_opt</span>():<br>    parser = argparse.ArgumentParser()<br>    <span class="hljs-comment"># omitted</span><br></code></pre></td></tr></table></figure>
<p>首先还是创建一个parser读取用户的配置。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">D_logit</span>(<span class="hljs-params">pred</span>):<br>    score = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> pred:<br>        score += i[-<span class="hljs-number">1</span>].mean((<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>)) / <span class="hljs-number">2</span><br>    <span class="hljs-keyword">return</span> score<br></code></pre></td></tr></table></figure>
<p><code>i[-1]</code>表示取出最后一个的特征图，在批次、高度和宽度维度上计算均值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_const</span>(<span class="hljs-params">opt, train_loader, tocg, D, length</span>):<br>    <span class="hljs-comment"># Model</span><br>    D.cuda()<br>    D.<span class="hljs-built_in">eval</span>()<br>    tocg.cuda()<br>    tocg.<span class="hljs-built_in">eval</span>()<br><br>    logit_list = []<br>    i = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> step <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(length // opt.batch_size):<br>        iter_start_time = time.time()<br>        inputs = train_loader.next_batch()<br><br>        <span class="hljs-comment"># input1</span><br>        c_paired = inputs[<span class="hljs-string">&#x27;cloth&#x27;</span>][<span class="hljs-string">&#x27;paired&#x27;</span>].cuda()<br>        cm_paired = inputs[<span class="hljs-string">&#x27;cloth_mask&#x27;</span>][<span class="hljs-string">&#x27;paired&#x27;</span>].cuda()<br>        cm_paired = torch.FloatTensor((cm_paired.detach().cpu().numpy() &gt; <span class="hljs-number">0.5</span>).astype(np.<span class="hljs-built_in">float</span>)).cuda()<br>        <span class="hljs-comment"># input2</span><br>        parse_agnostic = inputs[<span class="hljs-string">&#x27;parse_agnostic&#x27;</span>].cuda()<br>        densepose = inputs[<span class="hljs-string">&#x27;densepose&#x27;</span>].cuda()<br>        openpose = inputs[<span class="hljs-string">&#x27;pose&#x27;</span>].cuda()<br>        <span class="hljs-comment"># GT</span><br>        label_onehot = inputs[<span class="hljs-string">&#x27;parse_onehot&#x27;</span>].cuda()  <span class="hljs-comment"># CE</span><br>        label = inputs[<span class="hljs-string">&#x27;parse&#x27;</span>].cuda()  <span class="hljs-comment"># GAN loss</span><br>        parse_cloth_mask = inputs[<span class="hljs-string">&#x27;pcm&#x27;</span>].cuda()  <span class="hljs-comment"># L1</span><br>        im_c = inputs[<span class="hljs-string">&#x27;parse_cloth&#x27;</span>].cuda()  <span class="hljs-comment"># VGG</span><br>        <span class="hljs-comment"># visualization</span><br>        im = inputs[<span class="hljs-string">&#x27;image&#x27;</span>]<br>        <span class="hljs-keyword">with</span> torch.no_grad():<br>            <span class="hljs-comment"># inputs</span><br>            input1 = torch.cat([c_paired, cm_paired], <span class="hljs-number">1</span>)<br>            input2 = torch.cat([parse_agnostic, densepose], <span class="hljs-number">1</span>)<br><br>            flow_list, fake_segmap, warped_cloth_paired, warped_clothmask_paired = tocg(input1, input2)<br>            <span class="hljs-keyword">if</span> opt.clothmask_composition != <span class="hljs-string">&#x27;no_composition&#x27;</span>:<br>                <span class="hljs-keyword">if</span> opt.clothmask_composition == <span class="hljs-string">&#x27;detach&#x27;</span>:<br>                    warped_cm_onehot = torch.FloatTensor((warped_clothmask_paired.detach().cpu().numpy() &gt; <span class="hljs-number">0.5</span>).astype(np.<span class="hljs-built_in">float</span>)).cuda()<br>                    cloth_mask = torch.ones_like(fake_segmap.detach())<br>                    cloth_mask[:, <span class="hljs-number">3</span>:<span class="hljs-number">4</span>, :, :] = warped_cm_onehot<br>                    fake_segmap = fake_segmap * cloth_mask<br>                    <br>                <span class="hljs-keyword">if</span> opt.clothmask_composition == <span class="hljs-string">&#x27;warp_grad&#x27;</span>:<br>                    cloth_mask = torch.ones_like(fake_segmap.detach())<br>                    cloth_mask[:, <span class="hljs-number">3</span>:<span class="hljs-number">4</span>, :, :] = warped_clothmask_paired<br>                    fake_segmap = fake_segmap * cloth_mask<br>            <br>            <br>            fake_segmap_softmax = F.softmax(fake_segmap, dim=<span class="hljs-number">1</span>)<br>            <br>            real_segmap_pred = D(torch.cat((input1.detach(), input2.detach(), label),dim=<span class="hljs-number">1</span>))<br>            fake_segmap_pred = D(torch.cat((input1.detach(), input2.detach(), fake_segmap_softmax),dim=<span class="hljs-number">1</span>))<br>            <br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;real:&quot;</span>, D_logit(real_segmap_pred), <span class="hljs-string">&quot;fake:&quot;</span>, D_logit(fake_segmap_pred))<br>            <span class="hljs-comment"># print(fake_segmap_pred)</span><br>            logit_real = D_logit(real_segmap_pred)<br>            logit_fake = D_logit(fake_segmap_pred)<br>            <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> logit_real:<br>                l = l / (<span class="hljs-number">1</span>-l)<br>                logit_list.append(l.item())<br>            <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> logit_fake:<br>                l = l / (<span class="hljs-number">1</span>-l)<br>                logit_list.append(l.item())<br>                <br>        <span class="hljs-comment"># i += logit_real.shape[0]+logit_fake.shape[0]</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;i:&quot;</span>, i)<br>    logit_list.sort()<br>    <br>    <span class="hljs-keyword">return</span> logit_list[-<span class="hljs-number">1</span>]<br></code></pre></td></tr></table></figure>
<p>每次取出一个批次，然后进行前向传播，再经过 Discriminator 得到其预测。然后D是一个MultiscaleDiscriminator，我们计算logit的时候只取最后的那一个scale。这里变换将 <code>l</code> 从<span class="math inline">\([0, 1]\)</span>映射到<span class="math inline">\([0, +\infty]\)</span>。最后找出最大的logit值。</p>
<h1 id="test_condition.py">test_condition.py</h1>
<p>我们先看主函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():<br>    opt = get_opt()<br>    <span class="hljs-built_in">print</span>(opt)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Start to test %s!&quot;</span>)<br>    os.environ[<span class="hljs-string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>] = opt.gpu_ids<br>    <br>    <span class="hljs-comment"># create test dataset &amp; loader</span><br>    test_dataset = CPDatasetTest(opt)<br>    test_loader = CPDataLoader(opt, test_dataset)<br>    <br>    <span class="hljs-comment"># visualization</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(opt.tensorboard_dir):<br>        os.makedirs(opt.tensorboard_dir)<br>    board = SummaryWriter(log_dir=os.path.join(opt.tensorboard_dir, opt.tocg_checkpoint.split(<span class="hljs-string">&#x27;/&#x27;</span>)[-<span class="hljs-number">2</span>], opt.tocg_checkpoint.split(<span class="hljs-string">&#x27;/&#x27;</span>)[-<span class="hljs-number">1</span>], opt.datamode, opt.datasetting))<br><br>    <span class="hljs-comment"># Model</span><br>    input1_nc = <span class="hljs-number">4</span>  <span class="hljs-comment"># cloth + cloth-mask</span><br>    input2_nc = opt.semantic_nc + <span class="hljs-number">3</span>  <span class="hljs-comment"># parse_agnostic + densepose</span><br>    tocg = ConditionGenerator(opt, input1_nc=input1_nc, input2_nc=input2_nc, output_nc=opt.output_nc, ngf=<span class="hljs-number">96</span>, norm_layer=nn.BatchNorm2d)<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.D_checkpoint == <span class="hljs-string">&#x27;&#x27;</span> <span class="hljs-keyword">and</span> os.path.exists(opt.D_checkpoint):<br>        <span class="hljs-keyword">if</span> opt.norm_const <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            <span class="hljs-keyword">raise</span> NotImplementedError<br>        D = define_D(input_nc=input1_nc + input2_nc + opt.output_nc, Ddownx2 = opt.Ddownx2, Ddropout = opt.Ddropout, n_layers_D=<span class="hljs-number">3</span>, spectral = opt.spectral, num_D = opt.num_D)<br>    <span class="hljs-keyword">else</span>:<br>        D = <span class="hljs-literal">None</span><br>    <span class="hljs-comment"># Load Checkpoint</span><br>    load_checkpoint(tocg, opt.tocg_checkpoint)<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.D_checkpoint == <span class="hljs-string">&#x27;&#x27;</span> <span class="hljs-keyword">and</span> os.path.exists(opt.D_checkpoint):<br>        load_checkpoint(D, opt.D_checkpoint)<br>    <span class="hljs-comment"># Train</span><br>    test(opt, test_loader, board, tocg, D=D)<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Finished testing!&quot;</span>)<br><br></code></pre></td></tr></table></figure>
<p>这里的<code>define_D</code>是之前在网络中定义的一个辅助函数，用来生成<code>MultiscaleDiscriminator</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">define_D</span>(<span class="hljs-params">input_nc, ndf=<span class="hljs-number">64</span>, n_layers_D=<span class="hljs-number">3</span>, norm=<span class="hljs-string">&#x27;instance&#x27;</span>, use_sigmoid=<span class="hljs-literal">False</span>, num_D=<span class="hljs-number">2</span>, getIntermFeat=<span class="hljs-literal">False</span>, gpu_ids=[], Ddownx2=<span class="hljs-literal">False</span>, Ddropout=<span class="hljs-literal">False</span>, spectral=<span class="hljs-literal">False</span></span>):<br>    norm_layer = get_norm_layer(norm_type=norm)<br>    netD = MultiscaleDiscriminator(input_nc, ndf, n_layers_D, norm_layer, use_sigmoid, num_D, getIntermFeat, Ddownx2, Ddropout, spectral=spectral)<br>    <span class="hljs-built_in">print</span>(netD)<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(gpu_ids) &gt; <span class="hljs-number">0</span>:<br>        <span class="hljs-keyword">assert</span> (torch.cuda.is_available())<br>        netD.cuda()<br>    netD.apply(weights_init)<br>    <span class="hljs-keyword">return</span> netD<br></code></pre></td></tr></table></figure>
<p>如果D_checkpoint存在，也就是说 Discriminator 已经被训练了，就生成一个 Discriminator 给到 test。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">test</span>(<span class="hljs-params">opt, test_loader, board, tocg, D=<span class="hljs-literal">None</span></span>):  <br>    <span class="hljs-comment"># Model  </span><br>    tocg.cuda()  <br>    tocg.<span class="hljs-built_in">eval</span>()  <br>    <span class="hljs-keyword">if</span> D <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:  <br>        D.cuda()  <br>        D.<span class="hljs-built_in">eval</span>()  <br>  <br>    os.makedirs(os.path.join(<span class="hljs-string">&#x27;./output&#x27;</span>, opt.tocg_checkpoint.split(<span class="hljs-string">&#x27;/&#x27;</span>)[-<span class="hljs-number">2</span>], opt.tocg_checkpoint.split(<span class="hljs-string">&#x27;/&#x27;</span>)[-<span class="hljs-number">1</span>],  <br>                             opt.datamode, opt.datasetting, <span class="hljs-string">&#x27;multi-task&#x27;</span>), exist_ok=<span class="hljs-literal">True</span>)  <br>    num = <span class="hljs-number">0</span>  <br>    iter_start_time = time.time()  <br>    <span class="hljs-keyword">if</span> D <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:  <br>        D_score = []  <br>    <span class="hljs-keyword">for</span> inputs <span class="hljs-keyword">in</span> test_loader.data_loader:  <br>  <br>        <span class="hljs-comment"># input1  </span><br>        c_paired = inputs[<span class="hljs-string">&#x27;cloth&#x27;</span>][opt.datasetting].cuda()  <br>        cm_paired = inputs[<span class="hljs-string">&#x27;cloth_mask&#x27;</span>][opt.datasetting].cuda()  <br>        cm_paired = torch.FloatTensor((cm_paired.detach().cpu().numpy() &gt; <span class="hljs-number">0.5</span>).astype(np.<span class="hljs-built_in">float</span>)).cuda()  <br>        <span class="hljs-comment"># input2  </span><br>        parse_agnostic = inputs[<span class="hljs-string">&#x27;parse_agnostic&#x27;</span>].cuda()  <br>        densepose = inputs[<span class="hljs-string">&#x27;densepose&#x27;</span>].cuda()  <br>        openpose = inputs[<span class="hljs-string">&#x27;pose&#x27;</span>].cuda()  <br>        <span class="hljs-comment"># GT  </span><br>        label_onehot = inputs[<span class="hljs-string">&#x27;parse_onehot&#x27;</span>].cuda()  <span class="hljs-comment"># CE  </span><br>        label = inputs[<span class="hljs-string">&#x27;parse&#x27;</span>].cuda()  <span class="hljs-comment"># GAN loss  </span><br>        parse_cloth_mask = inputs[<span class="hljs-string">&#x27;pcm&#x27;</span>].cuda()  <span class="hljs-comment"># L1  </span><br>        im_c = inputs[<span class="hljs-string">&#x27;parse_cloth&#x27;</span>].cuda()  <span class="hljs-comment"># VGG  </span><br>        <span class="hljs-comment"># visualization        im = inputs[&#x27;image&#x27;]  </span><br>  <br>        <span class="hljs-keyword">with</span> torch.no_grad():  <br>            <span class="hljs-comment"># inputs  </span><br>            input1 = torch.cat([c_paired, cm_paired], <span class="hljs-number">1</span>)  <br>            input2 = torch.cat([parse_agnostic, densepose], <span class="hljs-number">1</span>)  <br>  <br>            <span class="hljs-comment"># forward  </span><br>            flow_list, fake_segmap, warped_cloth_paired, warped_clothmask_paired = tocg(input1, input2)  <br>  <br>            <span class="hljs-comment"># warped cloth mask one hot   </span><br>warped_cm_onehot = torch.FloatTensor(  <br>                (warped_clothmask_paired.detach().cpu().numpy() &gt; <span class="hljs-number">0.5</span>).astype(np.<span class="hljs-built_in">float</span>)).cuda()  <br>  <br>            <span class="hljs-keyword">if</span> opt.clothmask_composition != <span class="hljs-string">&#x27;no_composition&#x27;</span>:  <br>                <span class="hljs-keyword">if</span> opt.clothmask_composition == <span class="hljs-string">&#x27;detach&#x27;</span>:  <br>                    cloth_mask = torch.ones_like(fake_segmap)  <br>                    cloth_mask[:, <span class="hljs-number">3</span>:<span class="hljs-number">4</span>, :, :] = warped_cm_onehot  <br>                    fake_segmap = fake_segmap * cloth_mask  <br>  <br>                <span class="hljs-keyword">if</span> opt.clothmask_composition == <span class="hljs-string">&#x27;warp_grad&#x27;</span>:  <br>                    cloth_mask = torch.ones_like(fake_segmap)  <br>                    cloth_mask[:, <span class="hljs-number">3</span>:<span class="hljs-number">4</span>, :, :] = warped_clothmask_paired  <br>                    fake_segmap = fake_segmap * cloth_mask<br></code></pre></td></tr></table></figure>
<p>测试的时候和训练的代码大体都差不多，最开始还是加载数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> D <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:  <br>    fake_segmap_softmax = F.softmax(fake_segmap, dim=<span class="hljs-number">1</span>)  <br>    pred_segmap = D(torch.cat((input1.detach(), input2.detach(), fake_segmap_softmax), dim=<span class="hljs-number">1</span>))  <br>    score = D_logit(pred_segmap)  <br>    <span class="hljs-comment"># score = torch.exp(score) / opt.norm_const  </span><br>    score = (score / (<span class="hljs-number">1</span> - score)) / opt.norm_const  <br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;prob0&quot;</span>, score)  <br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(cm_paired.shape[<span class="hljs-number">0</span>]):  <br>        name = inputs[<span class="hljs-string">&#x27;c_name&#x27;</span>][<span class="hljs-string">&#x27;paired&#x27;</span>][i].replace(<span class="hljs-string">&#x27;.jpg&#x27;</span>, <span class="hljs-string">&#x27;.png&#x27;</span>)  <br>        D_score.append((name, score[i].item()))<br></code></pre></td></tr></table></figure>
<p>如果有Discriminator，就用<code>D_logit(pred_segmap)</code>计算出一个对数几率。然后对对数几率值进行变换，变换公式为<span class="math inline">\(\frac{score}{1 - score}\)</span>​。然后将变换后的值除以一个常数 <code>opt.norm_const</code> 进行归一化。 在parser的代码里对这段有注释： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">parser.add_argument(<span class="hljs-string">&#x27;--norm_const&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">float</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;Normalizing constant for rejection sampling&#x27;</span>)<br></code></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(c_paired.shape[<span class="hljs-number">0</span>]):  <br>    grid = make_grid([(c_paired[i].cpu() / <span class="hljs-number">2</span> + <span class="hljs-number">0.5</span>), (cm_paired[i].cpu()).expand(<span class="hljs-number">3</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>),  <br>                      visualize_segmap(parse_agnostic.cpu(), batch=i), ((densepose.cpu()[i] + <span class="hljs-number">1</span>) / <span class="hljs-number">2</span>),  <br>                      (im_c[i].cpu() / <span class="hljs-number">2</span> + <span class="hljs-number">0.5</span>), parse_cloth_mask[i].cpu().expand(<span class="hljs-number">3</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>),  <br>                      (warped_cloth_paired[i].cpu().detach() / <span class="hljs-number">2</span> + <span class="hljs-number">0.5</span>),  <br>                      (warped_cm_onehot[i].cpu().detach()).expand(<span class="hljs-number">3</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>),  <br>                      visualize_segmap(label.cpu(), batch=i), visualize_segmap(fake_segmap.cpu(), batch=i),  <br>                      (im[i] / <span class="hljs-number">2</span> + <span class="hljs-number">0.5</span>), (misalign[i].cpu().detach()).expand(<span class="hljs-number">3</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>)],  <br>                     nrow=<span class="hljs-number">4</span>)  <br>    save_image(grid, os.path.join(<span class="hljs-string">&#x27;./output&#x27;</span>, opt.tocg_checkpoint.split(<span class="hljs-string">&#x27;/&#x27;</span>)[-<span class="hljs-number">2</span>], opt.tocg_checkpoint.split(<span class="hljs-string">&#x27;/&#x27;</span>)[-<span class="hljs-number">1</span>],  <br>                                  opt.datamode, opt.datasetting, <span class="hljs-string">&#x27;multi-task&#x27;</span>,  <br>                                  (inputs[<span class="hljs-string">&#x27;c_name&#x27;</span>][<span class="hljs-string">&#x27;paired&#x27;</span>][i].split(<span class="hljs-string">&#x27;.&#x27;</span>)[<span class="hljs-number">0</span>] + <span class="hljs-string">&#x27;_&#x27;</span> +  <br>                                   inputs[<span class="hljs-string">&#x27;c_name&#x27;</span>][<span class="hljs-string">&#x27;unpaired&#x27;</span>][i].split(<span class="hljs-string">&#x27;.&#x27;</span>)[<span class="hljs-number">0</span>] + <span class="hljs-string">&#x27;.png&#x27;</span>)))  <br>num += c_paired.shape[<span class="hljs-number">0</span>]  <br><span class="hljs-built_in">print</span>(num)<br></code></pre></td></tr></table></figure>
<p>使用 <code>make_grid</code> 函数将多个图像拼接成一个网格。网格中的每个图像是对当前样本不同处理结果的可视化。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> D <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:  <br>    D_score.sort(key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>], reverse=<span class="hljs-literal">True</span>)  <br>    <span class="hljs-comment"># Save D_score  </span><br>    <span class="hljs-keyword">for</span> name, score <span class="hljs-keyword">in</span> D_score:  <br>        f = <span class="hljs-built_in">open</span>(os.path.join(<span class="hljs-string">&#x27;./output&#x27;</span>, opt.tocg_checkpoint.split(<span class="hljs-string">&#x27;/&#x27;</span>)[-<span class="hljs-number">2</span>], opt.tocg_checkpoint.split(<span class="hljs-string">&#x27;/&#x27;</span>)[-<span class="hljs-number">1</span>],  <br>                              opt.datamode, opt.datasetting, <span class="hljs-string">&#x27;multi-task&#x27;</span>, <span class="hljs-string">&#x27;rejection_prob.txt&#x27;</span>), <span class="hljs-string">&#x27;a&#x27;</span>)  <br>        f.write(name + <span class="hljs-string">&#x27; &#x27;</span> + <span class="hljs-built_in">str</span>(score) + <span class="hljs-string">&#x27;\n&#x27;</span>)  <br>        f.close()  <br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Test time <span class="hljs-subst">&#123;time.time() - iter_start_time&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure>
<p>对 <code>D_score</code> 按照评分进行降序排序，并写入到文件中。</p>
<p>然后主函数就是一些简单的初始化。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():  <br>    opt = get_opt()  <br>    <span class="hljs-built_in">print</span>(opt)  <br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Start to test %s!&quot;</span>)  <br>    os.environ[<span class="hljs-string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>] = opt.gpu_ids  <br>  <br>    <span class="hljs-comment"># create test dataset &amp; loader  </span><br>    test_dataset = CPDatasetTest(opt)  <br>    test_loader = CPDataLoader(opt, test_dataset)  <br>  <br>    <span class="hljs-comment"># visualization  </span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(opt.tensorboard_dir):  <br>        os.makedirs(opt.tensorboard_dir)  <br>    board = SummaryWriter(log_dir=os.path.join(opt.tensorboard_dir, opt.tocg_checkpoint.split(<span class="hljs-string">&#x27;/&#x27;</span>)[-<span class="hljs-number">2</span>],  opt.tocg_checkpoint.split(<span class="hljs-string">&#x27;/&#x27;</span>)[-<span class="hljs-number">1</span>], opt.datamode, opt.datasetting))  <br>  <br>    <span class="hljs-comment"># Model  </span><br>    input1_nc = <span class="hljs-number">4</span>  <span class="hljs-comment"># cloth + cloth-mask  </span><br>    input2_nc = opt.semantic_nc + <span class="hljs-number">3</span>  <span class="hljs-comment"># parse_agnostic + densepose  </span><br>    tocg = ConditionGenerator(opt, input1_nc=input1_nc, input2_nc=input2_nc, output_nc=opt.output_nc, ngf=<span class="hljs-number">96</span>,  <br>                              norm_layer=nn.BatchNorm2d)  <br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.D_checkpoint == <span class="hljs-string">&#x27;&#x27;</span> <span class="hljs-keyword">and</span> os.path.exists(opt.D_checkpoint):  <br>        <span class="hljs-keyword">if</span> opt.norm_const <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:  <br>            <span class="hljs-keyword">raise</span> NotImplementedError  <br>        D = define_D(input_nc=input1_nc + input2_nc + opt.output_nc, Ddownx2=opt.Ddownx2, Ddropout=opt.Ddropout,  <br>                     n_layers_D=<span class="hljs-number">3</span>, spectral=opt.spectral, num_D=opt.num_D)  <br>    <span class="hljs-keyword">else</span>:  <br>        D = <span class="hljs-literal">None</span>  <br>    <span class="hljs-comment"># Load Checkpoint  </span><br>    load_checkpoint(tocg, opt.tocg_checkpoint)  <br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.D_checkpoint == <span class="hljs-string">&#x27;&#x27;</span> <span class="hljs-keyword">and</span> os.path.exists(opt.D_checkpoint):  <br>        load_checkpoint(D, opt.D_checkpoint)  <br>    <span class="hljs-comment"># Train  </span><br>    test(opt, test_loader, board, tocg, D=D)  <br>  <br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Finished testing!&quot;</span>)  <br>  <br>  <br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:  <br>    main()<br></code></pre></td></tr></table></figure>
<p>然后主函数就是简单的初始化了。</p>
<h1 id="test_generator.py">test_generator.py</h1>
<p>test_generator这里和test_condition很类似，就只讲主要的部分了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">with</span> torch.no_grad():<br>    <span class="hljs-keyword">for</span> inputs <span class="hljs-keyword">in</span> test_loader.data_loader:<br>        <span class="hljs-keyword">if</span> opt.cuda :<br>            pose_map = inputs[<span class="hljs-string">&#x27;pose&#x27;</span>].cuda()<br>            pre_clothes_mask = inputs[<span class="hljs-string">&#x27;cloth_mask&#x27;</span>][opt.datasetting].cuda()<br>            label = inputs[<span class="hljs-string">&#x27;parse&#x27;</span>]<br>            parse_agnostic = inputs[<span class="hljs-string">&#x27;parse_agnostic&#x27;</span>]<br>            agnostic = inputs[<span class="hljs-string">&#x27;agnostic&#x27;</span>].cuda()<br>            clothes = inputs[<span class="hljs-string">&#x27;cloth&#x27;</span>][opt.datasetting].cuda() <span class="hljs-comment"># target cloth</span><br>            densepose = inputs[<span class="hljs-string">&#x27;densepose&#x27;</span>].cuda()<br>            im = inputs[<span class="hljs-string">&#x27;image&#x27;</span>]<br>            input_label, input_parse_agnostic = label.cuda(), parse_agnostic.cuda()<br>            pre_clothes_mask = torch.FloatTensor((pre_clothes_mask.detach().cpu().numpy() &gt; <span class="hljs-number">0.5</span>).astype(np.<span class="hljs-built_in">float</span>)).cuda()<br>        <span class="hljs-keyword">else</span> :<br>            pose_map = inputs[<span class="hljs-string">&#x27;pose&#x27;</span>]<br>            pre_clothes_mask = inputs[<span class="hljs-string">&#x27;cloth_mask&#x27;</span>][opt.datasetting]<br>            label = inputs[<span class="hljs-string">&#x27;parse&#x27;</span>]<br>            parse_agnostic = inputs[<span class="hljs-string">&#x27;parse_agnostic&#x27;</span>]<br>            agnostic = inputs[<span class="hljs-string">&#x27;agnostic&#x27;</span>]<br>            clothes = inputs[<span class="hljs-string">&#x27;cloth&#x27;</span>][opt.datasetting] <span class="hljs-comment"># target cloth</span><br>            densepose = inputs[<span class="hljs-string">&#x27;densepose&#x27;</span>]<br>            im = inputs[<span class="hljs-string">&#x27;image&#x27;</span>]<br>            input_label, input_parse_agnostic = label, parse_agnostic<br>            pre_clothes_mask = torch.FloatTensor((pre_clothes_mask.detach().cpu().numpy() &gt; <span class="hljs-number">0.5</span>).astype(np.<span class="hljs-built_in">float</span>))<br></code></pre></td></tr></table></figure>
<p>这里就是对是否是否使用GPU做了一个区分。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># down  </span><br>pose_map_down = F.interpolate(pose_map, size=(<span class="hljs-number">256</span>, <span class="hljs-number">192</span>), mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>)  <br>pre_clothes_mask_down = F.interpolate(pre_clothes_mask, size=(<span class="hljs-number">256</span>, <span class="hljs-number">192</span>), mode=<span class="hljs-string">&#x27;nearest&#x27;</span>)  <br>input_label_down = F.interpolate(input_label, size=(<span class="hljs-number">256</span>, <span class="hljs-number">192</span>), mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>)  <br>input_parse_agnostic_down = F.interpolate(input_parse_agnostic, size=(<span class="hljs-number">256</span>, <span class="hljs-number">192</span>), mode=<span class="hljs-string">&#x27;nearest&#x27;</span>)  <br>agnostic_down = F.interpolate(agnostic, size=(<span class="hljs-number">256</span>, <span class="hljs-number">192</span>), mode=<span class="hljs-string">&#x27;nearest&#x27;</span>)  <br>clothes_down = F.interpolate(clothes, size=(<span class="hljs-number">256</span>, <span class="hljs-number">192</span>), mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>)  <br>densepose_down = F.interpolate(densepose, size=(<span class="hljs-number">256</span>, <span class="hljs-number">192</span>), mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>)  <br>  <br>shape = pre_clothes_mask.shape  <br>  <br><span class="hljs-comment"># multi-task inputs  </span><br>input1 = torch.cat([clothes_down, pre_clothes_mask_down], <span class="hljs-number">1</span>)  <br>input2 = torch.cat([input_parse_agnostic_down, densepose_down], <span class="hljs-number">1</span>)  <br>  <br><span class="hljs-comment"># forward  </span><br>flow_list, fake_segmap, warped_cloth_paired, warped_clothmask_paired = tocg(opt, input1, input2)  <br>  <br><span class="hljs-comment"># warped cloth mask one hot  </span><br><span class="hljs-keyword">if</span> opt.cuda:  <br>    warped_cm_onehot = torch.FloatTensor((warped_clothmask_paired.detach().cpu().numpy() &gt; <span class="hljs-number">0.5</span>).astype(np.<span class="hljs-built_in">float</span>)).cuda()  <br><span class="hljs-keyword">else</span>:  <br>    warped_cm_onehot = torch.FloatTensor((warped_clothmask_paired.detach().cpu().numpy() &gt; <span class="hljs-number">0.5</span>).astype(np.<span class="hljs-built_in">float</span>))  <br>  <br><span class="hljs-keyword">if</span> opt.clothmask_composition != <span class="hljs-string">&#x27;no_composition&#x27;</span>:  <br>    <span class="hljs-keyword">if</span> opt.clothmask_composition == <span class="hljs-string">&#x27;detach&#x27;</span>:  <br>        cloth_mask = torch.ones_like(fake_segmap)  <br>        cloth_mask[:, <span class="hljs-number">3</span>:<span class="hljs-number">4</span>, :, :] = warped_cm_onehot  <br>        fake_segmap = fake_segmap * cloth_mask  <br>  <br>    <span class="hljs-keyword">if</span> opt.clothmask_composition == <span class="hljs-string">&#x27;warp_grad&#x27;</span>:  <br>        cloth_mask = torch.ones_like(fake_segmap)  <br>        cloth_mask[:, <span class="hljs-number">3</span>:<span class="hljs-number">4</span>, :, :] = warped_clothmask_paired  <br>        fake_segmap = fake_segmap * cloth_mask  <br>  <br><span class="hljs-comment"># make generator input parse map  </span><br>fake_parse_gauss = gauss(F.interpolate(fake_segmap, size=(opt.fine_height, opt.fine_width), mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>))  <br>fake_parse = fake_parse_gauss.argmax(dim=<span class="hljs-number">1</span>)[:, <span class="hljs-literal">None</span>]<br></code></pre></td></tr></table></figure>
<p>这里就是通过Try On Condition Generator生成合成图像的segmentation map，然后将segmentation map进行高斯处理，并合成为1个channel。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> opt.cuda:  <br>    old_parse = torch.FloatTensor(fake_parse.size(<span class="hljs-number">0</span>), <span class="hljs-number">13</span>, opt.fine_height, opt.fine_width).zero_().cuda()  <br><span class="hljs-keyword">else</span>:  <br>    old_parse = torch.FloatTensor(fake_parse.size(<span class="hljs-number">0</span>), <span class="hljs-number">13</span>, opt.fine_height, opt.fine_width).zero_()  <br>old_parse.scatter_(<span class="hljs-number">1</span>, fake_parse, <span class="hljs-number">1.0</span>)  <br>  <br>labels = &#123;  <br>    <span class="hljs-number">0</span>: [<span class="hljs-string">&#x27;background&#x27;</span>, [<span class="hljs-number">0</span>]],  <br>    <span class="hljs-number">1</span>: [<span class="hljs-string">&#x27;paste&#x27;</span>, [<span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">9</span>, <span class="hljs-number">10</span>, <span class="hljs-number">11</span>]],  <br>    <span class="hljs-number">2</span>: [<span class="hljs-string">&#x27;upper&#x27;</span>, [<span class="hljs-number">3</span>]],  <br>    <span class="hljs-number">3</span>: [<span class="hljs-string">&#x27;hair&#x27;</span>, [<span class="hljs-number">1</span>]],  <br>    <span class="hljs-number">4</span>: [<span class="hljs-string">&#x27;left_arm&#x27;</span>, [<span class="hljs-number">5</span>]],  <br>    <span class="hljs-number">5</span>: [<span class="hljs-string">&#x27;right_arm&#x27;</span>, [<span class="hljs-number">6</span>]],  <br>    <span class="hljs-number">6</span>: [<span class="hljs-string">&#x27;noise&#x27;</span>, [<span class="hljs-number">12</span>]]  <br>&#125;  <br><span class="hljs-keyword">if</span> opt.cuda:  <br>    parse = torch.FloatTensor(fake_parse.size(<span class="hljs-number">0</span>), <span class="hljs-number">7</span>, opt.fine_height, opt.fine_width).zero_().cuda()  <br><span class="hljs-keyword">else</span>:  <br>    parse = torch.FloatTensor(fake_parse.size(<span class="hljs-number">0</span>), <span class="hljs-number">7</span>, opt.fine_height, opt.fine_width).zero_()  <br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(labels)):  <br>    <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> labels[i][<span class="hljs-number">1</span>]:  <br>        parse[:, i] += old_parse[:, label]<br></code></pre></td></tr></table></figure>
<p>然后又将合并得到的1个channel的segmentation map分为13个channel，但是现在转化为了one-hot encoder。之后又将13个channel合并为7个channel，因为他不需要那么细的信息。</p>
<h2 id="scatter_的用法">scatter_的用法</h2>
<p><code>scatter_</code> 的参数含义如下： <code>dim</code>：指定沿哪个维度进行散射操作。 <code>index</code>：包含索引的张量。索引表示要将值写入目标张量的位置。 <code>src</code>：要写入的值或包含要写入值的张量。</p>
<p>For a 3-D tensor, <code>self</code> is updated as: <figure class="highlight inform7"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs inform7">self<span class="hljs-comment">[index<span class="hljs-comment">[i]</span><span class="hljs-comment">[j]</span><span class="hljs-comment">[k]</span>]</span><span class="hljs-comment">[j]</span><span class="hljs-comment">[k]</span> = src<span class="hljs-comment">[i]</span><span class="hljs-comment">[j]</span><span class="hljs-comment">[k]</span>  # if dim == 0<br>self<span class="hljs-comment">[i]</span><span class="hljs-comment">[index<span class="hljs-comment">[i]</span><span class="hljs-comment">[j]</span><span class="hljs-comment">[k]</span>]</span><span class="hljs-comment">[k]</span> = src<span class="hljs-comment">[i]</span><span class="hljs-comment">[j]</span><span class="hljs-comment">[k]</span>  # if dim == 1<br>self<span class="hljs-comment">[i]</span><span class="hljs-comment">[j]</span><span class="hljs-comment">[index<span class="hljs-comment">[i]</span><span class="hljs-comment">[j]</span><span class="hljs-comment">[k]</span>]</span> = src<span class="hljs-comment">[i]</span><span class="hljs-comment">[j]</span><span class="hljs-comment">[k]</span>  # if dim == 2<br></code></pre></td></tr></table></figure></p>
<blockquote>
<p><code>self</code>, <code>index</code> and <code>src</code> (if it is a Tensor) should all have the same number of dimensions. It is also required that <code>index.size(d) &lt;= src.size(d)</code> for all dimensions <code>d</code>, and that <code>index.size(d) &lt;= self.size(d)</code> for all dimensions <code>d != dim</code>. Note that <code>index</code> and <code>src</code> do not broadcast.</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">old_parse.scatter_(<span class="hljs-number">1</span>, fake_parse, <span class="hljs-number">1.0</span>)<br></code></pre></td></tr></table></figure>
<p>对于这种用法，意思就是把fake_parse的每个值，对应到old_parse的每个通道上，然后把相应的位置设为1。</p>
<p>然后后面就是一些生成图像和可视化的工作，和test_condition就差不多了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># warped cloth  </span><br>N, _, iH, iW = clothes.shape  <br>flow = F.interpolate(flow_list[-<span class="hljs-number">1</span>].permute(<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>), size=(iH, iW), mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>).permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)  <br>flow_norm = torch.cat([flow[:, :, :, <span class="hljs-number">0</span>:<span class="hljs-number">1</span>] / ((<span class="hljs-number">96</span> - <span class="hljs-number">1.0</span>) / <span class="hljs-number">2.0</span>), flow[:, :, :, <span class="hljs-number">1</span>:<span class="hljs-number">2</span>] / ((<span class="hljs-number">128</span> - <span class="hljs-number">1.0</span>) / <span class="hljs-number">2.0</span>)], <span class="hljs-number">3</span>)  <br>  <br>grid = make_grid(N, iH, iW, opt)  <br>warped_grid = grid + flow_norm  <br>warped_cloth = F.grid_sample(clothes, warped_grid, padding_mode=<span class="hljs-string">&#x27;border&#x27;</span>)  <br>warped_clothmask = F.grid_sample(pre_clothes_mask, warped_grid, padding_mode=<span class="hljs-string">&#x27;border&#x27;</span>)  <br><span class="hljs-keyword">if</span> opt.occlusion:  <br>    warped_clothmask = remove_overlap(F.softmax(fake_parse_gauss, dim=<span class="hljs-number">1</span>), warped_clothmask)  <br>    warped_cloth = warped_cloth * warped_clothmask + torch.ones_like(warped_cloth) * (<span class="hljs-number">1</span> - warped_clothmask)  <br>  <br>output = generator(torch.cat((agnostic, densepose, warped_cloth), dim=<span class="hljs-number">1</span>), parse)  <br><span class="hljs-comment"># visualize  </span><br>unpaired_names = []  <br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(shape[<span class="hljs-number">0</span>]):  <br>    grid = make_image_grid([(clothes[i].cpu() / <span class="hljs-number">2</span> + <span class="hljs-number">0.5</span>), (pre_clothes_mask[i].cpu()).expand(<span class="hljs-number">3</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>),  <br>                            visualize_segmap(parse_agnostic.cpu(), batch=i), ((densepose.cpu()[i] + <span class="hljs-number">1</span>) / <span class="hljs-number">2</span>),  <br>                            (warped_cloth[i].cpu().detach() / <span class="hljs-number">2</span> + <span class="hljs-number">0.5</span>),  <br>                            (warped_clothmask[i].cpu().detach()).expand(<span class="hljs-number">3</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>),  <br>                            visualize_segmap(fake_parse_gauss.cpu(), batch=i),  <br>                            (pose_map[i].cpu() / <span class="hljs-number">2</span> + <span class="hljs-number">0.5</span>), (warped_cloth[i].cpu() / <span class="hljs-number">2</span> + <span class="hljs-number">0.5</span>),  <br>                            (agnostic[i].cpu() / <span class="hljs-number">2</span> + <span class="hljs-number">0.5</span>),  <br>                            (im[i] / <span class="hljs-number">2</span> + <span class="hljs-number">0.5</span>), (output[i].cpu() / <span class="hljs-number">2</span> + <span class="hljs-number">0.5</span>)],  <br>                           nrow=<span class="hljs-number">4</span>)  <br>    unpaired_name = (  <br>                inputs[<span class="hljs-string">&#x27;c_name&#x27;</span>][<span class="hljs-string">&#x27;paired&#x27;</span>][i].split(<span class="hljs-string">&#x27;.&#x27;</span>)[<span class="hljs-number">0</span>] + <span class="hljs-string">&#x27;_&#x27;</span> + inputs[<span class="hljs-string">&#x27;c_name&#x27;</span>][opt.datasetting][i].split(<span class="hljs-string">&#x27;.&#x27;</span>)[  <br>            <span class="hljs-number">0</span>] + <span class="hljs-string">&#x27;.png&#x27;</span>)  <br>    save_image(grid, os.path.join(grid_dir, unpaired_name))  <br>    unpaired_names.append(unpaired_name)  <br>  <br><span class="hljs-comment"># save output  </span><br>save_images(output, unpaired_names, output_dir)  <br>  <br>num += shape[<span class="hljs-number">0</span>]  <br><span class="hljs-built_in">print</span>(num)  <br>  <br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Test time <span class="hljs-subst">&#123;time.time() - iter_start_time&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/CV/" class="category-chain-item">CV</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/VITON/" class="print-no-link">#VITON</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>HR-VITON代码笔记二</div>
      <div>https://blog.paraline.top/posts/hr-viton代码笔记二/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Paraline</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2024年5月13日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/posts/hr-viton%E4%BB%A3%E7%A0%81%E7%AC%94%E8%AE%B0/" title="HR-VITON代码笔记">
                        <span class="hidden-mobile">HR-VITON代码笔记</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  
  
    <article id="comments" lazyload>
      
  <script type="text/javascript">
    Fluid.utils.loadComments('#comments', function() {
      var light = 'github-light';
      var dark = 'github-dark';
      var schema = document.documentElement.getAttribute('data-user-color-scheme');
      if (schema === 'dark') {
        schema = dark;
      } else {
        schema = light;
      }
      window.UtterancesThemeLight = light;
      window.UtterancesThemeDark = dark;
      var s = document.createElement('script');
      s.setAttribute('src', 'https://utteranc.es/client.js');
      s.setAttribute('repo', 'Para-line/BlogComment');
      s.setAttribute('issue-term', 'pathname');
      
      s.setAttribute('label', 'utterances');
      
      s.setAttribute('theme', schema);
      s.setAttribute('crossorigin', 'anonymous');
      document.getElementById('comments').appendChild(s);
    })
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


    </article>
  


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="leancloud-site-pv-container" style="display: none">
        Visits 
        <span id="leancloud-site-pv"></span>
         
      </span>
    
    
      <span id="leancloud-site-uv-container" style="display: none">
        Visitors 
        <span id="leancloud-site-uv"></span>
         
      </span>
    
    

  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script defer src="/js/leancloud.js" ></script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  <script src="/js/background.js"></script>

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
