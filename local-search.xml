<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>HR-VITON代码笔记二</title>
    <link href="/posts/hr-viton%E4%BB%A3%E7%A0%81%E7%AC%94%E8%AE%B0%E4%BA%8C/"/>
    <url>/posts/hr-viton%E4%BB%A3%E7%A0%81%E7%AC%94%E8%AE%B0%E4%BA%8C/</url>
    
    <content type="html"><![CDATA[<h1 id="train_condition.py">train_condition.py</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br><span class="hljs-keyword">from</span> torchvision.utils <span class="hljs-keyword">import</span> make_grid<br><span class="hljs-keyword">from</span> networks <span class="hljs-keyword">import</span> make_grid <span class="hljs-keyword">as</span> mkgrid<br><br><span class="hljs-keyword">import</span> argparse<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">from</span> cp_dataset <span class="hljs-keyword">import</span> CPDataset, CPDatasetTest, CPDataLoader<br><span class="hljs-keyword">from</span> networks <span class="hljs-keyword">import</span> ConditionGenerator, VGGLoss, GANLoss, load_checkpoint, save_checkpoint, define_D<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><span class="hljs-keyword">from</span> tensorboardX <span class="hljs-keyword">import</span> SummaryWriter<br><span class="hljs-keyword">from</span> utils <span class="hljs-keyword">import</span> *<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Subset<br></code></pre></td></tr></table></figure><p>引入了很多库。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">iou_metric</span>(<span class="hljs-params">y_pred_batch, y_true_batch</span>):<br>    B = y_pred_batch.shape[<span class="hljs-number">0</span>]<br>    iou = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(B):<br>        y_pred = y_pred_batch[i]<br>        y_true = y_true_batch[i]<br>        <span class="hljs-comment"># y_pred is not one-hot, so need to threshold it</span><br>        y_pred = y_pred &gt; <span class="hljs-number">0.5</span><br>        <br>        y_pred = y_pred.flatten()<br>        y_true = y_true.flatten()<br><br>    <br>        intersection = torch.<span class="hljs-built_in">sum</span>(y_pred[y_true == <span class="hljs-number">1</span>])<br>        union = torch.<span class="hljs-built_in">sum</span>(y_pred) + torch.<span class="hljs-built_in">sum</span>(y_true)<br><br>    <br>        iou += (intersection + <span class="hljs-number">1e-7</span>) / (union - intersection + <span class="hljs-number">1e-7</span>) / B<br>    <span class="hljs-keyword">return</span> iou<br></code></pre></td></tr></table></figure><p>这个函数是用来计算IoU的，即Intersection Over Union，计算公式为 <span class="math display">\[IoU = \frac{\text{Area of Intersection}}{\text{Area of Union}}\]</span></p><p><img src="https://s2.loli.net/2024/05/05/9uDBxajop3U5F4O.png" /></p><p>这里代码中分母用的是<code>union - intersection</code>的原因是，代码中的"union"不是真正的并集，而是把他们两个的区域面积直接加起来，多算了一次交集的面积，所以要减掉。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">remove_overlap</span>(<span class="hljs-params">seg_out, warped_cm</span>):<br>    <br>    <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(warped_cm.shape) == <span class="hljs-number">4</span><br>    <br>    warped_cm = warped_cm - (torch.cat([seg_out[:, <span class="hljs-number">1</span>:<span class="hljs-number">3</span>, :, :], seg_out[:, <span class="hljs-number">5</span>:, :, :]], dim=<span class="hljs-number">1</span>)).<span class="hljs-built_in">sum</span>(dim=<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">True</span>) * warped_cm<br>    <span class="hljs-keyword">return</span> warped_cm<br></code></pre></td></tr></table></figure><p>其中<code>torch.cat([seg_out[:, 1:3, :, :], seg_out[:, 5:, :, :]], dim=1)</code>表示segmentation中可能和clothes mask重叠的人体部位。</p><p>这里就是把warped clothes mask中和segmentation map中没对齐的部分消掉。看下面这张图就很清晰了。</p><p><img src="https://s2.loli.net/2024/05/04/1zBHFVmKOcAR4uN.png" /></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_opt</span>():<br>    parser = argparse.ArgumentParser()<br><br>    parser.add_argument(<span class="hljs-string">&quot;--name&quot;</span>, default=<span class="hljs-string">&quot;test&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--gpu_ids&quot;</span>, default=<span class="hljs-string">&quot;&quot;</span>)<br><br><span class="hljs-comment"># omitted</span><br><br>    opt = parser.parse_args()<br>    <span class="hljs-keyword">return</span> opt<br></code></pre></td></tr></table></figure><p>然后是<code>get_opt</code>函数，从命令行中获取参数。</p><h2 id="train">train</h2><p>然后是训练的主体函数。HR-VITON在开源代码里提供了训练的细节，而VITON-HD根本没有关于训练的部分，可以作为一个很好的补充。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">opt, train_loader, test_loader, val_loader, board, tocg, D</span>):<br>    <span class="hljs-comment"># Model</span><br>    tocg.cuda() <br>    tocg.train()<br>    D.cuda()<br>    D.train()<br></code></pre></td></tr></table></figure><p>这里tocg指的是Try-On Condition Generator, D是Try-On Image Generator.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># criterion</span><br>criterionL1 = nn.L1Loss()<br>criterionVGG = VGGLoss(opt)<br><span class="hljs-keyword">if</span> opt.fp16:<br>    criterionGAN = GANLoss(use_lsgan=<span class="hljs-literal">True</span>, tensor=torch.cuda.HalfTensor)<br><span class="hljs-keyword">else</span> :<br>    criterionGAN = GANLoss(use_lsgan=<span class="hljs-literal">True</span>, tensor=torch.cuda.FloatTensor <span class="hljs-keyword">if</span> opt.gpu_ids <span class="hljs-keyword">else</span> torch.Tensor)<br><br><span class="hljs-comment"># optimizer</span><br>optimizer_G = torch.optim.Adam(tocg.parameters(), lr=opt.G_lr, betas=(<span class="hljs-number">0.5</span>, <span class="hljs-number">0.999</span>))<br>optimizer_D = torch.optim.Adam(D.parameters(), lr=opt.D_lr, betas=(<span class="hljs-number">0.5</span>, <span class="hljs-number">0.999</span>))<br></code></pre></td></tr></table></figure><p><strong>VGG Loss</strong>: - <code>criterionVGG = VGGLoss(opt)</code>：VGG损失是一种基于预训练的VGG网络的特征表示来计算的感知损失。它不仅比较像素值的差异，而且比较高级特征的差异，有助于生成视觉上更令人满意的结果。<code>opt</code>可能包含了配置VGG损失所需的特定选项或参数。</p><p>根据<code>opt.fp16</code>的设置，GAN损失可能使用半精度浮点数（<code>torch.cuda.HalfTensor</code>）以提高计算效率和降低内存使用，或者使用全精度浮点数（<code>torch.cuda.FloatTensor</code>）。<code>opt.gpu_ids</code>可能用来检查是否有GPU可用，如果没有，则使用默认的CPU tensor（<code>torch.Tensor</code>）。</p><p><code>optimizer_G = torch.optim.Adam(tocg.parameters(), lr=opt.G_lr, betas=(0.5, 0.999))</code>：为生成器<code>tocg</code>设置Adam优化器。这里，<code>lr=opt.G_lr</code>是学习率，<code>betas</code>是Adam优化器的动量项，用于调节梯度下降过程中的移动平均。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> step <span class="hljs-keyword">in</span> tqdm(<span class="hljs-built_in">range</span>(opt.load_step, opt.keep_step)):<br>        iter_start_time = time.time()<br>        inputs = train_loader.next_batch()<br></code></pre></td></tr></table></figure><p>这里tqdm是一个可以在控制台显示进度条的库。效果如下：</p><p><img src="https://s2.loli.net/2024/05/12/csQ6BhPAKMWbCyf.png" /></p><ul><li><code>opt.load_step</code>：可能表示模型加载时的起始步骤或迭代次数。在某些情况下，模型可能需要从先前训练的检查点继续训练，而 <code>opt.load_step</code> 就是指定了从哪一步开始加载模型的参数。</li><li><code>opt.keep_step</code>：可能表示模型训练的结束步骤或迭代次数。当模型训练达到这个步骤时，循环就会结束。</li></ul><p>然后就是用DataLoader加载数据集：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># input1</span><br>c_paired = inputs[<span class="hljs-string">&#x27;cloth&#x27;</span>][<span class="hljs-string">&#x27;paired&#x27;</span>].cuda()<br>cm_paired = inputs[<span class="hljs-string">&#x27;cloth_mask&#x27;</span>][<span class="hljs-string">&#x27;paired&#x27;</span>].cuda()<br>cm_paired = torch.FloatTensor((cm_paired.detach().cpu().numpy() &gt; <span class="hljs-number">0.5</span>).astype(np.<span class="hljs-built_in">float</span>)).cuda()<br><span class="hljs-comment"># input2</span><br>parse_agnostic = inputs[<span class="hljs-string">&#x27;parse_agnostic&#x27;</span>].cuda()<br>densepose = inputs[<span class="hljs-string">&#x27;densepose&#x27;</span>].cuda()<br>openpose = inputs[<span class="hljs-string">&#x27;pose&#x27;</span>].cuda()<br><span class="hljs-comment"># GT</span><br>label_onehot = inputs[<span class="hljs-string">&#x27;parse_onehot&#x27;</span>].cuda()  <span class="hljs-comment"># CE</span><br>label = inputs[<span class="hljs-string">&#x27;parse&#x27;</span>].cuda()  <span class="hljs-comment"># GAN loss</span><br>parse_cloth_mask = inputs[<span class="hljs-string">&#x27;pcm&#x27;</span>].cuda()  <span class="hljs-comment"># L1</span><br>im_c = inputs[<span class="hljs-string">&#x27;parse_cloth&#x27;</span>].cuda()  <span class="hljs-comment"># VGG</span><br><span class="hljs-comment"># visualization</span><br>im = inputs[<span class="hljs-string">&#x27;image&#x27;</span>]<br><br><span class="hljs-comment"># inputs</span><br>input1 = torch.cat([c_paired, cm_paired], <span class="hljs-number">1</span>)<br>input2 = torch.cat([parse_agnostic, densepose], <span class="hljs-number">1</span>)<br><br><span class="hljs-comment"># forward</span><br>flow_list, fake_segmap, warped_cloth_paired, warped_clothmask_paired = tocg(input1, input2)<br><br><span class="hljs-comment"># warped cloth mask one hot </span><br><br>warped_cm_onehot = torch.FloatTensor((warped_clothmask_paired.detach().cpu().numpy() &gt; <span class="hljs-number">0.5</span>).astype(np.<span class="hljs-built_in">float</span>)).cuda()<br></code></pre></td></tr></table></figure><p>加载之后经过Try-On Condition Generator产生相应的结果。并把产生的warped_cm进行二值化处理。</p><p>这里的fake_segmap应该并不是说产生的segmentation map是有问题的，而是说这个segmentation map并不是来自于真实的图像，而是计算机合成的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># fake segmap cloth channel * warped clothmask</span><br>   <span class="hljs-keyword">if</span> opt.clothmask_composition != <span class="hljs-string">&#x27;no_composition&#x27;</span>:<br>        <span class="hljs-keyword">if</span> opt.clothmask_composition == <span class="hljs-string">&#x27;detach&#x27;</span>:<br>            cloth_mask = torch.ones_like(fake_segmap.detach())<br>            cloth_mask[:, <span class="hljs-number">3</span>:<span class="hljs-number">4</span>, :, :] = warped_cm_onehot<br>            fake_segmap = fake_segmap * cloth_mask<br></code></pre></td></tr></table></figure><p>检查是否需要合成衣物掩码。如果 <code>opt.clothmask_composition</code> 不等于 <code>'no_composition'</code>，则表示需要进行衣物掩码的合成 - <code>opt.clothmask_composition == 'detach'</code>：如果选择了使用 <code>detach</code> 方式合成衣物掩码，则将生成的虚假分割图 <code>fake_segmap</code> 与变形后的衣物掩码 <code>warped_cm_onehot</code> 相乘。这里使用 <code>detach</code> 可能是为了避免反向传播对 <code>warped_cm_onehot</code> 的影响。 - <code>opt.clothmask_composition == 'warp_grad'</code>：如果选择了使用 <code>warp_grad</code> 方式合成衣物掩码，则将生成的虚假分割图 <code>fake_segmap</code> 与变形后的衣物掩码 <code>warped_clothmask_paired</code> 相乘。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> opt.occlusion:<br>    warped_clothmask_paired = remove_overlap(<br>        F.softmax(fake_segmap, dim=<span class="hljs-number">1</span>), warped_clothmask_paired)<br>    warped_cloth_paired = warped_cloth_paired * warped_clothmask_paired + \<br>        torch.ones_like(warped_cloth_paired) * (<span class="hljs-number">1</span>-warped_clothmask_paired)<br></code></pre></td></tr></table></figure><p>这里是做occlusion handling。</p><p>调用<code>remove_overlap</code>把warped clothes mask与segmentation map中不重叠的部分消除掉，然后对warped_cloth也根据warped clothes mask把不重叠的地方消除掉。</p><p><code>warped_cloth_paired * warped_clothmask_paired</code>让<code>warped_clothmask_paired</code>让未被遮挡的衣服保留下来，<code>torch.ones_like(warped_cloth_paired) * (1-warped_clothmask_paired)</code>为被遮挡的地方填充一个默认值（白色）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">fake_clothmask = (torch.argmax(fake_segmap.detach(), dim=<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">True</span>) == <span class="hljs-number">3</span>).long()<br>misalign = fake_clothmask - warped_cm_onehot<br>misalign[misalign &lt; <span class="hljs-number">0.0</span>] = <span class="hljs-number">0.0</span><br></code></pre></td></tr></table></figure><p><code>fake_clothmask = (torch.argmax(fake_segmap.detach(), dim=1, keepdim=True) == 3).long()</code>这句话找出了在fake_segmap上最有可能是衣服的像素点，当做<code>fake_clothmask</code>。然后与ground truth相比，计算损失。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">loss_l1_cloth = criterionL1(warped_clothmask_paired, parse_cloth_mask) <br>loss_vgg = criterionVGG(warped_cloth_paired, im_c) <br>loss_tv = <span class="hljs-number">0</span><br></code></pre></td></tr></table></figure><p>这里计算相应的损失。</p><p>首先计算了生成的clothmask和ground truth之间的 L1 Loss。</p><p>然后再计算了变形后的衣服与ground truth衣服之间的VGG Loss。</p><p>loss_tv先设置为0，下面再进行实际的运算。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> opt.edgeawaretv == <span class="hljs-string">&#x27;no_edge&#x27;</span>:<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.lasttvonly:<br>        <span class="hljs-keyword">for</span> flow <span class="hljs-keyword">in</span> flow_list:<br>            y_tv = torch.<span class="hljs-built_in">abs</span>(flow[:, <span class="hljs-number">1</span>:, :, :] - flow[:, :-<span class="hljs-number">1</span>, :, :]).mean()<br>            x_tv = torch.<span class="hljs-built_in">abs</span>(flow[:, :, <span class="hljs-number">1</span>:, :] - flow[:, :, :-<span class="hljs-number">1</span>, :]).mean()<br>            loss_tv = loss_tv + y_tv + x_tv<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">for</span> flow <span class="hljs-keyword">in</span> flow_list[-<span class="hljs-number">1</span>:]:<br>            y_tv = torch.<span class="hljs-built_in">abs</span>(flow[:, <span class="hljs-number">1</span>:, :, :] - flow[:, :-<span class="hljs-number">1</span>, :, :]).mean()<br>            x_tv = torch.<span class="hljs-built_in">abs</span>(flow[:, :, <span class="hljs-number">1</span>:, :] - flow[:, :, :-<span class="hljs-number">1</span>, :]).mean()<br>            loss_tv = loss_tv + y_tv + x_tv<br><br></code></pre></td></tr></table></figure><p>这里是Total Variation Loss的计算。</p><p>这里flow的四个维度分别为<span class="math inline">\((N, H, W, C)\)</span>。</p><p>我们这里回忆一下图像梯度的计算公式： <span class="math display">\[\frac{ \partial I(x,y) }{ \partial x } =  \frac{I(x + 1, y) - I(x - 1,y)}{2}\]</span> <span class="math display">\[\frac{ \partial I(x,y) }{ \partial y } = \frac{I(x, y + 1) - I(x,y-1)}{2}\]</span> 也可以写成： <span class="math display">\[\frac{ \partial I(x,y) }{ \partial x } =  \frac{I(x + 1, y) - I(x,y)}{1}\]</span> <span class="math display">\[\frac{ \partial I(x,y) }{ \partial y } = \frac{I(x, y + 1) - I(x,y)}{1}\]</span></p><p>如果 <code>opt.edgeawaretv</code> 为 <code>'no_edge'</code> 且未指定 <code>'lasttvonly'</code>: - 对于每个流（<code>flow</code>）： - 分别计算垂直方向（<code>y_tv</code>）和水平方向（<code>x_tv</code>）的像素变化的绝对值的平均值。 - 将这两个方向的总变差加到总的变差损失中。</p><p><code>flow[:, 1:, :, :]</code>意思是取出2到n行，<code>flow[:, :-1, :, :]</code>意思是取出1到n-1行，两者作差即得到我们需要的n-1个对应上下两行的差，即第二行减第一行，第三行减第二行，……，第n行减第n-1行。</p><p>如果指定了<code>'lasttvonly'</code>: - 仅对最后一个流进行处理。 - 与上述类似，计算垂直和水平方向的像素变化绝对值的平均值。</p><p>这里的<code>opt.edgeawaretv</code>表示在计算total variation的时候是否考虑边缘的信息。如果只有最后一个光流考虑边缘的信息。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">else</span>:<br>    <span class="hljs-keyword">if</span> opt.edgeawaretv == <span class="hljs-string">&#x27;last_only&#x27;</span>:<br>                flow = flow_list[-<span class="hljs-number">1</span>]<br>                warped_clothmask_paired_down = F.interpolate(warped_clothmask_paired, flow.shape[<span class="hljs-number">1</span>:<span class="hljs-number">3</span>], mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>)<br>                y_tv = torch.<span class="hljs-built_in">abs</span>(flow[:, <span class="hljs-number">1</span>:, :, :] - flow[:, :-<span class="hljs-number">1</span>, :, :])<br>                x_tv = torch.<span class="hljs-built_in">abs</span>(flow[:, :, <span class="hljs-number">1</span>:, :] - flow[:, :, :-<span class="hljs-number">1</span>, :])<br>                mask_y = torch.exp(-<span class="hljs-number">15</span>*torch.<span class="hljs-built_in">abs</span>(0warped_clothmask_paired_down.permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)[:, <span class="hljs-number">1</span>:, :, :] - warped_clothmask_paired_down.permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)[:, :-<span class="hljs-number">1</span>, :, :]))<br>                mask_x = torch.exp(-<span class="hljs-number">150</span>*torch.<span class="hljs-built_in">abs</span>(warped_clothmask_paired_down.permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)[:, :, <span class="hljs-number">1</span>:, :] - warped_clothmask_paired_down.permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)[:, :, :-<span class="hljs-number">1</span>, :]))<br>                y_tv = y_tv * mask_y<br>                x_tv = x_tv * mask_x<br>                y_tv = y_tv.mean()<br>                x_tv = x_tv.mean()<br>                loss_tv = loss_tv + y_tv + x_tv           <br></code></pre></td></tr></table></figure><p>这里首先是跟上一步一样，计算了垂直方向（<code>y_tv</code>）和水平方向（<code>x_tv</code>）的像素变化的绝对值的平均值。</p><p><code>mask_y = torch.exp(-150*torch.abs(warped_clothmask_paired_down.permute(0, 2, 3, 1)[:, 1:, :, :] - warped_clothmask_paired_down.permute(0, 2, 3, 1)[:, :-1, :, :]))</code>这个表达式，根据<code>warped_clothmask_paired_down</code>计算在垂直和水平方向上的像素变化幅度来计算<code>mask_y</code>。在变化幅度越大的地方权值越小。</p><p>因为在边缘区域，我们期望有更大的像素变化以保留边缘信息。通过这样的处理，梯度损失能更好地适应图像内容的具体情况，减少对边缘细节的平滑，这对于维持图像质量和视觉效果是非常重要的。</p><p>我们之后将这些计算出的边缘权重与原始的梯度值（<code>y_tv</code> 和 <code>x_tv</code>）相乘，并取平均值，得到最终的tv值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">elif</span> opt.edgeawaretv == <span class="hljs-string">&#x27;weighted&#x27;</span>:<br>                <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>):<br>                    flow = flow_list[i]<br>                    warped_clothmask_paired_down = F.interpolate(warped_clothmask_paired, flow.shape[<span class="hljs-number">1</span>:<span class="hljs-number">3</span>], mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>)<br>                    y_tv = torch.<span class="hljs-built_in">abs</span>(flow[:, <span class="hljs-number">1</span>:, :, :] - flow[:, :-<span class="hljs-number">1</span>, :, :])<br>                    x_tv = torch.<span class="hljs-built_in">abs</span>(flow[:, :, <span class="hljs-number">1</span>:, :] - flow[:, :, :-<span class="hljs-number">1</span>, :])<br>                    mask_y = torch.exp(-<span class="hljs-number">150</span>*torch.<span class="hljs-built_in">abs</span>(warped_clothmask_paired_down.permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)[:, <span class="hljs-number">1</span>:, :, :] - warped_clothmask_paired_down.permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)[:, :-<span class="hljs-number">1</span>, :, :]))<br>                    mask_x = torch.exp(-<span class="hljs-number">150</span>*torch.<span class="hljs-built_in">abs</span>(warped_clothmask_paired_down.permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)[:, :, <span class="hljs-number">1</span>:, :] - warped_clothmask_paired_down.permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)[:, :, :-<span class="hljs-number">1</span>, :]))<br>                    y_tv = y_tv * mask_y<br>                    x_tv = x_tv * mask_x<br>                    y_tv = y_tv.mean() / (<span class="hljs-number">2</span> ** (<span class="hljs-number">4</span>-i))<br>                    x_tv = x_tv.mean() / (<span class="hljs-number">2</span> ** (<span class="hljs-number">4</span>-i))<br>                    loss_tv = loss_tv + y_tv + x_tv  <br></code></pre></td></tr></table></figure><p>如果<code>opt.edgeawaretv == 'weighted'</code>，这里的处理大体上和上面相似，只是上面只计算最后一个flow的TV值，而这里计算所有flow的TV值，并对他们进行加权。</p><p>使用 2 ** (4-i) 对不同阶段的损失进行动态加权，越晚的光流被赋予更大的权重，可能因为后期的图像变换更能代表整个图像序列的重要特征。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> opt.add_lasttv:<br>    <span class="hljs-keyword">for</span> flow <span class="hljs-keyword">in</span> flow_list[-<span class="hljs-number">1</span>:]:<br>        y_tv = torch.<span class="hljs-built_in">abs</span>(flow[:, <span class="hljs-number">1</span>:, :, :] - flow[:, :-<span class="hljs-number">1</span>, :, :]).mean()<br>        x_tv = torch.<span class="hljs-built_in">abs</span>(flow[:, :, <span class="hljs-number">1</span>:, :] - flow[:, :, :-<span class="hljs-number">1</span>, :]).mean()<br>        loss_tv = loss_tv + y_tv + x_tv<br></code></pre></td></tr></table></figure><p>最后如果add_lasttv为true，那么就加上最后一个flow的TV值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> opt.interflowloss:<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(flow_list)-<span class="hljs-number">1</span>):<br>        flow = flow_list[i]<br>        N, fH, fW, _ = flow.size()<br>        grid = mkgrid(N, iH, iW)<br>        flow = F.interpolate(flow.permute(<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>), size=c_paired.shape[<span class="hljs-number">2</span>:], mode=opt.upsample).permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)<br>        flow_norm = torch.cat([flow[:, :, :, <span class="hljs-number">0</span>:<span class="hljs-number">1</span>] / ((fW - <span class="hljs-number">1.0</span>) / <span class="hljs-number">2.0</span>), flow[:, :, :, <span class="hljs-number">1</span>:<span class="hljs-number">2</span>] / ((fH - <span class="hljs-number">1.0</span>) / <span class="hljs-number">2.0</span>)], <span class="hljs-number">3</span>)<br>        warped_c = F.grid_sample(c_paired, flow_norm + grid, padding_mode=<span class="hljs-string">&#x27;border&#x27;</span>)<br>        warped_cm = F.grid_sample(cm_paired, flow_norm + grid, padding_mode=<span class="hljs-string">&#x27;border&#x27;</span>)<br>        warped_cm = remove_overlap(F.softmax(fake_segmap, dim=<span class="hljs-number">1</span>), warped_cm)<br>        loss_l1_cloth += criterionL1(warped_cm, parse_cloth_mask) / (<span class="hljs-number">2</span> ** (<span class="hljs-number">4</span>-i))<br>        loss_vgg += criterionVGG(warped_c, im_c) / (<span class="hljs-number">2</span> ** (<span class="hljs-number">4</span>-i))<br></code></pre></td></tr></table></figure><p>这里计算中间过程中的损失。同样是越后面的权重越大。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># loss segmentation</span><br><span class="hljs-comment"># generator</span><br>CE_loss = cross_entropy2d(fake_segmap, label_onehot.transpose(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>)[<span class="hljs-number">0</span>].long())<br></code></pre></td></tr></table></figure><p>这里首先计算生成的segmentation map和实际的segmentation map之间的cross entropy loss。</p><p>在深度学习中，交叉熵损失函数常用于分类任务中。而在像素级的分类任务，比如图像语义分割，每个像素都需要分到一个类别中。使用独热编码的标签形式有几个好处：</p><ol type="1"><li><strong>方便计算：</strong> 独热编码的标签形式将标签表示为一个向量，其中只有一个元素是1，其余元素都是0。这样在计算损失时，只需要比较模型的输出与独热编码的标签，计算对应位置的交叉熵损失即可，计算起来相对简单高效。</li><li><strong>适用性广泛：</strong> 独热编码的标签形式适用于多类别分类问题，可以处理类别不平衡的情况，每个类别的权重都可以独立地被考虑。</li><li><strong>数学上的连续性：</strong> 交叉熵损失函数可以直接衡量两个概率分布之间的差异，而独热编码的标签形式与概率分布形式相对应，这使得交叉熵损失函数的数学解释更加直观。</li></ol><p>这里的<code>cross_entropy2d</code>是在utils.py中定义的，并不是一个内置的函数。 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">cross_entropy2d</span>(<span class="hljs-params"><span class="hljs-built_in">input</span>, target, weight=<span class="hljs-literal">None</span>, size_average=<span class="hljs-literal">True</span></span>):<br>    n, c, h, w = <span class="hljs-built_in">input</span>.size()<br>    nt, ht, wt = target.size()<br><br>    <span class="hljs-comment"># Handle inconsistent size between input and target</span><br>    <span class="hljs-keyword">if</span> h != ht <span class="hljs-keyword">or</span> w != wt:<br>        <span class="hljs-built_in">input</span> = F.interpolate(<span class="hljs-built_in">input</span>, size=(ht, wt), mode=<span class="hljs-string">&quot;bilinear&quot;</span>, align_corners=<span class="hljs-literal">True</span>)<br><br>    <span class="hljs-built_in">input</span> = <span class="hljs-built_in">input</span>.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>).transpose(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>).contiguous().view(-<span class="hljs-number">1</span>, c)<br>    target = target.view(-<span class="hljs-number">1</span>)<br>    loss = F.cross_entropy(<br>        <span class="hljs-built_in">input</span>, target, weight=weight, size_average=size_average, ignore_index=<span class="hljs-number">250</span><br>    )<br>    <span class="hljs-keyword">return</span> loss<br></code></pre></td></tr></table></figure></p><p>首先取出了input和target的形状。如果input和target的形状不同，就进行缩放处理。</p><p><code>input.transpose(1, 2).transpose(2, 3).contiguous()</code> 将输入张量从 <code>(N, C, H, W)</code> 转换为 <code>(N, H, W, C)</code>。便于之后的展平。</p><p>这里我们回忆一下view的用法： <code>view</code> 方法用于改变张量的形状而不改变其数据。你可以将其视为重新排列或解释张量中数据的一种方式，但实际的数据内容和顺序不变。这通常用于调整数据的维度以匹配特定操作或模型的输入需求。 - <strong>使用场景</strong>：例如，如果你有一个形状为 <code>[10, 256]</code> 的张量，你可以使用 <code>.view(10, 16, 16)</code> 将其重新形状为 <code>[10, 16, 16]</code>，这样做是为了将它用作图像批次，其中每张图像是 16x16 像素。 - <strong>限制</strong>：使用 <code>view</code> 需要张量在内存中是连续的（即无跨步问题）。如果不是，可能需要先调用 <code>.contiguous()</code>。 - <strong>自动推断维度</strong>：用 <code>-1</code> 作为 <code>view</code> 方法中的一个参数，PyTorch 将自动计算这一维的大小，以使得总元素数量保持不变。</p><p><code>F.cross_entropy(input, target, weight=weight, size_average=size_average, ignore_index=250)</code>使用 PyTorch 提供的交叉熵函数计算损失。ignore_index=250 参数指示函数忽略值为 250 的目标标签，这通常用于表示某些像素不应该被计算损失（例如，标注不清的区域）。</p><p>现在我们再回过头来看刚才的CE Loss计算。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">CE_loss = cross_entropy2d(fake_segmap, label_onehot.transpose(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>)[<span class="hljs-number">0</span>].long())<br></code></pre></td></tr></table></figure><p>label_onehot的维度为(N, 1, H, W)，这样然后调用transpose转化为(1, N, H, W)，最后把第一维去掉，得到(N, H, W)，符合cross_entropy2d函数的要求。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> opt.no_GAN_loss:<br>    loss_G = (<span class="hljs-number">10</span> * loss_l1_cloth + loss_vgg + opt.tvlambda * loss_tv) + (CE_loss * opt.CElamda)<br>    <span class="hljs-comment"># step</span><br>    optimizer_G.zero_grad()<br>    loss_G.backward()<br>    optimizer_G.step()<br></code></pre></td></tr></table></figure><ol type="1"><li><code>optimizer_G.zero_grad()</code>: 这一步是将生成器的梯度缓存清零。在PyTorch中，梯度是累积的，因此在每次反向传播之前需要将梯度清零，以避免梯度的累积影响下一次的计算。</li><li><code>loss_G.backward()</code>: 这一步是执行反向传播，计算生成器损失 <code>loss_G</code> 对生成器参数的梯度。反向传播会沿着计算图反向传播误差，并计算每个参数对总体损失的贡献度。</li><li><code>optimizer_G.step()</code>: 这一步是利用优化器 <code>optimizer_G</code> 根据生成器参数的梯度更新参数值。优化器根据梯度和设定的优化算法（如随机梯度下降）更新参数，以减小损失函数的值，从而使生成器更好地生成符合期望的输出。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">else</span>:<br>            fake_segmap_softmax = torch.softmax(fake_segmap, <span class="hljs-number">1</span>)<br><br>            pred_segmap = D(torch.cat((input1.detach(), input2.detach(), fake_segmap_softmax), dim=<span class="hljs-number">1</span>))<br>            <br>            loss_G_GAN = criterionGAN(pred_segmap, <span class="hljs-literal">True</span>)<br>            <br></code></pre></td></tr></table></figure><p>这里是如果要加入GANLoss的操作。</p><p><code>pred_segmap = D(torch.cat((input1.detach(), input2.detach(), fake_segmap_softmax), dim=1))</code>：这一步将经过softmax处理后的生成器输出与输入图像以及其他信息（如输入的衣服图像）进行拼接，然后输入到鉴别器 <code>D</code> 中进行预测。预测得到的 <code>pred_segmap</code> 是鉴别器对合成图像的预测结果。</p><p><code>loss_G_GAN = criterionGAN(pred_segmap, True)</code>表示Generator希望它被判定为真实的。并计算相应的loss。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.G_D_seperate:<br>    <span class="hljs-comment"># discriminator</span><br>    fake_segmap_pred = D(torch.cat((input1.detach(), input2.detach(), fake_segmap_softmax.detach()), dim=<span class="hljs-number">1</span>))<br>    real_segmap_pred = D(torch.cat((input1.detach(), input2.detach(), label), dim=<span class="hljs-number">1</span>))<br>    loss_D_fake = criterionGAN(fake_segmap_pred, <span class="hljs-literal">False</span>)<br>    loss_D_real = criterionGAN(real_segmap_pred, <span class="hljs-literal">True</span>)<br><br>    <span class="hljs-comment"># loss sum</span><br>    loss_G = (<span class="hljs-number">10</span> * loss_l1_cloth + loss_vgg + opt.tvlambda * loss_tv) + (<br>                CE_loss * opt.CElamda + loss_G_GAN * opt.GANlambda)  <span class="hljs-comment"># warping + seg_generation</span><br>    loss_D = loss_D_fake + loss_D_real<br><br>    <span class="hljs-comment"># step</span><br>    optimizer_G.zero_grad()<br>    loss_G.backward()<br>    optimizer_G.step()<br><br>    optimizer_D.zero_grad()<br>    loss_D.backward()<br>    optimizer_D.step()<br></code></pre></td></tr></table></figure><p>如果Generator和Discriminator不分开训练，那么就再计算Discriminator的Loss，然后计算Generator的总Loss。然后调用optimizer进行优化。</p><p>这里将真实的input和fake_segmap一起作为<code>fake_segmap_pred</code>可能是因为将真实数据与生成数据一起输入判别器可以帮助判别器更好地学习如何区分真实数据和生成数据。</p><p><code>fake_segmap_pred = D(torch.cat((input1.detach(), input2.detach(), fake_segmap_softmax.detach()), dim=1))</code>这句使用 <code>detach</code> 函数将生成器输出的梯度信息从计算图中分离出来，以防止梯度更新传播到生成器，从而保持生成器参数不变。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">else</span>: <span class="hljs-comment"># train G first after that train D</span><br>                <span class="hljs-comment"># loss G sum</span><br>                loss_G = (<span class="hljs-number">10</span> * loss_l1_cloth + loss_vgg + opt.tvlambda * loss_tv) + (CE_loss * opt.CElamda + loss_G_GAN * opt.GANlambda)  <span class="hljs-comment"># warping + seg_generation</span><br>                <br>                <span class="hljs-comment"># step G</span><br>                optimizer_G.zero_grad()<br>                loss_G.backward()<br>                optimizer_G.step()<br>                <br>                <span class="hljs-comment"># discriminator</span><br>                <span class="hljs-keyword">with</span> torch.no_grad():<br>                    _, fake_segmap, _, _ = tocg(input1, input2)<br>                fake_segmap_softmax = torch.softmax(fake_segmap, <span class="hljs-number">1</span>)<br>                <br>                <span class="hljs-comment"># loss discriminator</span><br>                fake_segmap_pred = D(torch.cat((input1.detach(), input2.detach(), fake_segmap_softmax.detach()),dim=<span class="hljs-number">1</span>))<br>                real_segmap_pred = D(torch.cat((input1.detach(), input2.detach(), label),dim=<span class="hljs-number">1</span>))<br>                loss_D_fake = criterionGAN(fake_segmap_pred, <span class="hljs-literal">False</span>)<br>                loss_D_real = criterionGAN(real_segmap_pred, <span class="hljs-literal">True</span>)<br>                <br>                loss_D = loss_D_fake + loss_D_real<br>                <br>                optimizer_D.zero_grad()<br>                loss_D.backward()<br>                optimizer_D.step()<br></code></pre></td></tr></table></figure><p>如果<code>opt.G_D_seperate == True</code>，就先训练Generator，再训练Discriminator。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> (step + <span class="hljs-number">1</span>) % opt.val_count == <span class="hljs-number">0</span>:  <br>    tocg.<span class="hljs-built_in">eval</span>()  <br>    iou_list = []  <br>    <span class="hljs-keyword">with</span> torch.no_grad():  <br>        <span class="hljs-keyword">for</span> cnt <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2000</span> // opt.batch_size):  <br>  <br>            inputs = val_loader.next_batch()  <br>            <span class="hljs-comment"># input1  </span><br>            c_paired = inputs[<span class="hljs-string">&#x27;cloth&#x27;</span>][<span class="hljs-string">&#x27;paired&#x27;</span>].cuda()  <br>            cm_paired = inputs[<span class="hljs-string">&#x27;cloth_mask&#x27;</span>][<span class="hljs-string">&#x27;paired&#x27;</span>].cuda()  <br>            cm_paired = torch.FloatTensor((cm_paired.detach().cpu().numpy() &gt; <span class="hljs-number">0.5</span>).astype(np.<span class="hljs-built_in">float</span>)).cuda()  <br>            <span class="hljs-comment"># input2  </span><br>            parse_agnostic = inputs[<span class="hljs-string">&#x27;parse_agnostic&#x27;</span>].cuda()  <br>            densepose = inputs[<span class="hljs-string">&#x27;densepose&#x27;</span>].cuda()  <br>            openpose = inputs[<span class="hljs-string">&#x27;pose&#x27;</span>].cuda()  <br>            <span class="hljs-comment"># GT  </span><br>            label_onehot = inputs[<span class="hljs-string">&#x27;parse_onehot&#x27;</span>].cuda()  <span class="hljs-comment"># CE  </span><br>            label = inputs[<span class="hljs-string">&#x27;parse&#x27;</span>].cuda()  <span class="hljs-comment"># GAN loss  </span><br>            parse_cloth_mask = inputs[<span class="hljs-string">&#x27;pcm&#x27;</span>].cuda()  <span class="hljs-comment"># L1  </span><br>            im_c = inputs[<span class="hljs-string">&#x27;parse_cloth&#x27;</span>].cuda()  <span class="hljs-comment"># VGG  </span><br>            <span class="hljs-comment"># visualization            im = inputs[&#x27;image&#x27;]  </span><br>  <br>            input1 = torch.cat([c_paired, cm_paired], <span class="hljs-number">1</span>)  <br>            input2 = torch.cat([parse_agnostic, densepose], <span class="hljs-number">1</span>)  <br></code></pre></td></tr></table></figure><p><code>if (step + 1) % opt.val_count == 0:</code>每隔一段时间对模型进行一次评估。</p><p><code>tocg.eval()</code>将模型设置为评估模式，这会影响到某些层的行为，例如Dropout和Batch Normalization层，在评估模式下会采用不同的统计信息，以便更好地进行评估。</p><p>通过<code>torch.no_grad()</code>上下文管理器，禁用梯度计算，因为在验证过程中不需要计算梯度，这样可以减少内存的使用并提高计算速度。</p><p>接着循环遍历验证集，每次加载一个批次的数据，然后将数据传输到GPU上（如果可用）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># forward</span><br>flow_list, fake_segmap, warped_cloth_paired, warped_clothmask_paired = tocg(input1, input2)  <br>  <br><span class="hljs-comment"># fake segmap cloth channel * warped clothmask  </span><br><span class="hljs-keyword">if</span> opt.clothmask_composition != <span class="hljs-string">&#x27;no_composition&#x27;</span>:  <br>    <span class="hljs-keyword">if</span> opt.clothmask_composition == <span class="hljs-string">&#x27;detach&#x27;</span>:  <br>        cloth_mask = torch.ones_like(fake_segmap.detach())  <br>        cloth_mask[:, <span class="hljs-number">3</span>:<span class="hljs-number">4</span>, :, :] = warped_cm_onehot  <br>        fake_segmap = fake_segmap * cloth_mask  <br>  <br>    <span class="hljs-keyword">if</span> opt.clothmask_composition == <span class="hljs-string">&#x27;warp_grad&#x27;</span>:  <br>        cloth_mask = torch.ones_like(fake_segmap.detach())  <br>        cloth_mask[:, <span class="hljs-number">3</span>:<span class="hljs-number">4</span>, :, :] = warped_clothmask_paired  <br>        fake_segmap = fake_segmap * cloth_mask  <br>  <br><span class="hljs-comment"># calculate iou  </span><br>iou = iou_metric(F.softmax(fake_segmap, dim=<span class="hljs-number">1</span>).detach(), label)  <br>iou_list.append(iou.item())  <br>  <br>tocg.train()  <br>board.add_scalar(<span class="hljs-string">&#x27;val/iou&#x27;</span>, np.mean(iou_list), step + <span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><p>下面是<code>board.add_scalar</code>函数的各个参数的解释： <code>'val/iou'</code>：标签，用于标识被记录的数据类型，以便在tensorboard中显示。 <code>np.mean(iou_list)</code>：要记录的数值，这里是平均的IoU值。 <code>step + 1</code>：当前的步数，用于在tensorboard中横轴显示，以便对应模型训练的进度。</p><p>这里+1是因为循环的step从0开始，但是对于我们人类来说step从1开始更直观，所以我们+1。</p><p>Tensorboard是一个由Google开发的用于可视化神经网络训练过程中的各种指标和结果的工具。它可以帮助用户更直观地理解模型的训练过程和性能表现。在Tensorboard中，用户可以查看训练过程中的损失函数曲线、准确率曲线、模型参数分布、模型结构等信息，以及进行多组数据的对比分析。通过可视化，用户可以更好地监控模型的训练过程，发现潜在问题，并优化模型的训练策略。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># tensorboard  </span><br><span class="hljs-keyword">if</span> (step + <span class="hljs-number">1</span>) % opt.tensorboard_count == <span class="hljs-number">0</span>:  <br>    <span class="hljs-comment"># loss G  </span><br>    board.add_scalar(<span class="hljs-string">&#x27;Loss/G&#x27;</span>, loss_G.item(), step + <span class="hljs-number">1</span>)  <br>    board.add_scalar(<span class="hljs-string">&#x27;Loss/G/l1_cloth&#x27;</span>, loss_l1_cloth.item(), step + <span class="hljs-number">1</span>)  <br>    board.add_scalar(<span class="hljs-string">&#x27;Loss/G/vgg&#x27;</span>, loss_vgg.item(), step + <span class="hljs-number">1</span>)  <br>    board.add_scalar(<span class="hljs-string">&#x27;Loss/G/tv&#x27;</span>, loss_tv.item(), step + <span class="hljs-number">1</span>)  <br>    board.add_scalar(<span class="hljs-string">&#x27;Loss/G/CE&#x27;</span>, CE_loss.item(), step + <span class="hljs-number">1</span>)  <br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.no_GAN_loss:  <br>        board.add_scalar(<span class="hljs-string">&#x27;Loss/G/GAN&#x27;</span>, loss_G_GAN.item(), step + <span class="hljs-number">1</span>)  <br>        <span class="hljs-comment"># loss D  </span><br>        board.add_scalar(<span class="hljs-string">&#x27;Loss/D&#x27;</span>, loss_D.item(), step + <span class="hljs-number">1</span>)  <br>        board.add_scalar(<span class="hljs-string">&#x27;Loss/D/pred_real&#x27;</span>, loss_D_real.item(), step + <span class="hljs-number">1</span>)  <br>        board.add_scalar(<span class="hljs-string">&#x27;Loss/D/pred_fake&#x27;</span>, loss_D_fake.item(), step + <span class="hljs-number">1</span>)  <br>  <br>    grid = make_grid(  <br>        [(c_paired[<span class="hljs-number">0</span>].cpu() / <span class="hljs-number">2</span> + <span class="hljs-number">0.5</span>), (cm_paired[<span class="hljs-number">0</span>].cpu()).expand(<span class="hljs-number">3</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>), visualize_segmap(parse_agnostic.cpu()),  <br>         ((densepose.cpu()[<span class="hljs-number">0</span>] + <span class="hljs-number">1</span>) / <span class="hljs-number">2</span>),  <br>         (im_c[<span class="hljs-number">0</span>].cpu() / <span class="hljs-number">2</span> + <span class="hljs-number">0.5</span>), parse_cloth_mask[<span class="hljs-number">0</span>].cpu().expand(<span class="hljs-number">3</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>),  <br>         (warped_cloth_paired[<span class="hljs-number">0</span>].cpu().detach() / <span class="hljs-number">2</span> + <span class="hljs-number">0.5</span>), (warped_cm_onehot[<span class="hljs-number">0</span>].cpu().detach()).expand(<span class="hljs-number">3</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>),  <br>         visualize_segmap(label.cpu()), visualize_segmap(fake_segmap.cpu()), (im[<span class="hljs-number">0</span>] / <span class="hljs-number">2</span> + <span class="hljs-number">0.5</span>),  <br>         (misalign[<span class="hljs-number">0</span>].cpu().detach()).expand(<span class="hljs-number">3</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>)],  <br>        nrow=<span class="hljs-number">4</span>)  <br>    board.add_images(<span class="hljs-string">&#x27;train_images&#x27;</span>, grid.unsqueeze(<span class="hljs-number">0</span>), step + <span class="hljs-number">1</span>)  <br></code></pre></td></tr></table></figure><p>然后这段代码是在tensorboard里面记录一些其他的数据。</p><p>这里用的是torchvision库中的make_grid函数，而不是用的先前自己定义的。</p><p><code>make_grid</code> 函数是 PyTorch 中用于将一组图像排列成一个网格的工具函数。它接受一个张量列表作为输入，这些张量通常代表一组图像。下面是它的部分参数：</p><ol type="1"><li><strong>tensor (list of tensors)</strong>: 这是包含图像的张量列表。每个张量都代表一张图像，通常是 <code>(C, H, W)</code> 形状的张量，其中 <code>C</code> 是通道数，<code>H</code> 是高度，<code>W</code> 是宽度。这些张量可以具有不同的形状，但是它们的通道数必须相同。如果输入的张量是 <code>[N, C, H, W]</code> 形状的，<code>make_grid</code> 函数会将它们合并成一个 <code>(C, H, W * N)</code> 的张量，其中 <code>N</code> 是输入张量的数量。</li><li><strong>nrow (int, optional)</strong>: 这是一个可选参数，用于指定生成的网格中每行包含的图像数量。默认值为 8。</li><li><strong>padding (int, optional)</strong>: 这也是一个可选参数，用于指定每个图像之间的填充像素数。默认值为 2。</li><li><strong>normalize (bool, optional)</strong>: 这是一个可选参数，用于指定是否对输入张量进行归一化。如果设置为 <code>True</code>，则会对输入张量进行归一化，使其像素值范围在 <code>[0, 1]</code> 内。默认值为 <code>False</code>。</li><li><strong>value (float, optional)</strong>: 这是一个可选参数，用于指定填充像素的值。默认值为 0。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.no_test_visualize:  <br>    inputs = test_loader.next_batch()  <br>    <span class="hljs-comment"># input1  </span><br>    c_paired = inputs[<span class="hljs-string">&#x27;cloth&#x27;</span>][opt.test_datasetting].cuda()  <br>    cm_paired = inputs[<span class="hljs-string">&#x27;cloth_mask&#x27;</span>][opt.test_datasetting].cuda()  <br>    cm_paired = torch.FloatTensor((cm_paired.detach().cpu().numpy() &gt; <span class="hljs-number">0.5</span>).astype(np.<span class="hljs-built_in">float</span>)).cuda()  <br>    <span class="hljs-comment"># input2  </span><br>    parse_agnostic = inputs[<span class="hljs-string">&#x27;parse_agnostic&#x27;</span>].cuda()  <br>    densepose = inputs[<span class="hljs-string">&#x27;densepose&#x27;</span>].cuda()  <br>    openpose = inputs[<span class="hljs-string">&#x27;pose&#x27;</span>].cuda()  <br>    <span class="hljs-comment"># GT  </span><br>    label_onehot = inputs[<span class="hljs-string">&#x27;parse_onehot&#x27;</span>].cuda()  <span class="hljs-comment"># CE  </span><br>    label = inputs[<span class="hljs-string">&#x27;parse&#x27;</span>].cuda()  <span class="hljs-comment"># GAN loss  </span><br>    parse_cloth_mask = inputs[<span class="hljs-string">&#x27;pcm&#x27;</span>].cuda()  <span class="hljs-comment"># L1  </span><br>    im_c = inputs[<span class="hljs-string">&#x27;parse_cloth&#x27;</span>].cuda()  <span class="hljs-comment"># VGG  </span><br>    <span class="hljs-comment"># visualization        im = inputs[&#x27;image&#x27;]  </span><br>  <br>    tocg.<span class="hljs-built_in">eval</span>()<br></code></pre></td></tr></table></figure><p>如果不是no_test_visualize的话，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.no_test_visualize:  <br>    inputs = test_loader.next_batch()  <br>    <span class="hljs-comment"># input1  </span><br>    c_paired = inputs[<span class="hljs-string">&#x27;cloth&#x27;</span>][opt.test_datasetting].cuda()  <br>    cm_paired = inputs[<span class="hljs-string">&#x27;cloth_mask&#x27;</span>][opt.test_datasetting].cuda()  <br>    cm_paired = torch.FloatTensor((cm_paired.detach().cpu().numpy() &gt; <span class="hljs-number">0.5</span>).astype(np.<span class="hljs-built_in">float</span>)).cuda()  <br>    <span class="hljs-comment"># input2  </span><br>    parse_agnostic = inputs[<span class="hljs-string">&#x27;parse_agnostic&#x27;</span>].cuda()  <br>    densepose = inputs[<span class="hljs-string">&#x27;densepose&#x27;</span>].cuda()  <br>    openpose = inputs[<span class="hljs-string">&#x27;pose&#x27;</span>].cuda()  <br>    <span class="hljs-comment"># GT  </span><br>    label_onehot = inputs[<span class="hljs-string">&#x27;parse_onehot&#x27;</span>].cuda()  <span class="hljs-comment"># CE  </span><br>    label = inputs[<span class="hljs-string">&#x27;parse&#x27;</span>].cuda()  <span class="hljs-comment"># GAN loss  </span><br>    parse_cloth_mask = inputs[<span class="hljs-string">&#x27;pcm&#x27;</span>].cuda()  <span class="hljs-comment"># L1  </span><br>    im_c = inputs[<span class="hljs-string">&#x27;parse_cloth&#x27;</span>].cuda()  <span class="hljs-comment"># VGG  </span><br>    <span class="hljs-comment"># visualization    im = inputs[&#x27;image&#x27;]  </span><br>  <br>    tocg.<span class="hljs-built_in">eval</span>()  <br>    <span class="hljs-keyword">with</span> torch.no_grad():  <br>        <span class="hljs-comment"># inputs  </span><br>        input1 = torch.cat([c_paired, cm_paired], <span class="hljs-number">1</span>)  <br>        input2 = torch.cat([parse_agnostic, densepose], <span class="hljs-number">1</span>)  <br>  <br>        <span class="hljs-comment"># forward  </span><br>        flow_list, fake_segmap, warped_cloth_paired, warped_clothmask_paired = tocg(input1, input2)  <br>  <br>        warped_cm_onehot = torch.FloatTensor(  <br>            (warped_clothmask_paired.detach().cpu().numpy() &gt; <span class="hljs-number">0.5</span>).astype(np.<span class="hljs-built_in">float</span>)).cuda()  <br>        <span class="hljs-keyword">if</span> opt.clothmask_composition != <span class="hljs-string">&#x27;no_composition&#x27;</span>:  <br>            <span class="hljs-keyword">if</span> opt.clothmask_composition == <span class="hljs-string">&#x27;detach&#x27;</span>:  <br>                cloth_mask = torch.ones_like(fake_segmap)  <br>                cloth_mask[:, <span class="hljs-number">3</span>:<span class="hljs-number">4</span>, :, :] = warped_cm_onehot  <br>                fake_segmap = fake_segmap * cloth_mask  <br>  <br>            <span class="hljs-keyword">if</span> opt.clothmask_composition == <span class="hljs-string">&#x27;warp_grad&#x27;</span>:  <br>                cloth_mask = torch.ones_like(fake_segmap)  <br>                cloth_mask[:, <span class="hljs-number">3</span>:<span class="hljs-number">4</span>, :, :] = warped_clothmask_paired  <br>                fake_segmap = fake_segmap * cloth_mask  <br>        <span class="hljs-keyword">if</span> opt.occlusion:  <br>            warped_clothmask_paired = remove_overlap(F.softmax(fake_segmap, dim=<span class="hljs-number">1</span>), warped_clothmask_paired)  <br>            warped_cloth_paired = warped_cloth_paired * warped_clothmask_paired + torch.ones_like(  <br>                warped_cloth_paired) * (<span class="hljs-number">1</span> - warped_clothmask_paired)  <br>  <br>        <span class="hljs-comment"># generated fake cloth mask &amp; misalign mask  </span><br>        fake_clothmask = (torch.argmax(fake_segmap.detach(), dim=<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">True</span>) == <span class="hljs-number">3</span>).long()  <br>        misalign = fake_clothmask - warped_cm_onehot  <br>        misalign[misalign &lt; <span class="hljs-number">0.0</span>] = <span class="hljs-number">0.0</span>  <br>  <br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(opt.num_test_visualize):  <br>        grid = make_grid([(c_paired[i].cpu() / <span class="hljs-number">2</span> + <span class="hljs-number">0.5</span>), (cm_paired[i].cpu()).expand(<span class="hljs-number">3</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>),  <br>                          visualize_segmap(parse_agnostic.cpu(), batch=i), ((densepose.cpu()[i] + <span class="hljs-number">1</span>) / <span class="hljs-number">2</span>),  <br>                          (im_c[i].cpu() / <span class="hljs-number">2</span> + <span class="hljs-number">0.5</span>), parse_cloth_mask[i].cpu().expand(<span class="hljs-number">3</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>),  <br>                          (warped_cloth_paired[i].cpu().detach() / <span class="hljs-number">2</span> + <span class="hljs-number">0.5</span>),  <br>                          (warped_cm_onehot[i].cpu().detach()).expand(<span class="hljs-number">3</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>),  <br>                          visualize_segmap(label.cpu(), batch=i), visualize_segmap(fake_segmap.cpu(), batch=i),  <br>                          (im[i] / <span class="hljs-number">2</span> + <span class="hljs-number">0.5</span>), (misalign[i].cpu().detach()).expand(<span class="hljs-number">3</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>)],  <br>                         nrow=<span class="hljs-number">4</span>)  <br>        board.add_images(<span class="hljs-string">f&#x27;test_images/<span class="hljs-subst">&#123;i&#125;</span>&#x27;</span>, grid.unsqueeze(<span class="hljs-number">0</span>), step + <span class="hljs-number">1</span>)  <br>    tocg.train()<br></code></pre></td></tr></table></figure><p>这段代码和上面的差不多，只是做的是test时候的visualization。这个train函数训练到一定的时候，不仅会看看在训练集上的效果，还会加载一些测试集的数据来评估一下。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># display  </span><br><span class="hljs-keyword">if</span> (step + <span class="hljs-number">1</span>) % opt.display_count == <span class="hljs-number">0</span>:  <br>    t = time.time() - iter_start_time  <br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.no_GAN_loss:  <br>        <span class="hljs-built_in">print</span>(  <br>            <span class="hljs-string">&quot;step: %8d, time: %.3f\nloss G: %.4f, L1_cloth loss: %.4f, VGG loss: %.4f, TV loss: %.4f CE: %.4f, G GAN: %.4f\nloss D: %.4f, D real: %.4f, D fake: %.4f&quot;</span>  <br>            % (step + <span class="hljs-number">1</span>, t, loss_G.item(), loss_l1_cloth.item(), loss_vgg.item(), loss_tv.item(), CE_loss.item(),  <br>               loss_G_GAN.item(), loss_D.item(), loss_D_real.item(), loss_D_fake.item()), flush=<span class="hljs-literal">True</span>)  <br>  <br><span class="hljs-comment"># save  </span><br><span class="hljs-keyword">if</span> (step + <span class="hljs-number">1</span>) % opt.save_count == <span class="hljs-number">0</span>:  <br>    save_checkpoint(tocg, os.path.join(opt.checkpoint_dir, opt.name, <span class="hljs-string">&#x27;tocg_step_%06d.pth&#x27;</span> % (step + <span class="hljs-number">1</span>)), opt)  <br>    save_checkpoint(D, os.path.join(opt.checkpoint_dir, opt.name, <span class="hljs-string">&#x27;D_step_%06d.pth&#x27;</span> % (step + <span class="hljs-number">1</span>)), opt)<br></code></pre></td></tr></table></figure><p>这部分代码是用于在训练过程中进行显示和保存操作。</p><ol type="1"><li><strong>显示（Display）</strong>：当达到一定的步数间隔时，通过 <code>opt.display_count</code> 控制，会打印当前训练的一些信息，例如损失值、当前步数、训练时间等，以便实时监控训练过程中的情况。这可以帮助调试和监控模型的训练过程。</li><li><strong>保存（Save）</strong>：当达到一定的步数间隔时，通过 <code>opt.save_count</code> 控制，会保存当前的模型参数到文件中。这样可以定期保存模型的状态，以便在需要时进行恢复或者继续训练。</li></ol><p>然后就是调用train的main函数，就没什么特别的了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():<br>    opt = get_opt()<br>    <span class="hljs-built_in">print</span>(opt)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Start to train %s!&quot;</span> % opt.name)<br>    os.environ[<span class="hljs-string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>] = opt.gpu_ids<br>    <br>    <span class="hljs-comment"># create train dataset &amp; loader</span><br>    train_dataset = CPDataset(opt)<br>    train_loader = CPDataLoader(opt, train_dataset)<br>    <br>    <span class="hljs-comment"># create test dataset &amp; loader</span><br>    test_loader = <span class="hljs-literal">None</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.no_test_visualize:<br>        train_bsize = opt.batch_size<br>        opt.batch_size = opt.num_test_visualize<br>        opt.dataroot = opt.test_dataroot<br>        opt.datamode = <span class="hljs-string">&#x27;test&#x27;</span><br>        opt.data_list = opt.test_data_list<br>        test_dataset = CPDatasetTest(opt)<br>        opt.batch_size = train_bsize<br>        val_dataset = Subset(test_dataset, np.arange(<span class="hljs-number">2000</span>))<br>        test_loader = CPDataLoader(opt, test_dataset)<br>        val_loader = CPDataLoader(opt, val_dataset)<br>    <span class="hljs-comment"># visualization</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(opt.tensorboard_dir):<br>        os.makedirs(opt.tensorboard_dir)<br>    board = SummaryWriter(log_dir=os.path.join(opt.tensorboard_dir, opt.name))<br><br>    <span class="hljs-comment"># Model</span><br>    input1_nc = <span class="hljs-number">4</span>  <span class="hljs-comment"># cloth + cloth-mask</span><br>    input2_nc = opt.semantic_nc + <span class="hljs-number">3</span>  <span class="hljs-comment"># parse_agnostic + densepose</span><br>    tocg = ConditionGenerator(opt, input1_nc=<span class="hljs-number">4</span>, input2_nc=input2_nc, output_nc=opt.output_nc, ngf=<span class="hljs-number">96</span>, norm_layer=nn.BatchNorm2d)<br>    D = define_D(input_nc=input1_nc + input2_nc + opt.output_nc, Ddownx2 = opt.Ddownx2, Ddropout = opt.Ddropout, n_layers_D=<span class="hljs-number">3</span>, spectral = opt.spectral, num_D = opt.num_D)<br>    <br>    <span class="hljs-comment"># Load Checkpoint</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.tocg_checkpoint == <span class="hljs-string">&#x27;&#x27;</span> <span class="hljs-keyword">and</span> os.path.exists(opt.tocg_checkpoint):<br>        load_checkpoint(tocg, opt.tocg_checkpoint)<br><br>    <span class="hljs-comment"># Train</span><br>    train(opt, train_loader, val_loader, test_loader, board, tocg, D)<br><br>    <span class="hljs-comment"># Save Checkpoint</span><br>    save_checkpoint(tocg, os.path.join(opt.checkpoint_dir, opt.name, <span class="hljs-string">&#x27;tocg_final.pth&#x27;</span>),opt)<br>    save_checkpoint(D, os.path.join(opt.checkpoint_dir, opt.name, <span class="hljs-string">&#x27;D_final.pth&#x27;</span>),opt)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Finished training %s!&quot;</span> % opt.name)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    main()<br></code></pre></td></tr></table></figure><h1 id="train_generator.py">train_generator.py</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_opt</span>():<br>    parser = argparse.ArgumentParser()<br><br>    parser.add_argument(<span class="hljs-string">&#x27;--name&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, required=<span class="hljs-literal">True</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;--gpu_ids&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=<span class="hljs-string">&#x27;0&#x27;</span>)<br><br><span class="hljs-comment"># detailes omitted</span><br><br>    opt = parser.parse_args()<br><br>    <span class="hljs-comment"># set gpu ids</span><br>    str_ids = opt.gpu_ids.split(<span class="hljs-string">&#x27;,&#x27;</span>)<br>    opt.gpu_ids = []<br>    <span class="hljs-keyword">for</span> str_id <span class="hljs-keyword">in</span> str_ids:<br>        <span class="hljs-built_in">id</span> = <span class="hljs-built_in">int</span>(str_id)<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">id</span> &gt;= <span class="hljs-number">0</span>:<br>            opt.gpu_ids.append(<span class="hljs-built_in">id</span>)<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(opt.gpu_ids) &gt; <span class="hljs-number">0</span>:<br>        torch.cuda.set_device(opt.gpu_ids[<span class="hljs-number">0</span>])<br><br>    <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(opt.gpu_ids) == <span class="hljs-number">0</span> <span class="hljs-keyword">or</span> opt.batch_size % <span class="hljs-built_in">len</span>(opt.gpu_ids) == <span class="hljs-number">0</span>, \<br>        <span class="hljs-string">&quot;Batch size %d is wrong. It must be a multiple of # GPUs %d.&quot;</span> \<br>        % (opt.batch_size, <span class="hljs-built_in">len</span>(opt.gpu_ids))<br><br>    <span class="hljs-keyword">return</span> opt<br></code></pre></td></tr></table></figure><p>这里还是调用parser来获取用户的参数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">opt, train_loader, test_loader, test_vis_loader, board, tocg, generator, discriminator, model</span>):  <br>    <span class="hljs-comment"># Model  </span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.GT:  <br>        tocg.cuda()  <br>        tocg.<span class="hljs-built_in">eval</span>()  <br>    generator.train()  <br>    discriminator.train()  <br>    model.<span class="hljs-built_in">eval</span>()<br></code></pre></td></tr></table></figure><p>这里opt.GT控制是使用真实的数据（segmentation map）训练还是使用tocg生成的segmentation map进行训练。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># criterion  </span><br><span class="hljs-keyword">if</span> opt.fp16:  <br>    criterionGAN = GANLoss(<span class="hljs-string">&#x27;hinge&#x27;</span>, tensor=torch.cuda.HalfTensor)  <br><span class="hljs-keyword">else</span>:  <br>    criterionGAN = GANLoss(<span class="hljs-string">&#x27;hinge&#x27;</span>, tensor=torch.cuda.FloatTensor)  <br><span class="hljs-comment"># criterionL1 = nn.L1Loss()  </span><br>criterionFeat = nn.L1Loss()  <br>criterionVGG = VGGLoss(opt)  <br>  <br><span class="hljs-comment"># optimizer  </span><br>optimizer_gen = torch.optim.Adam(generator.parameters(), lr=opt.G_lr, betas=(<span class="hljs-number">0</span>, <span class="hljs-number">0.9</span>))  <br>scheduler_gen = torch.optim.lr_scheduler.LambdaLR(optimizer_gen, lr_lambda=<span class="hljs-keyword">lambda</span> step: <span class="hljs-number">1.0</span> -  <span class="hljs-built_in">max</span>(<span class="hljs-number">0</span>,step * <span class="hljs-number">1000</span> + opt.load_step - opt.keep_step) / <span class="hljs-built_in">float</span>(opt.decay_step + <span class="hljs-number">1</span>))  <br><br>optimizer_dis = torch.optim.Adam(discriminator.parameters(), lr=opt.D_lr, betas=(<span class="hljs-number">0</span>, <span class="hljs-number">0.9</span>))  <br>scheduler_dis = torch.optim.lr_scheduler.LambdaLR(optimizer_dis, lr_lambda=<span class="hljs-keyword">lambda</span> step: <span class="hljs-number">1.0</span> -  <span class="hljs-built_in">max</span>(<span class="hljs-number">0</span>, step * <span class="hljs-number">1000</span> + opt.load_step - opt.keep_step) / <span class="hljs-built_in">float</span>(opt.decay_step + <span class="hljs-number">1</span>))<br></code></pre></td></tr></table></figure><p>这里使用hinge loss。</p><p>这里还使用了学习率调度器（scheduler）。在深度学习训练过程中，学习率调度器（scheduler）是用来调整优化器的学习率的工具，以便控制训练过程中的学习速度。在这段代码中，使用的是 <code>torch.optim.lr_scheduler.LambdaLR</code> 调度器。这个调度器通过一个 lambda 函数来自定义学习率的调整策略，这提供了很大的灵活性。</p><p>这里的学习率调整策略为 <span class="math display">\[\lambda(\text{step}) = 1.0 - \frac{\max(0, \text{step} \times 1000 + \text{opt.load\_step} - \text{opt.keep\_step})}{\text{opt.decay\_step} + 1}\]</span> <strong>公式分析：</strong> 参数的含义：</p><p><strong>opt.load_step</strong></p><ul><li><strong>含义</strong>：<code>opt.load_step</code> 通常指的是从哪一个训练步骤开始加载模型继续训练。这个参数在恢复中断的训练或从预训练模型开始训练时特别有用。它表示已经执行的训练步骤数，用于确保学习率调度和其他训练逻辑可以从正确的时间点开始。</li></ul><p><strong>opt.keep_step</strong></p><ul><li><strong>含义</strong>：<code>opt.keep_step</code> 是指在训练过程中保持初始学习率不变的步数。换句话说，这是一个阈值，直到该步数之前，学习率将保持为开始时设置的初始值。</li><li><strong>作用</strong>：通过设定一个初始阶段在该步数内不改变学习率，可以让模型在训练初期快速下降到一个合理的损失水平。在很多优化任务中，初期使用较高的固定学习率可以帮助模型跳出不良的局部最小值，或更快地接近全局最小值。</li></ul><p><strong>opt.decay_step</strong></p><ul><li><strong>含义</strong>：<code>opt.decay_step</code> 定义了从 <code>opt.keep_step</code> 计算起，学习率需要经过多少步骤减少到0或接近0的一个阈值。它是学习率开始衰减后，直到衰减结束的步数总和。</li><li><strong>作用</strong>：这个参数控制了学习率衰减的速度和持续时间。较大的 <code>decay_step</code> 值意味着学习率将以较慢的速度减少，这可能有助于模型在接近优化问题的解时进行更细致的调整。相反，较小的 <code>decay_step</code> 值会使学习率较快减小，这可能在某些需要快速收敛的场景中更为适合。</li></ul><p><strong>step * 1000</strong></p><ul><li><strong>含义</strong>：在这个表达式中，<code>step * 1000</code> 很可能是用来加速学习率衰减过程的一个因子。这里的 <code>1000</code> 是一个放大系数，用于增加每一步对学习率调整影响的幅度。</li><li><strong>作用</strong>：这个乘法因子可以看作是加速衰减的一种方式。在许多训练场景中，可能希望在训练初期保持较高的学习率，而在经过较少的训练迭代后迅速减小学习率。<code>step * 1000</code> 通过增加步骤的权重，使得学习率在经过较少的迭代后迅速接近衰减的阶段，这样可以在训练早期快速探索，之后快速细化。</li></ul><p>我们其实可以先把这个公式看成 <span class="math display">\[\lambda(\text{step}) = 1.0 - \frac{\max(0, \text{step} + \text{opt.load\_step} - \text{opt.keep\_step})}{\text{opt.decay\_step} + 1}\]</span></p><p>这里step+load_step就表示真正的训练步数，然后在达到keep_step之前，分子一直是为0的，所以学习率一直保持不变，然后到了keep_step之后，经过decay_step步后衰减为0。这里分母decay_step加了1使代码更robust，防止除以0的错误。然后原始的公式step乘以了1000，也就是说分子近似于变为之前的1000倍，让 <span class="math inline">\(\lambda\)</span> 的衰减更快。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> opt.fp16:  <br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.GT:  <br>        <span class="hljs-keyword">from</span> apex <span class="hljs-keyword">import</span> amp  <br>        [tocg, generator, discriminator], [optimizer_gen, optimizer_dis] = amp.initialize(  <br>            [tocg, generator, discriminator], [optimizer_gen, optimizer_dis], opt_level=<span class="hljs-string">&#x27;O1&#x27;</span>, num_losses=<span class="hljs-number">2</span>)  <br>    <br>    <span class="hljs-keyword">else</span>:  <br>        <span class="hljs-keyword">from</span> apex <span class="hljs-keyword">import</span> amp  <br>        [generator, discriminator], [optimizer_gen, optimizer_dis] = amp.initialize(  <br>            [generator, discriminator], [optimizer_gen, optimizer_dis], opt_level=<span class="hljs-string">&#x27;O1&#x27;</span>, num_losses=<span class="hljs-number">2</span>)<br></code></pre></td></tr></table></figure><p>这部分代码涉及到混合精度训练（Mixed Precision Training），这是一种可以加快深度学习模型训练速度并减少模型训练或推断时所需内存的技术。在这个代码段中，使用了NVIDIA的 <code>apex</code> 库中的 <code>amp</code> (Automatic Mixed Precision) 模块来实现混合精度训练。</p><ol type="1"><li><strong>检查是否使用半精度（FP16）</strong>:<ul><li><code>if opt.fp16</code>: 这一行检查是否配置了使用FP16精度。FP16精度使用16位浮点数存储和计算，与传统的32位（FP32）相比，可以减少内存占用并提高计算速度。</li></ul></li><li><strong>混合精度初始化</strong>:<ul><li><code>from apex import amp</code>: 导入 <code>amp</code> 模块，它是专为PyTorch设计的，用于实现自动混合精度功能。</li><li><code>amp.initialize(...)</code>: 这个函数用于初始化模型和优化器以使用混合精度。它接收模型和优化器作为输入，并返回经过修改的模型和优化器，这些都是为混合精度训练准备的。</li></ul></li><li><strong>优化级别和损失数量</strong>:<ul><li><code>opt_level='O1'</code>: 这个参数指定了混合精度的优化级别。<code>O1</code> 是常用的优化级别之一，它执行动态张量类型转换。这意味着AMP会自动决定何时使用FP16何时使用FP32，以平衡计算速度和数值稳定性。</li><li><code>num_losses=2</code>: 这个参数指示有多少个损失函数会在训练过程中被计算。这对于正确地进行梯度缩放和更新非常关键。</li></ul></li><li><strong>对模型的处理</strong>:<ul><li><code>if not opt.GT</code>: <code>tocg</code>, <code>generator</code>, <code>discriminator</code> 三个模型同时进行混合精度配置。</li><li><code>else</code>: 如果使用GT进行训练，只对 <code>generator</code> 和 <code>discriminator</code> 进行混合精度配置。</li></ul></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(opt.gpu_ids) &gt; <span class="hljs-number">0</span>:<br>       <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.GT:<br>           tocg = DataParallelWithCallback(tocg, device_ids=opt.gpu_ids)<br>       generator = DataParallelWithCallback(generator, device_ids=opt.gpu_ids)<br>       discriminator = DataParallelWithCallback(discriminator, device_ids=opt.gpu_ids)<br>       criterionGAN = DataParallelWithCallback(criterionGAN, device_ids=opt.gpu_ids)<br>       criterionFeat = DataParallelWithCallback(criterionFeat, device_ids=opt.gpu_ids)<br>       criterionVGG = DataParallelWithCallback(criterionVGG, device_ids=opt.gpu_ids)<br>       <br>   upsample = torch.nn.Upsample(scale_factor=<span class="hljs-number">4</span>, mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>)<br>   gauss = tgm.image.GaussianBlur((<span class="hljs-number">15</span>, <span class="hljs-number">15</span>), (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>))<br>   gauss = gauss.cuda()<br></code></pre></td></tr></table></figure><p>这里的<code>DataParallelWithCallback</code>与<code>torch.nn.DataParallel</code>类似。</p><h3 id="dataparallel-工作原理">DataParallel 工作原理</h3><ol type="1"><li><strong>复制模型</strong>：在使用 <code>DataParallel</code> 时，首先在每个 GPU 上复制一份完整的模型。</li><li><strong>分割数据</strong>：将输入数据分割成多个小批次，每个批次由一个 GPU 处理。</li><li><strong>并行计算</strong>：每个 GPU 接收到分配给它的数据后，独立地进行前向和反向计算。</li><li><strong>梯度聚合</strong>：所有 GPU 上的梯度会被聚合到主 GPU 上，然后更新模型参数。</li><li><strong>同步参数</strong>：更新后的模型参数会从主 GPU 同步到其他所有 GPU，确保所有 GPU 上的模型保持一致。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> step <span class="hljs-keyword">in</span> tqdm(<span class="hljs-built_in">range</span>(opt.load_step, opt.keep_step + opt.decay_step)):  <br>    iter_start_time = time.time()  <br>    inputs = train_loader.next_batch()  <br>  <br>    <span class="hljs-comment"># input  </span><br>    agnostic = inputs[<span class="hljs-string">&#x27;agnostic&#x27;</span>].cuda()  <br>    parse_GT = inputs[<span class="hljs-string">&#x27;parse&#x27;</span>].cuda()  <br>    pose = inputs[<span class="hljs-string">&#x27;densepose&#x27;</span>].cuda()  <br>    parse_cloth = inputs[<span class="hljs-string">&#x27;parse_cloth&#x27;</span>].cuda()  <br>    parse_agnostic = inputs[<span class="hljs-string">&#x27;parse_agnostic&#x27;</span>].cuda()  <br>    pcm = inputs[<span class="hljs-string">&#x27;pcm&#x27;</span>].cuda()  <br>    cm = inputs[<span class="hljs-string">&#x27;cloth_mask&#x27;</span>][<span class="hljs-string">&#x27;paired&#x27;</span>].cuda()  <br>    c_paired = inputs[<span class="hljs-string">&#x27;cloth&#x27;</span>][<span class="hljs-string">&#x27;paired&#x27;</span>].cuda()  <br>  <br>    <span class="hljs-comment"># target  </span><br>    im = inputs[<span class="hljs-string">&#x27;image&#x27;</span>].cuda()<br></code></pre></td></tr></table></figure><p>然后这里就是开始正式训练。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">with</span> torch.no_grad():  <br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.GT:  <br>        <span class="hljs-comment"># Warping Cloth  </span><br>        <span class="hljs-comment"># down        pre_clothes_mask_down = F.interpolate(cm, size=(256, 192), mode=&#x27;nearest&#x27;)  </span><br>        input_parse_agnostic_down = F.interpolate(parse_agnostic, size=(<span class="hljs-number">256</span>, <span class="hljs-number">192</span>), mode=<span class="hljs-string">&#x27;nearest&#x27;</span>)  <br>        clothes_down = F.interpolate(c_paired, size=(<span class="hljs-number">256</span>, <span class="hljs-number">192</span>), mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>)  <br>        densepose_down = F.interpolate(pose, size=(<span class="hljs-number">256</span>, <span class="hljs-number">192</span>), mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>)  <br>  <br>        <span class="hljs-comment"># multi-task inputs  </span><br>        input1 = torch.cat([clothes_down, pre_clothes_mask_down], <span class="hljs-number">1</span>)  <br>        input2 = torch.cat([input_parse_agnostic_down, densepose_down], <span class="hljs-number">1</span>)  <br>  <br>        <span class="hljs-comment"># forward  </span><br>        flow_list, fake_segmap, _, warped_clothmask_paired = tocg(input1, input2)  <br>  <br>        <span class="hljs-comment"># warped cloth mask one hot   </span><br>warped_cm_onehot = torch.FloatTensor(  <br>            (warped_clothmask_paired.detach().cpu().numpy() &gt; <span class="hljs-number">0.5</span>).astype(np.<span class="hljs-built_in">float</span>)).cuda()  <br>  <br>        <span class="hljs-keyword">if</span> opt.clothmask_composition != <span class="hljs-string">&#x27;no_composition&#x27;</span>:  <br>            <span class="hljs-keyword">if</span> opt.clothmask_composition == <span class="hljs-string">&#x27;detach&#x27;</span>:  <br>                cloth_mask = torch.ones_like(fake_segmap)  <br>                cloth_mask[:, <span class="hljs-number">3</span>:<span class="hljs-number">4</span>, :, :] = warped_cm_onehot  <br>                fake_segmap = fake_segmap * cloth_mask  <br>  <br>            <span class="hljs-keyword">if</span> opt.clothmask_composition == <span class="hljs-string">&#x27;warp_grad&#x27;</span>:  <br>                cloth_mask = torch.ones_like(fake_segmap)  <br>                cloth_mask[:, <span class="hljs-number">3</span>:<span class="hljs-number">4</span>, :, :] = warped_clothmask_paired  <br>                fake_segmap = fake_segmap * cloth_mask<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">N, _, iH, iW = c_paired.shape  <br>grid = make_grid(N, iH, iW, opt)  <br>flow = F.interpolate(flow_list[-<span class="hljs-number">1</span>].permute(<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>), size=(iH, iW), mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>).permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)  <br>flow_norm = torch.cat([flow[:, :, :, <span class="hljs-number">0</span>:<span class="hljs-number">1</span>] / ((<span class="hljs-number">96</span> - <span class="hljs-number">1.0</span>) / <span class="hljs-number">2.0</span>), flow[:, :, :, <span class="hljs-number">1</span>:<span class="hljs-number">2</span>] / ((<span class="hljs-number">128</span> - <span class="hljs-number">1.0</span>) / <span class="hljs-number">2.0</span>)], <span class="hljs-number">3</span>)  <br>warped_grid = grid + flow_norm  <br>warped_cloth_paired = F.grid_sample(c_paired, warped_grid, padding_mode=<span class="hljs-string">&#x27;border&#x27;</span>).detach()  <br>warped_clothmask = F.grid_sample(cm, warped_grid, padding_mode=<span class="hljs-string">&#x27;border&#x27;</span>)<br></code></pre></td></tr></table></figure><p>这里是对光流场进行归一化。</p><p>在图像处理中，尤其是在使用网格采样 (<code>grid_sample</code>) 进行图像变形时，光流场必须归一化到 <code>[-1, 1]</code> 的范围内。这是因为 <code>grid_sample</code> 函数期望网格坐标在这个范围内，其中 <code>-1</code> 和 <code>1</code> 分别表示图像的边缘。如果光流数据没有正确归一化，变形效果可能会超出图像边界或无法正确对齐，从而导致图像质量下降或者边缘出现不期望的效果。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># make generator input parse map  </span><br>fake_parse_gauss = gauss(F.interpolate(fake_segmap, size=(iH, iW), mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>))  <br>fake_parse = fake_parse_gauss.argmax(dim=<span class="hljs-number">1</span>)[:, <span class="hljs-literal">None</span>]<br></code></pre></td></tr></table></figure><p><strong>高斯模糊</strong>： <code>gauss(...)</code>：应用高斯模糊函数到缩放后的 <code>fake_segmap</code> 上。高斯模糊是一种常用的图像平滑技术，用于去除图像噪声或细节，可以使图像的类别边界更加柔和。这在处理分割图时特别有用，因为它有助于减少类别边界处的锯齿效应或像素级的分类错误。</p><p><strong>求最大值索引</strong>： <code>fake_parse_gauss.argmax(dim=1)[:, None]</code>：这一步是从经过高斯模糊处理的分割图 <code>fake_parse_gauss</code> 中，沿特定维度（这里是维度 1，通常对应于通道维，假设每个通道代表一个特定的类别）求取最大值的索引。这意味着每个像素位置都会被赋予其最可能的类别标签。</p><p><code>[:, None]</code> 这部分是为了在结果中添加一个新的单通道维度，从而将这个二维数据转换为三维数据结构。保持一个统一的数据维度格式有助于减少数据处理中的错误，使得模型的设计和实现更加清晰和一致。</p><p>如果不用ground_truth进行训练，就先调用tocg产生相应的fake_segmap。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">else</span>:  <br><span class="hljs-comment"># parse pre-process  </span><br>    fake_parse = parse_GT.argmax(dim=<span class="hljs-number">1</span>)[:, <span class="hljs-literal">None</span>]  <br>    warped_cloth_paired = parse_cloth<br></code></pre></td></tr></table></figure><p>否则就用真实图像的segmentation map。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python">old_parse = torch.FloatTensor(fake_parse.size(<span class="hljs-number">0</span>), <span class="hljs-number">13</span>, opt.fine_height, opt.fine_width).zero_().cuda()  <br>old_parse.scatter_(<span class="hljs-number">1</span>, fake_parse, <span class="hljs-number">1.0</span>)  <br>  <br>labels = &#123;  <br>    <span class="hljs-number">0</span>: [<span class="hljs-string">&#x27;background&#x27;</span>, [<span class="hljs-number">0</span>]],  <br>    <span class="hljs-number">1</span>: [<span class="hljs-string">&#x27;paste&#x27;</span>, [<span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">9</span>, <span class="hljs-number">10</span>, <span class="hljs-number">11</span>]],  <br>    <span class="hljs-number">2</span>: [<span class="hljs-string">&#x27;upper&#x27;</span>, [<span class="hljs-number">3</span>]],  <br>    <span class="hljs-number">3</span>: [<span class="hljs-string">&#x27;hair&#x27;</span>, [<span class="hljs-number">1</span>]],  <br>    <span class="hljs-number">4</span>: [<span class="hljs-string">&#x27;left_arm&#x27;</span>, [<span class="hljs-number">5</span>]],  <br>    <span class="hljs-number">5</span>: [<span class="hljs-string">&#x27;right_arm&#x27;</span>, [<span class="hljs-number">6</span>]],  <br>    <span class="hljs-number">6</span>: [<span class="hljs-string">&#x27;noise&#x27;</span>, [<span class="hljs-number">12</span>]]  <br>&#125;  <br>parse = torch.FloatTensor(fake_parse.size(<span class="hljs-number">0</span>), <span class="hljs-number">7</span>, opt.fine_height, opt.fine_width).zero_().cuda()  <br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(labels)):  <br>    <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> labels[i][<span class="hljs-number">1</span>]:  <br>        parse[:, i] += old_parse[:, label]  <br>  <br>parse = parse.detach()<br></code></pre></td></tr></table></figure><p>这里又调整了原始的segmentation map。</p><p><code>"paste"</code> 类别的意义：</p><ul><li><code>"paste"</code> 在这里作为一个类别名称，很可能是为了简化模型处理的复杂性而创造的一个集合类别，它合并了多种不同的衣物和配件。这种合并可能是因为这些元素在特定任务（如风格迁移、虚拟试衣等）中具有相似的处理方式或者对结果的影响类似。</li><li>将多个类别合并为一个 <code>"paste"</code> 类别可以减少模型需要直接处理的类别总数，简化学习任务，尤其是在类别间差异不大或者对最终任务影响不大的情况下。</li></ul><p>这里再贴一个parse label的参考表来作为对照。 <figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs markdown"><span class="hljs-bullet">0.</span> Background<br><span class="hljs-bullet">1.</span> Hat<br><span class="hljs-bullet">2.</span> Hair<br><span class="hljs-bullet">3.</span> Glove<br><span class="hljs-bullet">4.</span> Sunglasses<br><span class="hljs-bullet">5.</span> Upper-clothes<br><span class="hljs-bullet">6.</span> Dress<br><span class="hljs-bullet">7.</span> Coat<br><span class="hljs-bullet">8.</span> Socks<br><span class="hljs-bullet">9.</span> Pants<br><span class="hljs-bullet">10.</span> Jumpsuits<br><span class="hljs-bullet">11.</span> Scarf<br><span class="hljs-bullet">12.</span> Skirt<br><span class="hljs-bullet">13.</span> Face<br><span class="hljs-bullet">14.</span> Left-arm<br><span class="hljs-bullet">15.</span> Right-arm<br><span class="hljs-bullet">16.</span> Left-leg<br><span class="hljs-bullet">17.</span> Right-leg<br><span class="hljs-bullet">18.</span> Left-shoe<br><span class="hljs-bullet">19.</span> Right-shoe<br></code></pre></td></tr></table></figure></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Train the generator  </span><br>output_paired = generator(torch.cat((agnostic, pose, warped_cloth_paired), dim=<span class="hljs-number">1</span>), parse)  <br>  <br>fake_concat = torch.cat((parse, output_paired), dim=<span class="hljs-number">1</span>)  <br>real_concat = torch.cat((parse, im), dim=<span class="hljs-number">1</span>)  <br>pred = discriminator(torch.cat((fake_concat, real_concat), dim=<span class="hljs-number">0</span>))  <br>  <br><span class="hljs-comment"># the prediction contains the intermediate outputs of multiscale GAN,  </span><br><span class="hljs-comment"># so it&#x27;s usually a list  </span><br><span class="hljs-keyword">if</span> <span class="hljs-built_in">type</span>(pred) == <span class="hljs-built_in">list</span>:  <br>    pred_fake = []  <br>    pred_real = []  <br>    <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> pred:  <br>        pred_fake.append([tensor[:tensor.size(<span class="hljs-number">0</span>) // <span class="hljs-number">2</span>] <span class="hljs-keyword">for</span> tensor <span class="hljs-keyword">in</span> p])  <br>        pred_real.append([tensor[tensor.size(<span class="hljs-number">0</span>) // <span class="hljs-number">2</span>:] <span class="hljs-keyword">for</span> tensor <span class="hljs-keyword">in</span> p])  <br><span class="hljs-keyword">else</span>:  <br>    pred_fake = pred[:pred.size(<span class="hljs-number">0</span>) // <span class="hljs-number">2</span>]  <br>    pred_real = pred[pred.size(<span class="hljs-number">0</span>) // <span class="hljs-number">2</span>:]  <br>  <br>G_losses = &#123;&#125;  <br>G_losses[<span class="hljs-string">&#x27;GAN&#x27;</span>] = criterionGAN(pred_fake, <span class="hljs-literal">True</span>, for_discriminator=<span class="hljs-literal">False</span>)  <br>  <br><span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.no_ganFeat_loss:  <br>    num_D = <span class="hljs-built_in">len</span>(pred_fake)  <br>    GAN_Feat_loss = torch.cuda.FloatTensor(<span class="hljs-built_in">len</span>(opt.gpu_ids)).zero_()  <br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_D):  <span class="hljs-comment"># for each discriminator  </span><br>        <span class="hljs-comment"># last output is the final prediction, so we exclude it        num_intermediate_outputs = len(pred_fake[i]) - 1  </span><br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_intermediate_outputs):  <span class="hljs-comment"># for each layer output  </span><br>            unweighted_loss = criterionFeat(pred_fake[i][j], pred_real[i][j].detach())  <br>            GAN_Feat_loss += unweighted_loss * opt.lambda_feat / num_D  <br>    G_losses[<span class="hljs-string">&#x27;GAN_Feat&#x27;</span>] = GAN_Feat_loss  <br>  <br><span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.no_vgg_loss:  <br>    G_losses[<span class="hljs-string">&#x27;VGG&#x27;</span>] = criterionVGG(output_paired, im) * opt.lambda_vgg  <br>  <br>loss_gen = <span class="hljs-built_in">sum</span>(G_losses.values()).mean()  <br>  <br>optimizer_gen.zero_grad()  <br><span class="hljs-keyword">if</span> opt.fp16:  <br>    <span class="hljs-keyword">with</span> amp.scale_loss(loss_gen, optimizer_gen, loss_id=<span class="hljs-number">0</span>) <span class="hljs-keyword">as</span> loss_gen_scaled:  <br>        loss_gen_scaled.backward()  <br><span class="hljs-keyword">else</span>:  <br>    loss_gen.backward()  <br>optimizer_gen.step()<br></code></pre></td></tr></table></figure><p>首先把<code>torch.cat((agnostic, pose, warped_cloth_paired)</code>输入进去产生假的图像。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">fake_concat = torch.cat((parse, output_paired), dim=<span class="hljs-number">1</span>)  <br>real_concat = torch.cat((parse, im), dim=<span class="hljs-number">1</span>)<br>pred = discriminator(torch.cat((fake_concat, real_concat), dim=<span class="hljs-number">0</span>))  <br></code></pre></td></tr></table></figure><p>然后把生成的和parse拼接在一起作为fake_concat，把GT和parse拼接在一起作为real_concat。然后传给discriminator让它来分辨。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> <span class="hljs-built_in">type</span>(pred) == <span class="hljs-built_in">list</span>:  <br>    pred_fake = []  <br>    pred_real = []  <br>    <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> pred:  <br>        pred_fake.append([tensor[:tensor.size(<span class="hljs-number">0</span>) // <span class="hljs-number">2</span>] <span class="hljs-keyword">for</span> tensor <span class="hljs-keyword">in</span> p])  <br>        pred_real.append([tensor[tensor.size(<span class="hljs-number">0</span>) // <span class="hljs-number">2</span>:] <span class="hljs-keyword">for</span> tensor <span class="hljs-keyword">in</span> p])  <br><span class="hljs-keyword">else</span>:  <br>    pred_fake = pred[:pred.size(<span class="hljs-number">0</span>) // <span class="hljs-number">2</span>]  <br>    pred_real = pred[pred.size(<span class="hljs-number">0</span>) // <span class="hljs-number">2</span>:]<br></code></pre></td></tr></table></figure><p>然后由于discriminator在不同分辨率下都产生了一个prediction，所以<code>pred</code>大概率是一个列表。然后把第一个维度（batch维度）的前一半加入到pred_fake中（对fake_concat的prediction），把第一个维度的后一半加入到pred_real中（对real_concat的prediction）。（因为discriminator的输入是fake_concat 和 real_concat 的 concatenation。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python">G_losses = &#123;&#125;  <br>G_losses[<span class="hljs-string">&#x27;GAN&#x27;</span>] = criterionGAN(pred_fake, <span class="hljs-literal">True</span>, for_discriminator=<span class="hljs-literal">False</span>)  <br>  <br><span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.no_ganFeat_loss:  <br>    num_D = <span class="hljs-built_in">len</span>(pred_fake)  <br>    GAN_Feat_loss = torch.cuda.FloatTensor(<span class="hljs-built_in">len</span>(opt.gpu_ids)).zero_()  <br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_D):  <span class="hljs-comment"># for each discriminator  </span><br>        <span class="hljs-comment"># last output is the final prediction, so we exclude it        num_intermediate_outputs = len(pred_fake[i]) - 1  </span><br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_intermediate_outputs):  <span class="hljs-comment"># for each layer output  </span><br>            unweighted_loss = criterionFeat(pred_fake[i][j], pred_real[i][j].detach())  <br>            GAN_Feat_loss += unweighted_loss * opt.lambda_feat / num_D  <br>    G_losses[<span class="hljs-string">&#x27;GAN_Feat&#x27;</span>] = GAN_Feat_loss<br></code></pre></td></tr></table></figure><p>然后先在Generator的Loss里面加入一个hinge Loss。</p><p>然后如果要ganFeat_loss的话，就相应的计算Generator生成的图片经过Discriminator分辨的结果与真实图片之间的差距，这个差距越小越好。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.no_vgg_loss:  <br>    G_losses[<span class="hljs-string">&#x27;VGG&#x27;</span>] = criterionVGG(output_paired, im) * opt.lambda_vgg<br></code></pre></td></tr></table></figure><p>然后加入VGG Loss。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">loss_gen = <span class="hljs-built_in">sum</span>(G_losses.values()).mean()  <br>  <br>optimizer_gen.zero_grad()  <br><span class="hljs-keyword">if</span> opt.fp16:  <br>    <span class="hljs-keyword">with</span> amp.scale_loss(loss_gen, optimizer_gen, loss_id=<span class="hljs-number">0</span>) <span class="hljs-keyword">as</span> loss_gen_scaled:  <br>        loss_gen_scaled.backward()  <br><span class="hljs-keyword">else</span>:  <br>    loss_gen.backward()  <br>optimizer_gen.step()<br></code></pre></td></tr></table></figure><p>然后就是对loss取平均，然后进行训练。</p><p><code>loss_gen.backward()</code> 或 <code>loss_gen_scaled.backward()</code>：根据是否开启了混合精度训练，使用 PyTorch 的自动求导功能计算生成器模型损失函数关于参数的梯度。</p><p><code>optimizer_gen.step()</code>：根据计算得到的梯度更新生成器模型的参数，这是优化器的一次迭代步骤。</p><p>接下来用类似的方法训练Discriminator。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">with</span> torch.no_grad():  <br>    output = generator(torch.cat((agnostic, pose, warped_cloth_paired), dim=<span class="hljs-number">1</span>), parse)  <br>    output = output.detach()  <br>    output.requires_grad_()  <br>  <br>fake_concat = torch.cat((parse, output), dim=<span class="hljs-number">1</span>)  <br>real_concat = torch.cat((parse, im), dim=<span class="hljs-number">1</span>)  <br>pred = discriminator(torch.cat((fake_concat, real_concat), dim=<span class="hljs-number">0</span>))<br></code></pre></td></tr></table></figure><p>这里不是很懂为什么在detach之后马上又调用<code>requires_grad_()</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">D_losses = &#123;&#125;  <br>D_losses[<span class="hljs-string">&#x27;D_Fake&#x27;</span>] = criterionGAN(pred_fake, <span class="hljs-literal">False</span>, for_discriminator=<span class="hljs-literal">True</span>)  <br>D_losses[<span class="hljs-string">&#x27;D_Real&#x27;</span>] = criterionGAN(pred_real, <span class="hljs-literal">True</span>, for_discriminator=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><p>对于Discriminator，它的loss就是对于假的图片，产生的prediction与全为假的tensor有多少差距，对于真的图片，产生的prediction与全为真的tensor有多少差距。</p><p>然后下面又是一段到一定时间把数据记录到TensorBoard，然后可视化当前产生的图片的代码，这里就不再赘述。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> (step + <span class="hljs-number">1</span>) % opt.tensorboard_count == <span class="hljs-number">0</span>:<br><span class="hljs-comment"># omitted</span><br></code></pre></td></tr></table></figure><p>然后到达一定时间之后也计算 lpips 指标。 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> (step + <span class="hljs-number">1</span>) % opt.lpips_count == <span class="hljs-number">0</span>:  <br>    generator.<span class="hljs-built_in">eval</span>()<br>    <span class="hljs-comment"># omitted</span><br><br>output_paired = generator(torch.cat((agnostic, pose, warped_cloth_paired), dim=<span class="hljs-number">1</span>), parse)  <br>avg_distance += model.forward(T2(im), T2(output_paired))<br><br>avg_distance = avg_distance / <span class="hljs-number">500</span>  <br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;LPIPS<span class="hljs-subst">&#123;avg_distance&#125;</span>&quot;</span>)  <br>board.add_scalar(<span class="hljs-string">&#x27;test/LPIPS&#x27;</span>, avg_distance, step + <span class="hljs-number">1</span>)  <br>  <br>generator.train()<br></code></pre></td></tr></table></figure></p><p>LPIPS（Learned Perceptual Image Patch Similarity）是一种衡量图像之间感知相似度的指标，它使用了深度学习模型来学习图像的感知特征，并根据这些特征来度量图像之间的相似度。这里的model是一个VGG，用来计算perceputal loss。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> (step + <span class="hljs-number">1</span>) % opt.display_count == <span class="hljs-number">0</span>:<br>    t = time.time() - iter_start_time<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;step: %8d, time: %.3f, G_loss: %.4f, G_adv_loss: %.4f, D_loss: %.4f, D_fake_loss: %.4f, D_real_loss: %.4f&quot;</span><br>          % (step + <span class="hljs-number">1</span>, t, loss_gen.item(), G_losses[<span class="hljs-string">&#x27;GAN&#x27;</span>].mean().item(), loss_dis.item(),<br>             D_losses[<span class="hljs-string">&#x27;D_Fake&#x27;</span>].mean().item(), D_losses[<span class="hljs-string">&#x27;D_Real&#x27;</span>].mean().item()), flush=<span class="hljs-literal">True</span>)<br><br><span class="hljs-keyword">if</span> (step + <span class="hljs-number">1</span>) % opt.save_count == <span class="hljs-number">0</span>:<br>    save_checkpoint(generator.module, os.path.join(opt.checkpoint_dir, opt.name, <span class="hljs-string">&#x27;gen_step_%06d.pth&#x27;</span> % (step + <span class="hljs-number">1</span>)), opt)<br>    save_checkpoint(discriminator.module, os.path.join(opt.checkpoint_dir, opt.name, <span class="hljs-string">&#x27;dis_step_%06d.pth&#x27;</span> % (step + <span class="hljs-number">1</span>)),<br>                    opt)<br><br><span class="hljs-keyword">if</span> (step + <span class="hljs-number">1</span>) % <span class="hljs-number">1000</span> == <span class="hljs-number">0</span>:<br>    scheduler_gen.step()<br>    scheduler_dis.step()<br></code></pre></td></tr></table></figure><p>然后<code>if (step + 1) % opt.display_count == 0</code>，就在控制台打印出相应的数据。然后到一定的时候也保存一下检查点。</p><p>在 PyTorch 中，学习率调度器（<code>lr_scheduler</code>）并不会自动在每个训练步骤中更新学习率。它必须通过调用 <code>scheduler.step()</code> 手动进行更新。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():<br>    opt = get_opt()<br>    <span class="hljs-built_in">print</span>(opt)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Start to train %s!&quot;</span> % opt.name)<br><br>    <span class="hljs-comment"># create dataset</span><br>    train_dataset = CPDataset(opt)<br><br>    <span class="hljs-comment"># create dataloader</span><br>    train_loader = CPDataLoader(opt, train_dataset)<br>    <br>    <span class="hljs-comment"># test dataloader</span><br>    opt.batch_size = <span class="hljs-number">1</span><br>    opt.dataroot = opt.test_dataroot<br>    opt.datamode = <span class="hljs-string">&#x27;test&#x27;</span><br>    opt.data_list = opt.test_data_list<br>    test_dataset = CPDatasetTest(opt)<br>    test_dataset = Subset(test_dataset, np.arange(<span class="hljs-number">500</span>))<br>    test_loader = CPDataLoader(opt, test_dataset)<br>    <br>    <span class="hljs-comment"># test vis loader</span><br>    opt.batch_size = opt.num_test_visualize<br>    test_vis_dataset = CPDatasetTest(opt)<br>    test_vis_loader = CPDataLoader(opt, test_vis_dataset)<br>    <br>    <span class="hljs-comment"># visualization</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(opt.tensorboard_dir):<br>        os.makedirs(opt.tensorboard_dir)<br>    board = SummaryWriter(log_dir=os.path.join(opt.tensorboard_dir, opt.name))<br>    <br>    <span class="hljs-comment"># warping-seg Model</span><br>    tocg = <span class="hljs-literal">None</span><br>    <br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.GT:<br>        input1_nc = <span class="hljs-number">4</span>  <span class="hljs-comment"># cloth + cloth-mask</span><br>        input2_nc = opt.semantic_nc + <span class="hljs-number">3</span>  <span class="hljs-comment"># parse_agnostic + densepose</span><br>        tocg = ConditionGenerator(opt, input1_nc=input1_nc, input2_nc=input2_nc, output_nc=<span class="hljs-number">13</span>, ngf=<span class="hljs-number">96</span>, norm_layer=nn.BatchNorm2d)<br>        <span class="hljs-comment"># Load Checkpoint</span><br>        load_checkpoint(tocg, opt.tocg_checkpoint)<br><br>    <span class="hljs-comment"># Generator model</span><br>    generator = SPADEGenerator(opt, <span class="hljs-number">3</span>+<span class="hljs-number">3</span>+<span class="hljs-number">3</span>)<br>    generator.print_network()<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(opt.gpu_ids) &gt; <span class="hljs-number">0</span>:<br>        <span class="hljs-keyword">assert</span>(torch.cuda.is_available())<br>        generator.cuda()<br>    generator.init_weights(opt.init_type, opt.init_variance)<br>    discriminator = create_network(MultiscaleDiscriminator, opt)<br><br>    <span class="hljs-comment"># lpips</span><br>    model = models.PerceptualLoss(model=<span class="hljs-string">&#x27;net-lin&#x27;</span>,net=<span class="hljs-string">&#x27;alex&#x27;</span>,use_gpu=<span class="hljs-literal">True</span>)<br><br>    <span class="hljs-comment"># Load Checkpoint</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.gen_checkpoint == <span class="hljs-string">&#x27;&#x27;</span> <span class="hljs-keyword">and</span> os.path.exists(opt.gen_checkpoint):<br>        load_checkpoint(generator, opt.gen_checkpoint)<br>        load_checkpoint(discriminator, opt.dis_checkpoint)<br><br>    <span class="hljs-comment"># Train</span><br>    train(opt, train_loader, test_loader, test_vis_loader, board, tocg, generator, discriminator, model)<br><br>    <span class="hljs-comment"># Save Checkpoint</span><br>    save_checkpoint(generator, os.path.join(opt.checkpoint_dir, opt.name, <span class="hljs-string">&#x27;gen_model_final.pth&#x27;</span>),opt)<br>    save_checkpoint(discriminator, os.path.join(opt.checkpoint_dir, opt.name, <span class="hljs-string">&#x27;dis_model_final.pth&#x27;</span>),opt)<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Finished training %s!&quot;</span> % opt.name)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    main()<br></code></pre></td></tr></table></figure><p>然后主函数就和训练generator的差不多了。</p><h1 id="evaluate.py">evaluate.py</h1><p>这个文件主要用于评估图像生成模型的性能。它计算了几个关键的图像质量评估指标，包括结构相似性指数（SSIM）、均方误差（MSE）、感知相似性指标（LPIPS），以及 Inception 分数（IS）。</p><h2 id="结构相似性指数-ssim">结构相似性指数 (SSIM)</h2><p>SSIM 用于衡量两幅图像的视觉相似度。它考虑了图像的亮度、对比度和结构三个方面的相似性。SSIM 的值范围在 -1 到 1 之间，1 表示两幅图像完全相同。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> i, img_pred <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(pred_list):<br>    img = img_pred.split(<span class="hljs-string">&#x27;_&#x27;</span>)[<span class="hljs-number">0</span>] + <span class="hljs-string">&#x27;_00.jpg&#x27;</span><br>    <span class="hljs-comment"># Calculate SSIM</span><br>    gt_img = Image.<span class="hljs-built_in">open</span>(os.path.join(opt.ground_truth_dir, img))<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.resolution == <span class="hljs-number">1024</span>:<br>        <span class="hljs-keyword">if</span> opt.resolution == <span class="hljs-number">512</span>:<br>            gt_img = gt_img.resize((<span class="hljs-number">384</span>, <span class="hljs-number">512</span>), Image.BILINEAR)<br>        <span class="hljs-keyword">elif</span> opt.resolution == <span class="hljs-number">256</span>:<br>            gt_img = gt_img.resize((<span class="hljs-number">192</span>, <span class="hljs-number">256</span>), Image.BILINEAR)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">raise</span> NotImplementedError<br><br>    gt_np = np.asarray(gt_img.convert(<span class="hljs-string">&#x27;L&#x27;</span>))<br>    pred_img = Image.<span class="hljs-built_in">open</span>(os.path.join(opt.predict_dir, img_pred))<br>    <span class="hljs-keyword">assert</span> gt_img.size == pred_img.size, <span class="hljs-string">f&quot;<span class="hljs-subst">&#123;gt_img.size&#125;</span> vs <span class="hljs-subst">&#123;pred_img.size&#125;</span>&quot;</span><br>    pred_np = np.asarray(pred_img.convert(<span class="hljs-string">&#x27;L&#x27;</span>))<br>    avg_ssim += ssim(gt_np, pred_np, data_range=<span class="hljs-number">255</span>, gaussian_weights=<span class="hljs-literal">True</span>, use_sample_covariance=<span class="hljs-literal">False</span>)<br></code></pre></td></tr></table></figure><p>这里简单来说就就是加载了ground truth和生成的图片，然后计算两幅图之间的SSIM。</p><p>SSIM的计算方法：</p><p><strong>亮度比较（Luminance Comparison）</strong>： <span class="math display">\[L(x, y) = \frac{2 \mu_x \mu_y + C_1}{\mu_x^2 + \mu_y^2 + C_1}\]</span> <strong>对比度比较（Contrast Comparison）</strong>： <span class="math display">\[C(x, y) = \frac{2 \sigma_x \sigma_y + C_2}{\sigma_x^2 + \sigma_y^2 + C_2}\]</span> <strong>结构比较（Structure Comparison）</strong> <span class="math display">\[S(x, y) = \frac{\sigma_{xy} + C_3}{\sigma_x \sigma_y + C_3}\]</span> <strong>综合计算 SSIM</strong> <span class="math display">\[SSIM(x, y) = [L(x, y)]^\alpha \cdot [C(x, y)]^\beta \cdot [S(x, y)]^\gamma\]</span> 通常取<span class="math inline">\(\alpha = \beta = \gamma = 1\)</span></p><p>公式变为： <span class="math display">\[SSIM(x, y) = \frac{(2 \mu_x \mu_y + C_1)(2 \sigma_{xy} + C_2)}{(\mu_x^2 + \mu_y^2 + C_1)(\sigma_x^2 + \sigma_y^2 + C_2)}\]</span></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Calculate LPIPS  </span><br>gt_img_LPIPS = T2(gt_img).unsqueeze(<span class="hljs-number">0</span>).cuda()  <br>pred_img_LPIPS = T2(pred_img).unsqueeze(<span class="hljs-number">0</span>).cuda()  <br>lpips_list.append((img_pred, model.forward(gt_img_LPIPS, pred_img_LPIPS).item()))  <br>avg_distance += lpips_list[-<span class="hljs-number">1</span>][<span class="hljs-number">1</span>]  <br></code></pre></td></tr></table></figure><p><code>.item()</code>：将计算得到的距离从张量（Tensor）转换为 Python 标量（scalar）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Calculate Inception model prediction  </span><br>pred_img_IS = T3(pred_img).unsqueeze(<span class="hljs-number">0</span>).cuda()  <br>preds[i] = F.softmax(inception_model(pred_img_IS)).data.cpu().numpy()  <br>  <br>gt_img_MSE = T1(gt_img).unsqueeze(<span class="hljs-number">0</span>).cuda()  <br>pred_img_MSE = T1(pred_img).unsqueeze(<span class="hljs-number">0</span>).cuda()  <br>avg_mse += F.mse_loss(gt_img_MSE, pred_img_MSE)  <br>  <br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;step: <span class="hljs-subst">&#123;i + <span class="hljs-number">1</span>&#125;</span> evaluation... lpips:<span class="hljs-subst">&#123;lpips_list[-<span class="hljs-number">1</span>][<span class="hljs-number">1</span>]&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure><p>这段代码计算perceptual loss。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">avg_ssim /= <span class="hljs-built_in">len</span>(gt_list)<br>avg_mse = avg_mse / <span class="hljs-built_in">len</span>(gt_list)<br>avg_distance = avg_distance / <span class="hljs-built_in">len</span>(gt_list)<br><br>lpips_list.sort(key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>], reverse=<span class="hljs-literal">True</span>)  <br><span class="hljs-keyword">for</span> name, score <span class="hljs-keyword">in</span> lpips_list:  <br>    f = <span class="hljs-built_in">open</span>(os.path.join(opt.predict_dir, <span class="hljs-string">&#x27;lpips.txt&#x27;</span>), <span class="hljs-string">&#x27;a&#x27;</span>)  <br>    f.write(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;name&#125;</span> <span class="hljs-subst">&#123;score&#125;</span>\n&quot;</span>)  <br>    f.close()<br></code></pre></td></tr></table></figure><p>这里对之前算的结果取一个平均值。然后是排序并记录inception score。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">split_scores = [] <span class="hljs-comment"># Now compute the mean kl-divergence</span><br><br><span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(splits):  <br>    part = preds[k * (<span class="hljs-built_in">len</span>(gt_list) // splits): (k + <span class="hljs-number">1</span>) * (<span class="hljs-built_in">len</span>(gt_list) // splits), :]  <br>    py = np.mean(part, axis=<span class="hljs-number">0</span>)  <br>    scores = []  <br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(part.shape[<span class="hljs-number">0</span>]):  <br>        pyx = part[i, :]  <br>        scores.append(entropy(pyx, py))  <br>    split_scores.append(np.exp(np.mean(scores)))<br></code></pre></td></tr></table></figure><p>这里将 <code>preds</code> 划分为 <code>splits</code> 个部分。<code>py = np.mean(part, axis=0)</code>计算每个部分的边缘概率分布 <code>py</code>（即p(y))。</p><p>假设有 <span class="math inline">\(N\)</span> 张生成图像，每张图像通过 Inception 模型得到一个概率分布<span class="math inline">\(p(y|x_i)\)</span>，其中<span class="math inline">\(x_{i}\)</span>表示第 <span class="math inline">\(i\)</span> 张生成图像。那么<span class="math inline">\(p(y) = \frac{1}{N} \sum_{i=1}^{N} p(y|x_i)\)</span>。</p><p>然后进行以下步骤：</p><ol type="1"><li><strong>计算每个图像的 KL 散度</strong>： 对每个图像，计算其预测概率 <span class="math inline">\(p(y|x)\)</span> 与边缘概率 <span class="math inline">\(p(y)\)</span>之间的 KL 散度。</li><li><strong>计算子集得分</strong>： 对每个子集的所有 KL 散度取平均，并取指数，得到该子集的 Inception Score。</li><li><strong>计算最终得分</strong>： 最后对所有子集的 Inception Score 取均值和标准差，作为最终的 Inception Score。</li></ol><p>这个函数的最后就是把评估结果写到文件中：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">f = <span class="hljs-built_in">open</span>(os.path.join(opt.predict_dir, <span class="hljs-string">&#x27;eval.txt&#x27;</span>), <span class="hljs-string">&#x27;a&#x27;</span>)  <br>f.write(<span class="hljs-string">f&quot;SSIM : <span class="hljs-subst">&#123;avg_ssim&#125;</span> / MSE : <span class="hljs-subst">&#123;avg_mse&#125;</span> / LPIPS : <span class="hljs-subst">&#123;avg_distance&#125;</span>\n&quot;</span>)  <br>f.write(<span class="hljs-string">f&quot;IS_mean : <span class="hljs-subst">&#123;IS_mean&#125;</span> / IS_std : <span class="hljs-subst">&#123;IS_std&#125;</span>\n&quot;</span>)  <br>  <br>f.close()  <br><span class="hljs-keyword">return</span> avg_ssim, avg_mse, avg_distance, IS_mean, IS_std<br></code></pre></td></tr></table></figure><p>下面主函数直接调用就好了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():<br>    opt = get_opt()<br><br>    <span class="hljs-comment"># Output과 Ground Truth Data</span><br>    pred_list = os.listdir(opt.predict_dir)<br>    gt_list = os.listdir(opt.ground_truth_dir)<br>    pred_list.sort()<br>    gt_list.sort()<br><br>    avg_ssim, avg_mse, avg_distance, IS_mean, IS_std = Evaluation(opt, pred_list, gt_list)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;SSIM : %f / MSE : %f / LPIPS : %f&quot;</span> % (avg_ssim, avg_mse, avg_distance))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;IS_mean : %f / IS_std : %f&quot;</span> % (IS_mean, IS_std))<br><br></code></pre></td></tr></table></figure><h1 id="get_norm_const.py">get_norm_const.py</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_opt</span>():<br>    parser = argparse.ArgumentParser()<br>    <span class="hljs-comment"># omitted</span><br></code></pre></td></tr></table></figure><p>首先还是创建一个parser读取用户的配置。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">D_logit</span>(<span class="hljs-params">pred</span>):<br>    score = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> pred:<br>        score += i[-<span class="hljs-number">1</span>].mean((<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>)) / <span class="hljs-number">2</span><br>    <span class="hljs-keyword">return</span> score<br></code></pre></td></tr></table></figure><p><code>i[-1]</code>表示取出最后一个的特征图，在批次、高度和宽度维度上计算均值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_const</span>(<span class="hljs-params">opt, train_loader, tocg, D, length</span>):<br>    <span class="hljs-comment"># Model</span><br>    D.cuda()<br>    D.<span class="hljs-built_in">eval</span>()<br>    tocg.cuda()<br>    tocg.<span class="hljs-built_in">eval</span>()<br><br>    logit_list = []<br>    i = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> step <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(length // opt.batch_size):<br>        iter_start_time = time.time()<br>        inputs = train_loader.next_batch()<br><br>        <span class="hljs-comment"># input1</span><br>        c_paired = inputs[<span class="hljs-string">&#x27;cloth&#x27;</span>][<span class="hljs-string">&#x27;paired&#x27;</span>].cuda()<br>        cm_paired = inputs[<span class="hljs-string">&#x27;cloth_mask&#x27;</span>][<span class="hljs-string">&#x27;paired&#x27;</span>].cuda()<br>        cm_paired = torch.FloatTensor((cm_paired.detach().cpu().numpy() &gt; <span class="hljs-number">0.5</span>).astype(np.<span class="hljs-built_in">float</span>)).cuda()<br>        <span class="hljs-comment"># input2</span><br>        parse_agnostic = inputs[<span class="hljs-string">&#x27;parse_agnostic&#x27;</span>].cuda()<br>        densepose = inputs[<span class="hljs-string">&#x27;densepose&#x27;</span>].cuda()<br>        openpose = inputs[<span class="hljs-string">&#x27;pose&#x27;</span>].cuda()<br>        <span class="hljs-comment"># GT</span><br>        label_onehot = inputs[<span class="hljs-string">&#x27;parse_onehot&#x27;</span>].cuda()  <span class="hljs-comment"># CE</span><br>        label = inputs[<span class="hljs-string">&#x27;parse&#x27;</span>].cuda()  <span class="hljs-comment"># GAN loss</span><br>        parse_cloth_mask = inputs[<span class="hljs-string">&#x27;pcm&#x27;</span>].cuda()  <span class="hljs-comment"># L1</span><br>        im_c = inputs[<span class="hljs-string">&#x27;parse_cloth&#x27;</span>].cuda()  <span class="hljs-comment"># VGG</span><br>        <span class="hljs-comment"># visualization</span><br>        im = inputs[<span class="hljs-string">&#x27;image&#x27;</span>]<br>        <span class="hljs-keyword">with</span> torch.no_grad():<br>            <span class="hljs-comment"># inputs</span><br>            input1 = torch.cat([c_paired, cm_paired], <span class="hljs-number">1</span>)<br>            input2 = torch.cat([parse_agnostic, densepose], <span class="hljs-number">1</span>)<br><br>            flow_list, fake_segmap, warped_cloth_paired, warped_clothmask_paired = tocg(input1, input2)<br>            <span class="hljs-keyword">if</span> opt.clothmask_composition != <span class="hljs-string">&#x27;no_composition&#x27;</span>:<br>                <span class="hljs-keyword">if</span> opt.clothmask_composition == <span class="hljs-string">&#x27;detach&#x27;</span>:<br>                    warped_cm_onehot = torch.FloatTensor((warped_clothmask_paired.detach().cpu().numpy() &gt; <span class="hljs-number">0.5</span>).astype(np.<span class="hljs-built_in">float</span>)).cuda()<br>                    cloth_mask = torch.ones_like(fake_segmap.detach())<br>                    cloth_mask[:, <span class="hljs-number">3</span>:<span class="hljs-number">4</span>, :, :] = warped_cm_onehot<br>                    fake_segmap = fake_segmap * cloth_mask<br>                    <br>                <span class="hljs-keyword">if</span> opt.clothmask_composition == <span class="hljs-string">&#x27;warp_grad&#x27;</span>:<br>                    cloth_mask = torch.ones_like(fake_segmap.detach())<br>                    cloth_mask[:, <span class="hljs-number">3</span>:<span class="hljs-number">4</span>, :, :] = warped_clothmask_paired<br>                    fake_segmap = fake_segmap * cloth_mask<br>            <br>            <br>            fake_segmap_softmax = F.softmax(fake_segmap, dim=<span class="hljs-number">1</span>)<br>            <br>            real_segmap_pred = D(torch.cat((input1.detach(), input2.detach(), label),dim=<span class="hljs-number">1</span>))<br>            fake_segmap_pred = D(torch.cat((input1.detach(), input2.detach(), fake_segmap_softmax),dim=<span class="hljs-number">1</span>))<br>            <br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;real:&quot;</span>, D_logit(real_segmap_pred), <span class="hljs-string">&quot;fake:&quot;</span>, D_logit(fake_segmap_pred))<br>            <span class="hljs-comment"># print(fake_segmap_pred)</span><br>            logit_real = D_logit(real_segmap_pred)<br>            logit_fake = D_logit(fake_segmap_pred)<br>            <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> logit_real:<br>                l = l / (<span class="hljs-number">1</span>-l)<br>                logit_list.append(l.item())<br>            <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> logit_fake:<br>                l = l / (<span class="hljs-number">1</span>-l)<br>                logit_list.append(l.item())<br>                <br>        <span class="hljs-comment"># i += logit_real.shape[0]+logit_fake.shape[0]</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;i:&quot;</span>, i)<br>    logit_list.sort()<br>    <br>    <span class="hljs-keyword">return</span> logit_list[-<span class="hljs-number">1</span>]<br></code></pre></td></tr></table></figure><p>每次取出一个批次，然后进行前向传播，再经过 Discriminator 得到其预测。然后D是一个MultiscaleDiscriminator，我们计算logit的时候只取最后的那一个scale。这里变换将 <code>l</code> 从<span class="math inline">\([0, 1]\)</span>映射到<span class="math inline">\([0, +\infty]\)</span>。最后找出最大的logit值。</p><h1 id="test_condition.py">test_condition.py</h1><p>我们先看主函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():<br>    opt = get_opt()<br>    <span class="hljs-built_in">print</span>(opt)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Start to test %s!&quot;</span>)<br>    os.environ[<span class="hljs-string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>] = opt.gpu_ids<br>    <br>    <span class="hljs-comment"># create test dataset &amp; loader</span><br>    test_dataset = CPDatasetTest(opt)<br>    test_loader = CPDataLoader(opt, test_dataset)<br>    <br>    <span class="hljs-comment"># visualization</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(opt.tensorboard_dir):<br>        os.makedirs(opt.tensorboard_dir)<br>    board = SummaryWriter(log_dir=os.path.join(opt.tensorboard_dir, opt.tocg_checkpoint.split(<span class="hljs-string">&#x27;/&#x27;</span>)[-<span class="hljs-number">2</span>], opt.tocg_checkpoint.split(<span class="hljs-string">&#x27;/&#x27;</span>)[-<span class="hljs-number">1</span>], opt.datamode, opt.datasetting))<br><br>    <span class="hljs-comment"># Model</span><br>    input1_nc = <span class="hljs-number">4</span>  <span class="hljs-comment"># cloth + cloth-mask</span><br>    input2_nc = opt.semantic_nc + <span class="hljs-number">3</span>  <span class="hljs-comment"># parse_agnostic + densepose</span><br>    tocg = ConditionGenerator(opt, input1_nc=input1_nc, input2_nc=input2_nc, output_nc=opt.output_nc, ngf=<span class="hljs-number">96</span>, norm_layer=nn.BatchNorm2d)<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.D_checkpoint == <span class="hljs-string">&#x27;&#x27;</span> <span class="hljs-keyword">and</span> os.path.exists(opt.D_checkpoint):<br>        <span class="hljs-keyword">if</span> opt.norm_const <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            <span class="hljs-keyword">raise</span> NotImplementedError<br>        D = define_D(input_nc=input1_nc + input2_nc + opt.output_nc, Ddownx2 = opt.Ddownx2, Ddropout = opt.Ddropout, n_layers_D=<span class="hljs-number">3</span>, spectral = opt.spectral, num_D = opt.num_D)<br>    <span class="hljs-keyword">else</span>:<br>        D = <span class="hljs-literal">None</span><br>    <span class="hljs-comment"># Load Checkpoint</span><br>    load_checkpoint(tocg, opt.tocg_checkpoint)<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.D_checkpoint == <span class="hljs-string">&#x27;&#x27;</span> <span class="hljs-keyword">and</span> os.path.exists(opt.D_checkpoint):<br>        load_checkpoint(D, opt.D_checkpoint)<br>    <span class="hljs-comment"># Train</span><br>    test(opt, test_loader, board, tocg, D=D)<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Finished testing!&quot;</span>)<br><br></code></pre></td></tr></table></figure><p>这里的<code>define_D</code>是之前在网络中定义的一个辅助函数，用来生成<code>MultiscaleDiscriminator</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">define_D</span>(<span class="hljs-params">input_nc, ndf=<span class="hljs-number">64</span>, n_layers_D=<span class="hljs-number">3</span>, norm=<span class="hljs-string">&#x27;instance&#x27;</span>, use_sigmoid=<span class="hljs-literal">False</span>, num_D=<span class="hljs-number">2</span>, getIntermFeat=<span class="hljs-literal">False</span>, gpu_ids=[], Ddownx2=<span class="hljs-literal">False</span>, Ddropout=<span class="hljs-literal">False</span>, spectral=<span class="hljs-literal">False</span></span>):<br>    norm_layer = get_norm_layer(norm_type=norm)<br>    netD = MultiscaleDiscriminator(input_nc, ndf, n_layers_D, norm_layer, use_sigmoid, num_D, getIntermFeat, Ddownx2, Ddropout, spectral=spectral)<br>    <span class="hljs-built_in">print</span>(netD)<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(gpu_ids) &gt; <span class="hljs-number">0</span>:<br>        <span class="hljs-keyword">assert</span> (torch.cuda.is_available())<br>        netD.cuda()<br>    netD.apply(weights_init)<br>    <span class="hljs-keyword">return</span> netD<br></code></pre></td></tr></table></figure><p>如果D_checkpoint存在，也就是说 Discriminator 已经被训练了，就生成一个 Discriminator 给到 test。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">test</span>(<span class="hljs-params">opt, test_loader, board, tocg, D=<span class="hljs-literal">None</span></span>):  <br>    <span class="hljs-comment"># Model  </span><br>    tocg.cuda()  <br>    tocg.<span class="hljs-built_in">eval</span>()  <br>    <span class="hljs-keyword">if</span> D <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:  <br>        D.cuda()  <br>        D.<span class="hljs-built_in">eval</span>()  <br>  <br>    os.makedirs(os.path.join(<span class="hljs-string">&#x27;./output&#x27;</span>, opt.tocg_checkpoint.split(<span class="hljs-string">&#x27;/&#x27;</span>)[-<span class="hljs-number">2</span>], opt.tocg_checkpoint.split(<span class="hljs-string">&#x27;/&#x27;</span>)[-<span class="hljs-number">1</span>],  <br>                             opt.datamode, opt.datasetting, <span class="hljs-string">&#x27;multi-task&#x27;</span>), exist_ok=<span class="hljs-literal">True</span>)  <br>    num = <span class="hljs-number">0</span>  <br>    iter_start_time = time.time()  <br>    <span class="hljs-keyword">if</span> D <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:  <br>        D_score = []  <br>    <span class="hljs-keyword">for</span> inputs <span class="hljs-keyword">in</span> test_loader.data_loader:  <br>  <br>        <span class="hljs-comment"># input1  </span><br>        c_paired = inputs[<span class="hljs-string">&#x27;cloth&#x27;</span>][opt.datasetting].cuda()  <br>        cm_paired = inputs[<span class="hljs-string">&#x27;cloth_mask&#x27;</span>][opt.datasetting].cuda()  <br>        cm_paired = torch.FloatTensor((cm_paired.detach().cpu().numpy() &gt; <span class="hljs-number">0.5</span>).astype(np.<span class="hljs-built_in">float</span>)).cuda()  <br>        <span class="hljs-comment"># input2  </span><br>        parse_agnostic = inputs[<span class="hljs-string">&#x27;parse_agnostic&#x27;</span>].cuda()  <br>        densepose = inputs[<span class="hljs-string">&#x27;densepose&#x27;</span>].cuda()  <br>        openpose = inputs[<span class="hljs-string">&#x27;pose&#x27;</span>].cuda()  <br>        <span class="hljs-comment"># GT  </span><br>        label_onehot = inputs[<span class="hljs-string">&#x27;parse_onehot&#x27;</span>].cuda()  <span class="hljs-comment"># CE  </span><br>        label = inputs[<span class="hljs-string">&#x27;parse&#x27;</span>].cuda()  <span class="hljs-comment"># GAN loss  </span><br>        parse_cloth_mask = inputs[<span class="hljs-string">&#x27;pcm&#x27;</span>].cuda()  <span class="hljs-comment"># L1  </span><br>        im_c = inputs[<span class="hljs-string">&#x27;parse_cloth&#x27;</span>].cuda()  <span class="hljs-comment"># VGG  </span><br>        <span class="hljs-comment"># visualization        im = inputs[&#x27;image&#x27;]  </span><br>  <br>        <span class="hljs-keyword">with</span> torch.no_grad():  <br>            <span class="hljs-comment"># inputs  </span><br>            input1 = torch.cat([c_paired, cm_paired], <span class="hljs-number">1</span>)  <br>            input2 = torch.cat([parse_agnostic, densepose], <span class="hljs-number">1</span>)  <br>  <br>            <span class="hljs-comment"># forward  </span><br>            flow_list, fake_segmap, warped_cloth_paired, warped_clothmask_paired = tocg(input1, input2)  <br>  <br>            <span class="hljs-comment"># warped cloth mask one hot   </span><br>warped_cm_onehot = torch.FloatTensor(  <br>                (warped_clothmask_paired.detach().cpu().numpy() &gt; <span class="hljs-number">0.5</span>).astype(np.<span class="hljs-built_in">float</span>)).cuda()  <br>  <br>            <span class="hljs-keyword">if</span> opt.clothmask_composition != <span class="hljs-string">&#x27;no_composition&#x27;</span>:  <br>                <span class="hljs-keyword">if</span> opt.clothmask_composition == <span class="hljs-string">&#x27;detach&#x27;</span>:  <br>                    cloth_mask = torch.ones_like(fake_segmap)  <br>                    cloth_mask[:, <span class="hljs-number">3</span>:<span class="hljs-number">4</span>, :, :] = warped_cm_onehot  <br>                    fake_segmap = fake_segmap * cloth_mask  <br>  <br>                <span class="hljs-keyword">if</span> opt.clothmask_composition == <span class="hljs-string">&#x27;warp_grad&#x27;</span>:  <br>                    cloth_mask = torch.ones_like(fake_segmap)  <br>                    cloth_mask[:, <span class="hljs-number">3</span>:<span class="hljs-number">4</span>, :, :] = warped_clothmask_paired  <br>                    fake_segmap = fake_segmap * cloth_mask<br></code></pre></td></tr></table></figure><p>测试的时候和训练的代码大体都差不多，最开始还是加载数据：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> D <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:  <br>    fake_segmap_softmax = F.softmax(fake_segmap, dim=<span class="hljs-number">1</span>)  <br>    pred_segmap = D(torch.cat((input1.detach(), input2.detach(), fake_segmap_softmax), dim=<span class="hljs-number">1</span>))  <br>    score = D_logit(pred_segmap)  <br>    <span class="hljs-comment"># score = torch.exp(score) / opt.norm_const  </span><br>    score = (score / (<span class="hljs-number">1</span> - score)) / opt.norm_const  <br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;prob0&quot;</span>, score)  <br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(cm_paired.shape[<span class="hljs-number">0</span>]):  <br>        name = inputs[<span class="hljs-string">&#x27;c_name&#x27;</span>][<span class="hljs-string">&#x27;paired&#x27;</span>][i].replace(<span class="hljs-string">&#x27;.jpg&#x27;</span>, <span class="hljs-string">&#x27;.png&#x27;</span>)  <br>        D_score.append((name, score[i].item()))<br></code></pre></td></tr></table></figure><p>如果有Discriminator，就用<code>D_logit(pred_segmap)</code>计算出一个对数几率。然后对对数几率值进行变换，变换公式为<span class="math inline">\(\frac{score}{1 - score}\)</span>​。然后将变换后的值除以一个常数 <code>opt.norm_const</code> 进行归一化。 在parser的代码里对这段有注释： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">parser.add_argument(<span class="hljs-string">&#x27;--norm_const&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">float</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;Normalizing constant for rejection sampling&#x27;</span>)<br></code></pre></td></tr></table></figure></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(c_paired.shape[<span class="hljs-number">0</span>]):  <br>    grid = make_grid([(c_paired[i].cpu() / <span class="hljs-number">2</span> + <span class="hljs-number">0.5</span>), (cm_paired[i].cpu()).expand(<span class="hljs-number">3</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>),  <br>                      visualize_segmap(parse_agnostic.cpu(), batch=i), ((densepose.cpu()[i] + <span class="hljs-number">1</span>) / <span class="hljs-number">2</span>),  <br>                      (im_c[i].cpu() / <span class="hljs-number">2</span> + <span class="hljs-number">0.5</span>), parse_cloth_mask[i].cpu().expand(<span class="hljs-number">3</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>),  <br>                      (warped_cloth_paired[i].cpu().detach() / <span class="hljs-number">2</span> + <span class="hljs-number">0.5</span>),  <br>                      (warped_cm_onehot[i].cpu().detach()).expand(<span class="hljs-number">3</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>),  <br>                      visualize_segmap(label.cpu(), batch=i), visualize_segmap(fake_segmap.cpu(), batch=i),  <br>                      (im[i] / <span class="hljs-number">2</span> + <span class="hljs-number">0.5</span>), (misalign[i].cpu().detach()).expand(<span class="hljs-number">3</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>)],  <br>                     nrow=<span class="hljs-number">4</span>)  <br>    save_image(grid, os.path.join(<span class="hljs-string">&#x27;./output&#x27;</span>, opt.tocg_checkpoint.split(<span class="hljs-string">&#x27;/&#x27;</span>)[-<span class="hljs-number">2</span>], opt.tocg_checkpoint.split(<span class="hljs-string">&#x27;/&#x27;</span>)[-<span class="hljs-number">1</span>],  <br>                                  opt.datamode, opt.datasetting, <span class="hljs-string">&#x27;multi-task&#x27;</span>,  <br>                                  (inputs[<span class="hljs-string">&#x27;c_name&#x27;</span>][<span class="hljs-string">&#x27;paired&#x27;</span>][i].split(<span class="hljs-string">&#x27;.&#x27;</span>)[<span class="hljs-number">0</span>] + <span class="hljs-string">&#x27;_&#x27;</span> +  <br>                                   inputs[<span class="hljs-string">&#x27;c_name&#x27;</span>][<span class="hljs-string">&#x27;unpaired&#x27;</span>][i].split(<span class="hljs-string">&#x27;.&#x27;</span>)[<span class="hljs-number">0</span>] + <span class="hljs-string">&#x27;.png&#x27;</span>)))  <br>num += c_paired.shape[<span class="hljs-number">0</span>]  <br><span class="hljs-built_in">print</span>(num)<br></code></pre></td></tr></table></figure><p>使用 <code>make_grid</code> 函数将多个图像拼接成一个网格。网格中的每个图像是对当前样本不同处理结果的可视化。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> D <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:  <br>    D_score.sort(key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">1</span>], reverse=<span class="hljs-literal">True</span>)  <br>    <span class="hljs-comment"># Save D_score  </span><br>    <span class="hljs-keyword">for</span> name, score <span class="hljs-keyword">in</span> D_score:  <br>        f = <span class="hljs-built_in">open</span>(os.path.join(<span class="hljs-string">&#x27;./output&#x27;</span>, opt.tocg_checkpoint.split(<span class="hljs-string">&#x27;/&#x27;</span>)[-<span class="hljs-number">2</span>], opt.tocg_checkpoint.split(<span class="hljs-string">&#x27;/&#x27;</span>)[-<span class="hljs-number">1</span>],  <br>                              opt.datamode, opt.datasetting, <span class="hljs-string">&#x27;multi-task&#x27;</span>, <span class="hljs-string">&#x27;rejection_prob.txt&#x27;</span>), <span class="hljs-string">&#x27;a&#x27;</span>)  <br>        f.write(name + <span class="hljs-string">&#x27; &#x27;</span> + <span class="hljs-built_in">str</span>(score) + <span class="hljs-string">&#x27;\n&#x27;</span>)  <br>        f.close()  <br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Test time <span class="hljs-subst">&#123;time.time() - iter_start_time&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure><p>对 <code>D_score</code> 按照评分进行降序排序，并写入到文件中。</p><p>然后主函数就是一些简单的初始化。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():  <br>    opt = get_opt()  <br>    <span class="hljs-built_in">print</span>(opt)  <br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Start to test %s!&quot;</span>)  <br>    os.environ[<span class="hljs-string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>] = opt.gpu_ids  <br>  <br>    <span class="hljs-comment"># create test dataset &amp; loader  </span><br>    test_dataset = CPDatasetTest(opt)  <br>    test_loader = CPDataLoader(opt, test_dataset)  <br>  <br>    <span class="hljs-comment"># visualization  </span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(opt.tensorboard_dir):  <br>        os.makedirs(opt.tensorboard_dir)  <br>    board = SummaryWriter(log_dir=os.path.join(opt.tensorboard_dir, opt.tocg_checkpoint.split(<span class="hljs-string">&#x27;/&#x27;</span>)[-<span class="hljs-number">2</span>],  opt.tocg_checkpoint.split(<span class="hljs-string">&#x27;/&#x27;</span>)[-<span class="hljs-number">1</span>], opt.datamode, opt.datasetting))  <br>  <br>    <span class="hljs-comment"># Model  </span><br>    input1_nc = <span class="hljs-number">4</span>  <span class="hljs-comment"># cloth + cloth-mask  </span><br>    input2_nc = opt.semantic_nc + <span class="hljs-number">3</span>  <span class="hljs-comment"># parse_agnostic + densepose  </span><br>    tocg = ConditionGenerator(opt, input1_nc=input1_nc, input2_nc=input2_nc, output_nc=opt.output_nc, ngf=<span class="hljs-number">96</span>,  <br>                              norm_layer=nn.BatchNorm2d)  <br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.D_checkpoint == <span class="hljs-string">&#x27;&#x27;</span> <span class="hljs-keyword">and</span> os.path.exists(opt.D_checkpoint):  <br>        <span class="hljs-keyword">if</span> opt.norm_const <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:  <br>            <span class="hljs-keyword">raise</span> NotImplementedError  <br>        D = define_D(input_nc=input1_nc + input2_nc + opt.output_nc, Ddownx2=opt.Ddownx2, Ddropout=opt.Ddropout,  <br>                     n_layers_D=<span class="hljs-number">3</span>, spectral=opt.spectral, num_D=opt.num_D)  <br>    <span class="hljs-keyword">else</span>:  <br>        D = <span class="hljs-literal">None</span>  <br>    <span class="hljs-comment"># Load Checkpoint  </span><br>    load_checkpoint(tocg, opt.tocg_checkpoint)  <br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.D_checkpoint == <span class="hljs-string">&#x27;&#x27;</span> <span class="hljs-keyword">and</span> os.path.exists(opt.D_checkpoint):  <br>        load_checkpoint(D, opt.D_checkpoint)  <br>    <span class="hljs-comment"># Train  </span><br>    test(opt, test_loader, board, tocg, D=D)  <br>  <br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Finished testing!&quot;</span>)  <br>  <br>  <br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:  <br>    main()<br></code></pre></td></tr></table></figure><p>然后主函数就是简单的初始化了。</p><h1 id="test_generator.py">test_generator.py</h1><p>test_generator这里和test_condition很类似，就只讲主要的部分了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">with</span> torch.no_grad():<br>    <span class="hljs-keyword">for</span> inputs <span class="hljs-keyword">in</span> test_loader.data_loader:<br>        <span class="hljs-keyword">if</span> opt.cuda :<br>            pose_map = inputs[<span class="hljs-string">&#x27;pose&#x27;</span>].cuda()<br>            pre_clothes_mask = inputs[<span class="hljs-string">&#x27;cloth_mask&#x27;</span>][opt.datasetting].cuda()<br>            label = inputs[<span class="hljs-string">&#x27;parse&#x27;</span>]<br>            parse_agnostic = inputs[<span class="hljs-string">&#x27;parse_agnostic&#x27;</span>]<br>            agnostic = inputs[<span class="hljs-string">&#x27;agnostic&#x27;</span>].cuda()<br>            clothes = inputs[<span class="hljs-string">&#x27;cloth&#x27;</span>][opt.datasetting].cuda() <span class="hljs-comment"># target cloth</span><br>            densepose = inputs[<span class="hljs-string">&#x27;densepose&#x27;</span>].cuda()<br>            im = inputs[<span class="hljs-string">&#x27;image&#x27;</span>]<br>            input_label, input_parse_agnostic = label.cuda(), parse_agnostic.cuda()<br>            pre_clothes_mask = torch.FloatTensor((pre_clothes_mask.detach().cpu().numpy() &gt; <span class="hljs-number">0.5</span>).astype(np.<span class="hljs-built_in">float</span>)).cuda()<br>        <span class="hljs-keyword">else</span> :<br>            pose_map = inputs[<span class="hljs-string">&#x27;pose&#x27;</span>]<br>            pre_clothes_mask = inputs[<span class="hljs-string">&#x27;cloth_mask&#x27;</span>][opt.datasetting]<br>            label = inputs[<span class="hljs-string">&#x27;parse&#x27;</span>]<br>            parse_agnostic = inputs[<span class="hljs-string">&#x27;parse_agnostic&#x27;</span>]<br>            agnostic = inputs[<span class="hljs-string">&#x27;agnostic&#x27;</span>]<br>            clothes = inputs[<span class="hljs-string">&#x27;cloth&#x27;</span>][opt.datasetting] <span class="hljs-comment"># target cloth</span><br>            densepose = inputs[<span class="hljs-string">&#x27;densepose&#x27;</span>]<br>            im = inputs[<span class="hljs-string">&#x27;image&#x27;</span>]<br>            input_label, input_parse_agnostic = label, parse_agnostic<br>            pre_clothes_mask = torch.FloatTensor((pre_clothes_mask.detach().cpu().numpy() &gt; <span class="hljs-number">0.5</span>).astype(np.<span class="hljs-built_in">float</span>))<br></code></pre></td></tr></table></figure><p>这里就是对是否是否使用GPU做了一个区分。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># down  </span><br>pose_map_down = F.interpolate(pose_map, size=(<span class="hljs-number">256</span>, <span class="hljs-number">192</span>), mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>)  <br>pre_clothes_mask_down = F.interpolate(pre_clothes_mask, size=(<span class="hljs-number">256</span>, <span class="hljs-number">192</span>), mode=<span class="hljs-string">&#x27;nearest&#x27;</span>)  <br>input_label_down = F.interpolate(input_label, size=(<span class="hljs-number">256</span>, <span class="hljs-number">192</span>), mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>)  <br>input_parse_agnostic_down = F.interpolate(input_parse_agnostic, size=(<span class="hljs-number">256</span>, <span class="hljs-number">192</span>), mode=<span class="hljs-string">&#x27;nearest&#x27;</span>)  <br>agnostic_down = F.interpolate(agnostic, size=(<span class="hljs-number">256</span>, <span class="hljs-number">192</span>), mode=<span class="hljs-string">&#x27;nearest&#x27;</span>)  <br>clothes_down = F.interpolate(clothes, size=(<span class="hljs-number">256</span>, <span class="hljs-number">192</span>), mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>)  <br>densepose_down = F.interpolate(densepose, size=(<span class="hljs-number">256</span>, <span class="hljs-number">192</span>), mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>)  <br>  <br>shape = pre_clothes_mask.shape  <br>  <br><span class="hljs-comment"># multi-task inputs  </span><br>input1 = torch.cat([clothes_down, pre_clothes_mask_down], <span class="hljs-number">1</span>)  <br>input2 = torch.cat([input_parse_agnostic_down, densepose_down], <span class="hljs-number">1</span>)  <br>  <br><span class="hljs-comment"># forward  </span><br>flow_list, fake_segmap, warped_cloth_paired, warped_clothmask_paired = tocg(opt, input1, input2)  <br>  <br><span class="hljs-comment"># warped cloth mask one hot  </span><br><span class="hljs-keyword">if</span> opt.cuda:  <br>    warped_cm_onehot = torch.FloatTensor((warped_clothmask_paired.detach().cpu().numpy() &gt; <span class="hljs-number">0.5</span>).astype(np.<span class="hljs-built_in">float</span>)).cuda()  <br><span class="hljs-keyword">else</span>:  <br>    warped_cm_onehot = torch.FloatTensor((warped_clothmask_paired.detach().cpu().numpy() &gt; <span class="hljs-number">0.5</span>).astype(np.<span class="hljs-built_in">float</span>))  <br>  <br><span class="hljs-keyword">if</span> opt.clothmask_composition != <span class="hljs-string">&#x27;no_composition&#x27;</span>:  <br>    <span class="hljs-keyword">if</span> opt.clothmask_composition == <span class="hljs-string">&#x27;detach&#x27;</span>:  <br>        cloth_mask = torch.ones_like(fake_segmap)  <br>        cloth_mask[:, <span class="hljs-number">3</span>:<span class="hljs-number">4</span>, :, :] = warped_cm_onehot  <br>        fake_segmap = fake_segmap * cloth_mask  <br>  <br>    <span class="hljs-keyword">if</span> opt.clothmask_composition == <span class="hljs-string">&#x27;warp_grad&#x27;</span>:  <br>        cloth_mask = torch.ones_like(fake_segmap)  <br>        cloth_mask[:, <span class="hljs-number">3</span>:<span class="hljs-number">4</span>, :, :] = warped_clothmask_paired  <br>        fake_segmap = fake_segmap * cloth_mask  <br>  <br><span class="hljs-comment"># make generator input parse map  </span><br>fake_parse_gauss = gauss(F.interpolate(fake_segmap, size=(opt.fine_height, opt.fine_width), mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>))  <br>fake_parse = fake_parse_gauss.argmax(dim=<span class="hljs-number">1</span>)[:, <span class="hljs-literal">None</span>]<br></code></pre></td></tr></table></figure><p>这里就是通过Try On Condition Generator生成合成图像的segmentation map，然后将segmentation map进行高斯处理，并合成为1个channel。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> opt.cuda:  <br>    old_parse = torch.FloatTensor(fake_parse.size(<span class="hljs-number">0</span>), <span class="hljs-number">13</span>, opt.fine_height, opt.fine_width).zero_().cuda()  <br><span class="hljs-keyword">else</span>:  <br>    old_parse = torch.FloatTensor(fake_parse.size(<span class="hljs-number">0</span>), <span class="hljs-number">13</span>, opt.fine_height, opt.fine_width).zero_()  <br>old_parse.scatter_(<span class="hljs-number">1</span>, fake_parse, <span class="hljs-number">1.0</span>)  <br>  <br>labels = &#123;  <br>    <span class="hljs-number">0</span>: [<span class="hljs-string">&#x27;background&#x27;</span>, [<span class="hljs-number">0</span>]],  <br>    <span class="hljs-number">1</span>: [<span class="hljs-string">&#x27;paste&#x27;</span>, [<span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">9</span>, <span class="hljs-number">10</span>, <span class="hljs-number">11</span>]],  <br>    <span class="hljs-number">2</span>: [<span class="hljs-string">&#x27;upper&#x27;</span>, [<span class="hljs-number">3</span>]],  <br>    <span class="hljs-number">3</span>: [<span class="hljs-string">&#x27;hair&#x27;</span>, [<span class="hljs-number">1</span>]],  <br>    <span class="hljs-number">4</span>: [<span class="hljs-string">&#x27;left_arm&#x27;</span>, [<span class="hljs-number">5</span>]],  <br>    <span class="hljs-number">5</span>: [<span class="hljs-string">&#x27;right_arm&#x27;</span>, [<span class="hljs-number">6</span>]],  <br>    <span class="hljs-number">6</span>: [<span class="hljs-string">&#x27;noise&#x27;</span>, [<span class="hljs-number">12</span>]]  <br>&#125;  <br><span class="hljs-keyword">if</span> opt.cuda:  <br>    parse = torch.FloatTensor(fake_parse.size(<span class="hljs-number">0</span>), <span class="hljs-number">7</span>, opt.fine_height, opt.fine_width).zero_().cuda()  <br><span class="hljs-keyword">else</span>:  <br>    parse = torch.FloatTensor(fake_parse.size(<span class="hljs-number">0</span>), <span class="hljs-number">7</span>, opt.fine_height, opt.fine_width).zero_()  <br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(labels)):  <br>    <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> labels[i][<span class="hljs-number">1</span>]:  <br>        parse[:, i] += old_parse[:, label]<br></code></pre></td></tr></table></figure><p>然后又将合并得到的1个channel的segmentation map分为13个channel，但是现在转化为了one-hot encoder。之后又将13个channel合并为7个channel，因为他不需要那么细的信息。</p><h2 id="scatter_的用法">scatter_的用法</h2><p><code>scatter_</code> 的参数含义如下： <code>dim</code>：指定沿哪个维度进行散射操作。 <code>index</code>：包含索引的张量。索引表示要将值写入目标张量的位置。 <code>src</code>：要写入的值或包含要写入值的张量。</p><p>For a 3-D tensor, <code>self</code> is updated as: <figure class="highlight inform7"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs inform7">self<span class="hljs-comment">[index<span class="hljs-comment">[i]</span><span class="hljs-comment">[j]</span><span class="hljs-comment">[k]</span>]</span><span class="hljs-comment">[j]</span><span class="hljs-comment">[k]</span> = src<span class="hljs-comment">[i]</span><span class="hljs-comment">[j]</span><span class="hljs-comment">[k]</span>  # if dim == 0<br>self<span class="hljs-comment">[i]</span><span class="hljs-comment">[index<span class="hljs-comment">[i]</span><span class="hljs-comment">[j]</span><span class="hljs-comment">[k]</span>]</span><span class="hljs-comment">[k]</span> = src<span class="hljs-comment">[i]</span><span class="hljs-comment">[j]</span><span class="hljs-comment">[k]</span>  # if dim == 1<br>self<span class="hljs-comment">[i]</span><span class="hljs-comment">[j]</span><span class="hljs-comment">[index<span class="hljs-comment">[i]</span><span class="hljs-comment">[j]</span><span class="hljs-comment">[k]</span>]</span> = src<span class="hljs-comment">[i]</span><span class="hljs-comment">[j]</span><span class="hljs-comment">[k]</span>  # if dim == 2<br></code></pre></td></tr></table></figure></p><blockquote><p><code>self</code>, <code>index</code> and <code>src</code> (if it is a Tensor) should all have the same number of dimensions. It is also required that <code>index.size(d) &lt;= src.size(d)</code> for all dimensions <code>d</code>, and that <code>index.size(d) &lt;= self.size(d)</code> for all dimensions <code>d != dim</code>. Note that <code>index</code> and <code>src</code> do not broadcast.</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">old_parse.scatter_(<span class="hljs-number">1</span>, fake_parse, <span class="hljs-number">1.0</span>)<br></code></pre></td></tr></table></figure><p>对于这种用法，意思就是把fake_parse的每个值，对应到old_parse的每个通道上，然后把相应的位置设为1。</p><p>然后后面就是一些生成图像和可视化的工作，和test_condition就差不多了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># warped cloth  </span><br>N, _, iH, iW = clothes.shape  <br>flow = F.interpolate(flow_list[-<span class="hljs-number">1</span>].permute(<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>), size=(iH, iW), mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>).permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)  <br>flow_norm = torch.cat([flow[:, :, :, <span class="hljs-number">0</span>:<span class="hljs-number">1</span>] / ((<span class="hljs-number">96</span> - <span class="hljs-number">1.0</span>) / <span class="hljs-number">2.0</span>), flow[:, :, :, <span class="hljs-number">1</span>:<span class="hljs-number">2</span>] / ((<span class="hljs-number">128</span> - <span class="hljs-number">1.0</span>) / <span class="hljs-number">2.0</span>)], <span class="hljs-number">3</span>)  <br>  <br>grid = make_grid(N, iH, iW, opt)  <br>warped_grid = grid + flow_norm  <br>warped_cloth = F.grid_sample(clothes, warped_grid, padding_mode=<span class="hljs-string">&#x27;border&#x27;</span>)  <br>warped_clothmask = F.grid_sample(pre_clothes_mask, warped_grid, padding_mode=<span class="hljs-string">&#x27;border&#x27;</span>)  <br><span class="hljs-keyword">if</span> opt.occlusion:  <br>    warped_clothmask = remove_overlap(F.softmax(fake_parse_gauss, dim=<span class="hljs-number">1</span>), warped_clothmask)  <br>    warped_cloth = warped_cloth * warped_clothmask + torch.ones_like(warped_cloth) * (<span class="hljs-number">1</span> - warped_clothmask)  <br>  <br>output = generator(torch.cat((agnostic, densepose, warped_cloth), dim=<span class="hljs-number">1</span>), parse)  <br><span class="hljs-comment"># visualize  </span><br>unpaired_names = []  <br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(shape[<span class="hljs-number">0</span>]):  <br>    grid = make_image_grid([(clothes[i].cpu() / <span class="hljs-number">2</span> + <span class="hljs-number">0.5</span>), (pre_clothes_mask[i].cpu()).expand(<span class="hljs-number">3</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>),  <br>                            visualize_segmap(parse_agnostic.cpu(), batch=i), ((densepose.cpu()[i] + <span class="hljs-number">1</span>) / <span class="hljs-number">2</span>),  <br>                            (warped_cloth[i].cpu().detach() / <span class="hljs-number">2</span> + <span class="hljs-number">0.5</span>),  <br>                            (warped_clothmask[i].cpu().detach()).expand(<span class="hljs-number">3</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>),  <br>                            visualize_segmap(fake_parse_gauss.cpu(), batch=i),  <br>                            (pose_map[i].cpu() / <span class="hljs-number">2</span> + <span class="hljs-number">0.5</span>), (warped_cloth[i].cpu() / <span class="hljs-number">2</span> + <span class="hljs-number">0.5</span>),  <br>                            (agnostic[i].cpu() / <span class="hljs-number">2</span> + <span class="hljs-number">0.5</span>),  <br>                            (im[i] / <span class="hljs-number">2</span> + <span class="hljs-number">0.5</span>), (output[i].cpu() / <span class="hljs-number">2</span> + <span class="hljs-number">0.5</span>)],  <br>                           nrow=<span class="hljs-number">4</span>)  <br>    unpaired_name = (  <br>                inputs[<span class="hljs-string">&#x27;c_name&#x27;</span>][<span class="hljs-string">&#x27;paired&#x27;</span>][i].split(<span class="hljs-string">&#x27;.&#x27;</span>)[<span class="hljs-number">0</span>] + <span class="hljs-string">&#x27;_&#x27;</span> + inputs[<span class="hljs-string">&#x27;c_name&#x27;</span>][opt.datasetting][i].split(<span class="hljs-string">&#x27;.&#x27;</span>)[  <br>            <span class="hljs-number">0</span>] + <span class="hljs-string">&#x27;.png&#x27;</span>)  <br>    save_image(grid, os.path.join(grid_dir, unpaired_name))  <br>    unpaired_names.append(unpaired_name)  <br>  <br><span class="hljs-comment"># save output  </span><br>save_images(output, unpaired_names, output_dir)  <br>  <br>num += shape[<span class="hljs-number">0</span>]  <br><span class="hljs-built_in">print</span>(num)  <br>  <br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Test time <span class="hljs-subst">&#123;time.time() - iter_start_time&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>CV</category>
      
    </categories>
    
    
    <tags>
      
      <tag>VITON</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>HR-VITON代码笔记</title>
    <link href="/posts/hr-viton%E4%BB%A3%E7%A0%81%E7%AC%94%E8%AE%B0/"/>
    <url>/posts/hr-viton%E4%BB%A3%E7%A0%81%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="cp_dataset.py">cp_dataset.py</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">CPDataset</span>(data.Dataset):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        Dataset for CP-VTON.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, opt</span>):<br>        <span class="hljs-built_in">super</span>(CPDataset, self).__init__()<br>        <span class="hljs-comment"># base setting</span><br>        self.opt = opt<br>        self.root = opt.dataroot<br>        self.datamode = opt.datamode <span class="hljs-comment"># train or test or self-defined</span><br>        self.data_list = opt.data_list<br>        self.fine_height = opt.fine_height<br>        self.fine_width = opt.fine_width<br>        self.semantic_nc = opt.semantic_nc<br>        self.data_path = osp.join(opt.dataroot, opt.datamode)<br>        self.transform = transforms.Compose([  \<br>                transforms.ToTensor(),   \<br>                transforms.Normalize((<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>), (<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>))])<br><br>        <span class="hljs-comment"># load data list</span><br>        im_names = []<br>        c_names = []<br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(osp.join(opt.dataroot, opt.data_list), <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>            <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> f.readlines():<br>                im_name, c_name = line.strip().split()<br>                im_names.append(im_name)<br>                c_names.append(c_name)<br><br>        self.im_names = im_names<br>        self.c_names = <span class="hljs-built_in">dict</span>()<br>        self.c_names[<span class="hljs-string">&#x27;paired&#x27;</span>] = im_names<br>        self.c_names[<span class="hljs-string">&#x27;unpaired&#x27;</span>] = c_names<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">name</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;CPDataset&quot;</span><br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_agnostic</span>(<span class="hljs-params">self, im, im_parse, pose_data</span>)<br></code></pre></td></tr></table></figure><p>前面这些部分都和VITON-HD差不多。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, index</span>):<br>       im_name = self.im_names[index]<br>       im_name = <span class="hljs-string">&#x27;image/&#x27;</span> + im_name<br>       c_name = &#123;&#125;<br>       c = &#123;&#125;<br>       cm = &#123;&#125;<br>       <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> [<span class="hljs-string">&#x27;paired&#x27;</span>]:<br>           c_name[key] = self.c_names[key][index]<br>           c[key] = Image.<span class="hljs-built_in">open</span>(osp.join(self.data_path, <span class="hljs-string">&#x27;cloth&#x27;</span>, c_name[key])).convert(<span class="hljs-string">&#x27;RGB&#x27;</span>)<br>           c[key] = transforms.Resize(self.fine_width, interpolation=<span class="hljs-number">2</span>)(c[key])<br>           cm[key] = Image.<span class="hljs-built_in">open</span>(osp.join(self.data_path, <span class="hljs-string">&#x27;cloth-mask&#x27;</span>, c_name[key]))<br>           cm[key] = transforms.Resize(self.fine_width, interpolation=<span class="hljs-number">0</span>)(cm[key])<br><br>           c[key] = self.transform(c[key])  <span class="hljs-comment"># [-1,1]</span><br>           cm_array = np.array(cm[key])<br>           cm_array = (cm_array &gt;= <span class="hljs-number">128</span>).astype(np.float32)<br>           cm[key] = torch.from_numpy(cm_array)  <span class="hljs-comment"># [0,1]</span><br>           cm[key].unsqueeze_(<span class="hljs-number">0</span>)<br><br></code></pre></td></tr></table></figure><p>这里和VITON-HD一样，都是把衣服的图片和衣服掩码的图片加载出来，缩放至合适的大小。把衣服的图片进行标准化并且转化为tensor。并把衣服掩码转化为0，1的二值数组，也变成tensor。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># person image</span><br>im_pil_big = Image.<span class="hljs-built_in">open</span>(osp.join(self.data_path, im_name))<br>im_pil = transforms.Resize(self.fine_width, interpolation=<span class="hljs-number">2</span>)(im_pil_big)<br>im = self.transform(im_pil)<br><br><span class="hljs-comment"># load parsing image</span><br>parse_name = im_name.replace(<span class="hljs-string">&#x27;image&#x27;</span>, <span class="hljs-string">&#x27;image-parse-v3&#x27;</span>).replace(<span class="hljs-string">&#x27;.jpg&#x27;</span>, <span class="hljs-string">&#x27;.png&#x27;</span>)<br>im_parse_pil_big = Image.<span class="hljs-built_in">open</span>(osp.join(self.data_path, parse_name))<br>im_parse_pil = transforms.Resize(self.fine_width, interpolation=<span class="hljs-number">0</span>)(im_parse_pil_big)<br>parse = torch.from_numpy(np.array(im_parse_pil)[<span class="hljs-literal">None</span>]).long()<br>im_parse = self.transform(im_parse_pil.convert(<span class="hljs-string">&#x27;RGB&#x27;</span>))<br></code></pre></td></tr></table></figure><p>这里就是分别加载人物的图片和segmentation map。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># parse map</span><br>      labels = &#123;<br>          <span class="hljs-number">0</span>:  [<span class="hljs-string">&#x27;background&#x27;</span>,  [<span class="hljs-number">0</span>, <span class="hljs-number">10</span>]],<br>          <span class="hljs-number">1</span>:  [<span class="hljs-string">&#x27;hair&#x27;</span>,        [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>]],<br>          <span class="hljs-number">2</span>:  [<span class="hljs-string">&#x27;face&#x27;</span>,        [<span class="hljs-number">4</span>, <span class="hljs-number">13</span>]],<br>          <span class="hljs-number">3</span>:  [<span class="hljs-string">&#x27;upper&#x27;</span>,       [<span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>]],<br>          <span class="hljs-number">4</span>:  [<span class="hljs-string">&#x27;bottom&#x27;</span>,      [<span class="hljs-number">9</span>, <span class="hljs-number">12</span>]],<br>          <span class="hljs-number">5</span>:  [<span class="hljs-string">&#x27;left_arm&#x27;</span>,    [<span class="hljs-number">14</span>]],<br>          <span class="hljs-number">6</span>:  [<span class="hljs-string">&#x27;right_arm&#x27;</span>,   [<span class="hljs-number">15</span>]],<br>          <span class="hljs-number">7</span>:  [<span class="hljs-string">&#x27;left_leg&#x27;</span>,    [<span class="hljs-number">16</span>]],<br>          <span class="hljs-number">8</span>:  [<span class="hljs-string">&#x27;right_leg&#x27;</span>,   [<span class="hljs-number">17</span>]],<br>          <span class="hljs-number">9</span>:  [<span class="hljs-string">&#x27;left_shoe&#x27;</span>,   [<span class="hljs-number">18</span>]],<br>          <span class="hljs-number">10</span>: [<span class="hljs-string">&#x27;right_shoe&#x27;</span>,  [<span class="hljs-number">19</span>]],<br>          <span class="hljs-number">11</span>: [<span class="hljs-string">&#x27;socks&#x27;</span>,       [<span class="hljs-number">8</span>]],<br>          <span class="hljs-number">12</span>: [<span class="hljs-string">&#x27;noise&#x27;</span>,       [<span class="hljs-number">3</span>, <span class="hljs-number">11</span>]]<br>      &#125;<br>      <br>      parse_map = torch.FloatTensor(<span class="hljs-number">20</span>, self.fine_height, self.fine_width).zero_()<br>      parse_map = parse_map.scatter_(<span class="hljs-number">0</span>, parse, <span class="hljs-number">1.0</span>)<br>      new_parse_map = torch.FloatTensor(self.semantic_nc, self.fine_height, self.fine_width).zero_()<br><br>      <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(labels)):<br>          <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> labels[i][<span class="hljs-number">1</span>]:<br>              new_parse_map[i] += parse_map[label]<br>              <br>      parse_onehot = torch.FloatTensor(<span class="hljs-number">1</span>, self.fine_height, self.fine_width).zero_()<br>      <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(labels)):<br>          <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> labels[i][<span class="hljs-number">1</span>]:<br>              parse_onehot[<span class="hljs-number">0</span>] += parse_map[label] * i<br></code></pre></td></tr></table></figure><p>这里也是和VITON-HD做了相同的操作，先把segmentation map根据label分成20个channel，再把一些label合并起来，根据新的label又合并一些channel。并”更新“segmentation map。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># load image-parse-agnostic</span><br>image_parse_agnostic = Image.<span class="hljs-built_in">open</span>(osp.join(self.data_path, parse_name.replace(<span class="hljs-string">&#x27;image-parse-v3&#x27;</span>, <span class="hljs-string">&#x27;image-parse-agnostic-v3.2&#x27;</span>)))<br>image_parse_agnostic = transforms.Resize(self.fine_width, interpolation=<span class="hljs-number">0</span>)(image_parse_agnostic)<br>parse_agnostic = torch.from_numpy(np.array(image_parse_agnostic)[<span class="hljs-literal">None</span>]).long()<br>image_parse_agnostic = self.transform(image_parse_agnostic.convert(<span class="hljs-string">&#x27;RGB&#x27;</span>))<br><br>parse_agnostic_map = torch.FloatTensor(<span class="hljs-number">20</span>, self.fine_height, self.fine_width).zero_()<br>parse_agnostic_map = parse_agnostic_map.scatter_(<span class="hljs-number">0</span>, parse_agnostic, <span class="hljs-number">1.0</span>)<br>new_parse_agnostic_map = torch.FloatTensor(self.semantic_nc, self.fine_height, self.fine_width).zero_()<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(labels)):<br>    <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> labels[i][<span class="hljs-number">1</span>]:<br>        new_parse_agnostic_map[i] += parse_agnostic_map[label]        <br></code></pre></td></tr></table></figure><p>这里原文说：For the clothing-agnostic person representation, we employ a clothing-agnostic person image <span class="math inline">\(I_{a}\)</span> and a clothing-agnostic segmentation map <span class="math inline">\(S_{a}\)</span> as those of VITON-HD. 所以HR-VITON就直接调用VITON-HD处理好的图片。</p><p>这里的image_parse_agnostic就是原图的segmentation map，然后做一点点的变换。这里的parse_agnostic_map其实就是跟之前的parse_one_hot差不多，只是这里的parse_agnostic_map值只是0或1，并且已经是消除了衣服的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># parse cloth &amp; parse cloth mask</span><br>pcm = new_parse_map[<span class="hljs-number">3</span>:<span class="hljs-number">4</span>]<br>im_c = im * pcm + (<span class="hljs-number">1</span> - pcm)<br><br><span class="hljs-comment"># load pose points</span><br>pose_name = im_name.replace(<span class="hljs-string">&#x27;image&#x27;</span>, <span class="hljs-string">&#x27;openpose_img&#x27;</span>).replace(<span class="hljs-string">&#x27;.jpg&#x27;</span>, <span class="hljs-string">&#x27;_rendered.png&#x27;</span>)<br>pose_map = Image.<span class="hljs-built_in">open</span>(osp.join(self.data_path, pose_name))<br>pose_map = transforms.Resize(self.fine_width, interpolation=<span class="hljs-number">2</span>)(pose_map)<br>pose_map = self.transform(pose_map)  <span class="hljs-comment"># [-1,1]</span><br><br><span class="hljs-comment"># pose name</span><br>pose_name = im_name.replace(<span class="hljs-string">&#x27;image&#x27;</span>, <span class="hljs-string">&#x27;openpose_json&#x27;</span>).replace(<span class="hljs-string">&#x27;.jpg&#x27;</span>, <span class="hljs-string">&#x27;_keypoints.json&#x27;</span>)<br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(osp.join(self.data_path, pose_name), <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    pose_label = json.load(f)<br>    pose_data = pose_label[<span class="hljs-string">&#x27;people&#x27;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&#x27;pose_keypoints_2d&#x27;</span>]<br>    pose_data = np.array(pose_data)<br>    pose_data = pose_data.reshape((-<span class="hljs-number">1</span>, <span class="hljs-number">3</span>))[:, :<span class="hljs-number">2</span>]<br></code></pre></td></tr></table></figure><p>im_c是原图上的clothes mask。</p><p>pose这里也用的是和VITON-HD一样的。</p><p>pose_map是这样的图片</p><figure><img src="https://s2.loli.net/2024/05/04/9VWb7hZNxDGmeTj.png" alt="" /><figcaption>00026_00_rendered.png</figcaption></figure><p>pose_data就是包含关键点坐标的json文件。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># load densepose</span><br>densepose_name = im_name.replace(<span class="hljs-string">&#x27;image&#x27;</span>, <span class="hljs-string">&#x27;image-densepose&#x27;</span>)<br>densepose_map = Image.<span class="hljs-built_in">open</span>(osp.join(self.data_path, densepose_name))<br>densepose_map = transforms.Resize(self.fine_width, interpolation=<span class="hljs-number">2</span>)(densepose_map)<br>densepose_map = self.transform(densepose_map)  <span class="hljs-comment"># [-1,1]</span><br><br><span class="hljs-comment"># agnostic</span><br>agnostic = self.get_agnostic(im_pil_big, im_parse_pil_big, pose_data)<br>agnostic = transforms.Resize(self.fine_width, interpolation=<span class="hljs-number">2</span>)(agnostic)<br>agnostic = self.transform(agnostic)<br></code></pre></td></tr></table></figure><p>densepose的图片是这样的</p><figure><img src="https://s2.loli.net/2024/05/04/63AHx2J4MdfXzm7.jpg" alt="" /><figcaption>00026_00.jpg</figcaption></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python">result = &#123;<br>    <span class="hljs-string">&#x27;c_name&#x27;</span>:   c_name,     <span class="hljs-comment"># for visualization</span><br>    <span class="hljs-string">&#x27;im_name&#x27;</span>:  im_name,    <span class="hljs-comment"># for visualization or ground truth</span><br>    <span class="hljs-comment"># intput 1 (clothfloww)</span><br>    <span class="hljs-string">&#x27;cloth&#x27;</span>:    c,          <span class="hljs-comment"># for input</span><br>    <span class="hljs-string">&#x27;cloth_mask&#x27;</span>:     cm,   <span class="hljs-comment"># for input</span><br>    <span class="hljs-comment"># intput 2 (segnet)</span><br>    <span class="hljs-string">&#x27;parse_agnostic&#x27;</span>: new_parse_agnostic_map,<br>    <span class="hljs-string">&#x27;densepose&#x27;</span>: densepose_map,<br>    <span class="hljs-string">&#x27;pose&#x27;</span>: pose_map,       <span class="hljs-comment"># for conditioning</span><br>    <span class="hljs-comment"># generator input</span><br>    <span class="hljs-string">&#x27;agnostic&#x27;</span> : agnostic,<br>    <span class="hljs-comment"># GT</span><br>    <span class="hljs-string">&#x27;parse_onehot&#x27;</span> : parse_onehot,  <span class="hljs-comment"># Cross Entropy</span><br>    <span class="hljs-string">&#x27;parse&#x27;</span>: new_parse_map, <span class="hljs-comment"># GAN Loss real</span><br>    <span class="hljs-string">&#x27;pcm&#x27;</span>: pcm,             <span class="hljs-comment"># L1 Loss &amp; vis</span><br>    <span class="hljs-string">&#x27;parse_cloth&#x27;</span>: im_c,    <span class="hljs-comment"># VGG Loss &amp; vis</span><br>    <span class="hljs-comment"># visualization &amp; GT</span><br>    <span class="hljs-string">&#x27;image&#x27;</span>:    im,         <span class="hljs-comment"># for visualization</span><br>    &#125;<br><br><span class="hljs-keyword">return</span> result<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">CPDataLoader</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, opt, dataset</span>):<br>        <span class="hljs-built_in">super</span>(CPDataLoader, self).__init__()<br><br>        <span class="hljs-keyword">if</span> opt.shuffle :<br>            train_sampler = torch.utils.data.sampler.RandomSampler(dataset)<br>        <span class="hljs-keyword">else</span>:<br>            train_sampler = <span class="hljs-literal">None</span><br><br>        self.data_loader = torch.utils.data.DataLoader(<br>                dataset, batch_size=opt.batch_size, shuffle=(train_sampler <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>),<br>                num_workers=opt.workers, pin_memory=<span class="hljs-literal">True</span>, drop_last=<span class="hljs-literal">True</span>, sampler=train_sampler)<br>        self.dataset = dataset<br>        self.data_iter = self.data_loader.__iter__()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">next_batch</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">try</span>:<br>            batch = self.data_iter.__next__()<br>        <span class="hljs-keyword">except</span> StopIteration:<br>            self.data_iter = self.data_loader.__iter__()<br>            batch = self.data_iter.__next__()<br><br>        <span class="hljs-keyword">return</span> batch<br></code></pre></td></tr></table></figure><p>然后这里也跟VITON-HD一样，这就是一个对batch进行抽样的类。</p><h1 id="get_parse_agnostic.py">get_parse_agnostic.py</h1><p>这里还专门定义了一个文件实现VITON-HD中的get_parse_agnostic函数。代码贴在这里，好像并没有什么特别的东西。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">from</span> os <span class="hljs-keyword">import</span> path <span class="hljs-keyword">as</span> osp<br><span class="hljs-keyword">import</span> os<br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image, ImageDraw<br><br><span class="hljs-keyword">import</span> argparse<br><br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_im_parse_agnostic</span>(<span class="hljs-params">im_parse, pose_data, w=<span class="hljs-number">768</span>, h=<span class="hljs-number">1024</span></span>):<br>    parse_array = np.array(im_parse)<br>    parse_upper = ((parse_array == <span class="hljs-number">5</span>).astype(np.float32) +<br>                    (parse_array == <span class="hljs-number">6</span>).astype(np.float32) +<br>                    (parse_array == <span class="hljs-number">7</span>).astype(np.float32))<br>    parse_neck = (parse_array == <span class="hljs-number">10</span>).astype(np.float32)<br><br>    r = <span class="hljs-number">10</span><br>    agnostic = im_parse.copy()<br><br>    <span class="hljs-comment"># mask arms</span><br>    <span class="hljs-keyword">for</span> parse_id, pose_ids <span class="hljs-keyword">in</span> [(<span class="hljs-number">14</span>, [<span class="hljs-number">2</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>]), (<span class="hljs-number">15</span>, [<span class="hljs-number">5</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>])]:<br>        mask_arm = Image.new(<span class="hljs-string">&#x27;L&#x27;</span>, (w, h), <span class="hljs-string">&#x27;black&#x27;</span>)<br>        mask_arm_draw = ImageDraw.Draw(mask_arm)<br>        i_prev = pose_ids[<span class="hljs-number">0</span>]<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> pose_ids[<span class="hljs-number">1</span>:]:<br>            <span class="hljs-keyword">if</span> (pose_data[i_prev, <span class="hljs-number">0</span>] == <span class="hljs-number">0.0</span> <span class="hljs-keyword">and</span> pose_data[i_prev, <span class="hljs-number">1</span>] == <span class="hljs-number">0.0</span>) <span class="hljs-keyword">or</span> (pose_data[i, <span class="hljs-number">0</span>] == <span class="hljs-number">0.0</span> <span class="hljs-keyword">and</span> pose_data[i, <span class="hljs-number">1</span>] == <span class="hljs-number">0.0</span>):<br>                <span class="hljs-keyword">continue</span><br>            mask_arm_draw.line([<span class="hljs-built_in">tuple</span>(pose_data[j]) <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> [i_prev, i]], <span class="hljs-string">&#x27;white&#x27;</span>, width=r*<span class="hljs-number">10</span>)<br>            pointx, pointy = pose_data[i]<br>            radius = r*<span class="hljs-number">4</span> <span class="hljs-keyword">if</span> i == pose_ids[-<span class="hljs-number">1</span>] <span class="hljs-keyword">else</span> r*<span class="hljs-number">15</span><br>            mask_arm_draw.ellipse((pointx-radius, pointy-radius, pointx+radius, pointy+radius), <span class="hljs-string">&#x27;white&#x27;</span>, <span class="hljs-string">&#x27;white&#x27;</span>)<br>            i_prev = i<br>        parse_arm = (np.array(mask_arm) / <span class="hljs-number">255</span>) * (parse_array == parse_id).astype(np.float32)<br>        agnostic.paste(<span class="hljs-number">0</span>, <span class="hljs-literal">None</span>, Image.fromarray(np.uint8(parse_arm * <span class="hljs-number">255</span>), <span class="hljs-string">&#x27;L&#x27;</span>))<br><br>    <span class="hljs-comment"># mask torso &amp; neck</span><br>    agnostic.paste(<span class="hljs-number">0</span>, <span class="hljs-literal">None</span>, Image.fromarray(np.uint8(parse_upper * <span class="hljs-number">255</span>), <span class="hljs-string">&#x27;L&#x27;</span>))<br>    agnostic.paste(<span class="hljs-number">0</span>, <span class="hljs-literal">None</span>, Image.fromarray(np.uint8(parse_neck * <span class="hljs-number">255</span>), <span class="hljs-string">&#x27;L&#x27;</span>))<br><br>    <span class="hljs-keyword">return</span> agnostic<br><br><br><span class="hljs-keyword">if</span> __name__==<span class="hljs-string">&quot;__main__&quot;</span>:<br>    parser = argparse.ArgumentParser()<br>    parser.add_argument(<span class="hljs-string">&#x27;--data_path&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;dataset dir&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;--output_path&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&quot;output dir&quot;</span>)<br><br>    args = parser.parse_args()<br>    data_path = args.data_path<br>    output_path = args.output_path<br>    <br>    os.makedirs(output_path, exist_ok=<span class="hljs-literal">True</span>)<br>    <br>    <span class="hljs-keyword">for</span> im_name <span class="hljs-keyword">in</span> tqdm(os.listdir(osp.join(data_path, <span class="hljs-string">&#x27;image&#x27;</span>))):<br>        <br>        <span class="hljs-comment"># load pose image</span><br>        pose_name = im_name.replace(<span class="hljs-string">&#x27;.jpg&#x27;</span>, <span class="hljs-string">&#x27;_keypoints.json&#x27;</span>)<br>        <br>        <span class="hljs-keyword">try</span>:<br>            <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(osp.join(data_path, <span class="hljs-string">&#x27;openpose_json&#x27;</span>, pose_name), <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>                pose_label = json.load(f)<br>                pose_data = pose_label[<span class="hljs-string">&#x27;people&#x27;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&#x27;pose_keypoints_2d&#x27;</span>]<br>                pose_data = np.array(pose_data)<br>                pose_data = pose_data.reshape((-<span class="hljs-number">1</span>, <span class="hljs-number">3</span>))[:, :<span class="hljs-number">2</span>]<br>        <span class="hljs-keyword">except</span> IndexError:<br>            <span class="hljs-built_in">print</span>(pose_name)<br>            <span class="hljs-keyword">continue</span><br><br>        <span class="hljs-comment"># load parsing image</span><br>        parse_name = im_name.replace(<span class="hljs-string">&#x27;.jpg&#x27;</span>, <span class="hljs-string">&#x27;.png&#x27;</span>)<br>        im_parse = Image.<span class="hljs-built_in">open</span>(osp.join(data_path, <span class="hljs-string">&#x27;image-parse-v3&#x27;</span>, parse_name))<br><br>        agnostic = get_im_parse_agnostic(im_parse, pose_data)<br>        <br>        agnostic.save(osp.join(output_path, parse_name))<br></code></pre></td></tr></table></figure><h1 id="networks.py">networks.py</h1><p>这里就是定义网络结构的地方。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">ResBlock</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, in_nc, out_nc, scale=<span class="hljs-string">&#x27;down&#x27;</span>, norm_layer=nn.BatchNorm2d</span>):<br>        <span class="hljs-built_in">super</span>(ResBlock, self).__init__()<br>        use_bias = norm_layer == nn.InstanceNorm2d<br>        <span class="hljs-keyword">assert</span> scale <span class="hljs-keyword">in</span> [<span class="hljs-string">&#x27;up&#x27;</span>, <span class="hljs-string">&#x27;down&#x27;</span>, <span class="hljs-string">&#x27;same&#x27;</span>], <span class="hljs-string">&quot;ResBlock scale must be in &#x27;up&#x27; &#x27;down&#x27; &#x27;same&#x27;&quot;</span><br><br>        <span class="hljs-keyword">if</span> scale == <span class="hljs-string">&#x27;same&#x27;</span>:<br>            self.scale = nn.Conv2d(in_nc, out_nc, kernel_size=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>)<br>        <span class="hljs-keyword">if</span> scale == <span class="hljs-string">&#x27;up&#x27;</span>:<br>            self.scale = nn.Sequential(<br>                nn.Upsample(scale_factor=<span class="hljs-number">2</span>, mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>),<br>                nn.Conv2d(in_nc, out_nc, kernel_size=<span class="hljs-number">1</span>,bias=<span class="hljs-literal">True</span>)<br>            )<br>        <span class="hljs-keyword">if</span> scale == <span class="hljs-string">&#x27;down&#x27;</span>:<br>            self.scale = nn.Conv2d(in_nc, out_nc, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>, bias=use_bias)<br>            <br>        self.block = nn.Sequential(<br>            nn.Conv2d(out_nc, out_nc, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>, bias=use_bias),<br>            norm_layer(out_nc),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br>            nn.Conv2d(out_nc, out_nc, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>, bias=use_bias),<br>            norm_layer(out_nc)<br>        )<br>        self.relu = nn.ReLU(inplace=<span class="hljs-literal">True</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        residual = self.scale(x)<br>        <span class="hljs-keyword">return</span> self.relu(residual + self.block(residual))<br></code></pre></td></tr></table></figure><p>首先（不在代码最前面，但是是最底层的块）定义了一个ResBlock类。</p><p>然后通过<code>norm_layer == nn.InstanceNorm2d</code>判断是否要加入偏置项。</p><p>因为当使用规范化层时，卷积层中的偏置项（bias）通常是不必要的，因为规范化层会调整数据的均值和方差，这使得卷积层的偏置项变得多余。具体来说，对于批量归一化（BatchNorm）来讲，它会计算输入数据的均值和方差，并进行规范化，之后还会引入新的可学习参数（scale和shift），这些操作已经隐式地包含了偏置的功能。</p><p>然而，在实例归一化（InstanceNorm）的情况下，偏置的使用则取决于具体实现和应用的需求。实例归一化是针对每个样本单独进行的，它在某些应用中（如风格迁移）比批量归一化表现得更好。实例归一化后使用偏置有时可以帮助模型更好地学习和调整每个样本的特定特征。</p><p>这里使用了<code>self.relu = nn.ReLU(inplace=True)</code> 。 <code>inplace=True</code>的优缺点分别是：</p><ul><li><strong>优点</strong>：<ul><li><strong>内存效率</strong>：使用 <code>inplace=True</code> 可以减少内存的使用，因为它避免了分配新的内存空间给操作的输出。这在处理大型网络或大规模数据时尤其有用，可以减少内存压力和潜在的内存不足错误。</li><li><strong>提速</strong>：少了内存分配的步骤，有时也可以稍微提高计算速度。</li></ul></li><li><strong>缺点</strong>：<ul><li><strong>潜在的梯度计算问题</strong>：当 <code>inplace=True</code> 被用于那些需要在反向传播中使用原始输入数据的场景时，可能会造成问题。因为原始输入数据被修改了，所以无法再使用它来计算梯度。这可能会在某些情况下导致错误或者难以调试的问题。</li><li><strong>对模型调试的影响</strong>：由于输入数据被直接修改，调试时可能难以观察原始数据和操作后的数据的区别。</li></ul></li></ul><h2 id="conditiongenerator">ConditionGenerator</h2><h2 id="网络总体结构">网络总体结构</h2><p>总体的网络结构如图所示， <img src="https://s2.loli.net/2024/05/04/5IJfjAKRQEx8wU9.png" /></p><p><img src="https://s2.loli.net/2024/05/04/1zBHFVmKOcAR4uN.png" /></p><p>这里要引用一下原文才能够理解这个部分的代码： There are two pathways in the feature fusion block: the <em>flow</em> pathway and the <em>seg</em> pathway. The flow and seg pathway generate the appearance flow map <span class="math inline">\(F_{f_{i}}\)</span> and the segmentation feature <span class="math inline">\(F_{s_{i}}\)</span> , respectively.</p><p>For the green arrow, <span class="math inline">\(F_{f_{i} - 1}\)</span> is used to deform the feature extracted from c and cm, which is then concatenated with <span class="math inline">\(F_{f_{s_{i}} - 1}\)</span> and <span class="math inline">\(E_{s_{i}}\)</span> to generate <span class="math inline">\(F_{s_{i}}\)</span> . For the blue arrow, <span class="math inline">\(F_{f_{s_{i}} - 1}\)</span> is used to guide the flow estimation.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">ConditionGenerator</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, opt, input1_nc, input2_nc, output_nc, ngf=<span class="hljs-number">64</span>, norm_layer=nn.BatchNorm2d</span>):<br>        <span class="hljs-built_in">super</span>(ConditionGenerator, self).__init__()<br>        self.warp_feature = opt.warp_feature<br>        self.out_layer_opt = opt.out_layer<br>        <br>        self.ClothEncoder = nn.Sequential(<br>            ResBlock(input1_nc, ngf, norm_layer=norm_layer, scale=<span class="hljs-string">&#x27;down&#x27;</span>),  <span class="hljs-comment"># 128</span><br>            ResBlock(ngf, ngf * <span class="hljs-number">2</span>, norm_layer=norm_layer, scale=<span class="hljs-string">&#x27;down&#x27;</span>),  <span class="hljs-comment"># 64</span><br>            ResBlock(ngf * <span class="hljs-number">2</span>, ngf * <span class="hljs-number">4</span>, norm_layer=norm_layer, scale=<span class="hljs-string">&#x27;down&#x27;</span>),  <span class="hljs-comment"># 32</span><br>            ResBlock(ngf * <span class="hljs-number">4</span>, ngf * <span class="hljs-number">4</span>, norm_layer=norm_layer, scale=<span class="hljs-string">&#x27;down&#x27;</span>),  <span class="hljs-comment"># 16</span><br>            ResBlock(ngf * <span class="hljs-number">4</span>, ngf * <span class="hljs-number">4</span>, norm_layer=norm_layer, scale=<span class="hljs-string">&#x27;down&#x27;</span>)  <span class="hljs-comment"># 8</span><br>        )<br>        <br>        self.PoseEncoder = nn.Sequential(<br>            ResBlock(input2_nc, ngf, norm_layer=norm_layer, scale=<span class="hljs-string">&#x27;down&#x27;</span>),<br>            ResBlock(ngf, ngf * <span class="hljs-number">2</span>, norm_layer=norm_layer, scale=<span class="hljs-string">&#x27;down&#x27;</span>),<br>            ResBlock(ngf * <span class="hljs-number">2</span>, ngf * <span class="hljs-number">4</span>, norm_layer=norm_layer, scale=<span class="hljs-string">&#x27;down&#x27;</span>),<br>            ResBlock(ngf * <span class="hljs-number">4</span>, ngf * <span class="hljs-number">4</span>, norm_layer=norm_layer, scale=<span class="hljs-string">&#x27;down&#x27;</span>),<br>            ResBlock(ngf * <span class="hljs-number">4</span>, ngf * <span class="hljs-number">4</span>, norm_layer=norm_layer, scale=<span class="hljs-string">&#x27;down&#x27;</span>)<br>        )<br>        <br>        self.conv = ResBlock(ngf * <span class="hljs-number">4</span>, ngf * <span class="hljs-number">8</span>, norm_layer=norm_layer, scale=<span class="hljs-string">&#x27;same&#x27;</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> opt.warp_feature == <span class="hljs-string">&#x27;encoder&#x27;</span>:<br>            <span class="hljs-comment"># in_nc -&gt; [x, skip_connection, warped_cloth_encoder_feature(E1)]</span><br>            self.SegDecoder = nn.Sequential(<br>                ResBlock(ngf * <span class="hljs-number">8</span>, ngf * <span class="hljs-number">4</span>, norm_layer=norm_layer, scale=<span class="hljs-string">&#x27;up&#x27;</span>),  <span class="hljs-comment"># 16</span><br>                ResBlock(ngf * <span class="hljs-number">4</span> * <span class="hljs-number">3</span>, ngf * <span class="hljs-number">4</span>, norm_layer=norm_layer, scale=<span class="hljs-string">&#x27;up&#x27;</span>),  <span class="hljs-comment"># 32</span><br>                ResBlock(ngf * <span class="hljs-number">4</span> * <span class="hljs-number">3</span>, ngf * <span class="hljs-number">2</span>, norm_layer=norm_layer, scale=<span class="hljs-string">&#x27;up&#x27;</span>),  <span class="hljs-comment"># 64</span><br>                ResBlock(ngf * <span class="hljs-number">2</span> * <span class="hljs-number">3</span>, ngf, norm_layer=norm_layer, scale=<span class="hljs-string">&#x27;up&#x27;</span>),  <span class="hljs-comment"># 128</span><br>                ResBlock(ngf * <span class="hljs-number">1</span> * <span class="hljs-number">3</span>, ngf, norm_layer=norm_layer, scale=<span class="hljs-string">&#x27;up&#x27;</span>)  <span class="hljs-comment"># 256</span><br>            )<br><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs python">    <span class="hljs-keyword">if</span> opt.out_layer == <span class="hljs-string">&#x27;relu&#x27;</span>:<br>        self.out_layer = ResBlock(ngf + input1_nc + input2_nc, output_nc, norm_layer=norm_layer, scale=<span class="hljs-string">&#x27;same&#x27;</span>)<br>    <span class="hljs-keyword">if</span> opt.out_layer == <span class="hljs-string">&#x27;conv&#x27;</span>:<br>        self.out_layer = nn.Sequential(<br>            ResBlock(ngf + input1_nc + input2_nc, ngf, norm_layer=norm_layer, scale=<span class="hljs-string">&#x27;same&#x27;</span>),<br>            nn.Conv2d(ngf, output_nc, kernel_size=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>)<br>        )<br>    <span class="hljs-comment"># Cloth Conv 1x1</span><br>    self.conv1 = nn.Sequential(<br>        nn.Conv2d(ngf, ngf * <span class="hljs-number">4</span>, kernel_size=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>),<br>        nn.Conv2d(ngf * <span class="hljs-number">2</span>, ngf * <span class="hljs-number">4</span>, kernel_size=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>),<br>        nn.Conv2d(ngf * <span class="hljs-number">4</span>, ngf * <span class="hljs-number">4</span>, kernel_size=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>),<br>        nn.Conv2d(ngf * <span class="hljs-number">4</span>, ngf * <span class="hljs-number">4</span>, kernel_size=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>),<br>    )<br><br>    <span class="hljs-comment"># Person Conv 1x1</span><br>    self.conv2 = nn.Sequential(<br>        nn.Conv2d(ngf, ngf * <span class="hljs-number">4</span>, kernel_size=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>),<br>        nn.Conv2d(ngf * <span class="hljs-number">2</span>, ngf * <span class="hljs-number">4</span>, kernel_size=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>),<br>        nn.Conv2d(ngf * <span class="hljs-number">4</span>, ngf * <span class="hljs-number">4</span>, kernel_size=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>),<br>        nn.Conv2d(ngf * <span class="hljs-number">4</span>, ngf * <span class="hljs-number">4</span>, kernel_size=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>),<br>    )<br>    <br>    self.flow_conv = nn.ModuleList([<br>        nn.Conv2d(ngf * <span class="hljs-number">8</span>, <span class="hljs-number">2</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>),<br>        nn.Conv2d(ngf * <span class="hljs-number">8</span>, <span class="hljs-number">2</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>),<br>        nn.Conv2d(ngf * <span class="hljs-number">8</span>, <span class="hljs-number">2</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>),<br>        nn.Conv2d(ngf * <span class="hljs-number">8</span>, <span class="hljs-number">2</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>),<br>        nn.Conv2d(ngf * <span class="hljs-number">8</span>, <span class="hljs-number">2</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>),<br>    ]<br>    )<br>    <br>    self.bottleneck = nn.Sequential(<br>        nn.Sequential(nn.Conv2d(ngf * <span class="hljs-number">4</span>, ngf * <span class="hljs-number">4</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>), nn.ReLU()),<br>        nn.Sequential(nn.Conv2d(ngf * <span class="hljs-number">4</span>, ngf * <span class="hljs-number">4</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>), nn.ReLU()),<br>        nn.Sequential(nn.Conv2d(ngf * <span class="hljs-number">2</span>, ngf * <span class="hljs-number">4</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>) , nn.ReLU()),<br>        nn.Sequential(nn.Conv2d(ngf, ngf * <span class="hljs-number">4</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>), nn.ReLU()),<br>    )<br>    <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">normalize</span>(<span class="hljs-params">self, x</span>):<br>    <span class="hljs-keyword">return</span> x<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,opt,input1, input2, upsample=<span class="hljs-string">&#x27;bilinear&#x27;</span></span>):<br>        E1_list = []<br>        E2_list = []<br>        flow_list = []<br>        <span class="hljs-comment"># warped_grid_list = []</span><br><br>        <span class="hljs-comment"># Feature Pyramid Network </span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>):<br>            <span class="hljs-keyword">if</span> i == <span class="hljs-number">0</span>:<br>                E1_list.append(self.ClothEncoder[i](input1))<br>                E2_list.append(self.PoseEncoder[i](input2))<br>            <span class="hljs-keyword">else</span>:<br>                E1_list.append(self.ClothEncoder[i](E1_list[i - <span class="hljs-number">1</span>]))<br>                E2_list.append(self.PoseEncoder[i](E2_list[i - <span class="hljs-number">1</span>]))      <br></code></pre></td></tr></table></figure><p>这里的input1这里的E1和E2应该就是指的论文里的 <span class="math inline">\(E_{c}\)</span> 和 <span class="math inline">\(E_{s}\)</span>。用原文的话说，这里做的是：</p><p>Our try-on condition generator consists of two encoders (i.e., a clothing encoder <span class="math inline">\(E_{c}\)</span> and a segmentation encoder <span class="math inline">\(E_{s}\)</span>) and a decoder. Given <span class="math inline">\((c, c_{m})\)</span> and <span class="math inline">\((S_{a}, P)\)</span>, we first extract the feature pyramid <span class="math inline">\(\{E_{c_{k}}\}_{k = 0}^{4}\)</span> and <span class="math inline">\(\{E_{s_{l}}\}_{l = 0}^{4}\)</span> from each encoder, respectively. The extracted features are fed into the feature fusion blocks of the decoder, where the feature maps obtained from the two different feature pyramids are fused to predict the segmentation map and the appearance flow for warping the clothing image.</p><h2 id="compute-clothflow">Compute Clothflow</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Compute Clothflow</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>):<br>    N, _, iH, iW = E1_list[<span class="hljs-number">4</span> - i].size()<br>    grid = make_grid(N, iH, iW,opt)<br><br><span class="hljs-comment"># Omitted, see detailed explanations below</span><br><br>N, _, iH, iW = input1.size()<br>grid = make_grid(N, iH, iW,opt)<br><br>flow = F.interpolate(flow_list[-<span class="hljs-number">1</span>].permute(<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>), scale_factor=<span class="hljs-number">2</span>, mode=upsample).permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)<br>flow_norm = torch.cat([flow[:, :, :, <span class="hljs-number">0</span>:<span class="hljs-number">1</span>] / ((iW/<span class="hljs-number">2</span> - <span class="hljs-number">1.0</span>) / <span class="hljs-number">2.0</span>), flow[:, :, :, <span class="hljs-number">1</span>:<span class="hljs-number">2</span>] / ((iH/<span class="hljs-number">2</span> - <span class="hljs-number">1.0</span>) / <span class="hljs-number">2.0</span>)], <span class="hljs-number">3</span>)<br>warped_input1 = F.grid_sample(input1, flow_norm + grid, padding_mode=<span class="hljs-string">&#x27;border&#x27;</span>)<br><br>x = self.out_layer(torch.cat([x, input2, warped_input1], <span class="hljs-number">1</span>))<br><br>warped_c = warped_input1[:, :-<span class="hljs-number">1</span>, :, :]<br>warped_cm = warped_input1[:, -<span class="hljs-number">1</span>:, :, :]<br><br><span class="hljs-keyword">return</span> flow_list, x, warped_c, warped_cm<br></code></pre></td></tr></table></figure><p>这里还要分成<code>i == 0</code>和<code>i != 0</code>来看： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> i == <span class="hljs-number">0</span>:<br>               T1 = E1_list[<span class="hljs-number">4</span> - i]  <span class="hljs-comment"># (ngf * 4) x 8 x 6</span><br>               T2 = E2_list[<span class="hljs-number">4</span> - i]<br>               E4 = torch.cat([T1, T2], <span class="hljs-number">1</span>)<br>               <br>               flow = self.flow_conv[i](self.normalize(E4)).permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)<br>               flow_list.append(flow)<br>               <br>               x = self.conv(T2)<br>               x = self.SegDecoder[i](x)<br></code></pre></td></tr></table></figure></p><p>第一层Feature Fusion Block的输入就是 <span class="math inline">\(F_{f_{0}}\)</span> 和 <span class="math inline">\(F_{s_{0}}\)</span> (也即 <span class="math inline">\(E_{c_{4}}\)</span> 和 <span class="math inline">\(E_{s_{4}}\)</span>). 然后把他们两个concatenate一下作为这里的E4，直接通过卷积网络得到。</p><p>然后将 E4 标准化之后通过<code>flow_conv[0]</code>（即一层卷积网络）得到flow_list里面的第一个元素。</p><p>然后再把T2在通过一次一次卷积得到x， 然后将 x 交给seg_decoder的第一层处理。</p><p><code>i != 0</code>时：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">else</span>:<br>    T1 = F.interpolate(T1, scale_factor=<span class="hljs-number">2</span>, mode=upsample) + \<br>        self.conv1[<span class="hljs-number">4</span> - i](E1_list[<span class="hljs-number">4</span> - i])<br>    T2 = F.interpolate(T2, scale_factor=<span class="hljs-number">2</span>, mode=upsample) + \<br>        self.conv2[<span class="hljs-number">4</span> - i](E2_list[<span class="hljs-number">4</span> - i])<br><br>    flow = F.interpolate(flow_list[i - <span class="hljs-number">1</span>].permute(<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>), scale_factor=<span class="hljs-number">2</span>,<br>                         <span class="hljs-comment"># upsample n-1 flow</span><br>                         mode=upsample).permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)<br>    flow_norm = torch.cat([flow[:, :, :, <span class="hljs-number">0</span>:<span class="hljs-number">1</span>] / ((iW/<span class="hljs-number">2</span> - <span class="hljs-number">1.0</span>) / <span class="hljs-number">2.0</span>),<br>                           flow[:, :, :, <span class="hljs-number">1</span>:<span class="hljs-number">2</span>] / ((iH/<span class="hljs-number">2</span> - <span class="hljs-number">1.0</span>) / <span class="hljs-number">2.0</span>)], <span class="hljs-number">3</span>)<br>    warped_T1 = F.grid_sample(T1, flow_norm + grid, padding_mode=<span class="hljs-string">&#x27;border&#x27;</span>)<br><br>    flow = flow + self.flow_conv[i](self.normalize(torch.cat(<br>          <span class="hljs-comment"># F(n)</span><br>          [warped_T1, self.bottleneck[i-<span class="hljs-number">1</span>](x)], <span class="hljs-number">1</span>))).permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)<br>    flow_list.append(flow)<br><br></code></pre></td></tr></table></figure><p>在python中对于<code>if</code>和<code>else</code>块中的变量，当在一个<code>if</code>块中初始化变量时，这些变量会在包含这个<code>if</code>块的更大代码块（如函数或循环）中存在，只要确保在使用这些变量之前已经对其进行了初始化。所以这里在else中能够直接调用<code>if i == 0</code>这个语句块中的 T1 和 T2。</p><p>这里T1是之前的T1和E1中相应元素进行相加而成的，T2同理。</p><p>这部分语句实际上是在处理 flow pathway。意思其实就是在说首先把T1和T2与前面连过来的feature相结合，以得到更好的效果。然后<span class="math inline">\(F_{f_{i-1}}\)</span>经过upsample之后，与<span class="math inline">\(E_{c_{i}}\)</span>一起预测变形后的衣服，也就是这里的warped_T1。然后warped_T1和 x 进行concatenation，然后再经过3x3卷积，并与flow求和，即得到了新的flow。下面再贴一下网络结构图以供参考。</p><p><img src="https://s2.loli.net/2024/05/04/1zBHFVmKOcAR4uN.png" /></p><p><code>flow=F.interpolate(flow_list[i - 1].permute(0,3,1,2),scale_factor=2,mode=upsample).permute(0, 2, 3, 1)</code> 这行代码是用于处理图像中的光流场（flow field），其目的是将前一迭代（或层级）的光流场上采样（upsample）到当前处理层的分辨率。</p><p><code>flow_norm = torch.cat([flow[:, :, :, 0:1] / ((iW/2 - 1.0) / 2.0), flow[:, :, :, 1:2] / ((iH/2 - 1.0) / 2.0)], 3)</code></p><p>这行代码进行了光流的规范化操作。光流通常表示像素点在图像序列中从一个位置到另一个位置的位移。当进行空间变换，如 <code>grid_sample</code> 时，这些光流值需要与实际图像尺寸相匹配和规范化，以便正确地应用到图像上。这里的规范化是为了适配 <code>grid_sample</code> 函数使用的坐标系统，其中坐标值通常在<code>[-1,1]</code>的范围内。详细解释如下：</p><ul><li>光流的每个分量被除以 <code>(iW/2 - 1.0) / 2.0</code> 或 <code>(iH/2 - 1.0) / 2.0</code>。这里的计算基于图像的实际尺寸（<code>iW</code> 是图像宽度，<code>iH</code> 是图像高度），将光流值转换为 -1 到 1 的范围内。这种转换是基于以下逻辑：<ul><li>图像的中心坐标（在像素索引中）大约是 <code>iW / 2</code> 和 <code>iH / 2</code>。</li><li>将宽度和高度除以 2 并减去 1 旨在获取到中心点左右各一半的距离。</li><li>进一步除以 2 是将坐标范围从 <code>[0, (iW/2 - 1)]</code> 调整到 <code>[0, 0.5]</code>，然后由于 grid_sample 中坐标要求为 <code>[-1, 1]</code>，因此不需要额外转换。</li></ul></li></ul><p><code>warped_T1 = F.grid_sample(T1, flow_norm + grid, padding_mode='border')</code> 这行代码使用了 PyTorch 的 <code>F.grid_sample</code> 函数，它是一个非常有用的函数，用于对给定的输入特征图 (<code>T1</code>) 进行空间变换。具体来说，它根据给定的流场 (<code>flow_norm</code>) 和网格 (<code>grid</code>) 来变形或重采样输入图像。</p><ul><li><strong>T1</strong>：这是被变换的特征图，可以视为一系列的高维数据（通常是图像或其特征表示）。</li><li><strong>flow_norm + grid</strong>：<ul><li><strong>flow_norm</strong>：这是光流场，已经被规范化以适应图像的坐标系统（通常在[-1, 1]的范围）。它表示特定像素应该从原始位置移动到的新位置。</li><li><strong>grid</strong>：通常是一个规则的网格，表示图像中每个像素的原始坐标。</li><li>通过将 <code>flow_norm</code> 和 <code>grid</code> 相加，你创建了一个新的变形网格。这个网格不再是均匀的，而是根据光流字段调整，指示每个输出像素应该从输入图像的哪个位置采样。</li></ul></li><li><strong>padding_mode='border'</strong>：<ul><li>这个参数定义了当采样位置超出输入图像边界时的行为。<code>'border'</code> 模式指定如果采样点超出边界，就使用边界上的像素值。这有助于防止引入任何不希望的伪影，特别是在边缘区域，因为其他模式如 <code>'zeros'</code> 可能会在图像边缘产生不自然的黑边。</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> self.warp_feature == <span class="hljs-string">&#x27;T1&#x27;</span>:<br>     x = self.SegDecoder[i](torch.cat([x, E2_list[<span class="hljs-number">4</span>-i], warped_T1], <span class="hljs-number">1</span>))<br> <span class="hljs-keyword">if</span> self.warp_feature == <span class="hljs-string">&#x27;encoder&#x27;</span>:<br>     warped_E1 = F.grid_sample(<br>         E1_list[<span class="hljs-number">4</span>-i], flow_norm + grid, padding_mode=<span class="hljs-string">&#x27;border&#x27;</span>)<br>     x = self.SegDecoder[i](torch.cat([x, E2_list[<span class="hljs-number">4</span>-i], warped_E1], <span class="hljs-number">1</span>))<br></code></pre></td></tr></table></figure><p>然后这部分就是更新 x， 即<span class="math inline">\(F_{s_{i-1}}\)</span>。</p><p>然后这里分了两种情况（似乎是想比较直接用encoder的一层提取出来的特征，和把这些特征累加起来，产生效果的区别)。</p><p>如果<code>self.warp_feature == 'T1'</code>,那么就直接将<span class="math inline">\(F_{s_{i-1}}\)</span>（即 x）,<span class="math inline">\(E_{s_{i}}\)</span>, warped_T1 做concatenation，然后经过SegDecoder网络得到新的 x。</p><p>如果<code>self.warp_feature == 'encoder'</code>这种情况下就直接用encoder的一层提取出来的特征，然后产生新的 x。</p><h3 id="make_grid">make_grid</h3><p>然后对得到的结果进行进一步的处理： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">make_grid</span>(<span class="hljs-params">N, iH, iW,opt</span>):<br>    grid_x = torch.linspace(-<span class="hljs-number">1.0</span>, <span class="hljs-number">1.0</span>, iW).view(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, iW, <span class="hljs-number">1</span>).expand(N, iH, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>)<br>    grid_y = torch.linspace(-<span class="hljs-number">1.0</span>, <span class="hljs-number">1.0</span>, iH).view(<span class="hljs-number">1</span>, iH, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>).expand(N, -<span class="hljs-number">1</span>, iW, -<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">if</span> opt.cuda :<br>        grid = torch.cat([grid_x, grid_y], <span class="hljs-number">3</span>).cuda()<br>    <span class="hljs-keyword">else</span>:<br>        grid = torch.cat([grid_x, grid_y], <span class="hljs-number">3</span>)<br>    <span class="hljs-keyword">return</span> grid<br></code></pre></td></tr></table></figure></p><h4 id="view">view</h4><p><code>view</code> 方法用于改变张量的形状而不改变其数据。你可以将其视为重新排列或解释张量中数据的一种方式，但实际的数据内容和顺序不变。这通常用于调整数据的维度以匹配特定操作或模型的输入需求。</p><ul><li><strong>使用场景</strong>：例如，如果你有一个形状为 <code>[10, 256]</code> 的张量，你可以使用 <code>.view(10, 16, 16)</code> 将其重新形状为 <code>[10, 16, 16]</code>，这样做是为了将它用作图像批次，其中每张图像是 16x16 像素。</li><li><strong>限制</strong>：使用 <code>view</code> 需要张量在内存中是连续的（即无跨步问题）。如果不是，可能需要先调用 <code>.contiguous()</code>。</li></ul><h4 id="expand">expand</h4><p><code>expand</code> 方法用于“广播”一个张量，让它在某些维度上看起来更大，但实际上不复制数据。这是一种内存高效的方式来使用原始数据执行批量操作，因为它只是改变张量的视图而不实际创建新的数据副本。</p><p>在 PyTorch 中使用 <code>expand</code> 方法时，参数 <code>-1</code> 指示在该维度上保持当前的尺寸不变。它相当于说“在这个维度上，不需要扩展或重复数据”。</p><p>在 <code>torch.cat</code> 函数中，第三个参数指的是 <code>dim</code>，即维度参数，它告诉函数沿哪个维度进行张量的拼接。在您的示例 <code>torch.cat([grid_x, grid_y], 3)</code> 中，这个参数是 <code>3</code>，意味着张量将沿着第四个维度（维度索引从 0 开始）进行合并。</p><p>这个函数做了四件事：</p><ol type="1"><li><strong>创建坐标网格</strong>:<ul><li><code>torch.linspace(-1.0, 1.0, iW)</code> 和 <code>torch.linspace(-1.0, 1.0, iH)</code> 分别生成水平和垂直方向上从 -1 到 1 的均匀间隔的数值，这些数值代表了归一化坐标系统中的位置。<code>iW</code> 和 <code>iH</code> 是图像的宽度和高度，这确保了网格覆盖了整个图像的每个像素。</li></ul></li><li><strong>调整维度和复制</strong>:<ul><li><code>view(1, 1, iW, 1)</code> 和 <code>view(1, iH, 1, 1)</code> 对生成的线性间隔进行维度调整，使其能够与图像的宽度和高度匹配。</li><li><code>expand(N, iH, -1, -1)</code> 和 <code>expand(N, -1, iW, -1)</code> 这两个函数调用将单个坐标行或列扩展成完整的 N×iH×iW 网格。<code>N</code> 是批处理大小，表示生成的网格需要复制 N 次以匹配批中的每个图像。</li></ul></li><li><strong>合并坐标网格</strong>:<ul><li><code>torch.cat([grid_x, grid_y], 3)</code> 将水平和垂直坐标网格沿着最后一个维度（通道维）合并，形成一个完整的网格。这个网格中的每个元素都是一个二维坐标点，对应于输入图像中的一个像素位置。</li></ul></li><li><strong>处理 CUDA 支持</strong>:<ul><li><code>if opt.cuda:</code> 检查一个选项（通常是一个配置对象）来确定是否使用 CUDA（即 GPU 加速）。如果是，将网格移动到 GPU 上以加速后续计算。否则，网格保留在 CPU 上。</li></ul></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python">N, _, iH, iW = input1.size()<br>grid = make_grid(N, iH, iW, opt)<br><br>flow = F.interpolate(flow_list[-<span class="hljs-number">1</span>].permute(<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>),<br>                     scale_factor=<span class="hljs-number">2</span>, mode=upsample).permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)<br>flow_norm = torch.cat([flow[:, :, :, <span class="hljs-number">0</span>:<span class="hljs-number">1</span>] / ((iW/<span class="hljs-number">2</span> - <span class="hljs-number">1.0</span>) / <span class="hljs-number">2.0</span>),<br>                       flow[:, :, :, <span class="hljs-number">1</span>:<span class="hljs-number">2</span>] / ((iH/<span class="hljs-number">2</span> - <span class="hljs-number">1.0</span>) / <span class="hljs-number">2.0</span>)], <span class="hljs-number">3</span>)<br>warped_input1 = F.grid_sample(<br>    input1, flow_norm + grid, padding_mode=<span class="hljs-string">&#x27;border&#x27;</span>)<br><br>x = self.out_layer(torch.cat([x, input2, warped_input1], <span class="hljs-number">1</span>))<br><br>warped_c = warped_input1[:, :-<span class="hljs-number">1</span>, :, :]<br>warped_cm = warped_input1[:, -<span class="hljs-number">1</span>:, :, :]<br><br><span class="hljs-keyword">return</span> flow_list, x, warped_c, warped_cm<br><br></code></pre></td></tr></table></figure><p>这里的代码是循环执行完，即生成好了<span class="math inline">\(F_{f_{4}}\)</span>和<span class="math inline">\(\hat{S}_{raw}\)</span>后执行的，然后就是用flow来对input进行变形。然后将 x，输入的segmentation map和warped clothes结合起来，经过卷积网络，生成最后的Segmentation map。</p><ul><li><code>grid = make_grid(N, iH, iW, opt)</code> 生成一个规则网格，用于后续的图像空间变换。这个网格与图像的每个像素对齐，并为 <code>grid_sample</code> 函数提供了参考坐标。</li></ul><h4 id="光流的上采样和规范化">光流的上采样和规范化</h4><ol type="1"><li><strong>光流上采样</strong>:<ul><li><code>flow = F.interpolate(flow_list[-1].permute(0, 3, 1, 2), scale_factor=2, mode=upsample).permute(0, 2, 3, 1)</code> 从光流列表中取出最后一个光流字段。而<code>interpolate</code> 函数期望数据的格式通常是 <code>(N, C, H, W)</code>，所以首先调整其维度以适配 <code>interpolate</code> 函数的输入要求，进行上采样以匹配当前输入图像的分辨率，然后再次调整维度回到正常的布局。</li></ul></li><li><strong>光流规范化</strong>:<ul><li><code>flow_norm = torch.cat([flow[:, :, :, 0:1] / ((iW/2 - 1.0) / 2.0), flow[:, :, :, 1:2] / ((iH/2 - 1.0) / 2.0)], 3)</code> 对上采样后的光流进行规范化，确保其值在<code>[-1, 1]</code>的范围内，适合用于 <code>grid_sample</code> 函数。</li></ul></li></ol><h4 id="图像的变形和特征处理">图像的变形和特征处理</h4><p>这里的input1是clothes image和clothes mask，而input2是parse_agnostic和densepose_map.</p><ol type="1"><li><strong>应用光流和网格变形</strong>:<ul><li><code>warped_input1 = F.grid_sample(input1, flow_norm + grid, padding_mode='border')</code> 使用规范化的光流和生成的网格对输入图像 <code>input1</code> 进行空间变换。这里使用的 <code>border</code> 填充模式，保证在图像边缘外的采样不会导致错误或异常值。</li></ul></li><li><strong>特征合并</strong>:<ul><li><code>x = self.out_layer(torch.cat([x, input2, warped_input1], 1))</code> 将中间特征 <code>x</code>、第二输入 <code>input2</code> 和变形后的图像 <code>warped_input1</code> 合并，并通过模型的输出层处理。这一步整合了来自不同源的信息，以产生综合的输出特征。</li></ul></li></ol><h4 id="输出分割和返回">输出分割和返回</h4><ol type="1"><li><strong>输出分割</strong>:<ul><li><code>warped_c = warped_input1[:, :-1, :, :]</code>这行代码提取除了最后一个通道之外的所有通道。<code>warped_cm = warped_input1[:, -1:, :, :]</code> 这行代码专门提取 <code>warped_input1</code> 张量中的最后一个通道。这是为了从变形后的图像中分离出颜色部分和掩模部分。</li></ul></li><li><strong>函数返回</strong>:<ul><li><code>return flow_list, x, warped_c, warped_cm</code> 返回光流列表、合成的输出特征 <code>x</code>、颜色信息 <code>warped_c</code> 和掩模信息 <code>warped_cm</code>。这些输出可以用于进一步的处理或作为模型训练的结果。</li></ul></li></ol><h2 id="loss-function">Loss Function</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Vgg19</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, requires_grad=<span class="hljs-literal">False</span></span>):<br>        <span class="hljs-built_in">super</span>(Vgg19, self).__init__()<br>        vgg_pretrained_features = models.vgg19(pretrained=<span class="hljs-literal">True</span>).features<br>        self.slice1 = torch.nn.Sequential()<br>        self.slice2 = torch.nn.Sequential()<br>        self.slice3 = torch.nn.Sequential()<br>        self.slice4 = torch.nn.Sequential()<br>        self.slice5 = torch.nn.Sequential()<br>        <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>):<br>            self.slice1.add_module(<span class="hljs-built_in">str</span>(x), vgg_pretrained_features[x])<br>        <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>, <span class="hljs-number">7</span>):<br>            self.slice2.add_module(<span class="hljs-built_in">str</span>(x), vgg_pretrained_features[x])<br>        <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">7</span>, <span class="hljs-number">12</span>):<br>            self.slice3.add_module(<span class="hljs-built_in">str</span>(x), vgg_pretrained_features[x])<br>        <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">12</span>, <span class="hljs-number">21</span>):<br>            self.slice4.add_module(<span class="hljs-built_in">str</span>(x), vgg_pretrained_features[x])<br>        <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">21</span>, <span class="hljs-number">30</span>):<br>            self.slice5.add_module(<span class="hljs-built_in">str</span>(x), vgg_pretrained_features[x])<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> requires_grad:<br>            <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.parameters():<br>                param.requires_grad = <span class="hljs-literal">False</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, X</span>):<br>        h_relu1 = self.slice1(X)<br>        h_relu2 = self.slice2(h_relu1)<br>        h_relu3 = self.slice3(h_relu2)<br>        h_relu4 = self.slice4(h_relu3)<br>        h_relu5 = self.slice5(h_relu4)<br>        out = [h_relu1, h_relu2, h_relu3, h_relu4, h_relu5]<br>        <span class="hljs-keyword">return</span> out<br></code></pre></td></tr></table></figure><p>首先定义了一个VGG19网络。</p><p><code>vgg_pretrained_features = models.vgg19(pretrained=True).features</code> 加载一个预训练的 VGG-19 模型，并且只获取其特征提取层（即卷积层和激活层，不包括分类用的全连接层）。</p><p><code>self.slice1</code> 到 <code>self.slice5</code> 是分层存储不同阶段的 VGG-19 特征图的模块。这些层按照在 VGG-19 中的顺序被组织，每个 <code>slice</code> 包含了一组特定的层，这样设计使得可以提取不同深度的特征。</p><p>循环通过预训练的 VGG-19 特征，将它们根据其在原始网络中的位置分配到五个 <code>slice</code> 中。每个 <code>slice</code> 包含了连续的几层，这是根据 VGG-19 网络的结构来划分的。</p><p>使用循环遍历 <code>vgg_pretrained_features</code>（这是一个从预训练 VGG-19 模型中提取出的模块序列，包含卷积层、ReLU 层等）。</p><p>如果 <code>requires_grad</code> 设置为 <code>False</code>（通常在特征提取任务中不需要计算梯度），则禁用所有参数的梯度计算，以提高效率和减少内存消耗。</p><p>在前向传播时，输入 <code>X</code> 依次通过每个 <code>slice</code>，每个 <code>slice</code> 输出的结果作为下一个 <code>slice</code> 的输入。这种方式允许模型在多个层次上提取特征。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">VGGLoss</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, opt,layids = <span class="hljs-literal">None</span></span>):<br>        <span class="hljs-built_in">super</span>(VGGLoss, self).__init__()<br>        self.vgg = Vgg19()<br>        <span class="hljs-keyword">if</span> opt.cuda:<br>            self.vgg.cuda()<br>        self.criterion = nn.L1Loss()<br>        self.weights = [<span class="hljs-number">1.0</span>/<span class="hljs-number">32</span>, <span class="hljs-number">1.0</span>/<span class="hljs-number">16</span>, <span class="hljs-number">1.0</span>/<span class="hljs-number">8</span>, <span class="hljs-number">1.0</span>/<span class="hljs-number">4</span>, <span class="hljs-number">1.0</span>]<br>        self.layids = layids<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x, y</span>):<br>        x_vgg, y_vgg = self.vgg(x), self.vgg(y)<br>        loss = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">if</span> self.layids <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            self.layids = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(x_vgg)))<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> self.layids:<br>            loss += self.weights[i] * self.criterion(x_vgg[i], y_vgg[i].detach())<br>        <span class="hljs-keyword">return</span> loss<br></code></pre></td></tr></table></figure><p><code>self.criterion = nn.L1Loss()</code> 初始化 L1 损失函数，用于计算预测和目标之间的绝对差异。</p><p><code>self.weights = [1.0/32, 1.0/16, 1.0/8, 1.0/4, 1.0]</code> 指定了不同层输出的权重，这些权重控制了每一层特征在总损失中的贡献。</p><p><code>self.layids = layids</code> 可选参数，允许用户指定使用 VGG-19 哪些层的输出来计算损失。如果未指定，默认使用所有层的输出。</p><p>在前向传播的时候，<code>x_vgg, y_vgg = self.vgg(x), self.vgg(y)</code> 分别计算两个输入 <code>x</code>（预测图像）和 <code>y</code>（目标图像）通过 VGG-19 网络的输出。结果是两个特征列表，每个列表包含由 <code>Vgg19</code> 类返回的五个层级的特征。</p><p><strong>损失计算</strong>: - 首先检查是否指定了 <code>layids</code>，若未指定，则使用所有层 (<code>list(range(len(x_vgg)))</code>)。 - 然后遍历每个指定的层索引，计算对应层的加权 L1 损失。<code>self.criterion(x_vgg[i], y_vgg[i].detach())</code> 计算两个特征图之间的差异，其中 <code>y_vgg[i].detach()</code> 确保目标图像特征不会参与梯度计算。 - 损失加权后累加，最终得到的 <code>loss</code> 表示两个图像在 VGG-19 不同层级特征上的整体差异。</p><ul class="task-list"><li><input type="checkbox" disabled="" />为什么只有y_vgg调用了detach</li></ul><h3 id="ganloss">GANLoss</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">GANLoss</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, use_lsgan=<span class="hljs-literal">True</span>, target_real_label=<span class="hljs-number">1.0</span>, target_fake_label=<span class="hljs-number">0.0</span>,</span><br><span class="hljs-params">                 tensor=torch.FloatTensor</span>):<br>        <span class="hljs-built_in">super</span>(GANLoss, self).__init__()<br>        self.real_label = target_real_label<br>        self.fake_label = target_fake_label<br>        self.real_label_var = <span class="hljs-literal">None</span><br>        self.fake_label_var = <span class="hljs-literal">None</span><br>        self.Tensor = tensor<br>        <span class="hljs-keyword">if</span> use_lsgan:<br>            self.loss = nn.MSELoss()<br>        <span class="hljs-keyword">else</span>:<br>            self.loss = nn.BCELoss()<br></code></pre></td></tr></table></figure><p><strong>初始化成员变量</strong>: - <code>self.real_label</code> 和 <code>self.fake_label</code> 设定了真实样本和假样本的标签默认值，通常在二分类问题中，真实样本标签为 1，假样本标签为 0。 - <code>self.real_label_var</code> 和 <code>self.fake_label_var</code> 初始化为 <code>None</code>，这些变量将用于存储基于当前批量大小的目标张量。</p><p><strong>选择损失函数</strong>: - <code>if use_lsgan:</code> 根据 <code>use_lsgan</code> 的值选择损失函数类型。如果为 <code>True</code>，使用均方误差损失（<code>nn.MSELoss()</code>），适用于LSGAN的设置。如果为 <code>False</code>，则使用二元交叉熵损失（<code>nn.BCELoss()</code>），适用于传统的GAN。</p><p><strong>设置张量类型</strong>: <code>self.Tensor</code> 用于指定在创建标签张量时使用的数据类型，通常是 <code>torch.FloatTensor</code> 或其他 PyTorch 支持的数据类型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_target_tensor</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span>, target_is_real</span>):<br>    <span class="hljs-keyword">if</span> target_is_real:<br>        create_label = ((self.real_label_var <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>) <span class="hljs-keyword">or</span><br>                        (self.real_label_var.numel() != <span class="hljs-built_in">input</span>.numel()))<br>        <span class="hljs-keyword">if</span> create_label:<br>            real_tensor = self.Tensor(<span class="hljs-built_in">input</span>.size()).fill_(self.real_label)<br>            self.real_label_var = Variable(real_tensor, requires_grad=<span class="hljs-literal">False</span>)<br>        target_tensor = self.real_label_var<br>    <span class="hljs-keyword">else</span>:<br>        create_label = ((self.fake_label_var <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>) <span class="hljs-keyword">or</span><br>                        (self.fake_label_var.numel() != <span class="hljs-built_in">input</span>.numel()))<br>        <span class="hljs-keyword">if</span> create_label:<br>            fake_tensor = self.Tensor(<span class="hljs-built_in">input</span>.size()).fill_(self.fake_label)<br>            self.fake_label_var = Variable(fake_tensor, requires_grad=<span class="hljs-literal">False</span>)<br>        target_tensor = self.fake_label_var<br>    <span class="hljs-keyword">return</span> target_tensor<br><br></code></pre></td></tr></table></figure><p>通过 <code>target_is_real</code> 参数判断需要创建的是真实标签还是假标签的张量。</p><p><code>if target_is_real</code>使用条件表达式检查 <code>self.real_label_var</code> 是否为 <code>None</code>（即之前没有创建过）或者其元素数量 (<code>numel()</code>) 是否与输入的元素数量不匹配。任一条件满足即重新创建标签张量。</p><p>如果需要，使用 <code>self.Tensor(input.size()).fill_(self.real_label)</code> 创建一个与输入相同大小的张量，并填充它为 <code>self.real_label</code>（通常为1.0）。</p><p><code>Variable</code>的用法： 1. <strong>封装<code>tensor</code></strong>: <code>Variable(real_tensor)</code>将<code>real_tensor</code>封装到一个<code>Variable</code>对象中。这样，原始的<code>tensor</code>现在有了自动梯度计算的功能。 2. <strong>梯度计算</strong>: 通过设置<code>requires_grad=False</code>，这个<code>Variable</code>被标记为不需要在反向传播过程中计算梯度。这通常用于目标标签或其他不需要学习的数据，因为标签的值是预设的，我们不需要对其进行优化。</p><p>从PyTorch 0.4.0版本开始，<code>Variable</code>和<code>tensor</code>被合并，现在直接使用<code>tensor</code>对象即可进行自动梯度计算，<code>Variable</code>类被废弃。现在可以直接对<code>tensor</code>设置<code>requires_grad</code>属性来控制梯度计算。如果您使用的是PyTorch的新版本，通常不需要显式使用<code>Variable</code>类。</p><p>假标签的处理步骤与真实标签处理类似，只是使用 <code>self.fake_label</code>（通常为0.0）来填充张量，创建假标签的目标张量。</p><p>最后，函数返回创建或更新后的目标张量 (<code>target_tensor</code>)，这将用于计算损失函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span>, target_is_real</span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(<span class="hljs-built_in">input</span>[<span class="hljs-number">0</span>], <span class="hljs-built_in">list</span>):<br>        loss = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> input_i <span class="hljs-keyword">in</span> <span class="hljs-built_in">input</span>:<br>            pred = input_i[-<span class="hljs-number">1</span>]<br>            target_tensor = self.get_target_tensor(pred, target_is_real)<br>            loss += self.loss(pred, target_tensor)<br>        <span class="hljs-keyword">return</span> loss<br>    <span class="hljs-keyword">else</span>:<br>        target_tensor = self.get_target_tensor(<span class="hljs-built_in">input</span>[-<span class="hljs-number">1</span>], target_is_real)<br>        <span class="hljs-keyword">return</span> self.loss(<span class="hljs-built_in">input</span>[-<span class="hljs-number">1</span>], target_tensor)<br></code></pre></td></tr></table></figure><p><code>__call__</code> 方法是 <code>GANLoss</code> 类的一个特殊方法，允许类的实例像函数一样被调用。这个方法处理输入数据，计算生成图像与目标图像（真实或假的）之间的损失。</p><p><code>if isinstance(input[0], list):</code> 检查输入 <code>input</code> 是否包含列表。这种情况通常发生在输入是一个批次数据，每个元素（或列表）包含一个或多个预测值。这种结构可能用于处理多输出的网络层。</p><p><strong>处理列表形式的输入</strong>: - 如果 <code>input</code> 包含列表，函数将初始化 <code>loss</code> 为 0，然后逐个处理列表中的每个元素（每个子列表代表一个单独的预测序列）。 - <strong>循环遍历每个输入元素</strong>： - 对于每个子列表 <code>input_i</code>，<code>pred = input_i[-1]</code> 提取该列表中的最后一个元素，假设它是最终的预测输出。 - 使用 <code>get_target_tensor(pred, target_is_real)</code> 生成与预测 <code>pred</code> 对应的目标张量。这里的 <code>target_is_real</code> 决定了目标张量表示真实图像还是假图像。 - 计算损失 <code>self.loss(pred, target_tensor)</code>，并将其累加到 <code>loss</code> 变量中。这里 <code>self.loss</code> 可以是 <code>MSELoss</code> 或 <code>BCELoss</code>，取决于类初始化时的设置。 - 返回计算得到的总损失。</p><p><strong>处理单一预测输出的输入</strong>: - <code>target_tensor = self.get_target_tensor(input[-1], target_is_real)</code> 获取对应的目标张量，同样基于 <code>target_is_real</code>。 - 计算并返回损失 <code>self.loss(input[-1], target_tensor)</code>。</p><h2 id="nlayerdiscriminator">NLayerDiscriminator</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">NLayerDiscriminator</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_nc, ndf=<span class="hljs-number">64</span>, n_layers=<span class="hljs-number">3</span>, norm_layer=nn.BatchNorm2d, use_sigmoid=<span class="hljs-literal">False</span>, getIntermFeat=<span class="hljs-literal">False</span>, Ddropout=<span class="hljs-literal">False</span>, spectral=<span class="hljs-literal">False</span></span>):<br>        <span class="hljs-built_in">super</span>(NLayerDiscriminator, self).__init__()<br>        self.getIntermFeat = getIntermFeat<br>        self.n_layers = n_layers<br>        self.spectral_norm = spectral_norm <span class="hljs-keyword">if</span> spectral <span class="hljs-keyword">else</span> <span class="hljs-keyword">lambda</span> x: x<br><br>        kw = <span class="hljs-number">4</span><br>        padw = <span class="hljs-built_in">int</span>(np.ceil((kw - <span class="hljs-number">1.0</span>) / <span class="hljs-number">2</span>))<br>        sequence = [[nn.Conv2d(input_nc, ndf, kernel_size=kw, stride=<span class="hljs-number">2</span>, padding=padw), nn.LeakyReLU(<span class="hljs-number">0.2</span>, <span class="hljs-literal">True</span>)]]<br><br>        nf = ndf<br>        <span class="hljs-keyword">for</span> n <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, n_layers):<br>            nf_prev = nf<br>            nf = <span class="hljs-built_in">min</span>(nf * <span class="hljs-number">2</span>, <span class="hljs-number">512</span>)<br>            <span class="hljs-keyword">if</span> Ddropout:<br>                sequence += [[<br>                self.spectral_norm(nn.Conv2d(nf_prev, nf, kernel_size=kw, stride=<span class="hljs-number">2</span>, padding=padw)),<br>                norm_layer(nf), nn.LeakyReLU(<span class="hljs-number">0.2</span>, <span class="hljs-literal">True</span>), nn.Dropout(<span class="hljs-number">0.5</span>)<br>            ]]<br>            <span class="hljs-keyword">else</span>:<br>                sequence += [[<br>                    self.spectral_norm(nn.Conv2d(nf_prev, nf, kernel_size=kw, stride=<span class="hljs-number">2</span>, padding=padw)),<br>                    norm_layer(nf), nn.LeakyReLU(<span class="hljs-number">0.2</span>, <span class="hljs-literal">True</span>)<br>                ]]<br></code></pre></td></tr></table></figure><p><code>sequence = [[nn.Conv2d(input_nc, ndf, kernel_size=kw, stride=2, padding=padw), nn.LeakyReLU(0.2, True)]]</code>这种写法可以方便之后使用列表乘法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python">nf_prev = nf<br>nf = <span class="hljs-built_in">min</span>(nf * <span class="hljs-number">2</span>, <span class="hljs-number">512</span>)<br>sequence += [[<br>    nn.Conv2d(nf_prev, nf, kernel_size=kw, stride=<span class="hljs-number">1</span>, padding=padw),<br>    norm_layer(nf),<br>    nn.LeakyReLU(<span class="hljs-number">0.2</span>, <span class="hljs-literal">True</span>)<br>]]<br><br>sequence += [[nn.Conv2d(nf, <span class="hljs-number">1</span>, kernel_size=kw, stride=<span class="hljs-number">1</span>, padding=padw)]]<br><br><span class="hljs-keyword">if</span> use_sigmoid:<br>    sequence += [[nn.Sigmoid()]]<br><br><span class="hljs-keyword">if</span> getIntermFeat:<br>    <span class="hljs-keyword">for</span> n <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(sequence)):<br>        <span class="hljs-built_in">setattr</span>(self, <span class="hljs-string">&#x27;model&#x27;</span> + <span class="hljs-built_in">str</span>(n), nn.Sequential(*sequence[n]))<br><span class="hljs-keyword">else</span>:<br>    sequence_stream = []<br>    <span class="hljs-keyword">for</span> n <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(sequence)):<br>        sequence_stream += sequence[n]<br>    self.model = nn.Sequential(*sequence_stream)<br></code></pre></td></tr></table></figure><p>这里就是定义了一些网络结构。</p><p>例如，如果<code>sequence[n]</code>是一个包含三个网络层（例如<code>[layer1, layer2, layer3]</code>）的列表，那么<code>nn.Sequential(*sequence[n])</code>等同于调用<code>nn.Sequential(layer1, layer2, layer3)</code>。这里的<code>nn.Sequential</code>是一个 PyTorch 中的模块，用于创建一个模块的容器，按顺序执行这些模块。</p><p>这里<code>getIntermFeat</code>表示是否需要从鉴别器中获取中间层的特征。如果是的话，就把中间层分别作为类的属性。反之就把整个网络作为类的属性。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span></span>):<br>    <span class="hljs-keyword">if</span> self.getIntermFeat:<br>        res = [<span class="hljs-built_in">input</span>]<br>        <span class="hljs-keyword">for</span> n <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.n_layers + <span class="hljs-number">2</span>):<br>            model = <span class="hljs-built_in">getattr</span>(self, <span class="hljs-string">&#x27;model&#x27;</span> + <span class="hljs-built_in">str</span>(n))<br>            res.append(model(res[-<span class="hljs-number">1</span>]))<br>        <span class="hljs-keyword">return</span> res[<span class="hljs-number">1</span>:]<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> self.model(<span class="hljs-built_in">input</span>)<br></code></pre></td></tr></table></figure><p>forward的时候，如果需要中间层的特征，就用res列表记录下每一个中间层的特征，否则就直接返回<code>self.model()</code>的结果。 ## MultiscaleDiscriminator</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MultiscaleDiscriminator</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_nc, ndf=<span class="hljs-number">64</span>, n_layers=<span class="hljs-number">3</span>, norm_layer=nn.BatchNorm2d,</span><br><span class="hljs-params">                 use_sigmoid=<span class="hljs-literal">False</span>, num_D=<span class="hljs-number">3</span>, getIntermFeat=<span class="hljs-literal">False</span>, Ddownx2=<span class="hljs-literal">False</span>, Ddropout=<span class="hljs-literal">False</span>, spectral=<span class="hljs-literal">False</span></span>):<br>        <span class="hljs-built_in">super</span>(MultiscaleDiscriminator, self).__init__()<br>        self.num_D = num_D<br>        self.n_layers = n_layers<br>        self.getIntermFeat = getIntermFeat<br>        self.Ddownx2 = Ddownx2<br></code></pre></td></tr></table></figure><ul><li><strong>参数解释</strong>:<ul><li><code>input_nc</code>: 输入图像的通道数。</li><li><code>ndf</code>: 鉴别器的基本特征数。</li><li><code>n_layers</code>: 鉴别器中的层数。</li><li><code>norm_layer</code>: 使用的标准化层类型，这里默认是批标准化 <code>BatchNorm2d</code>。</li><li><code>use_sigmoid</code>: 在输出层是否使用 <code>Sigmoid</code> 激活函数。</li><li><code>num_D</code>: 多尺度鉴别器的数量。</li><li><code>getIntermFeat</code>: 是否获取并输出每个层的中间特征。</li><li><code>Ddownx2</code>: 是否在每个鉴别器之间对输入进行下采样。</li><li><code>Ddropout</code>: 是否在卷积层之后添加 Dropout。</li><li><code>spectral</code>: 是否应用 spectral normalization。</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_D):<br>    netD = NLayerDiscriminator(input_nc, ndf, n_layers, norm_layer,<br>                        use_sigmoid,getIntermFeat,Ddropout,spectral=spectral)<br>    <span class="hljs-keyword">if</span> getIntermFeat:<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_layers + <span class="hljs-number">2</span>):<br>            <span class="hljs-built_in">setattr</span>(self, <span class="hljs-string">&#x27;scale&#x27;</span> + <span class="hljs-built_in">str</span>(i) + <span class="hljs-string">&#x27;_layer&#x27;</span> +<br>                    <span class="hljs-built_in">str</span>(j), <span class="hljs-built_in">getattr</span>(netD, <span class="hljs-string">&#x27;model&#x27;</span> + <span class="hljs-built_in">str</span>(j)))<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-built_in">setattr</span>(self, <span class="hljs-string">&#x27;layer&#x27;</span> + <span class="hljs-built_in">str</span>(i), netD.model)<br><br>self.downsample = nn.AvgPool2d(<br>    <span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>], count_include_pad=<span class="hljs-literal">False</span>)<br><br></code></pre></td></tr></table></figure><p>这里循环创建了 <code>num_D</code> 个鉴别器，每个鉴别器都是 <code>NLayerDiscriminator</code> 类的一个实例。如果<code>getIntermFeat == True</code>，那么这个类就会保存每一个<code>NLayerDiscriminator</code>的每一个中间层。否则就只保存每一个<code>NLayerDiscriminator</code>。</p><p>最后就是创建一个Average Pool层。参数 <code>count_include_pad</code> 在 <code>nn.AvgPool2d</code> 中用于控制在计算平均值时是否将填充（padding）像素包括在内。</p><p>剩下的就是一些helper function，这里就不再讲解。</p><h1 id="network_generator.py">network_generator.py</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">BaseNetwork</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(BaseNetwork, self).__init__()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">print_network</span>(<span class="hljs-params">self</span>):<br>        num_params = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.parameters():<br>            num_params += param.numel()<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Network [&#123;&#125;] was created. Total number of parameters: &#123;:.1f&#125; million. &quot;</span><br>              <span class="hljs-string">&quot;To see the architecture, do print(network).&quot;</span>.<span class="hljs-built_in">format</span>(self.__class__.__name__, num_params / <span class="hljs-number">1000000</span>))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">init_weights</span>(<span class="hljs-params">self, init_type=<span class="hljs-string">&#x27;normal&#x27;</span>, gain=<span class="hljs-number">0.02</span></span>):<br>        <span class="hljs-keyword">def</span> <span class="hljs-title function_">init_func</span>(<span class="hljs-params">m</span>):<br>            classname = m.__class__.__name__<br>            <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;BatchNorm2d&#x27;</span> <span class="hljs-keyword">in</span> classname:<br>                <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(m, <span class="hljs-string">&#x27;weight&#x27;</span>) <span class="hljs-keyword">and</span> m.weight <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>                    init.normal_(m.weight.data, <span class="hljs-number">1.0</span>, gain)<br>                <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(m, <span class="hljs-string">&#x27;bias&#x27;</span>) <span class="hljs-keyword">and</span> m.bias <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>                    init.constant_(m.bias.data, <span class="hljs-number">0.0</span>)<br>            <span class="hljs-keyword">elif</span> (<span class="hljs-string">&#x27;Conv&#x27;</span> <span class="hljs-keyword">in</span> classname <span class="hljs-keyword">or</span> <span class="hljs-string">&#x27;Linear&#x27;</span> <span class="hljs-keyword">in</span> classname) <span class="hljs-keyword">and</span> <span class="hljs-built_in">hasattr</span>(m, <span class="hljs-string">&#x27;weight&#x27;</span>):<br>                <span class="hljs-keyword">if</span> init_type == <span class="hljs-string">&#x27;normal&#x27;</span>:<br>                    init.normal_(m.weight.data, <span class="hljs-number">0.0</span>, gain)<br>                <span class="hljs-keyword">elif</span> init_type == <span class="hljs-string">&#x27;xavier&#x27;</span>:<br>                    init.xavier_normal_(m.weight.data, gain=gain)<br>                <span class="hljs-keyword">elif</span> init_type == <span class="hljs-string">&#x27;xavier_uniform&#x27;</span>:<br>                    init.xavier_uniform_(m.weight.data, gain=<span class="hljs-number">1.0</span>)<br>                <span class="hljs-keyword">elif</span> init_type == <span class="hljs-string">&#x27;kaiming&#x27;</span>:<br>                    init.kaiming_normal_(m.weight.data, a=<span class="hljs-number">0</span>, mode=<span class="hljs-string">&#x27;fan_in&#x27;</span>)<br>                <span class="hljs-keyword">elif</span> init_type == <span class="hljs-string">&#x27;orthogonal&#x27;</span>:<br>                    init.orthogonal_(m.weight.data, gain=gain)<br>                <span class="hljs-keyword">elif</span> init_type == <span class="hljs-string">&#x27;none&#x27;</span>:  <span class="hljs-comment"># uses pytorch&#x27;s default init method</span><br>                    m.reset_parameters()<br>                <span class="hljs-keyword">else</span>:<br>                    <span class="hljs-keyword">raise</span> NotImplementedError(<span class="hljs-string">&quot;initialization method &#x27;&#123;&#125;&#x27; is not implemented&quot;</span>.<span class="hljs-built_in">format</span>(init_type))<br>                <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(m, <span class="hljs-string">&#x27;bias&#x27;</span>) <span class="hljs-keyword">and</span> m.bias <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>                    init.constant_(m.bias.data, <span class="hljs-number">0.0</span>)<br><br>        self.apply(init_func)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, *inputs</span>):<br>        <span class="hljs-keyword">pass</span><br></code></pre></td></tr></table></figure><p>这里定义了打印网络的函数，定义了初始化权重的方法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MaskNorm</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, norm_nc</span>):<br>        <span class="hljs-built_in">super</span>(MaskNorm, self).__init__()<br><br>        self.norm_layer = nn.InstanceNorm2d(norm_nc, affine=<span class="hljs-literal">False</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">normalize_region</span>(<span class="hljs-params">self, region, mask</span>):<br>        b, c, h, w = region.size()<br><br>        num_pixels = mask.<span class="hljs-built_in">sum</span>((<span class="hljs-number">2</span>, <span class="hljs-number">3</span>), keepdim=<span class="hljs-literal">True</span>)  <span class="hljs-comment"># size: (b, 1, 1, 1)</span><br>        num_pixels[num_pixels == <span class="hljs-number">0</span>] = <span class="hljs-number">1</span><br>        mu = region.<span class="hljs-built_in">sum</span>((<span class="hljs-number">2</span>, <span class="hljs-number">3</span>), keepdim=<span class="hljs-literal">True</span>) / num_pixels  <span class="hljs-comment"># size: (b, c, 1, 1)</span><br><br>        normalized_region = self.norm_layer(region + (<span class="hljs-number">1</span> - mask) * mu)<br>        <span class="hljs-keyword">return</span> normalized_region * torch.sqrt(num_pixels / (h * w))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x, mask</span>):<br>        mask = mask.detach()<br>        normalized_foreground = self.normalize_region(x * mask, mask)<br>        normalized_background = self.normalize_region(x * (<span class="hljs-number">1</span> - mask), <span class="hljs-number">1</span> - mask)<br>        <span class="hljs-keyword">return</span> normalized_foreground + normalized_background<br></code></pre></td></tr></table></figure><p>这里定义了MaskNorm，沿用了VITON-HD的代码，实际效果就是VITON-HD中所说的ALIASNorm.</p><h2 id="spadenorm">SPADENorm</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">SPADENorm</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,opt, norm_type, norm_nc, label_nc</span>):<br>        <span class="hljs-built_in">super</span>(SPADENorm, self).__init__()<br>        self.param_opt=opt<br>        self.noise_scale = nn.Parameter(torch.zeros(norm_nc))<br><br>        <span class="hljs-keyword">assert</span> norm_type.startswith(<span class="hljs-string">&#x27;alias&#x27;</span>)<br>        param_free_norm_type = norm_type[<span class="hljs-built_in">len</span>(<span class="hljs-string">&#x27;alias&#x27;</span>):]<br>        <span class="hljs-keyword">if</span> param_free_norm_type == <span class="hljs-string">&#x27;batch&#x27;</span>:<br>            self.param_free_norm = nn.BatchNorm2d(norm_nc, affine=<span class="hljs-literal">False</span>)<br>        <span class="hljs-keyword">elif</span> param_free_norm_type == <span class="hljs-string">&#x27;instance&#x27;</span>:<br>            self.param_free_norm = nn.InstanceNorm2d(norm_nc, affine=<span class="hljs-literal">False</span>)<br>        <span class="hljs-keyword">elif</span> param_free_norm_type == <span class="hljs-string">&#x27;mask&#x27;</span>:<br>            self.param_free_norm = MaskNorm(norm_nc)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">raise</span> ValueError(<br>                <span class="hljs-string">&quot;&#x27;&#123;&#125;&#x27; is not a recognized parameter-free normalization type in SPADENorm&quot;</span>.<span class="hljs-built_in">format</span>(param_free_norm_type)<br>            )<br><br>        nhidden = <span class="hljs-number">128</span><br>        ks = <span class="hljs-number">3</span><br>        pw = ks // <span class="hljs-number">2</span><br>        self.conv_shared = nn.Sequential(nn.Conv2d(label_nc, nhidden, kernel_size=ks, padding=pw), nn.ReLU())<br>        self.conv_gamma = nn.Conv2d(nhidden, norm_nc, kernel_size=ks, padding=pw)<br>        self.conv_beta = nn.Conv2d(nhidden, norm_nc, kernel_size=ks, padding=pw)<br></code></pre></td></tr></table></figure><p>SPADE（Spatially-Adaptive (De)normalization）是一种先进的归一化技术，特别用于生成模型中，如生成对抗网络（GANs）。这种技术首次在论文《Semantic Image Synthesis with Spatially-Adaptive Normalization》中被详细介绍，该论文主要针对语义图像合成任务。 ### SPADENorm 的工作原理： - <strong>目的</strong>：传统的归一化技术（如Batch Normalization）会移除特征图中的语义信息，这对于分类任务可能是有利的，但在图像生成任务中可能会导致生成质量下降。SPADE 的目的是在进行归一化的同时保留足够的语义信息，以提高生成图像的质量和相关性。 - <strong>操作</strong>：SPADENorm 替代了标准的归一化方法中的scale和bias参数，使用从输入语义布局（例如，语义标签图）学习到的参数来调制归一化后的特征图。具体来说，它首先对特征图进行标准的归一化处理（均值为 0，方差为 1），然后通过一个从语义图学习的网络（通常是卷积网络）来预测调制（modulate）每个像素的scale和bias参数。 - <strong>结构</strong>：这个调制网络接受语义布局图作为输入，输出与归一化特征图尺寸相同的scale和bias图，这些图随后用于调整归一化特征图的每个像素。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x, seg, misalign_mask=<span class="hljs-literal">None</span></span>):<br>    <span class="hljs-comment"># Part 1. Generate parameter-free normalized activations.</span><br>    b, c, h, w = x.size()<br>    <span class="hljs-keyword">if</span> self.param_opt.cuda :<br>        noise = (torch.randn(b, w, h, <span class="hljs-number">1</span>).cuda() * self.noise_scale).transpose(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>)<br>    <span class="hljs-keyword">else</span>:<br>        noise = (torch.randn(b, w, h, <span class="hljs-number">1</span>)* self.noise_scale).transpose(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>)<br><br>    <span class="hljs-keyword">if</span> misalign_mask <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>        normalized = self.param_free_norm(x + noise)<br>    <span class="hljs-keyword">else</span>:<br>        normalized = self.param_free_norm(x + noise, misalign_mask)<br><br>    <span class="hljs-comment"># Part 2. Produce affine parameters conditioned on the segmentation map.</span><br>    actv = self.conv_shared(seg)<br>    gamma = self.conv_gamma(actv)<br>    beta = self.conv_beta(actv)<br><br>    <span class="hljs-comment"># Apply the affine parameters.</span><br>    output = normalized * (<span class="hljs-number">1</span> + gamma) + beta<br>    <span class="hljs-keyword">return</span> output<br></code></pre></td></tr></table></figure><p>这后面的处理也是和VITON-HD一样的，只是这里明确指出了这个是使用了SPADENorm。即通过一个从segmentation map学习的网络（通常是卷积网络）来预测调制（modulate）每个像素的scale和bias参数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">SPADEResBlock</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, opt, input_nc, output_nc, use_mask_norm=<span class="hljs-literal">True</span></span>):<br>        <span class="hljs-built_in">super</span>(SPADEResBlock, self).__init__()<br>        self.param_opt=opt<br>        self.learned_shortcut = (input_nc != output_nc)<br>        middle_nc = <span class="hljs-built_in">min</span>(input_nc, output_nc)<br><br>        self.conv_0 = nn.Conv2d(input_nc, middle_nc, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>)<br>        self.conv_1 = nn.Conv2d(middle_nc, output_nc, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">if</span> self.learned_shortcut:<br>            self.conv_s = nn.Conv2d(input_nc, output_nc, kernel_size=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">False</span>)<br><br>        subnorm_type = opt.norm_G<br>        <span class="hljs-keyword">if</span> subnorm_type.startswith(<span class="hljs-string">&#x27;spectral&#x27;</span>):<br>            subnorm_type = subnorm_type[<span class="hljs-built_in">len</span>(<span class="hljs-string">&#x27;spectral&#x27;</span>):]<br>            self.conv_0 = spectral_norm(self.conv_0)<br>            self.conv_1 = spectral_norm(self.conv_1)<br>            <span class="hljs-keyword">if</span> self.learned_shortcut:<br>                self.conv_s = spectral_norm(self.conv_s)<br><br>        gen_semantic_nc = opt.gen_semantic_nc<br>        <span class="hljs-keyword">if</span> use_mask_norm:<br>            subnorm_type = <span class="hljs-string">&#x27;aliasmask&#x27;</span><br>            gen_semantic_nc = gen_semantic_nc + <span class="hljs-number">1</span><br><br>        self.norm_0 = SPADENorm(opt,subnorm_type, input_nc, gen_semantic_nc)<br>        self.norm_1 = SPADENorm(opt,subnorm_type, middle_nc, gen_semantic_nc)<br>        <span class="hljs-keyword">if</span> self.learned_shortcut:<br>            self.norm_s = SPADENorm(opt,subnorm_type, input_nc, gen_semantic_nc)<br><br>        self.relu = nn.LeakyReLU(<span class="hljs-number">0.2</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">shortcut</span>(<span class="hljs-params">self, x, seg, misalign_mask</span>):<br>        <span class="hljs-keyword">if</span> self.learned_shortcut:<br>            <span class="hljs-keyword">return</span> self.conv_s(self.norm_s(x, seg, misalign_mask))<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">return</span> x<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x, seg, misalign_mask=<span class="hljs-literal">None</span></span>):<br>        seg = F.interpolate(seg, size=x.size()[<span class="hljs-number">2</span>:], mode=<span class="hljs-string">&#x27;nearest&#x27;</span>)<br>        <span class="hljs-keyword">if</span> misalign_mask <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            misalign_mask = F.interpolate(misalign_mask, size=x.size()[<span class="hljs-number">2</span>:], mode=<span class="hljs-string">&#x27;nearest&#x27;</span>)<br><br>        x_s = self.shortcut(x, seg, misalign_mask)<br><br>        dx = self.conv_0(self.relu(self.norm_0(x, seg, misalign_mask)))<br>        dx = self.conv_1(self.relu(self.norm_1(dx, seg, misalign_mask)))<br>        output = x_s + dx<br>        <span class="hljs-keyword">return</span> output<br></code></pre></td></tr></table></figure><p>这里也同样沿用了VITON-HD的代码，内容基本和VITON-HD中的ALIASResBlock基本一致。</p><p>下面的SPADEGenerator也和VITON-HD的ALIASGenerator几乎一模一样，不过为了完整性我还是把代码贴在下面。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">SPADEGenerator</span>(<span class="hljs-title class_ inherited__">BaseNetwork</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, opt, input_nc</span>):<br>        <span class="hljs-built_in">super</span>(SPADEGenerator, self).__init__()<br>        self.num_upsampling_layers = opt.num_upsampling_layers<br>        self.param_opt=opt<br>        self.sh, self.sw = self.compute_latent_vector_size(opt)<br><br>        nf = opt.ngf<br>        self.conv_0 = nn.Conv2d(input_nc, nf * <span class="hljs-number">16</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">8</span>):<br>            self.add_module(<span class="hljs-string">&#x27;conv_&#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(i), nn.Conv2d(input_nc, <span class="hljs-number">16</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>))<br><br>        self.head_0 = SPADEResBlock(opt, nf * <span class="hljs-number">16</span>, nf * <span class="hljs-number">16</span>, use_mask_norm=<span class="hljs-literal">False</span>)<br><br>        self.G_middle_0 = SPADEResBlock(opt, nf * <span class="hljs-number">16</span> + <span class="hljs-number">16</span>, nf * <span class="hljs-number">16</span>, use_mask_norm=<span class="hljs-literal">False</span>)<br>        self.G_middle_1 = SPADEResBlock(opt, nf * <span class="hljs-number">16</span> + <span class="hljs-number">16</span>, nf * <span class="hljs-number">16</span>, use_mask_norm=<span class="hljs-literal">False</span>)<br><br>        self.up_0 = SPADEResBlock(opt, nf * <span class="hljs-number">16</span> + <span class="hljs-number">16</span>, nf * <span class="hljs-number">8</span>, use_mask_norm=<span class="hljs-literal">False</span>)<br>        self.up_1 = SPADEResBlock(opt, nf * <span class="hljs-number">8</span> + <span class="hljs-number">16</span>, nf * <span class="hljs-number">4</span>, use_mask_norm=<span class="hljs-literal">False</span>)<br>        self.up_2 = SPADEResBlock(opt, nf * <span class="hljs-number">4</span> + <span class="hljs-number">16</span>, nf * <span class="hljs-number">2</span>, use_mask_norm=<span class="hljs-literal">False</span>)<br>        self.up_3 = SPADEResBlock(opt, nf * <span class="hljs-number">2</span> + <span class="hljs-number">16</span>, nf * <span class="hljs-number">1</span>, use_mask_norm=<span class="hljs-literal">False</span>)<br>        <span class="hljs-keyword">if</span> self.num_upsampling_layers == <span class="hljs-string">&#x27;most&#x27;</span>:<br>            self.up_4 = SPADEResBlock(opt, nf * <span class="hljs-number">1</span> + <span class="hljs-number">16</span>, nf // <span class="hljs-number">2</span>, use_mask_norm=<span class="hljs-literal">False</span>)<br>            nf = nf // <span class="hljs-number">2</span><br><br>        self.conv_img = nn.Conv2d(nf, <span class="hljs-number">3</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>)<br><br>        self.up = nn.Upsample(scale_factor=<span class="hljs-number">2</span>, mode=<span class="hljs-string">&#x27;nearest&#x27;</span>)<br>        self.relu = nn.LeakyReLU(<span class="hljs-number">0.2</span>)<br>        self.tanh = nn.Tanh()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_latent_vector_size</span>(<span class="hljs-params">self, opt</span>):<br>        <span class="hljs-keyword">if</span> self.num_upsampling_layers == <span class="hljs-string">&#x27;normal&#x27;</span>:<br>            num_up_layers = <span class="hljs-number">5</span><br>        <span class="hljs-keyword">elif</span> self.num_upsampling_layers == <span class="hljs-string">&#x27;more&#x27;</span>:<br>            num_up_layers = <span class="hljs-number">6</span><br>        <span class="hljs-keyword">elif</span> self.num_upsampling_layers == <span class="hljs-string">&#x27;most&#x27;</span>:<br>            num_up_layers = <span class="hljs-number">7</span><br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&quot;opt.num_upsampling_layers &#x27;&#123;&#125;&#x27; is not recognized&quot;</span>.<span class="hljs-built_in">format</span>(self.num_upsampling_layers))<br><br>        sh = opt.fine_height // <span class="hljs-number">2</span>**num_up_layers<br>        sw = opt.fine_width // <span class="hljs-number">2</span>**num_up_layers<br>        <span class="hljs-keyword">return</span> sh, sw<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x, seg</span>):<br>        samples = [F.interpolate(x, size=(self.sh * <span class="hljs-number">2</span>**i, self.sw * <span class="hljs-number">2</span>**i), mode=<span class="hljs-string">&#x27;nearest&#x27;</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">8</span>)]<br>        features = [self._modules[<span class="hljs-string">&#x27;conv_&#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(i)](samples[i]) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">8</span>)]<br><br>        x = self.head_0(features[<span class="hljs-number">0</span>], seg)<br>        x = self.up(x)<br>        x = self.G_middle_0(torch.cat((x, features[<span class="hljs-number">1</span>]), <span class="hljs-number">1</span>), seg)<br>        <span class="hljs-keyword">if</span> self.num_upsampling_layers <span class="hljs-keyword">in</span> [<span class="hljs-string">&#x27;more&#x27;</span>, <span class="hljs-string">&#x27;most&#x27;</span>]:<br>            x = self.up(x)<br>        x = self.G_middle_1(torch.cat((x, features[<span class="hljs-number">2</span>]), <span class="hljs-number">1</span>), seg)<br><br>        x = self.up(x)<br>        x = self.up_0(torch.cat((x, features[<span class="hljs-number">3</span>]), <span class="hljs-number">1</span>), seg)<br>        x = self.up(x)<br>        x = self.up_1(torch.cat((x, features[<span class="hljs-number">4</span>]), <span class="hljs-number">1</span>), seg)<br>        x = self.up(x)<br>        x = self.up_2(torch.cat((x, features[<span class="hljs-number">5</span>]), <span class="hljs-number">1</span>), seg)<br>        x = self.up(x)<br>        x = self.up_3(torch.cat((x, features[<span class="hljs-number">6</span>]), <span class="hljs-number">1</span>), seg)<br>        <span class="hljs-keyword">if</span> self.num_upsampling_layers == <span class="hljs-string">&#x27;most&#x27;</span>:<br>            x = self.up(x)<br>            x = self.up_4(torch.cat((x, features[<span class="hljs-number">7</span>]), <span class="hljs-number">1</span>), seg)<br><br>        x = self.conv_img(self.relu(x))<br>        <span class="hljs-keyword">return</span> self.tanh(x)<br></code></pre></td></tr></table></figure><h2 id="another-nlayerdiscriminator">Another NLayerDiscriminator</h2><p>这里又定义了一个NLayerDiscriminator <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">NLayerDiscriminator</span>(<span class="hljs-title class_ inherited__">BaseNetwork</span>):<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, opt</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.no_ganFeat_loss = opt.no_ganFeat_loss<br>        nf = opt.ndf<br><br>        kw = <span class="hljs-number">4</span><br>        pw = <span class="hljs-built_in">int</span>(np.ceil((kw - <span class="hljs-number">1.0</span>) / <span class="hljs-number">2</span>))<br>        norm_layer = get_nonspade_norm_layer(opt.norm_D)<br><br>        input_nc = opt.gen_semantic_nc + <span class="hljs-number">3</span><br>        <span class="hljs-comment"># input_nc = opt.gen_semantic_nc + 13</span><br>        sequence = [[nn.Conv2d(input_nc, nf, kernel_size=kw, stride=<span class="hljs-number">2</span>, padding=pw),<br>                     nn.LeakyReLU(<span class="hljs-number">0.2</span>, <span class="hljs-literal">False</span>)]]<br><br>        <span class="hljs-keyword">for</span> n <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, opt.n_layers_D):<br>            nf_prev = nf<br>            nf = <span class="hljs-built_in">min</span>(nf * <span class="hljs-number">2</span>, <span class="hljs-number">512</span>)<br>            sequence += [[norm_layer(nn.Conv2d(nf_prev, nf, kernel_size=kw, stride=<span class="hljs-number">2</span>, padding=pw)),<br>                          nn.LeakyReLU(<span class="hljs-number">0.2</span>, <span class="hljs-literal">False</span>)]]<br><br>        sequence += [[nn.Conv2d(nf, <span class="hljs-number">1</span>, kernel_size=kw, stride=<span class="hljs-number">1</span>, padding=pw)]]<br><br>        <span class="hljs-comment"># We divide the layers into groups to extract intermediate layer outputs</span><br>        <span class="hljs-keyword">for</span> n <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(sequence)):<br>            self.add_module(<span class="hljs-string">&#x27;model&#x27;</span> + <span class="hljs-built_in">str</span>(n), nn.Sequential(*sequence[n]))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span></span>):<br>        results = [<span class="hljs-built_in">input</span>]<br>        <span class="hljs-keyword">for</span> submodel <span class="hljs-keyword">in</span> self.children():<br>            intermediate_output = submodel(results[-<span class="hljs-number">1</span>])<br>            results.append(intermediate_output)<br><br>        get_intermediate_features = <span class="hljs-keyword">not</span> self.no_ganFeat_loss<br>        <span class="hljs-keyword">if</span> get_intermediate_features:<br>            <span class="hljs-keyword">return</span> results[<span class="hljs-number">1</span>:]<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">return</span> results[-<span class="hljs-number">1</span>]<br></code></pre></td></tr></table></figure></p><p>不同点在于，这次初始化网络的时候默认把中间层分开，然后在最后forward也算出所有中间特征，然后再视情况决定要不要返回中间的特征。</p><h2 id="another-multiscalediscriminator">Another MultiscaleDiscriminator</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MultiscaleDiscriminator</span>(<span class="hljs-title class_ inherited__">BaseNetwork</span>):<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, opt</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.no_ganFeat_loss = opt.no_ganFeat_loss<br><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(opt.num_D):<br>            subnetD = NLayerDiscriminator(opt)<br>            self.add_module(<span class="hljs-string">&#x27;discriminator_%d&#x27;</span> % i, subnetD)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">downsample</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span></span>):<br>        <span class="hljs-keyword">return</span> F.avg_pool2d(<span class="hljs-built_in">input</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>], count_include_pad=<span class="hljs-literal">False</span>)<br><br>    <span class="hljs-comment"># Returns list of lists of discriminator outputs.</span><br>    <span class="hljs-comment"># The final result is of size opt.num_D x opt.n_layers_D</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span></span>):<br>        result = []<br>        get_intermediate_features = <span class="hljs-keyword">not</span> self.no_ganFeat_loss<br>        <span class="hljs-keyword">for</span> name, D <span class="hljs-keyword">in</span> self.named_children():<br>            out = D(<span class="hljs-built_in">input</span>)<br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> get_intermediate_features:<br>                out = [out]<br>            result.append(out)<br>            <span class="hljs-built_in">input</span> = self.downsample(<span class="hljs-built_in">input</span>)<br><br>        <span class="hljs-keyword">return</span> result<br></code></pre></td></tr></table></figure><p><code>for name, D in self.named_children():</code> - <code>named_children()</code> 是 <code>nn.Module</code> 的一个方法，它返回一个迭代器，包含模块的所有子模块（children），每个子模块以 (name, module) 的形式呈现。这行代码的意思是对每个子模块进行遍历。</p><h2 id="ganloss-for-image-generator">GANLoss for Image Generator</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">GANLoss</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, gan_mode, target_real_label=<span class="hljs-number">1.0</span>, target_fake_label=<span class="hljs-number">0.0</span>, tensor=torch.FloatTensor</span>):<br>        <span class="hljs-built_in">super</span>(GANLoss, self).__init__()<br>        self.real_label = target_real_label<br>        self.fake_label = target_fake_label<br>        self.real_label_tensor = <span class="hljs-literal">None</span><br>        self.fake_label_tensor = <span class="hljs-literal">None</span><br>        self.zero_tensor = <span class="hljs-literal">None</span><br>        self.Tensor = tensor<br>        self.gan_mode = gan_mode<br>        <span class="hljs-keyword">if</span> gan_mode == <span class="hljs-string">&#x27;ls&#x27;</span>:<br>            <span class="hljs-keyword">pass</span><br>        <span class="hljs-keyword">elif</span> gan_mode == <span class="hljs-string">&#x27;original&#x27;</span>:<br>            <span class="hljs-keyword">pass</span><br>        <span class="hljs-keyword">elif</span> gan_mode == <span class="hljs-string">&#x27;w&#x27;</span>:<br>            <span class="hljs-keyword">pass</span><br>        <span class="hljs-keyword">elif</span> gan_mode == <span class="hljs-string">&#x27;hinge&#x27;</span>:<br>            <span class="hljs-keyword">pass</span><br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&#x27;Unexpected gan_mode &#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(gan_mode))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_target_tensor</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span>, target_is_real</span>):<br>        <span class="hljs-keyword">if</span> target_is_real:<br>            <span class="hljs-keyword">if</span> self.real_label_tensor <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>                self.real_label_tensor = self.Tensor(<span class="hljs-number">1</span>).fill_(self.real_label)<br>                self.real_label_tensor.requires_grad_(<span class="hljs-literal">False</span>)<br>            <span class="hljs-keyword">return</span> self.real_label_tensor.expand_as(<span class="hljs-built_in">input</span>)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">if</span> self.fake_label_tensor <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>                self.fake_label_tensor = self.Tensor(<span class="hljs-number">1</span>).fill_(self.fake_label)<br>                self.fake_label_tensor.requires_grad_(<span class="hljs-literal">False</span>)<br>            <span class="hljs-keyword">return</span> self.fake_label_tensor.expand_as(<span class="hljs-built_in">input</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_zero_tensor</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span></span>):<br>        <span class="hljs-keyword">if</span> self.zero_tensor <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            self.zero_tensor = self.Tensor(<span class="hljs-number">1</span>).fill_(<span class="hljs-number">0</span>)<br>            self.zero_tensor.requires_grad_(<span class="hljs-literal">False</span>)<br>        <span class="hljs-keyword">return</span> self.zero_tensor.expand_as(<span class="hljs-built_in">input</span>)<br></code></pre></td></tr></table></figure><p><code>gan_mode</code>: 一个字符串参数，指定使用的GAN模式，比如 <code>'ls'</code>（最小二乘GAN），<code>'original'</code>（原始GAN），<code>'w'</code>（Wasserstein GAN），或者 <code>'hinge'</code>。</p><p>然后代码根据不同的 <code>gan_mode</code> 设置损失函数的具体行为。当前代码示例中，对每种模式都只是简单通过 <code>pass</code> 语句占位，没有具体的实现。如果传入的 <code>gan_mode</code> 不是预期值之一，会抛出一个 <code>ValueError</code>。</p><p><code>get_target_tensor</code>方法用于生成目标张量，这个张量将用于计算损失函数。根据 <code>target_is_real</code> 的真假决定返回针对真实数据的标签张量还是假数据的标签张量。如果相应的张量尚未初始化，则创建一个新的填充了相应标签值的张量，并设置其不需要梯度。</p><p><code>get_zero_tensor</code>方法用于生成一个值为0的张量，主要用于计算某些类型的GAN损失函数时，需要用到0值的场景。同样地，如果零值张量尚未初始化，则创建它。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">loss</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span>, target_is_real, for_discriminator=<span class="hljs-literal">True</span></span>):<br>    <span class="hljs-keyword">if</span> self.gan_mode == <span class="hljs-string">&#x27;original&#x27;</span>:  <span class="hljs-comment"># cross entropy loss</span><br>        target_tensor = self.get_target_tensor(<span class="hljs-built_in">input</span>, target_is_real)<br>        loss = F.binary_cross_entropy_with_logits(<span class="hljs-built_in">input</span>, target_tensor)<br>        <span class="hljs-keyword">return</span> loss<br>    <span class="hljs-keyword">elif</span> self.gan_mode == <span class="hljs-string">&#x27;ls&#x27;</span>:<br>        target_tensor = self.get_target_tensor(<span class="hljs-built_in">input</span>, target_is_real)<br>        <span class="hljs-keyword">return</span> F.mse_loss(<span class="hljs-built_in">input</span>, target_tensor)<br>    <span class="hljs-keyword">elif</span> self.gan_mode == <span class="hljs-string">&#x27;hinge&#x27;</span>:<br>        <span class="hljs-keyword">if</span> for_discriminator:<br>            <span class="hljs-keyword">if</span> target_is_real:<br>                minval = torch.<span class="hljs-built_in">min</span>(<span class="hljs-built_in">input</span> - <span class="hljs-number">1</span>, self.get_zero_tensor(<span class="hljs-built_in">input</span>))<br>                loss = -torch.mean(minval)<br>            <span class="hljs-keyword">else</span>:<br>                minval = torch.<span class="hljs-built_in">min</span>(-<span class="hljs-built_in">input</span> - <span class="hljs-number">1</span>, self.get_zero_tensor(<span class="hljs-built_in">input</span>))<br>                loss = -torch.mean(minval)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">assert</span> target_is_real, <span class="hljs-string">&quot;The generator&#x27;s hinge loss must be aiming for real&quot;</span><br>            loss = -torch.mean(<span class="hljs-built_in">input</span>)<br>        <span class="hljs-keyword">return</span> loss<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-comment"># wgan</span><br>        <span class="hljs-keyword">if</span> target_is_real:<br>            <span class="hljs-keyword">return</span> -<span class="hljs-built_in">input</span>.mean()<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">return</span> <span class="hljs-built_in">input</span>.mean()<br></code></pre></td></tr></table></figure><p>这里是根据不同的gan_mode选用了不同的loss function。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span>, target_is_real, for_discriminator=<span class="hljs-literal">True</span></span>):<br>    <span class="hljs-comment"># computing loss is a bit complicated because |input| may not be</span><br>    <span class="hljs-comment"># a tensor, but list of tensors in case of multiscale discriminator</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(<span class="hljs-built_in">input</span>, <span class="hljs-built_in">list</span>):<br>        loss = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> pred_i <span class="hljs-keyword">in</span> <span class="hljs-built_in">input</span>:<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(pred_i, <span class="hljs-built_in">list</span>):<br>                pred_i = pred_i[-<span class="hljs-number">1</span>]<br>            loss_tensor = self.loss(pred_i, target_is_real, for_discriminator)<br>            bs = <span class="hljs-number">1</span> <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(loss_tensor.size()) == <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> loss_tensor.size(<span class="hljs-number">0</span>)<br>            new_loss = torch.mean(loss_tensor.view(bs, -<span class="hljs-number">1</span>), dim=<span class="hljs-number">1</span>)<br>            loss += new_loss<br>        <span class="hljs-keyword">return</span> loss / <span class="hljs-built_in">len</span>(<span class="hljs-built_in">input</span>)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> self.loss(<span class="hljs-built_in">input</span>, target_is_real, for_discriminator)<br></code></pre></td></tr></table></figure><p>然后call的时候，这里的注释能帮助我们理解为什么要看input是不是一个list（ |input| may not be a tensor, but list of tensors in case of multiscale discriminator）</p><p>多尺度判别器是一种特殊类型的判别器，它在多个不同的尺度（即不同的分辨率或细节层次）上分析输入数据，以提高模型的性能和鉴别能力。</p><p>这里的<code>for_discriminator</code>我暂时还不知道是什么意思，之后再看看各种关于GAN的论文吧。</p><h2 id="get_nonspade_norm_layer">get_nonspade_norm_layer</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_nonspade_norm_layer</span>(<span class="hljs-params">norm_type=<span class="hljs-string">&#x27;instance&#x27;</span></span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_out_channel</span>(<span class="hljs-params">layer</span>):<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(layer, <span class="hljs-string">&#x27;out_channels&#x27;</span>):<br>            <span class="hljs-keyword">return</span> <span class="hljs-built_in">getattr</span>(layer, <span class="hljs-string">&#x27;out_channels&#x27;</span>)<br>        <span class="hljs-keyword">return</span> layer.weight.size(<span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><p>首先这个函数里面定义了另外一个函数，以获得当前layer的output_channels，以方便使用norm_layer。</p><p>在深度学习框架如PyTorch中，<code>layer.weight</code>通常是一个张量（Tensor），它的维度或形状依赖于层的类型和配置。 - <strong>全连接层（Dense或Linear）</strong>：权重是一个二维张量，形状通常是[输出特征数量, 输入特征数量]。 - <strong>卷积层（Convolutional）</strong>：权重是一个四维张量，形状通常是[输出通道数, 输入通道数, 卷积核高度, 卷积核宽度]。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">add_norm_layer</span>(<span class="hljs-params">layer</span>):<br>    <span class="hljs-keyword">nonlocal</span> norm_type<br>    <span class="hljs-keyword">if</span> norm_type.startswith(<span class="hljs-string">&#x27;spectral&#x27;</span>):<br>        layer = spectral_norm(layer)<br>        subnorm_type = norm_type[<span class="hljs-built_in">len</span>(<span class="hljs-string">&#x27;spectral&#x27;</span>):]<br><br>    <span class="hljs-keyword">if</span> subnorm_type == <span class="hljs-string">&#x27;none&#x27;</span> <span class="hljs-keyword">or</span> <span class="hljs-built_in">len</span>(subnorm_type) == <span class="hljs-number">0</span>:<br>        <span class="hljs-keyword">return</span> layer<br><br>    <span class="hljs-comment"># remove bias in the previous layer, which is meaningless</span><br>    <span class="hljs-comment"># since it has no effect after normalization</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">getattr</span>(layer, <span class="hljs-string">&#x27;bias&#x27;</span>, <span class="hljs-literal">None</span>) <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>        <span class="hljs-built_in">delattr</span>(layer, <span class="hljs-string">&#x27;bias&#x27;</span>)<br>        layer.register_parameter(<span class="hljs-string">&#x27;bias&#x27;</span>, <span class="hljs-literal">None</span>)<br><br>    <span class="hljs-keyword">if</span> subnorm_type == <span class="hljs-string">&#x27;batch&#x27;</span>:<br>        norm_layer = nn.BatchNorm2d(get_out_channel(layer), affine=<span class="hljs-literal">True</span>)<br>    <span class="hljs-comment"># elif subnorm_type == &#x27;sync_batch&#x27;:</span><br>    <span class="hljs-comment">#     norm_layer = SynchronizedBatchNorm2d(get_out_channel(layer), affine=True)</span><br>    <span class="hljs-keyword">elif</span> subnorm_type == <span class="hljs-string">&#x27;instance&#x27;</span>:<br>        norm_layer = nn.InstanceNorm2d(get_out_channel(layer), affine=<span class="hljs-literal">False</span>)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&#x27;normalization layer %s is not recognized&#x27;</span> % subnorm_type)<br><br>    <span class="hljs-keyword">return</span> nn.Sequential(layer, norm_layer)<br><br><span class="hljs-keyword">return</span> add_norm_layer<br></code></pre></td></tr></table></figure><p>然后函数里面又定义了一个add_norm_layer这个函数，它根据不同的subnorm_type来创建不用的norm_layer。</p><ul class="task-list"><li><input type="checkbox" disabled="" />看看讲这几种normalization方式的原始论文。</li></ul>]]></content>
    
    
    <categories>
      
      <category>CV</category>
      
    </categories>
    
    
    <tags>
      
      <tag>VITON</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>VITON-HD代码阅读笔记</title>
    <link href="/posts/viton-hd%E4%BB%A3%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    <url>/posts/viton-hd%E4%BB%A3%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="datasets.py">datasets.py</h1><h2 id="vitondataset">VITONDataset</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">VITONDataset</span>(data.Dataset):<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">self.transform = transforms.Compose([<br>            transforms.ToTensor(),<br>            transforms.Normalize((<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>), (<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>))<br>        ])<br></code></pre></td></tr></table></figure><p><code>ToTensor()</code> 函数将读入的图片转化为tensor，它会自动将图像的数据从0到255的整数转换成0到1的浮点数。</p><p><code>transforms.Normalize(mean, std)</code> 对图像的每一个通道进行标准化</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">img_names = []<br>      c_names = []<br>      <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(osp.join(opt.dataset_dir, opt.dataset_list), <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>          <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> f.readlines():<br>              img_name, c_name = line.strip().split()<br>              img_names.append(img_name)<br>              c_names.append(c_name)<br><br>      self.img_names = img_names<br>      self.c_names = <span class="hljs-built_in">dict</span>()<br>      self.c_names[<span class="hljs-string">&#x27;unpaired&#x27;</span>] = c_names<br></code></pre></td></tr></table></figure><p><code>line.strip()</code> 去除行首行尾的空白字符（如空格、换行符等）。</p><p><code>line.strip().split()</code> 默认以空格为分隔符将处理过的字符串分割成多个部分。在这个例子中，它预期每行有两部分：一个是 <code>img_name</code>（图像的文件名），另一个是 <code>c_name</code>（图像对应的类别名或标签）。</p><p><code>c_names</code> 是一个列表，用于存储每一行数据中通过分割操作获得的第二个元素，这通常表示类别名或衣物名称等。</p><h3 id="图像加载__getitem__函数">图像加载（__getitem__函数）</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, index</span>):<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">c[key] = Image.<span class="hljs-built_in">open</span>(osp.join(self.data_path, <span class="hljs-string">&#x27;cloth&#x27;</span>, c_name[key])).convert(<span class="hljs-string">&#x27;RGB&#x27;</span>)<br></code></pre></td></tr></table></figure><p><code>Image.open()</code> 是来自 PIL（Python Imaging Library，也称为 Pillow）库的一个函数，用于打开并加载图像文件。上述 <code>osp.join(...)</code> 的结果是一个完整的文件路径，指向特定的衣物图像文件。<code>Image.open()</code> 使用这个路径打开相应的图像文件。</p><p><code>.convert('RGB')</code> 是 PIL 库中的一个方法，用于将图像转换为指定的颜色模式。在这里，使用 <code>'RGB'</code> 参数，意味着无论原始图像是什么颜色模式（如灰度、CMYK等），都会被转换成 RGB 模式。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">cm[key] = transforms.Resize(self.load_width, interpolation=<span class="hljs-number">0</span>)(cm[key])<br></code></pre></td></tr></table></figure><p>解释 <code>interpolation</code> 参数：</p><ul><li><strong><code>interpolation=2</code></strong>: 这通常代表 <code>BILINEAR</code> 插值。双线性插值是一种相对简单的技术，它通过对四个最接近的像素点进行加权平均来计算新像素的值。这种方法适用于放大和缩小图像，能够保持较好的图像质量，但可能在某些情况下造成图像轻微模糊。</li><li><strong><code>interpolation=0</code></strong>: 这通常代表 <code>NEAREST</code> 插值，也就是最邻近插值算法。最邻近插值是最简单的插值方法，它将输出像素的值设置为输入图像中最近像素的值。这种方法的计算速度非常快，但可能会在图像中产生锯齿边缘，特别是在显著放大时。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">c[key] = self.transform(c[key])  <span class="hljs-comment"># [-1,1]</span><br></code></pre></td></tr></table></figure><p>这里调用了之前的self.transform： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">self.transform = transforms.Compose([<br>            transforms.ToTensor(),<br>            transforms.Normalize((<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>), (<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>))<br>        ])<br></code></pre></td></tr></table></figure></p><p>即同时将图片转化为tensor，并将每个通道的数据标准化，转化为<code>[-1,1]</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">cm_array = np.array(cm[key])<br>cm_array = (cm_array &gt;= <span class="hljs-number">128</span>).astype(np.float32)<br>cm[key] = torch.from_numpy(cm_array)  <span class="hljs-comment"># [0,1]</span><br>cm[key].unsqueeze_(<span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><p>使用 <code>np.array()</code> 将这个 PIL 图像转换为一个 NumPy 数组。结果数组 <code>cm_array</code> 的形状将是 <code>(height, width)</code> 对于灰度图像，或 <code>(height, width, channels)</code> 对于彩色图像。数据类型通常是 <code>uint8</code>，表示像素值范围在 0 到 255。</p><p><strong><code>torch.from_numpy()</code></strong>：这是 PyTorch 的函数，用于将 NumPy 数组转换为 PyTorch 张量。这一步是必要的，因为 PyTorch 模型不能直接使用 NumPy 数组，它们需要 PyTorch 张量格式。</p><p>为什么不直接把<code>cm[key]</code>转化为 tensor？ 因为要先进行二值化操作，在numpy中实现更高效。</p><p><code>unsqueeze_(0)</code>：这是 PyTorch 张量的一个方法，用于在指定位置添加一个额外的维度，这里的 <code>0</code> 表示在最前面添加。<code>unsqueeze_</code> 的就地（in-place）版本意味着修改将直接作用于原张量，而不创建新的张量。这通常用于为单个图像添加批处理维度，以符合深度学习模型通常期望的输入形状 <code>[batch_size, channels, height, width]</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(osp.join(self.data_path, <span class="hljs-string">&#x27;openpose-json&#x27;</span>, pose_name), <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>            pose_label = json.load(f)<br>            pose_data = pose_label[<span class="hljs-string">&#x27;people&#x27;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&#x27;pose_keypoints_2d&#x27;</span>]<br>            pose_data = np.array(pose_data)<br>            pose_data = pose_data.reshape((-<span class="hljs-number">1</span>, <span class="hljs-number">3</span>))[:, :<span class="hljs-number">2</span>]<br></code></pre></td></tr></table></figure><p>json 文件加载后是一个字典的形式，字典里面的每个value都是一个列表</p><p>这个dataset的json文件大概是如下结构，这里<code>"people"</code>是字典的一个key，然后value是一个列表，列表的第一个元素是一个字典（也只有一个元素） <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br><span class="hljs-attr">&quot;version&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-number">1.3</span><span class="hljs-punctuation">,</span><br><span class="hljs-attr">&quot;people&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-punctuation">[</span><span class="hljs-punctuation">&#123;</span><span class="hljs-attr">&quot;person_id&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-punctuation">[</span><span class="hljs-number">-1</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><span class="hljs-attr">&quot;pose_keypoints_2d&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-punctuation">[</span><span class="hljs-number">374.438</span><span class="hljs-punctuation">,</span><span class="hljs-number">128.121</span><span class="hljs-punctuation">,</span>...<span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><span class="hljs-attr">&quot;face_keypoints_2d&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-punctuation">[</span><span class="hljs-number">318.361</span><span class="hljs-punctuation">,</span><span class="hljs-number">106.306</span><span class="hljs-punctuation">,</span><span class="hljs-number">0.771347</span>...<span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><span class="hljs-attr">&quot;hand_left_keypoints_2d&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-punctuation">[</span><span class="hljs-number">499.4</span><span class="hljs-punctuation">,</span><span class="hljs-number">487.407</span><span class="hljs-punctuation">,</span><span class="hljs-number">0.307236</span>...<span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><span class="hljs-attr">&quot;hand_right_keypoints_2d&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-punctuation">[</span><span class="hljs-number">218.23</span><span class="hljs-punctuation">,</span><span class="hljs-number">729.128</span><span class="hljs-punctuation">,</span><span class="hljs-number">0.672563</span><span class="hljs-punctuation">,</span>...<span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><span class="hljs-attr">&quot;pose_keypoints_3d&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-punctuation">[</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><span class="hljs-attr">&quot;face_keypoints_3d&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-punctuation">[</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><span class="hljs-attr">&quot;hand_left_keypoints_3d&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-punctuation">[</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><span class="hljs-attr">&quot;hand_right_keypoints_3d&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-punctuation">[</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">]</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure></p><p><code>pose_data.reshape((-1, 3))</code>：使用 <code>reshape</code> 方法重新排列数组的形状。<code>(-1, 3)</code> 表示将数组转换为三列，行数自动计算。每行三个元素对应一个关键点的 x 坐标、y 坐标和置信度。</p><p><code>[:, :2]</code>：这个索引操作切片数组的前两列，即丢弃置信度，只保留 x 和 y 坐标。这里的列数表示方法的意思就是：0到2，左闭右开。也即<span class="math inline">\([0,2)\)</span>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">parse_name = img_name.replace(<span class="hljs-string">&#x27;.jpg&#x27;</span>, <span class="hljs-string">&#x27;.png&#x27;</span>)<br>parse = Image.<span class="hljs-built_in">open</span>(osp.join(self.data_path, <span class="hljs-string">&#x27;image-parse&#x27;</span>, parse_name))<br>parse = transforms.Resize(self.load_width, interpolation=<span class="hljs-number">0</span>)(parse)<br>parse_agnostic = self.get_parse_agnostic(parse, pose_data)<br>parse_agnostic = torch.from_numpy(np.array(parse_agnostic)[<span class="hljs-literal">None</span>]).long()<br></code></pre></td></tr></table></figure><p>这段读取的代码就很trivial了，但是要看到数据集才知道他的parse到底指的是什么（虽然可以猜到是segmentation map）。</p><p>这里的 <code>get_parse_agnostic</code> 在下面马上会讲到，就是把segmentation map中和衣服与手臂有关的部分删掉。（刚开始看<code>get_parse_agnostic</code>这个函数硬是看不懂，现在知道parse, pose_data这些的含义了就好理解多了。)</p><p>同样的，<code>get_img_agnostic</code>同理。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python">labels = &#123;<br>    <span class="hljs-number">0</span>: [<span class="hljs-string">&#x27;background&#x27;</span>, [<span class="hljs-number">0</span>, <span class="hljs-number">10</span>]],<br>    <span class="hljs-number">1</span>: [<span class="hljs-string">&#x27;hair&#x27;</span>, [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>]],<br>    <span class="hljs-number">2</span>: [<span class="hljs-string">&#x27;face&#x27;</span>, [<span class="hljs-number">4</span>, <span class="hljs-number">13</span>]],<br>    <span class="hljs-number">3</span>: [<span class="hljs-string">&#x27;upper&#x27;</span>, [<span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>]],<br>    <span class="hljs-number">4</span>: [<span class="hljs-string">&#x27;bottom&#x27;</span>, [<span class="hljs-number">9</span>, <span class="hljs-number">12</span>]],<br>    <span class="hljs-number">5</span>: [<span class="hljs-string">&#x27;left_arm&#x27;</span>, [<span class="hljs-number">14</span>]],<br>    <span class="hljs-number">6</span>: [<span class="hljs-string">&#x27;right_arm&#x27;</span>, [<span class="hljs-number">15</span>]],<br>    <span class="hljs-number">7</span>: [<span class="hljs-string">&#x27;left_leg&#x27;</span>, [<span class="hljs-number">16</span>]],<br>    <span class="hljs-number">8</span>: [<span class="hljs-string">&#x27;right_leg&#x27;</span>, [<span class="hljs-number">17</span>]],<br>    <span class="hljs-number">9</span>: [<span class="hljs-string">&#x27;left_shoe&#x27;</span>, [<span class="hljs-number">18</span>]],<br>    <span class="hljs-number">10</span>: [<span class="hljs-string">&#x27;right_shoe&#x27;</span>, [<span class="hljs-number">19</span>]],<br>    <span class="hljs-number">11</span>: [<span class="hljs-string">&#x27;socks&#x27;</span>, [<span class="hljs-number">8</span>]],<br>    <span class="hljs-number">12</span>: [<span class="hljs-string">&#x27;noise&#x27;</span>, [<span class="hljs-number">3</span>, <span class="hljs-number">11</span>]]<br>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">parse_agnostic_map = torch.zeros(<br>    <span class="hljs-number">20</span>, self.load_height, self.load_width, dtype=torch.<span class="hljs-built_in">float</span>)<br>parse_agnostic_map.scatter_(<span class="hljs-number">0</span>, parse_agnostic, <span class="hljs-number">1.0</span>)<br>new_parse_agnostic_map = torch.zeros(self.semantic_nc, self.load_height, self.load_width, dtype=torch.<span class="hljs-built_in">float</span>)<br></code></pre></td></tr></table></figure><p><code>scatter_</code> 的基本调用形式如下：</p><p><code>tensor.scatter_(dim, index, src)</code></p><ul><li><code>dim</code>：是你想要操作的维度。</li><li><code>index</code>：是一个与原始张量同形的张量，包含在指定维度上填充数据的位置。</li><li><code>src</code>：是要填充的值，可以是一个与原始张量同形的张量或单个值。</li></ul><p>对于这里的图像，</p><ul><li><strong>维度 0</strong> - 深度：图像堆叠的深度，例如一系列医学扫描图像的序列。</li><li><strong>维度 1</strong> - 高度：每个图像的高度。</li><li><strong>维度 2</strong> - 宽度：每个图像的宽度。</li></ul><p>这里即把一张segmentation map分成20个通道，每个通道对应一个人体部位。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(labels)):<br>            <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> labels[i][<span class="hljs-number">1</span>]:<br>                new_parse_agnostic_map[i] += parse_agnostic_map[label]<br></code></pre></td></tr></table></figure><p>这里是把20个通道又压缩到labels中的12个通道。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># load person image</span><br>img = Image.<span class="hljs-built_in">open</span>(osp.join(self.data_path, <span class="hljs-string">&#x27;image&#x27;</span>, img_name))<br>img = transforms.Resize(self.load_width, interpolation=<span class="hljs-number">2</span>)(img)<br>img_agnostic = self.get_img_agnostic(img, parse, pose_data)<br>img = self.transform(img)<br>img_agnostic = self.transform(img_agnostic)  <span class="hljs-comment"># [-1,1]</span><br></code></pre></td></tr></table></figure><p>对person image也做同样的处理</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">result = &#123;<br>            <span class="hljs-string">&#x27;img_name&#x27;</span>: img_name,<br>            <span class="hljs-string">&#x27;c_name&#x27;</span>: c_name,<br>            <span class="hljs-string">&#x27;img&#x27;</span>: img,<br>            <span class="hljs-string">&#x27;img_agnostic&#x27;</span>: img_agnostic,<br>            <span class="hljs-string">&#x27;parse_agnostic&#x27;</span>: new_parse_agnostic_map,<br>            <span class="hljs-string">&#x27;pose&#x27;</span>: pose_rgb,<br>            <span class="hljs-string">&#x27;cloth&#x27;</span>: c,<br>            <span class="hljs-string">&#x27;cloth_mask&#x27;</span>: cm,<br>        &#125;<br>        <span class="hljs-keyword">return</span> result<br></code></pre></td></tr></table></figure><p>最后返回关于这个index所有需要的信息。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.img_names)<br></code></pre></td></tr></table></figure><h3 id="图像的格式">图像的格式</h3><p>在打开parse image的时候，图像是以“调色板”模式存储的。这种模式通常用于表示具有有限颜色的图像。</p><p>当你将一个以 <code>'P'</code> 模式（调色板模式）打开的 PIL 图像转换为 NumPy 数组时，得到的数组将反映图像中的像素值，这些像素值代表调色板中的索引，而不是直接的颜色值。这意味着每个像素的值将是一个整数，这个整数指向调色板中相应的颜色。</p><ol type="1"><li><strong>数组形状</strong>： 转换为 NumPy 数组后，你将得到一个二维数组，其形状为 <code>(height, width)</code>。每个元素的值是一个介于 0 到 255 之间的整数（假设使用的是标准的256色调色板），这个值是调色板中颜色的索引。</li><li><strong>查看索引</strong>： 数组中的每个索引值对应于调色板中的一个颜色。颜色本身是以 RGB 形式定义的，但在数组中，这些颜色仅通过索引来引用。 ### parse label的对照表</li></ol><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs markdown"><span class="hljs-bullet">0.</span> Background<br><span class="hljs-bullet">1.</span> Hat<br><span class="hljs-bullet">2.</span> Hair<br><span class="hljs-bullet">3.</span> Glove<br><span class="hljs-bullet">4.</span> Sunglasses<br><span class="hljs-bullet">5.</span> Upper-clothes<br><span class="hljs-bullet">6.</span> Dress<br><span class="hljs-bullet">7.</span> Coat<br><span class="hljs-bullet">8.</span> Socks<br><span class="hljs-bullet">9.</span> Pants<br><span class="hljs-bullet">10.</span> Jumpsuits<br><span class="hljs-bullet">11.</span> Scarf<br><span class="hljs-bullet">12.</span> Skirt<br><span class="hljs-bullet">13.</span> Face<br><span class="hljs-bullet">14.</span> Left-arm<br><span class="hljs-bullet">15.</span> Right-arm<br><span class="hljs-bullet">16.</span> Left-leg<br><span class="hljs-bullet">17.</span> Right-leg<br><span class="hljs-bullet">18.</span> Left-shoe<br><span class="hljs-bullet">19.</span> Right-shoe<br></code></pre></td></tr></table></figure><h3 id="get_parse_agnostic">get_parse_agnostic</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_parse_agnostic</span>(<span class="hljs-params">self, parse, pose_data</span>):<br></code></pre></td></tr></table></figure><p>这里的parse就是segmentation map, pose_data是之前的那个关键点。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">parse_array = np.array(parse)<br><br>parse_upper = ((parse_array == <span class="hljs-number">5</span>).astype(np.float32) +<br>            (parse_array == <span class="hljs-number">6</span>).astype(np.float32) +<br>                (parse_array == <span class="hljs-number">7</span>).astype(np.float32))<br>parse_neck = (parse_array == <span class="hljs-number">10</span>).astype(np.float32) <br></code></pre></td></tr></table></figure><p>标签10是jumpsuit, 好像和脖子没什么关系？脖子在这个model里面本身就是不标记的。</p><p><img src="https://s2.loli.net/2024/04/25/hfJByAauVMXis2m.png" /></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> parse_id, pose_ids <span class="hljs-keyword">in</span> [(<span class="hljs-number">14</span>, [<span class="hljs-number">2</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>]), (<span class="hljs-number">15</span>, [<span class="hljs-number">5</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>])]<br></code></pre></td></tr></table></figure><p><strong>第一次迭代</strong></p><ul><li><strong>元组</strong>: <code>(14, [2, 5, 6, 7])</code><ul><li><code>parse_id</code> 被赋值为 14。</li><li><code>pose_ids</code> 被赋值为列表 <code>[2, 5, 6, 7]</code>。</li><li>循环体中的代码现在可以使用这两个值来执行特定的操作，比如处理与 <code>parse_id</code> 14 相关的数据，使用索引 2, 5, 6, 7 来访问或操作数据结构中的元素。</li></ul></li></ul><p><strong>第二次迭代</strong></p><ul><li><strong>元组</strong>: <code>(15, [5, 2, 3, 4])</code><ul><li><code>parse_id</code> 被赋值为 15。</li><li><code>pose_ids</code> 被赋值为列表 <code>[5, 2, 3, 4]</code>。</li><li>这一次，循环体中的代码将根据 <code>parse_id</code> 15 来处理数据，使用列表中的索引 5, 2, 3, 4 来执行相关操作。</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">mask_arm = Image.new(<span class="hljs-string">&#x27;L&#x27;</span>, (self.load_width, self.load_height), <span class="hljs-string">&#x27;black&#x27;</span>)`<br></code></pre></td></tr></table></figure><h3 id="一些尺寸的问题">一些尺寸的问题</h3><p><strong>注意:</strong> 特别注意，在<code>torchvision.transforms.Resize</code>中，给的<code>size</code>参数是<code>(height,width)</code>，而在<code>Image.new</code>中，给的参数是<code>(width, height)</code>。</p><p>并且在<code>torchvision.transforms</code>中，if size is an int, smaller edge of the image will be matched to this number.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">mask_arm_draw = ImageDraw.Draw(mask_arm)<br></code></pre></td></tr></table></figure><p>创建一个新的灰度图像（'L' 模式），初始填充为黑色，大小由对象的 <code>load_width</code> 和 <code>load_height</code> 属性决定</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">i_prev = pose_ids[<span class="hljs-number">0</span>]<br><br><span class="hljs-comment"># mask arms</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> pose_ids[<span class="hljs-number">1</span>:]:<br>    <span class="hljs-keyword">if</span> (pose_data[i_prev, <span class="hljs-number">0</span>] == <span class="hljs-number">0.0</span> <span class="hljs-keyword">and</span> pose_data[i_prev, <span class="hljs-number">1</span>] == <span class="hljs-number">0.0</span>) <span class="hljs-keyword">or</span> (pose_data[i, <span class="hljs-number">0</span>] == <span class="hljs-number">0.0</span> <span class="hljs-keyword">and</span> pose_data[i, <span class="hljs-number">1</span>] == <span class="hljs-number">0.0</span>):<br>        <span class="hljs-keyword">continue</span><br>    mask_arm_draw.line([<span class="hljs-built_in">tuple</span>(pose_data[j]) <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> [i_prev, i]], <span class="hljs-string">&#x27;white&#x27;</span>, width=r*<span class="hljs-number">10</span>)<br>    pointx, pointy = pose_data[i]<br>    radius = r*<span class="hljs-number">4</span> <span class="hljs-keyword">if</span> i == pose_ids[-<span class="hljs-number">1</span>] <span class="hljs-keyword">else</span> r*<span class="hljs-number">15</span><br>    mask_arm_draw.ellipse((pointx-radius, pointy-radius, pointx+radius, pointy+radius), <span class="hljs-string">&#x27;white&#x27;</span>, <span class="hljs-string">&#x27;white&#x27;</span>)<br>    i_prev = i<br></code></pre></td></tr></table></figure><p><code>mask_arm_draw</code>是用于在<code>mask_arm</code>图像上进行绘图的对象，通过这个对象执行的任何绘图操作（如绘制线条、椭圆等）都会修改<code>mask_arm</code>图像的内容。</p><p>这段代码产生的大致图像如下，即根据keypoints生成一个很粗略的pose，然后和segmentation map结合</p><p>这里引用论文原文：The pose map P is utilized to remove the arms, but not the hands, as they are difficult to reproduce. (其实更直接说是The pose map P is utilized to preserve the hands.) 所以说代码在手那里的圆圈画的很小</p><figure><img src="https://s2.loli.net/2024/04/25/97SCKBGxqjYvEbh.png" alt="" /><figcaption>{70D0DED9-C3D4-4fbd-9E93-A5DD1EB45345}.png</figcaption></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">parse_arm = (np.array(mask_arm) / <span class="hljs-number">255</span>) * (parse_array == parse_id).astype(np.float32)<br>agnostic.paste(<span class="hljs-number">0</span>, <span class="hljs-literal">None</span>, Image.fromarray(np.uint8(parse_arm * <span class="hljs-number">255</span>), <span class="hljs-string">&#x27;L&#x27;</span>))<br></code></pre></td></tr></table></figure><p><code>np.array(mask_arm) / 255</code> 这部分是将 <code>mask_arm</code> 图像（一个PIL图像对象）转换成NumPy数组，并且将每个像素值从0-255的整数范围标准化到0-1的浮点数范围。这是图像处理中常见的归一化步骤，有助于后续的数学运算。</p><p><code>(parse_array == parse_id).astype(np.float32)</code> 这部分是在创建一个条件掩码，其中 <code>parse_array</code> 是一个数组，可能代表某种图像分割的结果（例如，每个像素属于某个部分的标识符），<code>parse_id</code> 是指定的部位标识符。这里将左右手的区域标记出来。</p><p>最后，两个数组相乘。这个操作将 <code>mask_arm</code> 的归一化像素值与条件掩码相乘。结果是一个新的数组 <code>parse_arm</code>，其中只有当 <code>parse_array</code> 的值等于 <code>parse_id</code> 时，原 <code>mask_arm</code> 中对应位置的像素值才被保留，其他位置的值将被置为0。这里是把 <code>pose_data</code> 的信息和 <code>segmentation</code>的信息结合起来，构成论文中说的 <em>Clothing-Agnostic Person Representation</em>。</p><p>将keypoints信息与parse信息match之后的结果如下：</p><p><img src="https://s2.loli.net/2024/04/25/wFP6m9AOZRg3bkG.png" /></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># mask torso &amp; neck</span><br>agnostic.paste(<span class="hljs-number">0</span>, <span class="hljs-literal">None</span>, Image.fromarray(np.uint8(parse_upper * <span class="hljs-number">255</span>), <span class="hljs-string">&#x27;L&#x27;</span>))<br>agnostic.paste(<span class="hljs-number">0</span>, <span class="hljs-literal">None</span>, Image.fromarray(np.uint8(parse_neck * <span class="hljs-number">255</span>), <span class="hljs-string">&#x27;L&#x27;</span>))<br><br><span class="hljs-keyword">return</span> agnostic<br></code></pre></td></tr></table></figure><p>至此就得到了一张parse_agnostic image</p><figure><img src="https://s2.loli.net/2024/04/25/khQVsaCcjtm4u7b.png" alt="" /><figcaption>00000_00.png</figcaption></figure><h3 id="get_image_agnostic">get_image_agnostic</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_img_agnostic</span>(<span class="hljs-params">self, img, parse, pose_data</span>):<br></code></pre></td></tr></table></figure><p>这个函数做的就也是很类似的事情了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">length_a = np.linalg.norm(pose_data[<span class="hljs-number">5</span>] - pose_data[<span class="hljs-number">2</span>])<br>length_b = np.linalg.norm(pose_data[<span class="hljs-number">12</span>] - pose_data[<span class="hljs-number">9</span>])<br>point = (pose_data[<span class="hljs-number">9</span>] + pose_data[<span class="hljs-number">12</span>]) / <span class="hljs-number">2</span><br>pose_data[<span class="hljs-number">9</span>] = point + (pose_data[<span class="hljs-number">9</span>] - point) / length_b * length_a<br>pose_data[<span class="hljs-number">12</span>] = point + (pose_data[<span class="hljs-number">12</span>] - point) / length_b * length_a<br></code></pre></td></tr></table></figure><p>这里是对pose_data的数据做了一些处理，其中<code>linalg</code>默认是求所给向量（矩阵）的 <span class="math inline">\(l_{2}\)</span> 范数。这里也就是欧几里得距离。</p><p>根据对照表，length_a是两肩的距离，length_b是左右髋关节的距离。</p><p>关于openpose的pose data数据的label，这里也写一个对照表： <figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs txt">// const std::map&lt;unsigned int, std::string&gt; POSE_BODY_25_BODY_PARTS &#123;<br>//     &#123;0,  &quot;Nose&quot;&#125;,<br>//     &#123;1,  &quot;Neck&quot;&#125;,<br>//     &#123;2,  &quot;RShoulder&quot;&#125;,<br>//     &#123;3,  &quot;RElbow&quot;&#125;,<br>//     &#123;4,  &quot;RWrist&quot;&#125;,<br>//     &#123;5,  &quot;LShoulder&quot;&#125;,<br>//     &#123;6,  &quot;LElbow&quot;&#125;,<br>//     &#123;7,  &quot;LWrist&quot;&#125;,<br>//     &#123;8,  &quot;MidHip&quot;&#125;,<br>//     &#123;9,  &quot;RHip&quot;&#125;,<br>//     &#123;10, &quot;RKnee&quot;&#125;,<br>//     &#123;11, &quot;RAnkle&quot;&#125;,<br>//     &#123;12, &quot;LHip&quot;&#125;,<br>//     &#123;13, &quot;LKnee&quot;&#125;,<br>//     &#123;14, &quot;LAnkle&quot;&#125;,<br>//     &#123;15, &quot;REye&quot;&#125;,<br>//     &#123;16, &quot;LEye&quot;&#125;,<br>//     &#123;17, &quot;REar&quot;&#125;,<br>//     &#123;18, &quot;LEar&quot;&#125;,<br>//     &#123;19, &quot;LBigToe&quot;&#125;,<br>//     &#123;20, &quot;LSmallToe&quot;&#125;,<br>//     &#123;21, &quot;LHeel&quot;&#125;,<br>//     &#123;22, &quot;RBigToe&quot;&#125;,<br>//     &#123;23, &quot;RSmallToe&quot;&#125;,<br>//     &#123;24, &quot;RHeel&quot;&#125;,<br>//     &#123;25, &quot;Background&quot;&#125;<br>// &#125;;<br></code></pre></td></tr></table></figure></p><p>这个函数之后就也是一些作图的逻辑了，只不过是在原图上直接画。</p><p>在这里生成的结果其实就已经参差不齐了，因为他在通过pose_map生成mask的时候用了人类的知识，但这种知识不能覆盖所有情况。</p><figure><img src="https://s2.loli.net/2024/04/25/UdrE4RCvhxeK7Zb.jpg" alt="" /><figcaption>00283_00.jpg</figcaption></figure><figure><img src="https://s2.loli.net/2024/04/25/Hprkd7su1gyJXPD.jpg" alt="" /><figcaption>00107_00.jpg</figcaption></figure><figure><img src="https://s2.loli.net/2024/04/25/5j34UgQvF1REbsh.jpg" alt="" /><figcaption>00228_00.jpg</figcaption></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> (pose_data[i - <span class="hljs-number">1</span>, <span class="hljs-number">0</span>] == <span class="hljs-number">0.0</span> <span class="hljs-keyword">and</span> pose_data[i - <span class="hljs-number">1</span>, <span class="hljs-number">1</span>] == <span class="hljs-number">0.0</span>) <span class="hljs-keyword">or</span> (pose_data[i, <span class="hljs-number">0</span>] == <span class="hljs-number">0.0</span> <span class="hljs-keyword">and</span> pose_data[i, <span class="hljs-number">1</span>] == <span class="hljs-number">0.0</span>):<br>    <span class="hljs-keyword">continue</span><br></code></pre></td></tr></table></figure><p>最后这张图好像是因为有些代码没有像处理pose_data不存在的情况，并且如果<code>pose_data[9]</code>和<code>pose_data[12]</code>没检测到，前面还会出现除以零的错误。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, index</span>):<br>img_name = self.img_names[index]<br>c_name = &#123;&#125;<br>c = &#123;&#125;<br>cm = &#123;&#125;<br><span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> self.c_names:<br>    c_name[key] = self.c_names[key][index]<br>    c[key] = Image.<span class="hljs-built_in">open</span>(<br>        osp.join(self.data_path, <span class="hljs-string">&#x27;cloth&#x27;</span>, c_name[key])).convert(<span class="hljs-string">&#x27;RGB&#x27;</span>)<br>    c[key] = transforms.Resize(self.load_width, interpolation=<span class="hljs-number">2</span>)(c[key])<br>    cm[key] = Image.<span class="hljs-built_in">open</span>(<br>        osp.join(self.data_path, <span class="hljs-string">&#x27;cloth-mask&#x27;</span>, c_name[key]))<br>    cm[key] = transforms.Resize(self.load_width, interpolation=<span class="hljs-number">0</span>)(cm[key])<br><br>    c[key] = self.transform(c[key])  <span class="hljs-comment"># [-1,1]</span><br>    cm_array = np.array(cm[key])<br>    cm_array = (cm_array &gt;= <span class="hljs-number">128</span>).astype(np.float32)<br>    cm[key] = torch.from_numpy(cm_array)  <span class="hljs-comment"># [0,1]</span><br>    cm[key].unsqueeze_(<span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><h2 id="vitondataloader">VITONDataLoader</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">VITONDataLoader</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">VITONDataLoader</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, opt, dataset</span>):<br>        <span class="hljs-built_in">super</span>(VITONDataLoader, self).__init__()<br><br>        <span class="hljs-keyword">if</span> opt.shuffle:<br>            train_sampler = data.sampler.RandomSampler(dataset)<br>        <span class="hljs-keyword">else</span>:<br>            train_sampler = <span class="hljs-literal">None</span><br></code></pre></td></tr></table></figure><p>根据<code>opt.shuffle</code>选择是否对<code>dataset</code>进行随机采样。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">self.data_loader = data.DataLoader(<br>        dataset, batch_size=opt.batch_size, shuffle=(train_sampler <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>),<br>        num_workers=opt.workers, pin_memory=<span class="hljs-literal">True</span>, drop_last=<span class="hljs-literal">True</span>, sampler=train_sampler<br>)<br></code></pre></td></tr></table></figure><p><strong>data.sampler.RandomSampler</strong></p><ul><li><strong>定义</strong>：<code>RandomSampler</code> 是 PyTorch 中一个具体的迭代器，它每次迭代时都随机地从数据集中抽取元素，而不是按顺序选取。</li><li><strong>用途</strong>：当你需要更多控制或者需要在自定义采样器中嵌入额外的逻辑时使用。例如，你可以在不改变原始数据集结构的情况下实现复杂的抽样策略。</li><li><strong>实现</strong>：当你指定 <code>RandomSampler</code> 作为 <code>DataLoader</code> 的 <code>sampler</code> 参数时，应该将 <code>shuffle</code> 设置为 <code>False</code>，因为 <code>shuffle</code> 和 <code>sampler</code> 参数不能同时使用。如果同时使用，<code>DataLoader</code> 会抛出错误。</li></ul><p><strong><code>shuffle=True</code> 在 <code>DataLoader</code> 中</strong></p><ul><li><strong>定义</strong>：这是一个简便的参数，可以直接在 <code>DataLoader</code> 初始化时设置。如果设置为 <code>True</code>，<code>DataLoader</code> 将在每个epoch开始时对数据进行随机打乱。</li><li><strong>用途</strong>：当你不需要复杂的抽样逻辑，仅仅想在每个epoch训练前打乱数据时使用。</li><li><strong>实现</strong>：当 <code>shuffle=True</code> 时，<code>DataLoader</code> 内部实际上使用了一个随机抽样器，但你不需要显式地定义它。这种方式比较简洁，适合大多数标准的训练场景。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">self.dataset = dataset<br>   self.data_iter = self.data_loader.__iter__()<br>   <br>   <span class="hljs-keyword">def</span> <span class="hljs-title function_">next_batch</span>(<span class="hljs-params">self</span>):<br>       <span class="hljs-keyword">try</span>:<br>           batch = self.data_iter.__next__()<br>       <span class="hljs-keyword">except</span> StopIteration:<br>           self.data_iter = self.data_loader.__iter__()<br>           batch = self.data_iter.__next__()<br><br>       <span class="hljs-keyword">return</span> batch<br></code></pre></td></tr></table></figure><h3 id="iter__-方法"><code>__iter__()</code> 方法：</h3><ul><li><strong>定义</strong>：<code>__iter__()</code> 是Python中的一个特殊方法，用于获取一个对象的迭代器。当对象支持迭代时，<code>__iter__()</code> 方法会返回迭代器对象本身，这个迭代器包含了一个 <code>__next__()</code> 方法，用于获取迭代器的下一个元素。</li><li><strong>用途</strong>：在 <code>DataLoader</code> 的上下文中，<code>__iter__()</code> 被用来创建一个可以遍历数据集所有批次的迭代器。每次调用这个迭代器的 <code>__next__()</code> 方法时，它会返回数据集的下一个批次。</li></ul><h3 id="在-dataloader-中的应用">在 <code>DataLoader</code> 中的应用：</h3><ul><li><strong>初始化迭代器</strong>：<code>self.data_iter = self.data_loader.__iter__()</code> 这行代码初始化了一个迭代器，该迭代器负责从 <code>DataLoader</code> 中逐批次提取数据。通过这种方式，你可以在训练循环中连续调用 <code>__next__()</code> 来获取新的数据批次，直到数据集的所有数据都被处理完毕。</li><li><strong>数据批次的提取</strong>：每次调用迭代器的 <code>__next__()</code> 方法（如在你的 <code>next_batch</code> 方法中所做的），都会加载下一批数据。如果数据已经迭代完毕，迭代器会抛出 <code>StopIteration</code> 异常，此时通常会重新初始化迭代器，从而开始新一轮的数据遍历。</li></ul><h1 id="utils.py">utils.py</h1><h2 id="gen_noise">gen_noise</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">gen_noise</span>(<span class="hljs-params">shape</span>):<br>    noise = np.zeros(shape, dtype=np.uint8)<br>    <span class="hljs-comment">### noise</span><br>    noise = cv2.randn(noise, <span class="hljs-number">0</span>, <span class="hljs-number">255</span>)<br>    noise = np.asarray(noise / <span class="hljs-number">255</span>, dtype=np.uint8)<br>    noise = torch.tensor(noise, dtype=torch.float32)<br>    <span class="hljs-keyword">return</span> noise<br></code></pre></td></tr></table></figure><p>使用 <code>cv2.randn()</code> 函数填充数组，生成平均值为 0，标准差为 255 的正态分布噪声。 将噪声值缩放到 <code>[0, 1]</code> 范围内，并转换为 <code>uint8</code> 类型。</p><h3 id="np.asarray-与-np.array-的不同">np.asarray 与 np.array 的不同</h3><p><code>np.asarray</code>的定义： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">asarray</span>(<span class="hljs-params">a, dtype=<span class="hljs-literal">None</span>, order=<span class="hljs-literal">None</span></span>):<br>    <span class="hljs-keyword">return</span> array(a, dtype, copy=<span class="hljs-literal">False</span>, order=order)<br></code></pre></td></tr></table></figure></p><p>而 <code>np.array</code>的定义： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">array</span>(<span class="hljs-params">a, dtype=<span class="hljs-literal">None</span>, order=<span class="hljs-literal">None</span></span>):<br>    <span class="hljs-keyword">return</span> array(a, dtype, copy=<span class="hljs-literal">True</span>, order=order)<br></code></pre></td></tr></table></figure></p><p><strong><code>np.array</code></strong>：此函数默认情况下会创建输入数据的一个新副本，即使输入数据已经是一个 NumPy 数组。这意味着即使原始数据没有必要被复制，<code>np.array</code> 也会进行复制，除非显式设置 <code>copy=False</code>。</p><p><strong><code>np.asarray</code></strong>：这个函数会尽可能避免复制原始数据。如果输入数据已经是一个 NumPy 数组，<code>np.asarray</code> 将不会创建数据的副本，而是直接返回原始数组。</p><p>用来做data augmentation</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">save_images</span>(<span class="hljs-params">img_tensors, img_names, save_dir</span>):<br>    <span class="hljs-keyword">for</span> img_tensor, img_name <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(img_tensors, img_names):<br>        tensor = (img_tensor.clone()+<span class="hljs-number">1</span>) * <span class="hljs-number">0.5</span> * <span class="hljs-number">255</span><br>        tensor = tensor.cpu().clamp(<span class="hljs-number">0</span>,<span class="hljs-number">255</span>)<br><br>        <span class="hljs-keyword">try</span>:<br>            array = tensor.numpy().astype(<span class="hljs-string">&#x27;uint8&#x27;</span>)<br>        <span class="hljs-keyword">except</span>:<br>            array = tensor.detach().numpy().astype(<span class="hljs-string">&#x27;uint8&#x27;</span>)<br><br>        <span class="hljs-keyword">if</span> array.shape[<span class="hljs-number">0</span>] == <span class="hljs-number">1</span>:<br>            array = array.squeeze(<span class="hljs-number">0</span>)<br>        <span class="hljs-keyword">elif</span> array.shape[<span class="hljs-number">0</span>] == <span class="hljs-number">3</span>:<br>            array = array.swapaxes(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>).swapaxes(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br><br>        im = Image.fromarray(array)<br>        im.save(os.path.join(save_dir, img_name), <span class="hljs-built_in">format</span>=<span class="hljs-string">&#x27;JPEG&#x27;</span>)<br></code></pre></td></tr></table></figure><p>这是保存图像的函数，首先将 tensor 去标准化。 <code>.cpu()</code> 确保张量被移动到CPU。如果张量原先在GPU上，这一步是必要的，因为接下来的保存或进一步处理通常在CPU上进行。</p><p><code>.clamp(0, 255)</code>: <code>clamp()</code> 方法用于将张量中的所有元素限制在指定的范围内，本例中是0到255。这是一个安全措施，用来确保即使在之前的操作中有任何计算误差或异常值，最终的像素值也会被限制在有效的RGB范围内。</p><p><strong><code>tensor.numpy()</code></strong>：这个方法尝试将 PyTorch 张量直接转换为一个 NumPy 数组。这一转换要求张量 <code>tensor</code> 必须在 CPU 上，并且没有计算图依赖（即它必须是一个叶子张量）。在 PyTorch 中，只有当张量是叶子节点并且不要求梯度时，才能直接通过 <code>.numpy()</code> 方法转换为 NumPy 数组。如果张量是计算图的一部分，直接调用 <code>.numpy()</code> 会抛出错误，因为这会尝试绕过 PyTorch 的自动微分系统。使用 <code>.detach()</code> 是确保张量从任何梯度计算中分离出来，从而安全地进行转换。</p><p><strong><code>tensor.detach()</code></strong>：这个方法创建了张量的一个副本，但副本与原始数据共享内存，并且从当前计算图中分离出来。这意味着这个新张量不会有梯度信息，可以安全地转换为 NumPy 数组，而不会影响反向传播或梯度计算。</p><p><strong>叶子张量</strong></p><p><strong>定义</strong>：在PyTorch的计算图中，叶子张量（Leaf Tensor）是直接由用户创建的张量，而不是通过任何前向操作（如加法或乘法）生成的。简而言之，叶子张量是计算图中的输入节点。</p><h3 id="对灰度图和rgb图的不同处理">对灰度图和RGB图的不同处理</h3><p>处理单通道图像 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> array.shape[<span class="hljs-number">0</span>] == <span class="hljs-number">1</span>:     <br>array = array.squeeze(<span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure></p><ul><li><strong>条件</strong>：检查数组的第一个维度（通道数）是否为1，即判断这是否是一个单通道（如灰度）图像。</li><li><strong>操作</strong>：使用 <code>.squeeze(0)</code> 方法从数组中移除第一个维度。这是因为单通道图像在某些图像处理库中不需要显式的单一通道维度，<code>squeeze(0)</code> 将形状从 <code>(1, height, width)</code> 改变为 <code>(height, width)</code>，使其适合作为灰度图像处理或显示。</li></ul><p>处理三通道图像</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">elif</span> array.shape[<span class="hljs-number">0</span>] == <span class="hljs-number">3</span>:     <br>array = array.swapaxes(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>).swapaxes(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br></code></pre></td></tr></table></figure><ul><li><strong>条件</strong>：检查数组的第一个维度是否为3，这通常意味着它是一个具有三个颜色通道（通常是RGB）的图像。</li><li><strong>操作</strong>：<ul><li><strong><code>array.swapaxes(0, 1)</code></strong>：这一步将第一个维度（通常是通道）与第二个维度（高度）交换。此操作后，数组形状从 <code>(3, height, width)</code> 变为 <code>(height, 3, width)</code>。</li><li><strong><code>.swapaxes(1, 2)</code></strong>：接着将现在的第二个维度（原先的通道现在的位置）与第三个维度（宽度）交换。这将形状最终从 <code>(height, 3, width)</code> 调整为 <code>(height, width, 3)</code>。</li></ul></li></ul><p>这种调整是必要的因为在PyTorch（和很多其他深度学习框架中）中，图像数据通常按照 <code>(channels, height, width)</code>（CHW）的顺序存储，而在常规图像处理库（如PIL）和图像格式中，数据通常需要以 <code>(height, width, channels)</code>（HWC）的格式存在。这种转换确保图像数据在可视化或保存时具有正确的格式。</p><h3 id="pil和numpy互换">PIL和numpy互换</h3><h4 id="从-pil-image-到-numpy-数组">从 PIL Image 到 NumPy 数组</h4><ul><li><strong>PIL Image</strong>：在PIL中，图像被视为 <code>(width, height)</code> 格式，其中 <code>width</code> 是图像的宽度（列数），<code>height</code> 是图像的高度（行数）。</li><li><strong>转换为 NumPy</strong>：当你使用例如 <code>numpy.array()</code> 函数将PIL图像转换为NumPy数组时，得到的数组将按 <code>(height, width)</code> 的顺序排列。如果是彩色图像，它会有三个维度 <code>(height, width, channels)</code>，其中 <code>channels</code> 表示颜色通道（通常为RGB三个通道）。</li></ul><h3 id="从-numpy-数组到-pil-image">从 NumPy 数组到 PIL Image</h3><ul><li><strong>NumPy 数组</strong>：通常，NumPy数组存储图像数据时使用 <code>(height, width, channels)</code> 的格式，对于灰度图像则是 <code>(height, width)</code>。</li><li><strong>转换为 PIL Image</strong>：当你想把一个NumPy数组转换回PIL图像时，你需要确保数组是 <code>(height, width)</code> 或 <code>(height, width, channels)</code> 格式。PIL的<code>Image.fromarray()</code>方法接受这种格式，直接将它转换为PIL Image对象。 ### 总结 在转换过程中，你通常不需要手动交换宽度和高度的维度，因为这些库的函数已经处理好了这些细节。当从PIL Image转到NumPy数组时，维度自动从 <code>(width, height)</code> 转换为 <code>(height, width)</code>，反之亦然。这个细节尤其重要，当你在使用这两个库进行图像处理和分析时，需要清楚它们数据表示的不同。</li></ul><h2 id="load_checkpoint">load_checkpoint</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_checkpoint</span>(<span class="hljs-params">model, checkpoint_path</span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(checkpoint_path):<br>        <span class="hljs-keyword">raise</span> ValueError(<br>            <span class="hljs-string">&quot;&#x27;&#123;&#125;&#x27; is not a valid checkpointpath&quot;</span>.<span class="hljs-built_in">format</span>(checkpoint_path))<br>    model.load_state_dict(torch.load(checkpoint_path))<br></code></pre></td></tr></table></figure><p><code>model.load_state_dict(torch.load(checkpoint_path))</code>: 这行代码是加载和应用检查点的核心。</p><p><code>torch.load(checkpoint_path)</code>: 使用PyTorch的<code>torch.load</code>函数从指定的文件路径加载检查点。这个函数默认情况下会读取文件内容，并反序列化为Python对象，这里是模型的状态字典。</p><p><code>model.load_state_dict(...)</code>: 这个方法将加载的状态字典应用到提供的模型上。状态字典通常包括模型参数（权重和偏差）等。这一步是将保存的模型状态恢复到指定的模型实例中。</p><h3 id="重要性">重要性</h3><p>加载检查点对于深度学习模型的训练非常重要，尤其是在训练过程需要中断后继续训练的场景。此外，这也是将训练好的模型部署到生产环境中的常见步骤，因为你通常会保存训练好的模型并在需要时加载它们进行预测。</p><h3 id="总结">总结</h3><p>这个<code>load_checkpoint</code>函数提供了一种简洁的方法来确保模型状态可以从磁盘恢复。通过检查文件存在性并使用PyTorch的API加载和应用状态字典，这段代码有效地支持了模型的持久化和再利用，是深度学习工作流中的一个基本组件。</p><h1 id="nn.module">nn.Module</h1><p><code>nn.Module</code> 是 PyTorch 中所有神经网络模块的基类，几乎所有使用 PyTorch 构建的神经网络组件都应该继承自这个类。这个类封装了神经网络需要的多种功能，使得网络构建、训练、保存和加载都变得方便和直观。下面是 <code>nn.Module</code> 中的一些重要特性和组成部分： ## 主要属性和方法</p><ol type="1"><li><strong>构造函数 <code>__init__()</code></strong>:<ul><li>这是初始化模块时调用的方法，通常用于定义模型的层和其他需要的组件。在这里，通常会调用父类的构造函数来保证 <code>Module</code> 的正确初始化。</li></ul></li><li><strong><code>forward()</code> 方法</strong>:<ul><li>必须由所有继承自 <code>nn.Module</code> 的类实现的方法。这是定义模块如何执行前向传递的地方。在 PyTorch 中，你不直接调用这个方法，而是通过调用模块实例来间接调用它。</li></ul></li><li><strong><code>parameters()</code> 和 <code>named_parameters()</code></strong>:<ul><li><code>parameters()</code> 返回模块的参数迭代器，通常用于优化器配置。这些参数是需要通过训练学习的权重和偏置。</li><li><code>named_parameters()</code> 同样返回参数迭代器，但它会返回一个元组，其中包含参数的名称和参数本身，非常有用于调试和特定参数的操作。</li></ul></li><li><strong><code>children()</code> 和 <code>modules()</code></strong>:<ul><li><code>children()</code> 方法返回模块的直接子模块迭代器，而 <code>modules()</code> 返回当前模块的所有子模块（递归地），包括模块本身。</li></ul></li><li><strong><code>to(device)</code></strong>:<ul><li>将模块的所有参数和缓冲区移动到给定的设备（CPU或GPU）上。这是多设备支持的关键方法，非常重要以确保计算的一致性。</li></ul></li><li><strong><code>train()</code> 和 <code>eval()</code></strong>:<ul><li><code>train()</code> 将模块设置为训练模式，这对于某些层（如Dropout和BatchNorm）是必要的，因为它们在训练和评估阶段的行为是不同的。</li><li><code>eval()</code> 将模块设置为评估模式。</li></ul></li><li><strong><code>state_dict()</code></strong>:<ul><li>返回包含模块所有状态信息（参数和持久缓冲区）的字典。这在保存和加载模型时非常有用。</li></ul></li><li><strong><code>load_state_dict(state_dict)</code></strong>:<ul><li>加载一个状态字典。这通常用于模型的反序列化，是在训练后恢复模型状态的标准方法。</li></ul></li></ol><h2 id="parameters">parameters()</h2><p>在 PyTorch 中，<code>self.parameters()</code> 和 <code>param.numel()</code> 是与模型参数操作相关的重要方法和函数。它们通常用于管理和统计模型中的参数。下面详细解释这两者的作用和使用方法：</p><h4 id="定义和用途">定义和用途</h4><ul><li><p><code>self.parameters()</code> 是 <code>nn.Module</code> 类的一个方法，它返回一个生成器，遍历模型中所有的参数（通常是权重和偏差），这些参数是需要通过训练学习的。此方法是许多 PyTorch 操作的基础，特别是在配置优化器和计算模型的总参数数量时。 #### 返回值</p></li><li><p>返回的生成器包含模型中定义为 <code>nn.Parameter</code> 的所有参数。<code>nn.Parameter</code> 是对张量的一个封装，标记这些张量是模型的一部分，需要进行梯度计算。</p></li></ul><h3 id="param.numel"><code>param.numel()</code></h3><h4 id="定义和用途-1">定义和用途</h4><ul><li><code>numel()</code> 是一个 PyTorch 张量（Tensor）的方法，它返回张量中元素的总数。这对于确定模型大小或进行性能分析是非常有用的。</li></ul><h4 id="返回值">返回值</h4><ul><li>返回一个整数，表示张量中的元素总数。</li></ul><h3 id="生成器">生成器</h3><p>生成器是使用简单的函数来创建的，函数中包含 <code>yield</code> 表达式。当函数执行到 <code>yield</code> 时，函数会暂停并返回一个值，下次迭代时，函数从停止的位置继续执行。</p><p>生成器自动实现了迭代器协议，所以不需要显式定义 <code>__iter__()</code> 和 <code>__next__()</code>。</p><p>使用生成器通常比手动实现迭代器更简洁、更易于编写和理解。</p><h4 id="生成器示例"><strong>生成器示例</strong>：</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">simple_generator</span>():     <br><span class="hljs-keyword">yield</span> <span class="hljs-number">1</span>     <br><span class="hljs-keyword">yield</span> <span class="hljs-number">2</span>     <br><span class="hljs-keyword">yield</span> <span class="hljs-number">3</span>  <br><br><span class="hljs-comment"># 使用生成器 </span><br>gen = simple_generator() <br><span class="hljs-keyword">for</span> value <span class="hljs-keyword">in</span> gen:     <br><span class="hljs-built_in">print</span>(value)  <span class="hljs-comment"># 输出 1, 2, 3</span><br></code></pre></td></tr></table></figure><h1 id="networks.py">networks.py</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> init<br><span class="hljs-keyword">from</span> torch.nn.utils.spectral_norm <span class="hljs-keyword">import</span> spectral_norm<br></code></pre></td></tr></table></figure><h2 id="common-classes">common classes</h2><h3 id="basenetwork">BaseNetwork</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">BaseNetwork</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(BaseNetwork, self).__init__()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">print_network</span>(<span class="hljs-params">self</span>):<br>        num_params = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.parameters():<br>            num_params += param.numel()<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Network [&#123;&#125;] was created. Total number of parameters: &#123;:.1f&#125; million. &quot;</span><br>              <span class="hljs-string">&quot;To see the architecture, do print(network).&quot;</span>.<span class="hljs-built_in">format</span>(self.__class__.__name__, num_params / <span class="hljs-number">1000000</span>))<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_weights</span>(<span class="hljs-params">self, init_type=<span class="hljs-string">&#x27;normal&#x27;</span>, gain=<span class="hljs-number">0.02</span></span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">init_func</span>(<span class="hljs-params">m</span>):<br>        classname = m.__class__.__name__<br>        <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;BatchNorm2d&#x27;</span> <span class="hljs-keyword">in</span> classname:<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(m, <span class="hljs-string">&#x27;weight&#x27;</span>) <span class="hljs-keyword">and</span> m.weight <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>                init.normal_(m.weight.data, <span class="hljs-number">1.0</span>, gain)<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(m, <span class="hljs-string">&#x27;bias&#x27;</span>) <span class="hljs-keyword">and</span> m.bias <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>                init.constant_(m.bias.data, <span class="hljs-number">0.0</span>)<br>        <span class="hljs-keyword">elif</span> (<span class="hljs-string">&#x27;Conv&#x27;</span> <span class="hljs-keyword">in</span> classname <span class="hljs-keyword">or</span> <span class="hljs-string">&#x27;Linear&#x27;</span> <span class="hljs-keyword">in</span> classname) <span class="hljs-keyword">and</span> <span class="hljs-built_in">hasattr</span>(m, <span class="hljs-string">&#x27;weight&#x27;</span>):<br>            <span class="hljs-keyword">if</span> init_type == <span class="hljs-string">&#x27;normal&#x27;</span>:<br>                init.normal_(m.weight.data, <span class="hljs-number">0.0</span>, gain)<br>            <span class="hljs-keyword">elif</span> init_type == <span class="hljs-string">&#x27;xavier&#x27;</span>:<br>                init.xavier_normal_(m.weight.data, gain=gain)<br>            <span class="hljs-keyword">elif</span> init_type == <span class="hljs-string">&#x27;xavier_uniform&#x27;</span>:<br>                init.xavier_uniform_(m.weight.data, gain=<span class="hljs-number">1.0</span>)<br>            <span class="hljs-keyword">elif</span> init_type == <span class="hljs-string">&#x27;kaiming&#x27;</span>:<br>                init.kaiming_normal_(m.weight.data, a=<span class="hljs-number">0</span>, mode=<span class="hljs-string">&#x27;fan_in&#x27;</span>)<br>            <span class="hljs-keyword">elif</span> init_type == <span class="hljs-string">&#x27;orthogonal&#x27;</span>:<br>                init.orthogonal_(m.weight.data, gain=gain)<br>            <span class="hljs-keyword">elif</span> init_type == <span class="hljs-string">&#x27;none&#x27;</span>:  <span class="hljs-comment"># uses pytorch&#x27;s default init method</span><br>                m.reset_parameters()<br>            <span class="hljs-keyword">else</span>:<br>                <span class="hljs-keyword">raise</span> NotImplementedError(<br>                    <span class="hljs-string">&quot;initialization method &#x27;&#123;&#125;&#x27; is not implemented&quot;</span>.<span class="hljs-built_in">format</span>(init_type))<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(m, <span class="hljs-string">&#x27;bias&#x27;</span>) <span class="hljs-keyword">and</span> m.bias <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>                init.constant_(m.bias.data, <span class="hljs-number">0.0</span>)<br><br>    self.apply(init_func)<br></code></pre></td></tr></table></figure><p>这里定义了几种初始化weight的方式，根据不同的layer选择。</p><p>这里的<code>init_weights</code>是一个高阶函数，会根据你需要的类型选择一个具体的初始化函数。</p><p>这里的apply表示将这个初始化函数应用于self的所有子模块，也就是构成模型的各个组件（可以是单独的卷积层、池化层、全连接层（线性层）、激活层，或者是更高级的组合，如块（block）或序列（sequence）等）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, *inputs</span>):<br>    <span class="hljs-keyword">pass</span> <br></code></pre></td></tr></table></figure><p>这里的forward需要根据具体的网络来实现，所以在BaseNetwork中先不写。</p><h2 id="seggenerator-related-classes">SegGenerator-related classes</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">SegGenerator</span>(<span class="hljs-title class_ inherited__">BaseNetwork</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, opt, input_nc, output_nc=<span class="hljs-number">13</span>, norm_layer=nn.InstanceNorm2d</span>):<br>        <span class="hljs-built_in">super</span>(SegGenerator, self).__init__()<br><br>    self.conv1 = nn.Sequential(nn.Conv2d(input_nc, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>), norm_layer(<span class="hljs-number">64</span>), nn.ReLU(),<br>                           nn.Conv2d(<span class="hljs-number">64</span>, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>), norm_layer(<span class="hljs-number">64</span>), nn.ReLU())<br><br><span class="hljs-comment"># ...</span><br><br> self.up6 = nn.Sequential(nn.Upsample(scale_factor=<span class="hljs-number">2</span>, mode=<span class="hljs-string">&#x27;nearest&#x27;</span>),<br>                                 nn.Conv2d(<span class="hljs-number">1024</span>, <span class="hljs-number">512</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>), norm_layer(<span class="hljs-number">512</span>), nn.ReLU())<br><br>        self.pool = nn.MaxPool2d(<span class="hljs-number">2</span>)<br>        self.drop = nn.Dropout(<span class="hljs-number">0.5</span>)<br>        self.sigmoid = nn.Sigmoid()<br><br>        self.print_network()<br>        self.init_weights(opt.init_type, opt.init_variance)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        conv1 = self.conv1(x)<br>        conv2 = self.conv2(self.pool(conv1))<br>        conv3 = self.conv3(self.pool(conv2))<br>        conv4 = self.drop(self.conv4(self.pool(conv3)))<br>        conv5 = self.drop(self.conv5(self.pool(conv4)))<br><br>        conv6 = self.conv6(torch.cat((conv4, self.up6(conv5)), <span class="hljs-number">1</span>))<br>        conv7 = self.conv7(torch.cat((conv3, self.up7(conv6)), <span class="hljs-number">1</span>))<br>        conv8 = self.conv8(torch.cat((conv2, self.up8(conv7)), <span class="hljs-number">1</span>))<br>        conv9 = self.conv9(torch.cat((conv1, self.up9(conv8)), <span class="hljs-number">1</span>))<br>        <span class="hljs-keyword">return</span> self.sigmoid(conv9)<br></code></pre></td></tr></table></figure><p><code>nn.Conv2d</code>函数原型: <code>torch.nn.Conv2d(_in_channels_, _out_channels_, _kernel_size_, _stride=1_, _padding=0_, _dilation=1_, _groups=1_, _bias=True_, _padding_mode='zeros'_, _device=None_, _dtype=None_)</code></p><ol type="1"><li><strong>in_channels</strong> (<code>input_nc</code>): 输入通道数。这指定了输入数据的深度（例如，对于RGB图像，深度为3）。</li><li><strong>out_channels</strong> (<code>64</code>): 输出通道数。这是卷积操作后生成的特征图（或称为过滤器或卷积核）的数量。</li><li></li><li><strong>kernel_size</strong> (<code>3</code>): 卷积核的大小。这里是<code>3</code>，表示使用3x3的卷积核。这个参数可以是一个单一的整数或一个元组，指定卷积核在每个空间维度的长度。</li><li><strong>stride</strong> (默认为<code>1</code>): 卷积步长。这决定了卷积核在输入数据上滑动时每次移动的像素数。步长为1意味着卷积核每次移动一个像素。</li><li><strong>padding</strong> (<code>1</code>): 边缘填充。这是在输入数据的边缘添加的零填充的层数，用于控制输出的空间维度。填充为1意味着在输入的每一边均添加一层零。</li><li><strong>dilation</strong> (默认为<code>1</code>): 卷积核元素之间的间隔。这个参数允许你使用间隔更大的卷积核来提取更广范围的特征。</li><li><strong>groups</strong> (默认为<code>1</code>): 分组卷积的组数。这是一个高级功能，允许网络设计者将输入通道和输出通道分组，独立进行卷积操作。</li><li><strong>bias</strong> (默认为<code>True</code>): 是否添加偏置项。大多数卷积层会有一个可学习的偏置参数，每个输出通道一个。</li></ol><p>使用两个<code>nn.Conv2d</code>是为了<strong>深度特征提取</strong>：通过在一个卷积层中使用两个连续的卷积操作（<code>nn.Conv2d</code>），网络能够在不改变特征图空间尺寸的情况下学习更深层次的特征。这是因为第一个卷积层提取基本特征后，第二个卷积层可以在这些特征的基础上进一步构建更复杂的特征表示。</p><p><code>norm_layer(64)</code>中的数字64表示规范化层应该处理的通道数。这个数字必须与它前面的卷积层输出的通道数相匹配。</p><p><code>mode='nearest'</code>：这个参数定义了上采样时使用的插值方法。<code>'nearest'</code>意味着使用最近邻插值，这是一种简单的插值方法，直接将源像素的值赋给最近的目标像素，不涉及任何计算。相比其他插值方法如双线性（bilinear）或双三次（bicubic）插值，最近邻插值计算速度更快，但可能在视觉质量上不如其他方法平滑。</p><p><code>self.pool = nn.MaxPool2d(2)</code>：这表示池化窗口的大小是2x2。</p><p><code>self.drop = nn.Dropout(0.5)</code> 这表示在训练过程中，每个神经元有50%的概率被丢弃（其输出被设置为0）。这种随机性使得网络的不同部分能够独立学习特征，从而提高了模型的泛化能力</p><h2 id="gmm-related-geometric-matching-module-classes">GMM-related (Geometric Matching Module) classes</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">FeatureExtraction</span>(<span class="hljs-title class_ inherited__">BaseNetwork</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_nc, ngf=<span class="hljs-number">64</span>, num_layers=<span class="hljs-number">4</span>, norm_layer=nn.BatchNorm2d</span>):<br>        <span class="hljs-built_in">super</span>(FeatureExtraction, self).__init__()<br><br>        nf = ngf <span class="hljs-comment"># number of generator features</span><br>        layers = [nn.Conv2d(input_nc, nf, kernel_size=<span class="hljs-number">4</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>), nn.ReLU(), norm_layer(nf)]<br><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, num_layers):<br>            nf_prev = nf<br>            nf = <span class="hljs-built_in">min</span>(nf * <span class="hljs-number">2</span>, <span class="hljs-number">512</span>)<br>            layers += [nn.Conv2d(nf_prev, nf, kernel_size=<span class="hljs-number">4</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>), nn.ReLU(), norm_layer(nf)]<br><br>        layers += [nn.Conv2d(nf, <span class="hljs-number">512</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>), nn.ReLU(), norm_layer(<span class="hljs-number">512</span>)]<br>        layers += [nn.Conv2d(<span class="hljs-number">512</span>, <span class="hljs-number">512</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>), nn.ReLU()]<br><br>        self.model = nn.Sequential(*layers)<br>        self.init_weights()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">return</span> self.model(x)<br><br></code></pre></td></tr></table></figure><p>这个类的目的是实现一个特征提取网络，通常用于深度学习和计算机视觉任务中从输入图像中自动学习有效特征。</p><p>在<code>nn.Sequential(*layers)</code>这段代码中，<code>*layers</code>的作用就是将<code>layers</code>列表中的每个元素作为单独的参数传递给<code>nn.Sequential</code>构造器。</p><h3 id="featurecorrelation-and-featureregression-class">FeatureCorrelation and FeatureRegression Class</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">FeatureCorrelation</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(FeatureCorrelation, self).__init__()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, featureA, featureB</span>):<br>        <span class="hljs-comment"># Reshape features for matrix multiplication.</span><br>        b, c, h, w = featureA.size()<br>        featureA = featureA.permute(<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>).reshape(b, w * h, c)<br>        featureB = featureB.reshape(b, c, h * w)<br><br>        <span class="hljs-comment"># Perform matrix multiplication.</span><br>        corr = torch.bmm(featureA, featureB).reshape(b, w * h, h, w)<br>        <span class="hljs-keyword">return</span> corr<br></code></pre></td></tr></table></figure><p><code>FeatureCorrelation</code>类用于计算两组特征映射（featureA和featureB）之间的相关性。这通常用于确定两个不同图像区域的相似度或特征对齐程度。</p><h5 id="permute函数">permute函数：</h5><p>在PyTorch中，<code>permute</code>函数用于重新排列多维数组（张量）的维度。</p><p><strong>示例：</strong></p><p>假设有一个四维张量<code>A</code>，其形状为<code>(b, c, h, w)</code>，其中<code>b</code>是批大小，<code>c</code>是通道数，<code>h</code>是高度，<code>w</code>是宽度。 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">A_permuted = A.permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure></p><p>这会改变<code>A</code>的形状为<code>(b, h, w, c)</code>。</p><h4 id="三维矩阵乘法batch-matrix-multiplication">三维矩阵乘法（batch matrix multiplication）</h4><p><code>torch.bmm</code>用于批次矩阵乘法。这个函数接受两个三维张量，通常形状为<code>(b, n, m)</code>和<code>(b, m, p)</code>，并对这两个张量的每一个相应的二维矩阵执行矩阵乘法，结果是一个形状为<code>(b, n, p)</code>的三维张量。</p><h5 id="为什么用三维矩阵乘法">为什么用三维矩阵乘法：</h5><p>在处理批次数据时，常常需要独立地对每个样本执行操作。使用<code>torch.bmm</code>允许在一个操作中同时处理整个批次，这比循环每个样本进行矩阵乘法要高效得多。</p><p>这里的乘法其实就是对 H x W 图像的每一个像素点上的feature vector与另一个图像上的每一个feature vector做dot product得到的矩阵.</p><p>reshape之后，图像的大小还是 <span class="math inline">\(H \times W\)</span>， 然后每个channel表示图像A在这个位置的feature vector, 与图像B每个位置feature vector的点积构成的 <span class="math inline">\(H \times W\)</span> 的map</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">FeatureRegression</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_nc=<span class="hljs-number">512</span>, output_size=<span class="hljs-number">6</span>, norm_layer=nn.BatchNorm2d</span>):<br>        <span class="hljs-built_in">super</span>(FeatureRegression, self).__init__()<br><br>        self.conv = nn.Sequential(<br>            nn.Conv2d(input_nc, <span class="hljs-number">512</span>, kernel_size=<span class="hljs-number">4</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>), norm_layer(<span class="hljs-number">512</span>), nn.ReLU(),<br>            nn.Conv2d(<span class="hljs-number">512</span>, <span class="hljs-number">256</span>, kernel_size=<span class="hljs-number">4</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>), norm_layer(<span class="hljs-number">256</span>), nn.ReLU(),<br>            nn.Conv2d(<span class="hljs-number">256</span>, <span class="hljs-number">128</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>), norm_layer(<span class="hljs-number">128</span>), nn.ReLU(),<br>            nn.Conv2d(<span class="hljs-number">128</span>, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>), norm_layer(<span class="hljs-number">64</span>), nn.ReLU()<br>        )<br>        self.linear = nn.Linear(<span class="hljs-number">64</span> * (input_nc // <span class="hljs-number">16</span>), output_size)<br>        self.tanh = nn.Tanh()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.conv(x)<br>        x = self.linear(x.reshape(x.size(<span class="hljs-number">0</span>), -<span class="hljs-number">1</span>))<br>        <span class="hljs-keyword">return</span> self.tanh(x)<br></code></pre></td></tr></table></figure><p><code>FeatureRegression</code>类通过多层卷积网络进一步处理特征（或已经某种方式提取的特征），然后使用一个线性层将结果映射到一个较小的输出空间（通常用于决策或预测）。例如，在视觉姿态估计中，可以用于从特征映射中预测对象的旋转和平移。</p><ol type="1"><li>第一层卷积层<code>nn.Conv2d(input_nc, 512, kernel_size=4, stride=2, padding=1)</code>: 这一层会将特征图的高度和宽度都减半（假设h和w足够大，可以被2整除）。新的尺寸大约是 <code>h/2</code> 和 <code>w/2</code>。</li><li>第二层卷积层<code>nn.Conv2d(512, 256, kernel_size=4, stride=2, padding=1)</code>: 再次将特征图尺寸减半，变为 <code>h/4</code> 和 <code>w/4</code>。</li><li>第三层卷积层<code>nn.Conv2d(256, 128, kernel_size=3, padding=1)</code>: 这一层因为步长默认为1，所以尺寸几乎保持不变，仍然是 <code>h/4</code> 和 <code>w/4</code>。</li><li>第四层卷积层<code>nn.Conv2d(128, 64, kernel_size=3, padding=1)</code>: 同样，尺寸几乎保持不变，为 <code>h/4</code> 和 <code>w/4</code>。</li></ol><p>所以最后一个卷积层输出的特征图的尺寸是 <code>(b, 64, h/4, w/4)</code>，所以线性层的大小应该为<code>64 * (h/4) * (w/4)</code>， 而这里是令<code>input_nc = h * w</code>，所以就有了他最后的表达式<code>self.linear = nn.Linear(64 * (input_nc // 16), output_size)</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">TpsGridGen</span>(nn.Module)<br></code></pre></td></tr></table></figure><p>然后是一个TPS变换的实现，这里我不太懂原理，就先不写了。</p><h3 id="gmm-class">GMM Class</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">GMM</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, opt, inputA_nc, inputB_nc</span>):<br>        <span class="hljs-built_in">super</span>(GMM, self).__init__()<br><br>        self.extractionA = FeatureExtraction(inputA_nc, ngf=<span class="hljs-number">64</span>, num_layers=<span class="hljs-number">4</span>)<br>        self.extractionB = FeatureExtraction(inputB_nc, ngf=<span class="hljs-number">64</span>, num_layers=<span class="hljs-number">4</span>)<br>        self.correlation = FeatureCorrelation()<br>        self.regression = FeatureRegression(input_nc=(opt.load_width // <span class="hljs-number">64</span>) * (opt.load_height // <span class="hljs-number">64</span>),<br>                                            output_size=<span class="hljs-number">2</span> * opt.grid_size**<span class="hljs-number">2</span>)<br>        self.gridGen = TpsGridGen(opt)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, inputA, inputB</span>):<br>        featureA = F.normalize(self.extractionA(inputA), dim=<span class="hljs-number">1</span>)<br>        featureB = F.normalize(self.extractionB(inputB), dim=<span class="hljs-number">1</span>)<br>        corr = self.correlation(featureA, featureB)<br>        theta = self.regression(corr)<br><br>        warped_grid = self.gridGen(theta)<br>        <span class="hljs-keyword">return</span> theta, warped_grid<br></code></pre></td></tr></table></figure><p><code>self.regression = FeatureRegression(input_nc=(opt.load_width // 64) * (opt.load_height // 64), output_size=2 * opt.grid_size**2)</code>实例化一个特征回归模块，用于从特征相关性数据中回归出变换参数。输入特征数量是图像维度减小64倍后的乘积，输出大小是控制点数量的两倍（通常用于薄板样条变换）。</p><p><code>self.gridGen = TpsGridGen(opt)</code> 初始化一个TPS网格生成模块，用于根据回归出的变换参数生成变形后的网格。</p><p><code>return theta, warped_grid</code>返回变换参数theta和变换后的网格。这使得可以进一步用于图像变形或分析变换效果。 ## ALIASGenerator-related classes</p><h3 id="masknorm">MaskNorm</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MaskNorm</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, norm_nc</span>):<br>        <span class="hljs-built_in">super</span>(MaskNorm, self).__init__()<br><br>        self.norm_layer = nn.InstanceNorm2d(norm_nc, affine=<span class="hljs-literal">False</span>)<br></code></pre></td></tr></table></figure><p>在深度学习中，特别是在使用归一化层（如批量归一化、实例归一化等）时，"affine" 参数指的是是否要在归一化之后应用可学习的缩放（scale）和平移（shift）参数。这两个参数允许模型在归一化过程中进一步调整数据，以适应特定的数据分布。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">normalize_region</span>(<span class="hljs-params">self, region, mask</span>):<br>    b, c, h, w = region.size()<br><br>    num_pixels = mask.<span class="hljs-built_in">sum</span>((<span class="hljs-number">2</span>, <span class="hljs-number">3</span>), keepdim=<span class="hljs-literal">True</span>)  <span class="hljs-comment"># size: (b, 1, 1, 1)</span><br>    num_pixels[num_pixels == <span class="hljs-number">0</span>] = <span class="hljs-number">1</span><br>    mu = region.<span class="hljs-built_in">sum</span>((<span class="hljs-number">2</span>, <span class="hljs-number">3</span>), keepdim=<span class="hljs-literal">True</span>) / num_pixels  <span class="hljs-comment"># size: (b, c, 1, 1)</span><br><br>    normalized_region = self.norm_layer(region + (<span class="hljs-number">1</span> - mask) * mu)<br>    <span class="hljs-keyword">return</span> normalized_region * torch.sqrt(num_pixels / (h * w))<br></code></pre></td></tr></table></figure><p>根据论文，这里的region是 <span class="math inline">\(\hat{S}_{c}\)</span> , 即segmentation map中的衣服部分, 然后mask即为<span class="math inline">\(W(M_{c}, \theta)\)</span>.</p><p><code>num_pixels = mask.sum((2, 3), keepdim=True)  # size: (b, 1, 1, 1)</code></p><ul><li><code>mask.sum((2, 3), keepdim=True)</code>：这里的<code>mask</code>是一个形状为<code>(b, c, h, w)</code>的张量，其中<code>b</code>是批次大小，<code>c</code>是通道数，<code>h</code>和<code>w</code>分别是高度和宽度。<code>mask.sum((2, 3), keepdim=True)</code>对每个通道的所有像素进行求和，这意味着对每个样本（batch）和每个通道，在高度<code>h</code>和宽度<code>w</code>的维度上进行求和。</li><li><code>keepdim=True</code>保持原有的四维张量形状，使输出的维度仍然是<code>(b, c, 1, 1)</code>而不是折叠成<code>(b, c)</code>。这对于后续的广播操作非常重要。</li></ul><p><code>num_pixels[num_pixels == 0] = 1</code></p><ul><li>这行代码处理了一个特殊情况：如果某个通道中没有任何被掩码覆盖的像素（即该通道的像素总和为0），则将这些通道的像素数设置为1。这样做的目的是避免后续计算中出现除以零的错误。</li><li>将像素数设为1是一个常用的技巧，以保证数值稳定性。这在统计和计算中很常见，例如，在计算平均值或归一化时，需要通过总数除以某个数，如果这个数为零则会导致计算错误或结果为无穷大。</li></ul><p><code>mu = region.sum((2, 3), keepdim=True) / num_pixels  # size: (b, c, 1, 1)</code>计算被掩码覆盖的区域的均值<code>mu</code>。</p><p><code>normalized_region = self.norm_layer(region + (1 - mask) * mu)</code></p><p>这一句使整张图像素的均值变成<span class="math inline">\(\mu\)</span> , 从而对整张图进行normalization相当于只在mask的区域上进行normalization。</p><p><code>return normalized_region * torch.sqrt(num_pixels / (h * w))</code></p><p>原文: ALIAS normalization standardizes the regions of <span class="math inline">\(M_{misalign}\)</span> and the other regions in <span class="math inline">\(h_{i}\)</span> separately, and then modulates the standardized activation using affine (仿射的）transformation parameters inferred from <span class="math inline">\(\hat{S}_{div}\)</span> .</p><p>返回归一化后的区域，乘以一个校正因子，这个因子基于掩码覆盖的像素数与总像素数的比例的平方根，以调整归一化的尺度。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x, mask</span>):<br>    mask = mask.detach()<br>    normalized_foreground = self.normalize_region(x * mask, mask)<br>    normalized_background = self.normalize_region(x * (<span class="hljs-number">1</span> - mask), <span class="hljs-number">1</span> - mask)<br>    <span class="hljs-keyword">return</span> normalized_foreground + normalized_background<br></code></pre></td></tr></table></figure><p>在 PyTorch 中，当你使用 <code>.detach()</code> 方法时，你实际上是在创建一个新的张量，该张量与原始张量共享数据，但不会在其上进行梯度计算。</p><h3 id="aliasnorm">ALIASNorm</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">ALIASNorm</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, norm_type, norm_nc, label_nc</span>):<br>        <span class="hljs-built_in">super</span>(ALIASNorm, self).__init__()<br><br>        self.noise_scale = nn.Parameter(torch.zeros(norm_nc))<br><br>        <span class="hljs-keyword">assert</span> norm_type.startswith(<span class="hljs-string">&#x27;alias&#x27;</span>)<br>        param_free_norm_type = norm_type[<span class="hljs-built_in">len</span>(<span class="hljs-string">&#x27;alias&#x27;</span>):]<br>        <span class="hljs-keyword">if</span> param_free_norm_type == <span class="hljs-string">&#x27;batch&#x27;</span>:<br>            self.param_free_norm = nn.BatchNorm2d(norm_nc, affine=<span class="hljs-literal">False</span>)<br>        <span class="hljs-keyword">elif</span> param_free_norm_type == <span class="hljs-string">&#x27;instance&#x27;</span>:<br>            self.param_free_norm = nn.InstanceNorm2d(norm_nc, affine=<span class="hljs-literal">False</span>)<br>        <span class="hljs-keyword">elif</span> param_free_norm_type == <span class="hljs-string">&#x27;mask&#x27;</span>:<br>            self.param_free_norm = MaskNorm(norm_nc)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">raise</span> ValueError(<br>                <span class="hljs-string">&quot;&#x27;&#123;&#125;&#x27; is not a recognized parameter-free normalization type in ALIASNorm&quot;</span>.<span class="hljs-built_in">format</span>(param_free_norm_type)<br>            )<br><br>        nhidden = <span class="hljs-number">128</span> <br>        ks = <span class="hljs-number">3</span> <span class="hljs-comment"># kernel size</span><br>        pw = ks // <span class="hljs-number">2</span> <span class="hljs-comment"># Padding Width</span><br>        self.conv_shared = nn.Sequential(nn.Conv2d(label_nc, nhidden, kernel_size=ks, padding=pw), nn.ReLU())<br>        self.conv_gamma = nn.Conv2d(nhidden, norm_nc, kernel_size=ks, padding=pw)<br>        self.conv_beta = nn.Conv2d(nhidden, norm_nc, kernel_size=ks, padding=pw)<br></code></pre></td></tr></table></figure><p><code>self.noise_scale = nn.Parameter(torch.zeros(norm_nc))</code>定义一个可学习的参数 <code>noise_scale</code>，其形状为 <code>(norm_nc,)</code>，用于调整噪声的强度。</p><p>这里传入的归一化类型以 "alias" 开始，并从 <code>norm_type</code> 字符串中提取真实的归一化类型。</p><p>定义三个卷积层：<code>conv_shared</code> 用于从输入的分割图中提取特征；<code>conv_gamma</code> 和 <code>conv_beta</code> 用这些特征生成 <code>gamma</code>（缩放）和 <code>beta</code>（偏移）参数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x, seg, misalign_mask=<span class="hljs-literal">None</span></span>):<br>    <span class="hljs-comment"># Part 1. Generate parameter-free normalized activations.</span><br>    b, c, h, w = x.size()<br>    noise = (torch.randn(b, w, h, <span class="hljs-number">1</span>).cuda() * self.noise_scale).transpose(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>)<br><br>    <span class="hljs-keyword">if</span> misalign_mask <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>        normalized = self.param_free_norm(x + noise)<br>    <span class="hljs-keyword">else</span>:<br>        normalized = self.param_free_norm(x + noise, misalign_mask)<br><br>    <span class="hljs-comment"># Part 2. Produce affine parameters conditioned on the segmentation map.</span><br>    actv = self.conv_shared(seg)<br>    gamma = self.conv_gamma(actv)<br>    beta = self.conv_beta(actv)<br><br>    <span class="hljs-comment"># Apply the affine parameters.</span><br>    output = normalized * (<span class="hljs-number">1</span> + gamma) + beta<br>    <span class="hljs-keyword">return</span> output<br></code></pre></td></tr></table></figure><p><code>torch.randn(b, w, h, 1)</code> 生成一个形状为 <code>(b, w, h, 1)</code> 的张量, 这个形状的选择初始是不匹配输入 <code>x</code> 的形状 <code>(b, c, h, w)</code>，特别是在通道维度上。</p><p><code>.transpose(1, 3)</code> 交换噪声张量的第二和第四维，从 <code>(b, w, h, 1)</code> 转换为 <code>(b, 1, h, w)</code>。这个转置操作是为了使噪声张量的形状与输入 <code>x</code> 的形状对齐，特别是匹配通道维度 <code>c</code>，使得噪声可以被正确地加到输入 <code>x</code> 上。</p><p><code>.cuda()</code> 确保生成的噪声张量在 GPU 上进行计算（假设使用 CUDA），以加速后续操作。 <code>* self.noise_scale</code> 将噪声张量的每个元素乘以一个可学习的参数</p><p>这种方式生成并处理噪声的目的是为了引入一种随机性，可能用于增强模型的泛化能力，防止过拟合，或在特定应用中模拟一些实际的变化情况（如在图像数据中模拟感应器噪声等）。通过可学习的噪声强度，模型可以自适应地调整噪声对学习过程的影响程度。</p><h3 id="aliasresblock">ALIASResBlock</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">ALIASResBlock</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, opt, input_nc, output_nc, use_mask_norm=<span class="hljs-literal">True</span></span>):<br>        <span class="hljs-built_in">super</span>(ALIASResBlock, self).__init__()<br><br>        self.learned_shortcut = (input_nc != output_nc)<br>        middle_nc = <span class="hljs-built_in">min</span>(input_nc, output_nc)<br><br>        self.conv_0 = nn.Conv2d(input_nc, middle_nc, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>)<br>        self.conv_1 = nn.Conv2d(middle_nc, output_nc, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">if</span> self.learned_shortcut:<br>            self.conv_s = nn.Conv2d(input_nc, output_nc, kernel_size=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">False</span>)<br><br>        subnorm_type = opt.norm_G<br>        <span class="hljs-keyword">if</span> subnorm_type.startswith(<span class="hljs-string">&#x27;spectral&#x27;</span>):<br>            subnorm_type = subnorm_type[<span class="hljs-built_in">len</span>(<span class="hljs-string">&#x27;spectral&#x27;</span>):]<br>            self.conv_0 = spectral_norm(self.conv_0)<br>            self.conv_1 = spectral_norm(self.conv_1)<br>            <span class="hljs-keyword">if</span> self.learned_shortcut:<br>                self.conv_s = spectral_norm(self.conv_s)<br><br>        semantic_nc = opt.semantic_nc<br>        <span class="hljs-keyword">if</span> use_mask_norm:<br>            subnorm_type = <span class="hljs-string">&#x27;aliasmask&#x27;</span><br>            semantic_nc = semantic_nc + <span class="hljs-number">1</span><br><br>        self.norm_0 = ALIASNorm(subnorm_type, input_nc, semantic_nc)<br>        self.norm_1 = ALIASNorm(subnorm_type, middle_nc, semantic_nc)<br>        <span class="hljs-keyword">if</span> self.learned_shortcut:<br>            self.norm_s = ALIASNorm(subnorm_type, input_nc, semantic_nc)<br><br>        self.relu = nn.LeakyReLU(<span class="hljs-number">0.2</span>)<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> use_mask_norm:<br>    subnorm_type = <span class="hljs-string">&#x27;aliasmask&#x27;</span><br>    semantic_nc = semantic_nc + <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p>这段代码是因为之后的Generator中，如果用mask_norm，那么传给ALIASResBlock的channel就会多一个。</p><p>通过<code>self.learned_shortcut = (input_nc != output_nc)</code>判断输入和输出通道数是否相同，以决定是否需要学习一个额外的快捷路径（shortcut 或 skip connection）。如果通道数不同，通过一个卷积层调整维度使之匹配。因为这里的相加并不是concatenate，就是直接把数值相加。</p><p><code>middle_nc = min(input_nc, output_nc)</code>选择输入和输出通道数中较小的一个作为中间层的通道数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> self.learned_shortcut:         <br>self.conv_s = nn.Conv2d(input_nc, output_nc, kernel_size=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">False</span>)`<br></code></pre></td></tr></table></figure><p>如果需要一个学习的快捷路径（当输入和输出通道数不同时），则定义一个额外的 <code>conv_s</code> 卷积层，使用 1x1 的卷积核调整通道数，没有偏置项（<code>bias=False</code>），以减少参数数量。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> subnorm_type.startswith(<span class="hljs-string">&#x27;spectral&#x27;</span>):<br></code></pre></td></tr></table></figure><p>这句话检验是否指定了频谱归一化（<code>spectral</code>）。如果是，将频谱归一化应用于相关的卷积层，以稳定训练过程并限制特定层的权重范围。</p><p><code>semantic_nc = opt.semantic_nc</code>获取语义通道数，用于后续的归一化层配置。</p><p>如果启用了掩码归一化，则设置归一化类型为 <code>aliasmask</code> 并调整语义通道数。</p><p>定义两个归一化层 <code>norm_0</code> 和 <code>norm_1</code>，分别应用于 <code>conv_0</code> 和 <code>conv_1</code> 的输出。</p><p>如果有学习的快捷路径，则为该路径也定义一个归一化层。</p><ul><li>定义激活函数为泄漏的ReLU，斜率为0.2，这有助于保持梯度流通，特别是在GAN中常见。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x, seg, misalign_mask=<span class="hljs-literal">None</span></span>):<br>    seg = F.interpolate(seg, size=x.size()[<span class="hljs-number">2</span>:], mode=<span class="hljs-string">&#x27;nearest&#x27;</span>)<br>    <span class="hljs-keyword">if</span> misalign_mask <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>        misalign_mask = F.interpolate(misalign_mask, size=x.size()[<span class="hljs-number">2</span>:], mode=<span class="hljs-string">&#x27;nearest&#x27;</span>)<br><br>    x_s = self.shortcut(x, seg, misalign_mask)<br><br>    dx = self.conv_0(self.relu(self.norm_0(x, seg, misalign_mask)))<br>    dx = self.conv_1(self.relu(self.norm_1(dx, seg, misalign_mask)))<br>    output = x_s + dx<br>    <span class="hljs-keyword">return</span> output<br></code></pre></td></tr></table></figure><p>先看forward，这里的逻辑与图片相匹配，一条线是 x 经过两次conv， 一条线是 x 经过一次conv，然后加在一起。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">ALIASNorm</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, norm_type, norm_nc, label_nc</span>)<br><span class="hljs-keyword">elif</span> param_free_norm_type == <span class="hljs-string">&#x27;mask&#x27;</span>:<br>            self.param_free_norm = MaskNorm(norm_nc)<br>            <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x, seg, misalign_mask=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-comment"># Part 1. Generate parameter-free normalized activations.</span><br>        b, c, h, w = x.size()<br>        noise = (torch.randn(b, w, h, <span class="hljs-number">1</span>).cuda() * self.noise_scale).transpose(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>)<br><br>        <span class="hljs-keyword">if</span> misalign_mask <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            normalized = self.param_free_norm(x + noise)<br>        <span class="hljs-keyword">else</span>:<br>            normalized = self.param_free_norm(x + noise, misalign_mask)<br><br>        <span class="hljs-comment"># Part 2. Produce affine parameters conditioned on the segmentation map.</span><br>        actv = self.conv_shared(seg)<br>        gamma = self.conv_gamma(actv)<br>        beta = self.conv_beta(actv)<br><br>        <span class="hljs-comment"># Apply the affine parameters.</span><br>        output = normalized * (<span class="hljs-number">1</span> + gamma) + beta<br>        <span class="hljs-keyword">return</span> output<br><br>self.norm_0 = ALIASNorm(subnorm_type, input_nc, semantic_nc)<br><br>dx = self.conv_0(self.relu(self.norm_0(x, seg, misalign_mask)))<br></code></pre></td></tr></table></figure><p>这里嵌套有点多了，所以解释一下: 这里 ALIASResBlock 的每一个 norm 层都是一个 ALIAS norm实例，然后这里的<code>norm_nc</code>是归一化层的通道数，即 <span class="math inline">\(C\)</span>. <code>label_nc</code>表示segmentation map的通道数，因为 shift parameters 还要通过 segmentation map 经过卷积产生。</p><p>这里返回的是一个ALIASNorm对象，为什么可以直接再当做函数，对<code>(x, seg, misalignment_mask)</code>调用呢: 在 PyTorch 中，实例化后的对象（如 <code>ALIASNorm</code>）可以直接调用，这通常是因为该类实现了一个 <code>__call__</code> 方法。在大多数 PyTorch 模块中，这是通过继承自 <code>nn.Module</code> 并实现 <code>forward</code> 方法实现的。当你像调用函数那样调用一个模块实例时，Python 实际上会执行该对象的 <code>__call__</code> 方法，而 <code>__call__</code> 方法会进一步调用 <code>forward</code> 方法。</p><p>所以这里<code>self.norm_0(x, seg, misalign_mask)</code>其实是<code>ALIASNorm.forward(x, seg, misalign_mask)</code>，然后在forward的过程中，seg被用来产生<span class="math inline">\(\gamma\)</span> 和 <span class="math inline">\(\beta\)</span>。<code>(x, seg)</code>又被<code>MaskNorm.forward(x, seg)</code>来进行ALIAS Normalization.（如果使用论文中所说的方法的话）</p><p><img src="https://s2.loli.net/2024/04/27/VRkCs2NeiMJ6hE9.png" /> ### ALIASGenerator 先看看这个类的compute_latent_vector_size函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">ALIASGenerator</span>(<span class="hljs-title class_ inherited__">BaseNetwork</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_latent_vector_size</span>(<span class="hljs-params">self, opt</span>):<br>        <span class="hljs-keyword">if</span> self.num_upsampling_layers == <span class="hljs-string">&#x27;normal&#x27;</span>:<br>            num_up_layers = <span class="hljs-number">5</span><br>        <span class="hljs-keyword">elif</span> self.num_upsampling_layers == <span class="hljs-string">&#x27;more&#x27;</span>:<br>            num_up_layers = <span class="hljs-number">6</span><br>        <span class="hljs-keyword">elif</span> self.num_upsampling_layers == <span class="hljs-string">&#x27;most&#x27;</span>:<br>            num_up_layers = <span class="hljs-number">7</span><br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&quot;opt.num_upsampling_layers &#x27;&#123;&#125;&#x27; is not recognized&quot;</span>.<span class="hljs-built_in">format</span>(self.num_upsampling_layers))<br><br>        sh = opt.load_height // <span class="hljs-number">2</span>**num_up_layers<br>        sw = opt.load_width // <span class="hljs-number">2</span>**num_up_layers<br>        <span class="hljs-keyword">return</span> sh, sw    <br></code></pre></td></tr></table></figure><p><code>compute_latent_vector_size</code> 方法的目的是为了确定生成模型在生成过程开始时应该使用的潜在向量的初始尺寸，从而确保整个上采样过程能够顺利进行，最终生成期望尺寸的图像。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, opt, input_nc</span>):<br>    <span class="hljs-built_in">super</span>(ALIASGenerator, self).__init__()<br>    self.num_upsampling_layers = opt.num_upsampling_layers<br><br>    self.sh, self.sw = self.compute_latent_vector_size(opt)<br><br>    nf = opt.ngf<br>    self.conv_0 = nn.Conv2d(input_nc, nf * <span class="hljs-number">16</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">8</span>):<br>        self.add_module(<span class="hljs-string">&#x27;conv_&#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(i), nn.Conv2d(input_nc, <span class="hljs-number">16</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>))<br><br>    self.head_0 = ALIASResBlock(opt, nf * <span class="hljs-number">16</span>, nf * <span class="hljs-number">16</span>)<br><br>    self.G_middle_0 = ALIASResBlock(opt, nf * <span class="hljs-number">16</span> + <span class="hljs-number">16</span>, nf * <span class="hljs-number">16</span>)<br>    self.G_middle_1 = ALIASResBlock(opt, nf * <span class="hljs-number">16</span> + <span class="hljs-number">16</span>, nf * <span class="hljs-number">16</span>)<br><br>    self.up_0 = ALIASResBlock(opt, nf * <span class="hljs-number">16</span> + <span class="hljs-number">16</span>, nf * <span class="hljs-number">8</span>)<br>    self.up_1 = ALIASResBlock(opt, nf * <span class="hljs-number">8</span> + <span class="hljs-number">16</span>, nf * <span class="hljs-number">4</span>)<br>    self.up_2 = ALIASResBlock(opt, nf * <span class="hljs-number">4</span> + <span class="hljs-number">16</span>, nf * <span class="hljs-number">2</span>, use_mask_norm=<span class="hljs-literal">False</span>)<br>    self.up_3 = ALIASResBlock(opt, nf * <span class="hljs-number">2</span> + <span class="hljs-number">16</span>, nf * <span class="hljs-number">1</span>, use_mask_norm=<span class="hljs-literal">False</span>)<br>    <span class="hljs-keyword">if</span> self.num_upsampling_layers == <span class="hljs-string">&#x27;most&#x27;</span>:<br>        self.up_4 = ALIASResBlock(opt, nf * <span class="hljs-number">1</span> + <span class="hljs-number">16</span>, nf // <span class="hljs-number">2</span>, use_mask_norm=<span class="hljs-literal">False</span>)<br>        nf = nf // <span class="hljs-number">2</span><br><br>    self.conv_img = nn.Conv2d(nf, <span class="hljs-number">3</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>)<br><br>    self.up = nn.Upsample(scale_factor=<span class="hljs-number">2</span>, mode=<span class="hljs-string">&#x27;nearest&#x27;</span>)<br>    self.relu = nn.LeakyReLU(<span class="hljs-number">0.2</span>)<br>    self.tanh = nn.Tanh()<br><br>    self.print_network()<br>    self.init_weights(opt.init_type, opt.init_variance)<br></code></pre></td></tr></table></figure><p>这里就是定义了一些基本模块，要结合下面的<code>forward</code>函数来看。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x, seg, seg_div, misalign_mask</span>):<br>    samples = [F.interpolate(x, size=(self.sh * <span class="hljs-number">2</span>**i, self.sw * <span class="hljs-number">2</span>**i), mode=<span class="hljs-string">&#x27;nearest&#x27;</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">8</span>)]<br>    features = [self._modules[<span class="hljs-string">&#x27;conv_&#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(i)](samples[i]) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">8</span>)]<br><br>    x = self.head_0(features[<span class="hljs-number">0</span>], seg_div, misalign_mask)<br><br>    x = self.up(x)<br>    x = self.G_middle_0(torch.cat((x, features[<span class="hljs-number">1</span>]), <span class="hljs-number">1</span>), seg_div, misalign_mask)<br>    <span class="hljs-keyword">if</span> self.num_upsampling_layers <span class="hljs-keyword">in</span> [<span class="hljs-string">&#x27;more&#x27;</span>, <span class="hljs-string">&#x27;most&#x27;</span>]:<br>        x = self.up(x)<br>    x = self.G_middle_1(torch.cat((x, features[<span class="hljs-number">2</span>]), <span class="hljs-number">1</span>), seg_div, misalign_mask)<br><br>    x = self.up(x)<br>    x = self.up_0(torch.cat((x, features[<span class="hljs-number">3</span>]), <span class="hljs-number">1</span>), seg_div, misalign_mask)<br>    x = self.up(x)<br>    x = self.up_1(torch.cat((x, features[<span class="hljs-number">4</span>]), <span class="hljs-number">1</span>), seg_div, misalign_mask)<br>    x = self.up(x)<br>    x = self.up_2(torch.cat((x, features[<span class="hljs-number">5</span>]), <span class="hljs-number">1</span>), seg)<br>    x = self.up(x)<br>    x = self.up_3(torch.cat((x, features[<span class="hljs-number">6</span>]), <span class="hljs-number">1</span>), seg)<br>    <span class="hljs-keyword">if</span> self.num_upsampling_layers == <span class="hljs-string">&#x27;most&#x27;</span>:<br>        x = self.up(x)<br>        x = self.up_4(torch.cat((x, features[<span class="hljs-number">7</span>]), <span class="hljs-number">1</span>), seg)<br><br>    x = self.conv_img(self.relu(x))<br>    <span class="hljs-keyword">return</span> self.tanh(x)<br></code></pre></td></tr></table></figure><p>这里第一步缩放 x，用原文的话说就是</p><blockquote><p>The input <span class="math inline">\((I_{a}, P, \mathcal{W}(c, \theta)\)</span> is resized and injected into each layer of the generator. In this manner, the network performs the multi-scale refinement at a feature level that preserves the clothing details than a single refinement at the pixel level.</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">features = [self._modules[<span class="hljs-string">&#x27;conv_&#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(i)](samples[i]) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">8</span>)]<br></code></pre></td></tr></table></figure><p>然后进一步是从图片中提取feature</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">x = self.up_0(torch.cat((x, features[<span class="hljs-number">3</span>]), <span class="hljs-number">1</span>), seg_div, misalign_mask)<br></code></pre></td></tr></table></figure><p>这里引用原文就是</p><blockquote><p>Before each ResBlk, the resized inputs <span class="math inline">\((I_{a}, P, \mathcal{W}(c, \theta)\)</span> are concatenated to the activation of the previous layer after passing through a convolutional layer, and each ResBlk utilizes the concatenated inputs to refine the activations. # test.py</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> argparse<br><span class="hljs-keyword">import</span> os<br><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">import</span> torchgeometry <span class="hljs-keyword">as</span> tgm<br><br><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> VITONDataset, VITONDataLoader<br><span class="hljs-keyword">from</span> networks <span class="hljs-keyword">import</span> SegGenerator, GMM, ALIASGenerator<br><span class="hljs-keyword">from</span> utils <span class="hljs-keyword">import</span> gen_noise, load_checkpoint, save_images<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_opt</span>():<br>    parser = argparse.ArgumentParser()<br>    parser.add_argument(<span class="hljs-string">&#x27;--name&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, required=<span class="hljs-literal">True</span>)<br><br>    parser.add_argument(<span class="hljs-string">&#x27;-b&#x27;</span>, <span class="hljs-string">&#x27;--batch_size&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">1</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;-j&#x27;</span>, <span class="hljs-string">&#x27;--workers&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">1</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;--load_height&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">1024</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;--load_width&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">768</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;--shuffle&#x27;</span>, action=<span class="hljs-string">&#x27;store_true&#x27;</span>)<br><br><span class="hljs-comment"># 中间省略了很多的add_argument</span><br><br>    opt = parser.parse_args()<br>    <span class="hljs-keyword">return</span> opt<br></code></pre></td></tr></table></figure><p>这个函数使用 Python 的 <code>argparse</code> 库来解析命令行参数。<code>argparse</code> 是一个非常有用的库，用于编写用户友好的命令行接口，它能够处理用户输入的参数，并自动生成帮助和使用信息。</p><p><code>parser = argparse.ArgumentParser()</code>: 创建一个新的 <code>ArgumentParser</code> 对象，这个对象会存储所有需要从命令行解析的信息。</p><p><code>parser.add_argument('--name', type=str, required=True)</code>: 这行代码添加了一个必需的参数 <code>--name</code>。用户在命令行中必须提供这个参数，否则程序会报错。参数类型被设定为字符串 (<code>str</code>)。</p><p><code>parser.add_argument('-b', '--batch_size', type=int, default=1)</code>: 添加一个可选参数 <code>--batch_size</code>，它有一个短选项 <code>-b</code>。这个参数的类型是整数 (<code>int</code>)，如果用户没有在命令行中指定这个参数，它的默认值将为 <code>1</code>。</p><p>在 Python 的 <code>argparse</code> 模块中，<code>action</code> 选项是 <code>add_argument()</code> 函数的一个参数，用来定义当参数在命令行中出现时应该执行什么操作。<code>action</code> 选项决定了如何处理命令行参数的值。下面是一些常用的 <code>action</code> 选项：</p><p><code>store</code> 这是默认的动作。当使用此动作时，会存储命令行中参数的值。如果没有指定动作，那么使用 <code>store</code> 是默认行为。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">parser.add_argument(<span class="hljs-string">&#x27;--name&#x27;</span>, action=<span class="hljs-string">&#x27;store&#x27;</span>)<br></code></pre></td></tr></table></figure><p>这将把 <code>--name</code> 后面指定的值存储在 <code>name</code> 属性中。</p><h3 id="store_true-和-store_false"><code>store_true</code> 和 <code>store_false</code></h3><p>这两种动作用于创建布尔开关。<code>store_true</code> 会在指定了参数的情况下设置属性为 <code>True</code>，未指定时为 <code>False</code>；<code>store_false</code> 则相反，当参数被指定时设置属性为 <code>False</code>，未指定时为 <code>True</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">parser.add_argument(<span class="hljs-string">&#x27;--shuffle&#x27;</span>, action=<span class="hljs-string">&#x27;store_true&#x27;</span>) <br>parser.add_argument(<span class="hljs-string">&#x27;--no-shuffle&#x27;</span>, action=<span class="hljs-string">&#x27;store_false&#x27;</span>)<br></code></pre></td></tr></table></figure><p>这样，如果命令行中包含了 <code>--shuffle</code>，则 <code>args.shuffle</code> 会被设置为 <code>True</code>。如果包含了 <code>--no-shuffle</code>，则相应的属性会被设置为 <code>False</code>。</p><p>默认情况下，参数的属性名（即在 <code>args</code> 对象中访问此参数的名称）将基于长选项名称。长选项名称通常是在双破折号 <code>--</code> 之后的字符串。对于 <code>--no-shuffle</code> 这个选项，属性名会是 <code>no_shuffle</code>。</p><h2 id="test">test</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">test</span>(<span class="hljs-params">opt, seg, gmm, alias</span>):<br>    up = nn.Upsample(size=(opt.load_height, opt.load_width), mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>)<br>    gauss = tgm.image.GaussianBlur((<span class="hljs-number">15</span>, <span class="hljs-number">15</span>), (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>))<br>    gauss.cuda()<br><br>    test_dataset = VITONDataset(opt)<br>    test_loader = VITONDataLoader(opt, test_dataset)<br></code></pre></td></tr></table></figure><p>如果给定的<code>size</code>小于图像本身的尺寸，通常<code>Upsample</code>仍会执行，但实际操作将是下采样（减小图像尺寸），这依赖于<code>mode</code>参数。</p><p><strong>Gaussian Blur（高斯模糊）</strong>:</p><ul><li><code>tgm.image.GaussianBlur</code>是应用高斯模糊的操作。高斯模糊是一种图像滤波技术，用于减少图像噪声和细节，通常用于图像预处理以改善后续处理步骤的性能或质量。</li><li>这里使用了一个15x15的核和标准差为3的高斯函数。这种较大的核会使图像变得更加模糊。</li><li>将高斯模糊应用于图像可以帮助平滑过渡区域，减少模型训练或推断中可能遇到的边缘效应，或是用来预处理以降低过拟合的风险。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> i, inputs <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(test_loader.data_loader):<br>            img_names = inputs[<span class="hljs-string">&#x27;img_name&#x27;</span>]<br>            c_names = inputs[<span class="hljs-string">&#x27;c_name&#x27;</span>][<span class="hljs-string">&#x27;unpaired&#x27;</span>]<br><br>            img_agnostic = inputs[<span class="hljs-string">&#x27;img_agnostic&#x27;</span>].cuda()<br>            parse_agnostic = inputs[<span class="hljs-string">&#x27;parse_agnostic&#x27;</span>].cuda()<br>            pose = inputs[<span class="hljs-string">&#x27;pose&#x27;</span>].cuda()<br>            c = inputs[<span class="hljs-string">&#x27;cloth&#x27;</span>][<span class="hljs-string">&#x27;unpaired&#x27;</span>].cuda()<br>            cm = inputs[<span class="hljs-string">&#x27;cloth_mask&#x27;</span>][<span class="hljs-string">&#x27;unpaired&#x27;</span>].cuda()<br><br>            <span class="hljs-comment"># Part 1. Segmentation generation</span><br>            parse_agnostic_down = F.interpolate(parse_agnostic, size=(<span class="hljs-number">256</span>, <span class="hljs-number">192</span>), mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>)<br>            pose_down = F.interpolate(pose, size=(<span class="hljs-number">256</span>, <span class="hljs-number">192</span>), mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>)<br>            c_masked_down = F.interpolate(c * cm, size=(<span class="hljs-number">256</span>, <span class="hljs-number">192</span>), mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>)<br>            cm_down = F.interpolate(cm, size=(<span class="hljs-number">256</span>, <span class="hljs-number">192</span>), mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>)<br>            seg_input = torch.cat((cm_down, c_masked_down, parse_agnostic_down, pose_down, gen_noise(cm_down.size()).cuda()), dim=<span class="hljs-number">1</span>)<br><br>            parse_pred_down = seg(seg_input)<br>            parse_pred = gauss(up(parse_pred_down))<br>            parse_pred = parse_pred.argmax(dim=<span class="hljs-number">1</span>)[:, <span class="hljs-literal">None</span>]<br><br>            parse_old = torch.zeros(parse_pred.size(<span class="hljs-number">0</span>), <span class="hljs-number">13</span>, opt.load_height, opt.load_width, dtype=torch.<span class="hljs-built_in">float</span>).cuda()<br>            parse_old.scatter_(<span class="hljs-number">1</span>, parse_pred, <span class="hljs-number">1.0</span>)<br></code></pre></td></tr></table></figure><p><code>parse_pred_down</code>表示生成出来的穿上相应衣服 <span class="math inline">\(c\)</span> 后的segmentation map。然后再对其进行上采样和高斯模糊处理。</p><p><code>parse_pred = parse_pred.argmax(dim=1)[:, None]</code></p><p><code>parse_pred.argmax(dim=1)</code>在每个像素位置找出具有最高预测概率的类别索引。这里<code>dim=1</code>表示沿着类别的维度进行操作，因为模型输出的每个像素位置都有一个概率分布来表示属于各个类别的概率。 <code>[:, None]</code>：这个操作会在结果张量中增加一个新的维度。这是在原有的二维结果（形状为 <code>[batch_size, height, width]</code>）上，沿着第二维（索引为 1 的维度）添加一个新的维度，从而将其变为 <code>[batch_size, 1, height, width]</code>。</p><p><code>None</code> is an alias for NP.newaxis. It creates an axis with length 1.</p><p><code>A = A[:, :, None, None]</code></p><p>这里的每个组件的作用是：</p><ul><li>第一个 <code>:</code> 表示选择 <code>batch_size</code> 维度上的所有数据。</li><li>第二个 <code>:</code> 表示选择 <code>height</code> 维度上的所有数据，并在其后使用 <code>None</code> 来插入一个新的维度。</li><li>最后一个 <code>None</code> 是在 <code>width</code> 维度之后插入另一个新的维度。</li></ul><p>执行上述操作后，原始张量 <code>A</code> 的形状 <code>[batch_size, height, width]</code> 将变为 <code>[batch_size, height, 1, width, 1]</code>。这样，每个原先的 <code>height</code> 和 <code>width</code> 维度后面都会跟随一个大小为 1 的新维度。</p><p><code>parse_old.scatter_(1, parse_pred, 1.0)</code>是一个就地操作（由下划线<code>_</code>表示）。这个操作将<code>parse_pred</code>中的类别索引用于填充<code>parse_old</code>。具体来说，它将<code>parse_old</code>中对应于<code>parse_pred</code>中每个位置的类别索引的位置设为1.0。这样，<code>parse_old</code>的每个通道就成为了一个二进制掩码，表示预测的类别。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">labels = &#123;<br>    <span class="hljs-number">0</span>:  [<span class="hljs-string">&#x27;background&#x27;</span>,  [<span class="hljs-number">0</span>]],<br>    <span class="hljs-number">1</span>:  [<span class="hljs-string">&#x27;paste&#x27;</span>,       [<span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">9</span>, <span class="hljs-number">10</span>, <span class="hljs-number">11</span>]],<br>    <span class="hljs-number">2</span>:  [<span class="hljs-string">&#x27;upper&#x27;</span>,       [<span class="hljs-number">3</span>]],<br>    <span class="hljs-number">3</span>:  [<span class="hljs-string">&#x27;hair&#x27;</span>,        [<span class="hljs-number">1</span>]],<br>    <span class="hljs-number">4</span>:  [<span class="hljs-string">&#x27;left_arm&#x27;</span>,    [<span class="hljs-number">5</span>]],<br>    <span class="hljs-number">5</span>:  [<span class="hljs-string">&#x27;right_arm&#x27;</span>,   [<span class="hljs-number">6</span>]],<br>    <span class="hljs-number">6</span>:  [<span class="hljs-string">&#x27;noise&#x27;</span>,       [<span class="hljs-number">12</span>]]<br>&#125;<br>parse = torch.zeros(parse_pred.size(<span class="hljs-number">0</span>), <span class="hljs-number">7</span>, opt.load_height, opt.load_width, dtype=torch.<span class="hljs-built_in">float</span>).cuda()<br><span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(labels)):<br>    <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> labels[j][<span class="hljs-number">1</span>]:<br>        parse[:, j] += parse_old[:, label]<br></code></pre></td></tr></table></figure><p>这段代码又把其中一些标签和为一类。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Part 2. Clothes Deformation</span><br>agnostic_gmm = F.interpolate(img_agnostic, size=(<span class="hljs-number">256</span>, <span class="hljs-number">192</span>), mode=<span class="hljs-string">&#x27;nearest&#x27;</span>)<br>parse_cloth_gmm = F.interpolate(parse[:, <span class="hljs-number">2</span>:<span class="hljs-number">3</span>], size=(<span class="hljs-number">256</span>, <span class="hljs-number">192</span>), mode=<span class="hljs-string">&#x27;nearest&#x27;</span>)<br>pose_gmm = F.interpolate(pose, size=(<span class="hljs-number">256</span>, <span class="hljs-number">192</span>), mode=<span class="hljs-string">&#x27;nearest&#x27;</span>)<br>c_gmm = F.interpolate(c, size=(<span class="hljs-number">256</span>, <span class="hljs-number">192</span>), mode=<span class="hljs-string">&#x27;nearest&#x27;</span>)<br>gmm_input = torch.cat((parse_cloth_gmm, pose_gmm, agnostic_gmm), dim=<span class="hljs-number">1</span>)<br><br>_, warped_grid = gmm(gmm_input, c_gmm)<br>warped_c = F.grid_sample(c, warped_grid, padding_mode=<span class="hljs-string">&#x27;border&#x27;</span>)<br>warped_cm = F.grid_sample(cm, warped_grid, padding_mode=<span class="hljs-string">&#x27;border&#x27;</span>)<br><br></code></pre></td></tr></table></figure><p>With the correlation matrix as an input, the regression network predicts the TPS transformation parameters <span class="math inline">\(\theta \in R^{2 \times 5 \times 5}\)</span>, and then c is warped by θ.</p><p>在 PyTorch 中，<code>F.grid_sample</code> 函数是用于进行高级图像采样操作的一个功能强大的工具。这个函数允许你根据指定的变换网格（通常是一个流场或变形场）来对输入图像进行重新采样。这在许多计算机视觉任务中非常有用，特别是在涉及到图像对齐、形变或任意几何变换的情况下。</p><p><code>F.grid_sample</code> 接受一个输入图像和一个变换网格。它使用变换网格中的坐标来从输入图像中抓取像素值，并生成输出图像。如果网格指定的位置在原始输入图像的边界之外，它将根据<code>padding_mode</code>来处理。</p><p><code>padding_mode='border'</code> 表示如果网格引导采样点超出原始图像的边界，那么采样操作将使用边界上的像素值。这有助于防止在图像边缘产生伪影。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Part 3. Try-on synthesis</span><br>misalign_mask = parse[:, <span class="hljs-number">2</span>:<span class="hljs-number">3</span>] - warped_cm<br>misalign_mask[misalign_mask &lt; <span class="hljs-number">0.0</span>] = <span class="hljs-number">0.0</span><br>parse_div = torch.cat((parse, misalign_mask), dim=<span class="hljs-number">1</span>)<br>parse_div[:, <span class="hljs-number">2</span>:<span class="hljs-number">3</span>] -= misalign_mask<br><br>output = alias(torch.cat((img_agnostic, pose, warped_c), dim=<span class="hljs-number">1</span>), parse, parse_div, misalign_mask)<br><br></code></pre></td></tr></table></figure><p><code>misalign_mask = parse[:, 2:3] - warped_cm</code></p><p><code>parse[:, 2:3]</code> 提取了解析图中代表上衣的部分（假设索引 2 对应于上衣）。这是一个包含衣物应在模型上出现位置的掩模。</p><p>然后就是进行最后的生成： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">unpaired_names = []<br>         <span class="hljs-keyword">for</span> img_name, c_name <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(img_names, c_names):<br>             unpaired_names.append(<span class="hljs-string">&#x27;&#123;&#125;_&#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(img_name.split(<span class="hljs-string">&#x27;_&#x27;</span>)[<span class="hljs-number">0</span>], c_name))<br><br>         save_images(output, unpaired_names, os.path.join(opt.save_dir, opt.name))<br><br>         <span class="hljs-keyword">if</span> (i + <span class="hljs-number">1</span>) % opt.display_freq == <span class="hljs-number">0</span>:<br>             <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;step: &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(i + <span class="hljs-number">1</span>))<br><br></code></pre></td></tr></table></figure></p><p>这里第一个循环通过结合 <code>img_names</code> 和 <code>c_names</code> 中的元素来构建输出图片的新文件名。具体来说，它取每个 <code>img_name</code> 的第一部分（用下划线分割）并附加相应的 <code>c_name</code>。这种命名方案有助于组织和识别基于输入和使用的特定服装项生成的图片。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> (i + <span class="hljs-number">1</span>) % opt.display_freq == <span class="hljs-number">0</span>:     <br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;step: &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(i + <span class="hljs-number">1</span>))<br></code></pre></td></tr></table></figure><p>这行代码在每处理 <code>opt.display_freq</code> 设定次数的图片后记录当前步骤。通过打印当前的步骤编号，可以跟踪处理进度，这在处理大量数据时尤其有用，以监控程序运行状态。</p>]]></content>
    
    
    <categories>
      
      <category>CV</category>
      
    </categories>
    
    
    <tags>
      
      <tag>VITON</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
